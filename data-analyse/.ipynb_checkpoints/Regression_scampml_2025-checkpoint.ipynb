{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numpy import random\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, r2_score\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt.plots import plot_objective, plot_histogram\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Util.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  read_dataset(feat_select, # _all, _rf ...\n",
    "                  feat_type, #OG,HG,\n",
    "                  scale, #standard, minMax\n",
    "                  feature_path,\n",
    "                  ranks_path):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    data = read_output(sufix='_1min_8alg', dir_path = ranks_path)\n",
    "    data = data.drop(columns=[\"Problem\"])\n",
    "    \n",
    "    df_input = pd.read_csv(f'{feature_path}/{feat_type}/features_{feat_select}_{scale}.csv')\n",
    "    df_input = df_input.drop(columns=[\"problem\"])\n",
    "    return df_input, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input, data = read_dataset(feat_select='all',feat_type='HG-F', scale=\"standard\",\n",
    "                             feature_path='../datasets/results/features/ianuarie2025-v2/',\n",
    "                             ranks_path='../datasets/results/ranks/runTime_1min_sa_ts_filtered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fold(index, number_folds, test_fold_index):\n",
    "    data_size = len(index)\n",
    "    fold_size = data_size//number_folds\n",
    "    start_index_test = test_fold_index*fold_size\n",
    "    if test_fold_index != number_folds-1:\n",
    "        end_index_test = test_fold_index*fold_size + fold_size\n",
    "    else:\n",
    "        end_index_test = data_size\n",
    "    test_index = index[start_index_test:end_index_test]\n",
    "    if start_index_test == 0:\n",
    "        train_index = index[end_index_test:]\n",
    "    elif end_index_test == data_size:\n",
    "        train_index = index[:start_index_test]\n",
    "    else:\n",
    "        train_index = np.concatenate((index[:start_index_test], index[end_index_test:]))\n",
    "    return train_index, test_index    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(number_folds, feat_select='_all', feat_type='op', reg_type='rfr'):    \n",
    "    df_all_input, df_all_output = read_dataset(feat_select=feat_select, feat_type=feat_type)\n",
    "    index = np.random.permutation(len(df_all_input))\n",
    "    scores_train = []\n",
    "    scores_test = []\n",
    "    for f in range(number_folds):\n",
    "        train_index, test_index = get_fold(index, number_folds, f)\n",
    "        train_scaler = MinMaxScaler()\n",
    "        x_train_scaled = train_scaler.fit_transform(df_all_input.iloc[train_index])\n",
    "        y_train = df_all_output.iloc[train_index]\n",
    "        #y_train = train_scaler.fit_transform(df_all_output.iloc[train_index])\n",
    "        # unscaled output\n",
    "        test_scaler = MinMaxScaler()\n",
    "        x_test_scaled = test_scaler.fit_transform(df_all_input.iloc[test_index])\n",
    "        y_test = df_all_output.iloc[test_index]\n",
    "        #print(\"x_train_scaled=\",x_train_scaled)\n",
    "        #print(\"x_test_scaled=\",x_test_scaled)\n",
    "        if reg_type == 'gbr':\n",
    "            reg = MultiOutputRegressor(GradientBoostingRegressor(n_estimators=50,random_state=0)).fit(x_train_scaled, y_train)\n",
    "        if reg_type == 'hgbr':\n",
    "            reg = MultiOutputRegressor(HistGradientBoostingRegressor(max_iter=50,random_state=0)).fit(x_train_scaled, y_train)    \n",
    "        if reg_type == 'rfr':\n",
    "            reg = MultiOutputRegressor(RandomForestRegressor(n_estimators=20, random_state=0)).fit(x_train_scaled, y_train)\n",
    "        if reg_type == 'svr':    \n",
    "            reg = MultiOutputRegressor(SVR(C=5.0, epsilon=0.3, kernel='rbf')).fit(x_train_scaled, y_train) #  epsilon=0.3,\n",
    "        if reg_type == 'mlp':    \n",
    "            reg = MultiOutputRegressor(MLPRegressor(hidden_layer_sizes=(20,),max_iter=5000)).fit(x_train_scaled, y_train)\n",
    "        score = reg.score(x_test_scaled, y_test)\n",
    "        scores_test.append(score)\n",
    "        score = reg.score(x_train_scaled, y_train)\n",
    "        scores_train.append(score)\n",
    "    return reg, scores_train, scores_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression model tuning using Grid Search and Randomized Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression models tuning using Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scikit-optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt.plots import plot_objective, plot_histogram\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning based on Bayesian Optimization\n",
    "import sys\n",
    "import csv\n",
    "def regression_tuning(out_dir_path, ft_type, ft_select, regression_types, feature_path, ranks_path):\n",
    "    print(feature_path)\n",
    "    print(ranks_path)\n",
    "    #varianta veche de generarare, data_size  veenea ca parametru\n",
    "    #index = np.random.permutation(data_size)\n",
    "    # idx_X_train, idx_X_test, idx_y_train, idx_y_test = train_test_split(index, index, train_size = 0.8, test_size = 0.2, random_state=0)\n",
    "    # print(data_size)\n",
    "    # print('idx_X_train=',idx_X_train)\n",
    "    # print('idx_X_test=',idx_X_test)\n",
    "    Path(dir_path).mkdir(exist_ok=True)\n",
    "\n",
    "    #generate in  fisierul DatasetsRanking\n",
    "    idx_X_test = [99, 161, 95, 175, 45, 166, 224, 50, 249, 102, 107, 284, 177, 121, 136, \n",
    "                  241, 34, 260, 119, 199, 40, 24, 264, 169, 280, 51, 152, 110, 290, 4, \n",
    "                  6, 55, 77, 167, 217, 124, 278, 56, 144, 91, 170, 74, 159, 232, 27, 41, \n",
    "                  245, 164, 214, 230, 246, 263, 101, 18, 292, 92, 147, 115, 277, 15, 254, 62]\n",
    "\n",
    "    idx_X_train = [30, 194, 248, 17, 81, 16, 58, 188, 160, 287, 129, 240, 213, 130, 256, \n",
    "                   79, 282, 84, 145, 36, 257, 220, 28, 134, 265, 286, 142, 195, 201, 66, \n",
    "                   273, 157, 128, 279, 150, 125, 109, 96, 26, 29, 227, 259, 276, 61, 73, \n",
    "                   209, 178, 215, 11, 80, 218, 163, 98, 253, 20, 225, 168, 205, 104, 200, \n",
    "                   197, 94, 106, 105, 118, 22, 187, 112, 202, 60, 237, 153, 75, 7, 294, 219, \n",
    "                   285, 151, 204, 222, 196, 156, 90, 193, 10, 72, 155, 1, 247, 57, 13, 131, \n",
    "                   113, 35, 5, 266, 139, 182, 38, 47, 12, 141, 207, 233, 123, 43, 88, 180, \n",
    "                   165, 46, 267, 203, 179, 242, 184, 3, 198, 25, 39, 281, 87, 234, 138, 132, \n",
    "                   126, 149, 68, 173, 216, 33, 171, 100, 86, 44, 255, 231, 23, 174, 71, 235, \n",
    "                   172, 283, 250, 89, 192, 143, 8, 14, 65, 78, 93, 146, 275, 272, 82, 293, \n",
    "                   262, 261, 133, 228, 212, 236, 70, 148, 116, 189, 226, 190, 210, 49, 52, \n",
    "                   67, 186, 103, 181, 221, 85, 42, 239, 140, 21, 223, 76, 63, 206, 291, 274, \n",
    "                   48, 0, 32, 238, 295, 185, 37, 288, 117, 162, 83, 137, 252, 64, 54, 251, \n",
    "                   53, 208, 108, 191, 229, 183, 154, 59, 270, 271, 244, 122, 31, 19, 69, 114,\n",
    "                   135, 176, 111, 258, 158, 9, 120, 268, 2, 289, 97, 243, 211, 127, 269] \n",
    "      \n",
    "    idx_y_train = idx_X_train\n",
    "    idx_y_test = idx_X_test\n",
    "    if not sys.warnoptions:\n",
    "        import os, warnings\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        os.environ[\"PYTHONWARNINGS\"] = \"ignore\" # Also affect subprocesses\n",
    "    for regression_type in regression_types:\n",
    "        print(\"regression_type\", regression_type)\n",
    "        test_results_score={}\n",
    "        test_results_metaheuristic={}\n",
    "        test_results={}\n",
    "        for fs in ft_select:\n",
    "            for ft in ft_type:  \n",
    "                df_all_input, df_all_output = read_dataset(feat_select=fs, feat_type=ft, scale=\"standard\",\n",
    "                                                           feature_path=feature_path, ranks_path=ranks_path)\n",
    "                print(df_all_input.shape, df_all_output.shape)\n",
    "                #df_all_input=df_all_input.filter(regex='^(?!.*gini)(?!.*q25)(?!.*q50)(?!.*q75)(?!.*min)(?!.*max)')\n",
    "                #df_all_input = df_all_input.filter(regex='^(?!.*gini)(?!.*q25)(?!.*q50)(?!.*q75)(?!.*min)(?!.*max)(?!machine_mean.*)(?!operation_mean.*)(?!machine_fraction_stdev.*)(?!levels_mean)') #doar mean si std din statistici\n",
    "                #df_all_input = df_all_input.filter(regex='(?!machine_mean.*)(?!operation_mean.*)(?!machine_fraction_stdev.*)(?!levels_mean.*)') #doar mean si std din statistici\n",
    "\n",
    "\n",
    "                from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "                # vif_data = pd.DataFrame()\n",
    "                # vif_data[\"feature\"] = df_all_input.columns\n",
    "                # vif_data[\"VIF\"] = [variance_inflation_factor(df_all_input.values, i) for i in range(df_all_input.shape[1])]\n",
    "                # good = vif_data.loc[vif_data['VIF'] < 5]\n",
    "\n",
    "                # print(good[\"feature\"].to_list())\n",
    "                #df_all_input = df_all_input.filter(good[\"feature\"])\n",
    "                print(df_all_input.shape, df_all_output.shape)\n",
    "        \n",
    "                #index = np.random.permutation(len(df_all_input))\n",
    "                X_train = df_all_input.iloc[idx_X_train]\n",
    "                X_test = df_all_input.iloc[idx_X_test]\n",
    "                y_train = df_all_output.iloc[idx_y_train]\n",
    "                y_test = df_all_output.iloc[idx_y_test]\n",
    "                train_scaler = MinMaxScaler()\n",
    "                X_train = train_scaler.fit_transform(X_train)\n",
    "                X_test = train_scaler.fit_transform(X_test)\n",
    "                #y = df_all_output.iloc[index]\n",
    "                #X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, test_size = 0.2, random_state=0)\n",
    "                if regression_type == 'kr':\n",
    "                    regression_model = MultiOutputRegressor(KernelRidge())\n",
    "                    param = {\n",
    "                            'estimator__alpha': (1e-3, 1e+2, 'uniform'), # (1e-6, 1e+6, 'log-uniform'),\n",
    "                            'estimator__gamma': (1e-2, 1e+1, 'uniform'),\n",
    "                            'estimator__kernel': ['linear', 'poly', 'rbf','laplacian'],  # categorical parameter\n",
    "                            }\n",
    "                if regression_type == 'svr':\n",
    "                    regression_model = MultiOutputRegressor(SVR())\n",
    "                    param = {\n",
    "                            'estimator__C': (1e-2, 1e+2, 'uniform'), # (1e-6, 1e+6, 'log-uniform'),\n",
    "                            'estimator__gamma': (1e-2, 1e+1, 'uniform'),\n",
    "                            'estimator__degree': (2, 4),  # integer valued parameter\n",
    "                            'estimator__kernel': ['linear', 'poly', 'rbf'],  # categorical parameter\n",
    "                            }\n",
    "                if regression_type == 'gbr':\n",
    "                    regression_model = MultiOutputRegressor(GradientBoostingRegressor())\n",
    "                    param = {'estimator__n_estimators':[10,25,50,75,100,125,150],\n",
    "                             'estimator__loss':['squared_error', 'absolute_error', 'huber', 'quantile'],\n",
    "                             'estimator__min_samples_split':(0.1, 0.99, 'uniform'),\n",
    "                             'estimator__min_samples_leaf':(0.01, 0.99, 'uniform')\n",
    "                             }\n",
    "                if regression_type == 'rfr':\n",
    "                    regression_model = MultiOutputRegressor(RandomForestRegressor())\n",
    "                    param = {'estimator__n_estimators':[10,25,50,75,100,125,150],\n",
    "                             'estimator__criterion':['squared_error', 'absolute_error', 'friedman_mse', 'poisson'],\n",
    "                             'estimator__min_samples_split':(0.05, 0.2, 'uniform'),\n",
    "                             'estimator__max_features':['sqrt', 'log2', 1]\n",
    "                             }\n",
    "                if regression_type == 'mlp':\n",
    "                    from sklearn.base import BaseEstimator, ClassifierMixin, RegressorMixin\n",
    "                    class MLPWrapper(BaseEstimator, RegressorMixin):\n",
    "                        def __init__(self, activation='relu', max_iter=500,layer1=10, layer2=10):#, layer3=10):\n",
    "                            self.layer1 = layer1\n",
    "                            self.layer2 = layer2\n",
    "                            #self.layer3 = layer3\n",
    "                            self.activation=activation\n",
    "                            self.max_iter=max_iter\n",
    "                    \n",
    "                        def fit(self, X, y):\n",
    "                            model = MLPRegressor(\n",
    "                                hidden_layer_sizes=[self.layer1, self.layer2],#, self.layer3]\n",
    "                                activation = self.activation,\n",
    "                                max_iter = self.max_iter\n",
    "                            )\n",
    "                            model.fit(X, y)\n",
    "                            self.model = model\n",
    "                            return self\n",
    "                    \n",
    "                        def predict(self, X):\n",
    "                            return self.model.predict(X)\n",
    "                    \n",
    "                        def score(self, X, y):\n",
    "                            return self.model.score(X, y)\n",
    "        \n",
    "                    regression_model = MultiOutputRegressor(MLPWrapper())\n",
    "                    param = {#'estimator__hidden_layer_sizes':[(40,20), (64,32), (64,64)], # (20,),(30,),(40,), (64,),\n",
    "                            'estimator__layer1': [40, 64],\n",
    "                            'estimator__layer2': [20, 32],\n",
    "                             'estimator__activation':['logistic', 'tanh', 'relu'],\n",
    "                             'estimator__max_iter':[500, 1000, 2000, 5000]\n",
    "                             }      \n",
    "                \n",
    "                opt = BayesSearchCV(regression_model,param, n_iter=32, # default value: 32, 50\n",
    "                               cv=KFold(n_splits=5, random_state=100, shuffle=True),#5, # default value: 3\n",
    "                               return_train_score = True, verbose = 0)\n",
    "                opt.fit(X_train, y_train)\n",
    "                df_results=pd.DataFrame.from_dict(opt.cv_results_)\n",
    "                df_results.to_csv(f'{out_dir_path}/feat_{fs}_{ft}_regr_{regression_type}.csv', sep=',')\n",
    "        \n",
    "                print(\"******* Feature select:\",fs,\" Feature type:\",ft, \"Regression model:\", regression_type, \"******\")\n",
    "                best_estimator = opt.best_estimator_\n",
    "                print('Best estimator:', best_estimator)\n",
    "\n",
    "                results_train = best_estimator.predict(X_train)\n",
    "                results_test = best_estimator.predict(X_test)\n",
    "                \n",
    "                print('R2 of the best estimator (training dataset): ', r2_score(y_pred = results_train, y_true = y_train))\n",
    "                print('R2 Best score (validation) val. score : ', opt.best_score_)\n",
    "                test_score = r2_score(y_pred = best_estimator.predict(X_test), y_true = y_test)\n",
    "                print('R2 of the best estimator (testing dataset): ',test_score)\n",
    "\n",
    "                print(\"resKendall train\", stats.kendalltau(results_train, y_train).statistic)\n",
    "                print(\"resKendall test\", stats.kendalltau(results_test, y_test).statistic)\n",
    "\n",
    "                metaheuristic=[]\n",
    "                test_results[f'res_{regression_type}_{fs}_{ft}']={}\n",
    "\n",
    "                # for i in range(results_test.shape[0]):\n",
    "                #     print( 'pred', results_test[i])\n",
    "                    \n",
    "                for i in range(results_test.shape[0]):\n",
    "                    test_results[f'res_{regression_type}_{fs}_{ft}'][i]=results_test[i]\n",
    "                    idx_best=np.argmin(results_test[i])\n",
    "                    metaheuristic.append(y_test.columns[idx_best])\n",
    "                    #print(\"predicted\", results_test[i], \"real\", y_test[i].)\n",
    "                #print(\"Selected metaheuristics:\",metaheuristic)\n",
    "                test_results_score[f'R2_{regression_type}_{fs}_{ft}']=[test_score]\n",
    "                test_results_metaheuristic[f'meta_{regression_type}_{fs}_{ft}']=metaheuristic\n",
    "    # save results on test instances \n",
    "        df_results = pd.DataFrame(test_results)\n",
    "        df_results.to_csv(f'{out_dir_path}/results_{regression_type}_test.csv')\n",
    "        df_results_score = pd.DataFrame(test_results_score)\n",
    "        df_results_score.to_csv(f'{out_dir_path}/results_{regression_type}_test_scores.csv')\n",
    "        df_results_metaheuristic = pd.DataFrame(test_results_metaheuristic)\n",
    "        df_results_metaheuristic.to_csv(f'{out_dir_path}/results_{regression_type}_test_metaheuristic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../datasets/results/features/februarie2025-v4/\n",
      "../datasets/results/ranks/runTime_1min_sa_ts_filtered\n",
      "regression_type rfr\n",
      "(296, 90) (296, 8)\n",
      "(296, 90) (296, 8)\n",
      "******* Feature select: all  Feature type: ST-F Regression model: rfr ******\n",
      "Best estimator: MultiOutputRegressor(estimator=RandomForestRegressor(criterion='friedman_mse',\n",
      "                                                     max_features='sqrt',\n",
      "                                                     min_samples_split=0.05,\n",
      "                                                     n_estimators=125))\n",
      "R2 of the best estimator (training dataset):  0.8494605232591441\n",
      "R2 Best score (validation) val. score :  0.5707032006109756\n",
      "R2 of the best estimator (testing dataset):  0.3794025815679809\n",
      "resKendall train 0.8006379686994899\n",
      "resKendall test 0.5050683881289619\n",
      "(296, 10) (296, 8)\n",
      "(296, 10) (296, 8)\n",
      "******* Feature select: LR10  Feature type: ST-F Regression model: rfr ******\n",
      "Best estimator: MultiOutputRegressor(estimator=RandomForestRegressor(criterion='poisson',\n",
      "                                                     max_features='sqrt',\n",
      "                                                     min_samples_split=0.05))\n",
      "R2 of the best estimator (training dataset):  0.8028038687964743\n",
      "R2 Best score (validation) val. score :  0.5353993402472905\n",
      "R2 of the best estimator (testing dataset):  0.389834352740729\n",
      "resKendall train 0.761454924773207\n",
      "resKendall test 0.49211904492339764\n",
      "(296, 20) (296, 8)\n",
      "(296, 20) (296, 8)\n",
      "******* Feature select: LR20  Feature type: ST-F Regression model: rfr ******\n",
      "Best estimator: MultiOutputRegressor(estimator=RandomForestRegressor(max_features='log2',\n",
      "                                                     min_samples_split=0.05,\n",
      "                                                     n_estimators=125))\n",
      "R2 of the best estimator (training dataset):  0.8224527104442141\n",
      "R2 Best score (validation) val. score :  0.5539138179112737\n",
      "R2 of the best estimator (testing dataset):  0.3431800261376521\n",
      "resKendall train 0.7800698781013934\n",
      "resKendall test 0.4757536049500225\n",
      "(296, 30) (296, 8)\n",
      "(296, 30) (296, 8)\n",
      "******* Feature select: LR30  Feature type: ST-F Regression model: rfr ******\n",
      "Best estimator: MultiOutputRegressor(estimator=RandomForestRegressor(max_features='sqrt',\n",
      "                                                     min_samples_split=0.05,\n",
      "                                                     n_estimators=75))\n",
      "R2 of the best estimator (training dataset):  0.8337104161175911\n",
      "R2 Best score (validation) val. score :  0.5642308581556119\n",
      "R2 of the best estimator (testing dataset):  0.3619490866143561\n",
      "resKendall train 0.7883710736483368\n",
      "resKendall test 0.48867822490390683\n",
      "(296, 40) (296, 8)\n",
      "(296, 40) (296, 8)\n",
      "******* Feature select: LR40  Feature type: ST-F Regression model: rfr ******\n",
      "Best estimator: MultiOutputRegressor(estimator=RandomForestRegressor(max_features='sqrt',\n",
      "                                                     min_samples_split=0.05))\n",
      "R2 of the best estimator (training dataset):  0.8399792031372455\n",
      "R2 Best score (validation) val. score :  0.5720945459810267\n",
      "R2 of the best estimator (testing dataset):  0.4082878920196179\n",
      "resKendall train 0.7923912647288508\n",
      "resKendall test 0.5218680152173278\n",
      "(296, 25) (296, 8)\n",
      "(296, 25) (296, 8)\n",
      "******* Feature select: FS_S  Feature type: ST-F Regression model: rfr ******\n",
      "Best estimator: MultiOutputRegressor(estimator=RandomForestRegressor(criterion='poisson',\n",
      "                                                     max_features='sqrt',\n",
      "                                                     min_samples_split=0.05,\n",
      "                                                     n_estimators=50))\n",
      "R2 of the best estimator (training dataset):  0.8355700200833833\n",
      "R2 Best score (validation) val. score :  0.5602074097674947\n",
      "R2 of the best estimator (testing dataset):  0.4014270034521607\n",
      "resKendall train 0.7854550881209815\n",
      "resKendall test 0.5101413021883391\n",
      "(296, 57) (296, 8)\n",
      "(296, 57) (296, 8)\n",
      "******* Feature select: RF  Feature type: ST-F Regression model: rfr ******\n",
      "Best estimator: MultiOutputRegressor(estimator=RandomForestRegressor(max_features='sqrt',\n",
      "                                                     min_samples_split=0.05))\n",
      "R2 of the best estimator (training dataset):  0.8475485757274577\n",
      "R2 Best score (validation) val. score :  0.5651361618373513\n",
      "R2 of the best estimator (testing dataset):  0.3325348560236292\n",
      "resKendall train 0.7990404953264252\n",
      "resKendall test 0.4696072157748389\n",
      "(296, 28) (296, 8)\n",
      "(296, 28) (296, 8)\n",
      "******* Feature select: PCA99  Feature type: ST-F Regression model: rfr ******\n",
      "Best estimator: MultiOutputRegressor(estimator=RandomForestRegressor(criterion='poisson',\n",
      "                                                     max_features='sqrt',\n",
      "                                                     min_samples_split=0.050421299736087215,\n",
      "                                                     n_estimators=75))\n",
      "R2 of the best estimator (training dataset):  0.8275669838449273\n",
      "R2 Best score (validation) val. score :  0.4889608302499172\n",
      "R2 of the best estimator (testing dataset):  0.13393405248384208\n",
      "resKendall train 0.7979762834454001\n",
      "resKendall test 0.3923205575193948\n",
      "(296, 48) (296, 8)\n",
      "(296, 48) (296, 8)\n",
      "******* Feature select: PCA999  Feature type: ST-F Regression model: rfr ******\n",
      "Best estimator: MultiOutputRegressor(estimator=RandomForestRegressor(max_features='sqrt',\n",
      "                                                     min_samples_split=0.05018820972246903,\n",
      "                                                     n_estimators=150))\n",
      "R2 of the best estimator (training dataset):  0.8175470280359911\n",
      "R2 Best score (validation) val. score :  0.4457892381038545\n",
      "R2 of the best estimator (testing dataset):  0.10820013270775068\n",
      "resKendall train 0.8060695500526605\n",
      "resKendall test 0.3907986801519635\n",
      "(296, 62) (296, 8)\n",
      "(296, 62) (296, 8)\n",
      "******* Feature select: PCA9999  Feature type: ST-F Regression model: rfr ******\n",
      "Best estimator: MultiOutputRegressor(estimator=RandomForestRegressor(criterion='poisson',\n",
      "                                                     max_features='sqrt',\n",
      "                                                     min_samples_split=0.05059876764911135))\n",
      "R2 of the best estimator (training dataset):  0.8204257700092681\n",
      "R2 Best score (validation) val. score :  0.42451027563123506\n",
      "R2 of the best estimator (testing dataset):  0.09883554548151827\n",
      "resKendall train 0.8114290078194716\n",
      "resKendall test 0.3793204037179831\n",
      "(296, 31) (296, 8)\n",
      "(296, 31) (296, 8)\n",
      "******* Feature select: FS_P  Feature type: ST-F Regression model: rfr ******\n",
      "Best estimator: MultiOutputRegressor(estimator=RandomForestRegressor(max_features='sqrt',\n",
      "                                                     min_samples_split=0.05))\n",
      "R2 of the best estimator (training dataset):  0.831925733474863\n",
      "R2 Best score (validation) val. score :  0.5674834038110246\n",
      "R2 of the best estimator (testing dataset):  0.3726222687769918\n",
      "resKendall train 0.7858618926653107\n",
      "resKendall test 0.5008351740222646\n",
      "(296, 40) (296, 8)\n",
      "(296, 40) (296, 8)\n",
      "******* Feature select: FS_K  Feature type: ST-F Regression model: rfr ******\n",
      "Best estimator: MultiOutputRegressor(estimator=RandomForestRegressor(criterion='friedman_mse',\n",
      "                                                     max_features='sqrt',\n",
      "                                                     min_samples_split=0.05,\n",
      "                                                     n_estimators=150))\n",
      "R2 of the best estimator (training dataset):  0.8415085255734499\n",
      "R2 Best score (validation) val. score :  0.5675471497474419\n",
      "R2 of the best estimator (testing dataset):  0.40244117680775643\n",
      "resKendall train 0.7932138670826612\n",
      "resKendall test 0.5125250199026596\n",
      "(296, 14) (296, 8)\n",
      "(296, 14) (296, 8)\n",
      "******* Feature select: LASSO  Feature type: ST-F Regression model: rfr ******\n",
      "Best estimator: MultiOutputRegressor(estimator=RandomForestRegressor(max_features='log2',\n",
      "                                                     min_samples_split=0.05,\n",
      "                                                     n_estimators=75))\n",
      "R2 of the best estimator (training dataset):  0.8137712908259873\n",
      "R2 Best score (validation) val. score :  0.5594982346045474\n",
      "R2 of the best estimator (testing dataset):  0.3374431317627039\n",
      "resKendall train 0.7683652586930368\n",
      "resKendall test 0.47623261549111284\n",
      "(296, 28) (296, 8)\n",
      "(296, 28) (296, 8)\n",
      "******* Feature select: ELASTICNET  Feature type: ST-F Regression model: rfr ******\n",
      "Best estimator: MultiOutputRegressor(estimator=RandomForestRegressor(max_features='sqrt',\n",
      "                                                     min_samples_split=0.05017535452184188,\n",
      "                                                     n_estimators=125))\n",
      "R2 of the best estimator (training dataset):  0.8320391620419668\n",
      "R2 Best score (validation) val. score :  0.5569797734293475\n",
      "R2 of the best estimator (testing dataset):  0.3467838198888409\n",
      "resKendall train 0.7884206911493788\n",
      "resKendall test 0.4802076821893638\n",
      "regression_type kr\n",
      "(296, 90) (296, 8)\n",
      "(296, 90) (296, 8)\n",
      "******* Feature select: all  Feature type: ST-F Regression model: kr ******\n",
      "Best estimator: MultiOutputRegressor(estimator=KernelRidge(alpha=3.426637747930558,\n",
      "                                           gamma=7.944584231374604))\n",
      "R2 of the best estimator (training dataset):  0.4557684623756677\n",
      "R2 Best score (validation) val. score :  0.31038289172336714\n",
      "R2 of the best estimator (testing dataset):  0.18153988757850062\n",
      "resKendall train 0.5171327186584673\n",
      "resKendall test 0.4161014989062725\n",
      "(296, 10) (296, 8)\n",
      "(296, 10) (296, 8)\n",
      "******* Feature select: LR10  Feature type: ST-F Regression model: kr ******\n",
      "Best estimator: MultiOutputRegressor(estimator=KernelRidge(alpha=18.710627914779398,\n",
      "                                           gamma=6.336210219824908,\n",
      "                                           kernel='poly'))\n",
      "R2 of the best estimator (training dataset):  0.6010934222870369\n",
      "R2 Best score (validation) val. score :  0.39099446879852673\n",
      "R2 of the best estimator (testing dataset):  -0.24151984015837646\n",
      "resKendall train 0.6171639491704612\n",
      "resKendall test 0.426210156247553\n",
      "(296, 20) (296, 8)\n",
      "(296, 20) (296, 8)\n",
      "******* Feature select: LR20  Feature type: ST-F Regression model: kr ******\n",
      "Best estimator: MultiOutputRegressor(estimator=KernelRidge(alpha=29.41835211806503,\n",
      "                                           gamma=2.9987958012702767,\n",
      "                                           kernel='poly'))\n",
      "R2 of the best estimator (training dataset):  0.6580065135902498\n",
      "R2 Best score (validation) val. score :  0.42187726999465125\n",
      "R2 of the best estimator (testing dataset):  0.03591013103724791\n",
      "resKendall train 0.6482519592775764\n",
      "resKendall test 0.4447071969903498\n",
      "(296, 30) (296, 8)\n",
      "(296, 30) (296, 8)\n",
      "******* Feature select: LR30  Feature type: ST-F Regression model: kr ******\n",
      "Best estimator: MultiOutputRegressor(estimator=KernelRidge(alpha=0.001, gamma=0.01,\n",
      "                                           kernel='laplacian'))\n",
      "R2 of the best estimator (training dataset):  0.9786672022784575\n",
      "R2 Best score (validation) val. score :  0.49679209750357084\n",
      "R2 of the best estimator (testing dataset):  0.22982404780928672\n",
      "resKendall train 0.9308930954941159\n",
      "resKendall test 0.44020171762430094\n",
      "(296, 40) (296, 8)\n",
      "(296, 40) (296, 8)\n",
      "******* Feature select: LR40  Feature type: ST-F Regression model: kr ******\n",
      "Best estimator: MultiOutputRegressor(estimator=KernelRidge(alpha=18.11826897926837,\n",
      "                                           gamma=1.0559250233186188,\n",
      "                                           kernel='poly'))\n",
      "R2 of the best estimator (training dataset):  0.7409593575066937\n",
      "R2 Best score (validation) val. score :  0.4549179152106076\n",
      "R2 of the best estimator (testing dataset):  0.2746305628003396\n",
      "resKendall train 0.7018624702058666\n",
      "resKendall test 0.5116176614665074\n",
      "(296, 25) (296, 8)\n",
      "(296, 25) (296, 8)\n",
      "******* Feature select: FS_S  Feature type: ST-F Regression model: kr ******\n",
      "Best estimator: MultiOutputRegressor(estimator=KernelRidge(alpha=100.0, gamma=2.893574220886655,\n",
      "                                           kernel='poly'))\n",
      "R2 of the best estimator (training dataset):  0.6799678412688874\n",
      "R2 Best score (validation) val. score :  0.37136024781763927\n",
      "R2 of the best estimator (testing dataset):  0.11297285519975106\n",
      "resKendall train 0.6601097751894437\n",
      "resKendall test 0.4598947583442671\n",
      "(296, 57) (296, 8)\n",
      "(296, 57) (296, 8)\n",
      "******* Feature select: RF  Feature type: ST-F Regression model: kr ******\n",
      "Best estimator: MultiOutputRegressor(estimator=KernelRidge(alpha=2.285780446946793,\n",
      "                                           gamma=0.1787850911677982))\n",
      "R2 of the best estimator (training dataset):  0.3810228702338422\n",
      "R2 Best score (validation) val. score :  0.2563942180924682\n",
      "R2 of the best estimator (testing dataset):  0.07046788618623859\n",
      "resKendall train 0.48227239349513634\n",
      "resKendall test 0.36888407515008087\n",
      "(296, 28) (296, 8)\n",
      "(296, 28) (296, 8)\n",
      "******* Feature select: PCA99  Feature type: ST-F Regression model: kr ******\n",
      "Best estimator: MultiOutputRegressor(estimator=KernelRidge(alpha=72.06265367696889,\n",
      "                                           gamma=2.083474775621659,\n",
      "                                           kernel='poly'))\n",
      "R2 of the best estimator (training dataset):  0.7340962846627771\n",
      "R2 Best score (validation) val. score :  0.35320970439557653\n",
      "R2 of the best estimator (testing dataset):  -0.8661005819864155\n",
      "resKendall train 0.6946899040441851\n",
      "resKendall test 0.31357317209633245\n",
      "(296, 48) (296, 8)\n",
      "(296, 48) (296, 8)\n",
      "******* Feature select: PCA999  Feature type: ST-F Regression model: kr ******\n",
      "Best estimator: MultiOutputRegressor(estimator=KernelRidge(alpha=43.627489418531816,\n",
      "                                           gamma=9.077640678709308))\n",
      "R2 of the best estimator (training dataset):  0.11596254180249936\n",
      "R2 Best score (validation) val. score :  0.0372898270268971\n",
      "R2 of the best estimator (testing dataset):  -0.019703295072330318\n",
      "resKendall train 0.3577320244002465\n",
      "resKendall test 0.3249925143440998\n",
      "(296, 62) (296, 8)\n",
      "(296, 62) (296, 8)\n",
      "******* Feature select: PCA9999  Feature type: ST-F Regression model: kr ******\n",
      "Best estimator: MultiOutputRegressor(estimator=KernelRidge(alpha=0.001, gamma=0.01,\n",
      "                                           kernel='laplacian'))\n",
      "R2 of the best estimator (training dataset):  0.9979853757784418\n",
      "R2 Best score (validation) val. score :  0.3741321478764509\n",
      "R2 of the best estimator (testing dataset):  -0.10759958420284933\n",
      "resKendall train 0.9836549790779484\n",
      "resKendall test 0.3017278572539568\n",
      "(296, 31) (296, 8)\n",
      "(296, 31) (296, 8)\n",
      "******* Feature select: FS_P  Feature type: ST-F Regression model: kr ******\n",
      "Best estimator: MultiOutputRegressor(estimator=KernelRidge(alpha=21.66987111382652,\n",
      "                                           gamma=1.4698189017500733,\n",
      "                                           kernel='poly'))\n",
      "R2 of the best estimator (training dataset):  0.7227574773834066\n",
      "R2 Best score (validation) val. score :  0.42848115003350057\n",
      "R2 of the best estimator (testing dataset):  0.09738743238523909\n",
      "resKendall train 0.6899323085257979\n",
      "resKendall test 0.4738699361596839\n",
      "(296, 40) (296, 8)\n",
      "(296, 40) (296, 8)\n",
      "******* Feature select: FS_K  Feature type: ST-F Regression model: kr ******\n",
      "Best estimator: MultiOutputRegressor(estimator=KernelRidge(alpha=1.9359631346459714,\n",
      "                                           gamma=10.0))\n",
      "R2 of the best estimator (training dataset):  0.4302609636992866\n",
      "R2 Best score (validation) val. score :  0.28834727782221536\n",
      "R2 of the best estimator (testing dataset):  0.16958415534385562\n",
      "resKendall train 0.5018826900598233\n",
      "resKendall test 0.42129508784822695\n",
      "(296, 14) (296, 8)\n",
      "(296, 14) (296, 8)\n",
      "******* Feature select: LASSO  Feature type: ST-F Regression model: kr ******\n",
      "Best estimator: MultiOutputRegressor(estimator=KernelRidge(alpha=0.001, gamma=0.01,\n",
      "                                           kernel='poly'))\n",
      "R2 of the best estimator (training dataset):  0.4573910196216249\n",
      "R2 Best score (validation) val. score :  0.28928217685506785\n",
      "R2 of the best estimator (testing dataset):  0.09676795743084095\n",
      "resKendall train 0.5265412765162656\n",
      "resKendall test 0.4069758552448573\n",
      "(296, 28) (296, 8)\n",
      "(296, 28) (296, 8)\n",
      "******* Feature select: ELASTICNET  Feature type: ST-F Regression model: kr ******\n",
      "Best estimator: MultiOutputRegressor(estimator=KernelRidge(alpha=0.001, gamma=0.01,\n",
      "                                           kernel='rbf'))\n",
      "R2 of the best estimator (training dataset):  0.5861764138824941\n",
      "R2 Best score (validation) val. score :  0.3725626966562684\n",
      "R2 of the best estimator (testing dataset):  0.07921484755049797\n",
      "resKendall train 0.5949331281131458\n",
      "resKendall test 0.4234741015052615\n"
     ]
    }
   ],
   "source": [
    "dir_path = '../datasets/results/regression/februarie2025-v4/'\n",
    "\n",
    "ft_type=['ST-F']\n",
    "ft_select=['all','LR10','LR20', 'LR30', 'LR40', 'FS_S','RF','PCA99', 'PCA999', 'PCA9999','FS_P','FS_K', 'LASSO', 'ELASTICNET']\n",
    "regression_types = ['rfr', 'kr']\n",
    "\n",
    "regression_tuning(dir_path, ft_type, ft_select, regression_types, \n",
    "                  feature_path='../datasets/results/features/februarie2025-v4/',\n",
    "                  #ranks_path='../datasets/results/ranks/runTime_1min_sa_ts_agregated_filtered')\n",
    "                  ranks_path='../datasets/results/ranks/runTime_1min_sa_ts_filtered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../datasets/results/features/februarie2025-v4/\n",
      "../datasets/results/ranks/runTime_1min_sa_ts_filtered\n",
      "regression_type svr\n",
      "(296, 90) (296, 8)\n",
      "(296, 90) (296, 8)\n",
      "******* Feature select: all  Feature type: ST-F Regression model: svr ******\n",
      "Best estimator: MultiOutputRegressor(estimator=SVR(C=48.9358067910631,\n",
      "                                   gamma=2.8607474425223223))\n",
      "R2 of the best estimator (training dataset):  0.9829012334498571\n",
      "R2 Best score (validation) val. score :  0.4864619525222353\n",
      "R2 of the best estimator (testing dataset):  0.2694900297787551\n",
      "resKendall train 0.9515828368541888\n",
      "resKendall test 0.4687091143403917\n",
      "(296, 10) (296, 8)\n",
      "(296, 10) (296, 8)\n",
      "******* Feature select: LR10  Feature type: ST-F Regression model: svr ******\n",
      "Best estimator: MultiOutputRegressor(estimator=SVR(C=14.269200165015443, degree=4, gamma=10.0))\n",
      "R2 of the best estimator (training dataset):  0.9022040532336673\n",
      "R2 Best score (validation) val. score :  0.4424073084647307\n",
      "R2 of the best estimator (testing dataset):  0.2358151240629328\n",
      "resKendall train 0.864279868163533\n",
      "resKendall test 0.43415618349312995\n",
      "(296, 20) (296, 8)\n",
      "(296, 20) (296, 8)\n",
      "******* Feature select: LR20  Feature type: ST-F Regression model: svr ******\n",
      "Best estimator: MultiOutputRegressor(estimator=SVR(C=13.463674675834534,\n",
      "                                   gamma=1.3115894695034371))\n",
      "R2 of the best estimator (training dataset):  0.8239499053456676\n",
      "R2 Best score (validation) val. score :  0.5076017957640062\n",
      "R2 of the best estimator (testing dataset):  0.32903967938662365\n",
      "resKendall train 0.7777761479596736\n",
      "resKendall test 0.4852073606007959\n",
      "(296, 30) (296, 8)\n",
      "(296, 30) (296, 8)\n",
      "******* Feature select: LR30  Feature type: ST-F Regression model: svr ******\n",
      "Best estimator: MultiOutputRegressor(estimator=SVR(C=20.102707132178146,\n",
      "                                   gamma=2.7363102966300246))\n",
      "R2 of the best estimator (training dataset):  0.9613698993107644\n",
      "R2 Best score (validation) val. score :  0.4678759276191343\n",
      "R2 of the best estimator (testing dataset):  0.3900959828083606\n",
      "resKendall train 0.9195853370896846\n",
      "resKendall test 0.508881606724216\n",
      "(296, 40) (296, 8)\n",
      "(296, 40) (296, 8)\n",
      "******* Feature select: LR40  Feature type: ST-F Regression model: svr ******\n",
      "Best estimator: MultiOutputRegressor(estimator=SVR(C=7.295423775444252, degree=4,\n",
      "                                   gamma=5.025185826785305))\n",
      "R2 of the best estimator (training dataset):  0.9732153981797037\n",
      "R2 Best score (validation) val. score :  0.5079976535363606\n",
      "R2 of the best estimator (testing dataset):  0.3075176875270156\n",
      "resKendall train 0.9386099774355984\n",
      "resKendall test 0.4832249496797344\n",
      "(296, 25) (296, 8)\n",
      "(296, 25) (296, 8)\n",
      "******* Feature select: FS_S  Feature type: ST-F Regression model: svr ******\n",
      "Best estimator: MultiOutputRegressor(estimator=SVR(C=16.607505018521078, degree=2,\n",
      "                                   gamma=9.581429021463064))\n",
      "R2 of the best estimator (training dataset):  0.978530766683307\n",
      "R2 Best score (validation) val. score :  0.49558769710649864\n",
      "R2 of the best estimator (testing dataset):  0.26469735924070653\n",
      "resKendall train 0.9473178815668873\n",
      "resKendall test 0.46541601851284325\n",
      "(296, 57) (296, 8)\n",
      "(296, 57) (296, 8)\n",
      "******* Feature select: RF  Feature type: ST-F Regression model: svr ******\n",
      "Best estimator: MultiOutputRegressor(estimator=SVR(C=38.650655054544956,\n",
      "                                   gamma=6.754037875660253))\n",
      "R2 of the best estimator (training dataset):  0.9827642154423519\n",
      "R2 Best score (validation) val. score :  0.46589665895537624\n",
      "R2 of the best estimator (testing dataset):  0.2981751679945575\n",
      "resKendall train 0.9518549947440893\n",
      "resKendall test 0.49996894936010494\n",
      "(296, 28) (296, 8)\n",
      "(296, 28) (296, 8)\n",
      "******* Feature select: PCA99  Feature type: ST-F Regression model: svr ******\n",
      "Best estimator: MultiOutputRegressor(estimator=SVR(C=50.57657290741567,\n",
      "                                   gamma=5.299210038122359))\n",
      "R2 of the best estimator (training dataset):  0.9802097049284636\n",
      "R2 Best score (validation) val. score :  0.4727740309718632\n",
      "R2 of the best estimator (testing dataset):  -0.01901410328701006\n",
      "resKendall train 0.947248980835267\n",
      "resKendall test 0.3007448435740916\n",
      "(296, 48) (296, 8)\n",
      "(296, 48) (296, 8)\n",
      "******* Feature select: PCA999  Feature type: ST-F Regression model: svr ******\n",
      "Best estimator: MultiOutputRegressor(estimator=SVR(C=34.493687551617064,\n",
      "                                   gamma=3.3490888816535573))\n",
      "R2 of the best estimator (training dataset):  0.9847925801312329\n",
      "R2 Best score (validation) val. score :  0.42507583547396444\n",
      "R2 of the best estimator (testing dataset):  -0.012753764812514917\n",
      "resKendall train 0.95707537350986\n",
      "resKendall test 0.3181605692690367\n",
      "(296, 62) (296, 8)\n",
      "(296, 62) (296, 8)\n",
      "******* Feature select: PCA9999  Feature type: ST-F Regression model: svr ******\n",
      "Best estimator: MultiOutputRegressor(estimator=SVR(C=22.148816885679068, degree=2,\n",
      "                                   gamma=0.9991990266120747))\n",
      "R2 of the best estimator (training dataset):  0.9830712840410365\n",
      "R2 Best score (validation) val. score :  0.4740746101901506\n",
      "R2 of the best estimator (testing dataset):  0.06411709471807084\n",
      "resKendall train 0.9532031523927947\n",
      "resKendall test 0.4094333894445203\n",
      "(296, 31) (296, 8)\n",
      "(296, 31) (296, 8)\n",
      "******* Feature select: FS_P  Feature type: ST-F Regression model: svr ******\n",
      "Best estimator: MultiOutputRegressor(estimator=SVR(C=9.13848422190172, gamma=6.09345189215926))\n",
      "R2 of the best estimator (training dataset):  0.9720121157110856\n",
      "R2 Best score (validation) val. score :  0.5047797641827556\n",
      "R2 of the best estimator (testing dataset):  0.2907002255912238\n",
      "resKendall train 0.9352212097854027\n",
      "resKendall test 0.4690040184443512\n",
      "(296, 40) (296, 8)\n",
      "(296, 40) (296, 8)\n",
      "******* Feature select: FS_K  Feature type: ST-F Regression model: svr ******\n",
      "Best estimator: MultiOutputRegressor(estimator=SVR(C=73.9861330373079, gamma=6.910365496241695))\n",
      "R2 of the best estimator (training dataset):  0.9857076014078429\n",
      "R2 Best score (validation) val. score :  0.46843133981000734\n",
      "R2 of the best estimator (testing dataset):  0.1784349873373477\n",
      "resKendall train 0.9561877024174842\n",
      "resKendall test 0.42401475902918734\n",
      "(296, 14) (296, 8)\n",
      "(296, 14) (296, 8)\n",
      "******* Feature select: LASSO  Feature type: ST-F Regression model: svr ******\n",
      "Best estimator: MultiOutputRegressor(estimator=SVR(C=15.050730398761065, degree=2,\n",
      "                                   gamma=4.955662804866362))\n",
      "R2 of the best estimator (training dataset):  0.8837442980158252\n",
      "R2 Best score (validation) val. score :  0.4454075918048087\n",
      "R2 of the best estimator (testing dataset):  0.10153616696296161\n",
      "resKendall train 0.8428184720831987\n",
      "resKendall test 0.3870206775435937\n",
      "(296, 28) (296, 8)\n",
      "(296, 28) (296, 8)\n",
      "******* Feature select: ELASTICNET  Feature type: ST-F Regression model: svr ******\n",
      "Best estimator: MultiOutputRegressor(estimator=SVR(C=2.748037301072595, degree=2,\n",
      "                                   gamma=1.2786603681650637))\n",
      "R2 of the best estimator (training dataset):  0.7651559013028588\n",
      "R2 Best score (validation) val. score :  0.47640586789490785\n",
      "R2 of the best estimator (testing dataset):  0.36505055121604824\n",
      "resKendall train 0.7415033577981248\n",
      "resKendall test 0.4815702099852947\n",
      "regression_type gbr\n",
      "(296, 90) (296, 8)\n",
      "(296, 90) (296, 8)\n",
      "******* Feature select: all  Feature type: ST-F Regression model: gbr ******\n",
      "Best estimator: MultiOutputRegressor(estimator=GradientBoostingRegressor(min_samples_leaf=0.01,\n",
      "                                                         min_samples_split=0.1,\n",
      "                                                         n_estimators=50))\n",
      "R2 of the best estimator (training dataset):  0.8685964061221727\n",
      "R2 Best score (validation) val. score :  0.5406052096314365\n",
      "R2 of the best estimator (testing dataset):  0.33981026797859804\n",
      "resKendall train 0.8077469687727872\n",
      "resKendall test 0.45835481773631775\n",
      "(296, 10) (296, 8)\n",
      "(296, 10) (296, 8)\n",
      "******* Feature select: LR10  Feature type: ST-F Regression model: gbr ******\n",
      "Best estimator: MultiOutputRegressor(estimator=GradientBoostingRegressor(min_samples_leaf=0.01,\n",
      "                                                         min_samples_split=0.1,\n",
      "                                                         n_estimators=75))\n",
      "R2 of the best estimator (training dataset):  0.8433851186759149\n",
      "R2 Best score (validation) val. score :  0.5149175191931756\n",
      "R2 of the best estimator (testing dataset):  0.3418681216562395\n",
      "resKendall train 0.785796085100159\n",
      "resKendall test 0.47025662604409973\n",
      "(296, 20) (296, 8)\n",
      "(296, 20) (296, 8)\n",
      "******* Feature select: LR20  Feature type: ST-F Regression model: gbr ******\n",
      "Best estimator: MultiOutputRegressor(estimator=GradientBoostingRegressor(min_samples_leaf=0.02150714821472474,\n",
      "                                                         min_samples_split=0.1,\n",
      "                                                         n_estimators=75))\n",
      "R2 of the best estimator (training dataset):  0.8582888325671967\n",
      "R2 Best score (validation) val. score :  0.5367149251544058\n",
      "R2 of the best estimator (testing dataset):  0.28195097885368564\n",
      "resKendall train 0.7953153002190703\n",
      "resKendall test 0.43421194224457477\n",
      "(296, 30) (296, 8)\n",
      "(296, 30) (296, 8)\n",
      "******* Feature select: LR30  Feature type: ST-F Regression model: gbr ******\n",
      "Best estimator: MultiOutputRegressor(estimator=GradientBoostingRegressor(loss='huber',\n",
      "                                                         min_samples_leaf=0.07681178015863277,\n",
      "                                                         min_samples_split=0.1,\n",
      "                                                         n_estimators=50))\n",
      "R2 of the best estimator (training dataset):  0.7950294715756623\n",
      "R2 Best score (validation) val. score :  0.5202803542032481\n",
      "R2 of the best estimator (testing dataset):  0.3129861309639475\n",
      "resKendall train 0.7524132384127528\n",
      "resKendall test 0.46407004165552396\n",
      "(296, 40) (296, 8)\n",
      "(296, 40) (296, 8)\n",
      "******* Feature select: LR40  Feature type: ST-F Regression model: gbr ******\n",
      "Best estimator: MultiOutputRegressor(estimator=GradientBoostingRegressor(loss='huber',\n",
      "                                                         min_samples_leaf=0.01,\n",
      "                                                         min_samples_split=0.1,\n",
      "                                                         n_estimators=50))\n",
      "R2 of the best estimator (training dataset):  0.8431554122351876\n",
      "R2 Best score (validation) val. score :  0.5437796202099276\n",
      "R2 of the best estimator (testing dataset):  0.3766269713153925\n",
      "resKendall train 0.790792428634553\n",
      "resKendall test 0.47720343377652025\n",
      "(296, 25) (296, 8)\n",
      "(296, 25) (296, 8)\n",
      "******* Feature select: FS_S  Feature type: ST-F Regression model: gbr ******\n",
      "Best estimator: MultiOutputRegressor(estimator=GradientBoostingRegressor(min_samples_leaf=0.01,\n",
      "                                                         min_samples_split=0.23315145118723538,\n",
      "                                                         n_estimators=50))\n",
      "R2 of the best estimator (training dataset):  0.8089188200474652\n",
      "R2 Best score (validation) val. score :  0.5377707476839373\n",
      "R2 of the best estimator (testing dataset):  0.3625215414618728\n",
      "resKendall train 0.7536663593705766\n",
      "resKendall test 0.48551470111670364\n",
      "(296, 57) (296, 8)\n",
      "(296, 57) (296, 8)\n",
      "******* Feature select: RF  Feature type: ST-F Regression model: gbr ******\n",
      "Best estimator: MultiOutputRegressor(estimator=GradientBoostingRegressor(min_samples_leaf=0.01,\n",
      "                                                         min_samples_split=0.1,\n",
      "                                                         n_estimators=50))\n",
      "R2 of the best estimator (training dataset):  0.8632074533755207\n",
      "R2 Best score (validation) val. score :  0.5310317979015516\n",
      "R2 of the best estimator (testing dataset):  0.3349851918398841\n",
      "resKendall train 0.8020013249005985\n",
      "resKendall test 0.45466106194817224\n",
      "(296, 28) (296, 8)\n",
      "(296, 28) (296, 8)\n",
      "******* Feature select: PCA99  Feature type: ST-F Regression model: gbr ******\n",
      "Best estimator: MultiOutputRegressor(estimator=GradientBoostingRegressor(loss='huber',\n",
      "                                                         min_samples_leaf=0.01,\n",
      "                                                         min_samples_split=0.1,\n",
      "                                                         n_estimators=75))\n",
      "R2 of the best estimator (training dataset):  0.9085247465755799\n",
      "R2 Best score (validation) val. score :  0.5119269299556327\n",
      "R2 of the best estimator (testing dataset):  -0.05870819695199425\n",
      "resKendall train 0.8530705512114707\n",
      "resKendall test 0.24520436872671572\n",
      "(296, 48) (296, 8)\n",
      "(296, 48) (296, 8)\n",
      "******* Feature select: PCA999  Feature type: ST-F Regression model: gbr ******\n",
      "Best estimator: MultiOutputRegressor(estimator=GradientBoostingRegressor(loss='huber',\n",
      "                                                         min_samples_leaf=0.01,\n",
      "                                                         min_samples_split=0.1698031475682334,\n",
      "                                                         n_estimators=75))\n",
      "R2 of the best estimator (training dataset):  0.908451075593472\n",
      "R2 Best score (validation) val. score :  0.5059878290973335\n",
      "R2 of the best estimator (testing dataset):  0.006728968271771663\n",
      "resKendall train 0.8568446696802549\n",
      "resKendall test 0.2790188681946417\n",
      "(296, 62) (296, 8)\n",
      "(296, 62) (296, 8)\n",
      "******* Feature select: PCA9999  Feature type: ST-F Regression model: gbr ******\n",
      "Best estimator: MultiOutputRegressor(estimator=GradientBoostingRegressor(loss='huber',\n",
      "                                                         min_samples_leaf=0.02770932814756369,\n",
      "                                                         min_samples_split=0.1,\n",
      "                                                         n_estimators=75))\n",
      "R2 of the best estimator (training dataset):  0.9291171588890792\n",
      "R2 Best score (validation) val. score :  0.49094417857563444\n",
      "R2 of the best estimator (testing dataset):  0.01050739189290241\n",
      "resKendall train 0.8823635267126667\n",
      "resKendall test 0.281346706958085\n",
      "(296, 31) (296, 8)\n",
      "(296, 31) (296, 8)\n",
      "******* Feature select: FS_P  Feature type: ST-F Regression model: gbr ******\n",
      "Best estimator: MultiOutputRegressor(estimator=GradientBoostingRegressor(min_samples_leaf=0.01,\n",
      "                                                         min_samples_split=0.1,\n",
      "                                                         n_estimators=50))\n",
      "R2 of the best estimator (training dataset):  0.8528462081223362\n",
      "R2 Best score (validation) val. score :  0.543637045365517\n",
      "R2 of the best estimator (testing dataset):  0.35498252493651333\n",
      "resKendall train 0.7922896291599065\n",
      "resKendall test 0.46720844357587205\n",
      "(296, 40) (296, 8)\n",
      "(296, 40) (296, 8)\n",
      "******* Feature select: FS_K  Feature type: ST-F Regression model: gbr ******\n",
      "Best estimator: MultiOutputRegressor(estimator=GradientBoostingRegressor(min_samples_leaf=0.01,\n",
      "                                                         min_samples_split=0.1,\n",
      "                                                         n_estimators=50))\n",
      "R2 of the best estimator (training dataset):  0.8563085938625088\n",
      "R2 Best score (validation) val. score :  0.5409603038182021\n",
      "R2 of the best estimator (testing dataset):  0.37380026915489173\n",
      "resKendall train 0.796278648735277\n",
      "resKendall test 0.49025047895705687\n",
      "(296, 14) (296, 8)\n",
      "(296, 14) (296, 8)\n",
      "******* Feature select: LASSO  Feature type: ST-F Regression model: gbr ******\n",
      "Best estimator: MultiOutputRegressor(estimator=GradientBoostingRegressor(min_samples_leaf=0.01,\n",
      "                                                         min_samples_split=0.12635682864798214,\n",
      "                                                         n_estimators=50))\n",
      "R2 of the best estimator (training dataset):  0.8073996133108414\n",
      "R2 Best score (validation) val. score :  0.5293680974674222\n",
      "R2 of the best estimator (testing dataset):  0.3400157182611599\n",
      "resKendall train 0.7527706579872023\n",
      "resKendall test 0.469799295507958\n",
      "(296, 28) (296, 8)\n",
      "(296, 28) (296, 8)\n",
      "******* Feature select: ELASTICNET  Feature type: ST-F Regression model: gbr ******\n",
      "Best estimator: MultiOutputRegressor(estimator=GradientBoostingRegressor(min_samples_leaf=0.012872873851020388,\n",
      "                                                         min_samples_split=0.1,\n",
      "                                                         n_estimators=75))\n",
      "R2 of the best estimator (training dataset):  0.8827065832174286\n",
      "R2 Best score (validation) val. score :  0.5419337378999748\n",
      "R2 of the best estimator (testing dataset):  0.3267568161096944\n",
      "resKendall train 0.8205996503717817\n",
      "resKendall test 0.46417402304782407\n",
      "regression_type mlp\n",
      "(296, 90) (296, 8)\n",
      "(296, 90) (296, 8)\n",
      "******* Feature select: all  Feature type: ST-F Regression model: mlp ******\n",
      "Best estimator: MultiOutputRegressor(estimator=MLPWrapper(activation='tanh', layer1=40,\n",
      "                                          layer2=20))\n",
      "R2 of the best estimator (training dataset):  0.6545046288727929\n",
      "R2 Best score (validation) val. score :  0.35417108595276925\n",
      "R2 of the best estimator (testing dataset):  0.2901945449985386\n",
      "resKendall train 0.6397415705769325\n",
      "resKendall test 0.4518831968533657\n",
      "(296, 10) (296, 8)\n",
      "(296, 10) (296, 8)\n",
      "******* Feature select: LR10  Feature type: ST-F Regression model: mlp ******\n",
      "Best estimator: MultiOutputRegressor(estimator=MLPWrapper(layer1=64, layer2=20, max_iter=5000))\n",
      "R2 of the best estimator (training dataset):  0.6508475780097962\n",
      "R2 Best score (validation) val. score :  0.5026368382878873\n",
      "R2 of the best estimator (testing dataset):  0.30218694147167136\n",
      "resKendall train 0.6372691826572879\n",
      "resKendall test 0.5042778259901807\n",
      "(296, 20) (296, 8)\n",
      "(296, 20) (296, 8)\n",
      "******* Feature select: LR20  Feature type: ST-F Regression model: mlp ******\n",
      "Best estimator: MultiOutputRegressor(estimator=MLPWrapper(activation='tanh', layer1=40,\n",
      "                                          layer2=20, max_iter=5000))\n",
      "R2 of the best estimator (training dataset):  0.6233661324097439\n",
      "R2 Best score (validation) val. score :  0.49690184598570186\n",
      "R2 of the best estimator (testing dataset):  0.24887366896530858\n",
      "resKendall train 0.6215873761404895\n",
      "resKendall test 0.4616477994066933\n",
      "(296, 30) (296, 8)\n",
      "(296, 30) (296, 8)\n",
      "******* Feature select: LR30  Feature type: ST-F Regression model: mlp ******\n",
      "Best estimator: MultiOutputRegressor(estimator=MLPWrapper(activation='tanh', layer1=49,\n",
      "                                          layer2=20, max_iter=1000))\n",
      "R2 of the best estimator (training dataset):  0.6363173254179206\n",
      "R2 Best score (validation) val. score :  0.37861305693039926\n",
      "R2 of the best estimator (testing dataset):  0.25178252803853074\n",
      "resKendall train 0.6268272767802193\n",
      "resKendall test 0.4520634160280077\n",
      "(296, 40) (296, 8)\n",
      "(296, 40) (296, 8)\n",
      "******* Feature select: LR40  Feature type: ST-F Regression model: mlp ******\n",
      "Best estimator: MultiOutputRegressor(estimator=MLPWrapper(activation='tanh', layer1=40,\n",
      "                                          layer2=20, max_iter=1000))\n",
      "R2 of the best estimator (training dataset):  0.6712421188188693\n",
      "R2 Best score (validation) val. score :  0.4441639143635361\n",
      "R2 of the best estimator (testing dataset):  0.3453348459827318\n",
      "resKendall train 0.650177734726366\n",
      "resKendall test 0.48843492218302\n",
      "(296, 25) (296, 8)\n",
      "(296, 25) (296, 8)\n",
      "******* Feature select: FS_S  Feature type: ST-F Regression model: mlp ******\n",
      "Best estimator: MultiOutputRegressor(estimator=MLPWrapper(activation='tanh', layer1=40,\n",
      "                                          layer2=20, max_iter=1000))\n",
      "R2 of the best estimator (training dataset):  0.623285458254653\n",
      "R2 Best score (validation) val. score :  0.36566985899754767\n",
      "R2 of the best estimator (testing dataset):  0.24122612962563447\n",
      "resKendall train 0.6208914787511236\n",
      "resKendall test 0.44641108736878277\n",
      "(296, 57) (296, 8)\n",
      "(296, 57) (296, 8)\n",
      "******* Feature select: RF  Feature type: ST-F Regression model: mlp ******\n",
      "Best estimator: MultiOutputRegressor(estimator=MLPWrapper(activation='tanh', layer1=45,\n",
      "                                          layer2=23, max_iter=1000))\n",
      "R2 of the best estimator (training dataset):  0.633378174630743\n",
      "R2 Best score (validation) val. score :  0.3435037402755518\n",
      "R2 of the best estimator (testing dataset):  0.3108807549510001\n",
      "resKendall train 0.6301735556459158\n",
      "resKendall test 0.465563470564823\n",
      "(296, 28) (296, 8)\n",
      "(296, 28) (296, 8)\n",
      "******* Feature select: PCA99  Feature type: ST-F Regression model: mlp ******\n",
      "Best estimator: MultiOutputRegressor(estimator=MLPWrapper(activation='tanh', layer1=40,\n",
      "                                          layer2=20, max_iter=2000))\n",
      "R2 of the best estimator (training dataset):  0.33517815429007775\n",
      "R2 Best score (validation) val. score :  0.1038550415093904\n",
      "R2 of the best estimator (testing dataset):  -0.16432621043915235\n",
      "resKendall train 0.4389143114319585\n",
      "resKendall test 0.28624539179607994\n",
      "(296, 48) (296, 8)\n",
      "(296, 48) (296, 8)\n",
      "******* Feature select: PCA999  Feature type: ST-F Regression model: mlp ******\n",
      "Best estimator: MultiOutputRegressor(estimator=MLPWrapper(activation='tanh', layer1=40,\n",
      "                                          layer2=20, max_iter=1000))\n",
      "R2 of the best estimator (training dataset):  0.17323135862486205\n",
      "R2 Best score (validation) val. score :  0.05238932856404106\n",
      "R2 of the best estimator (testing dataset):  0.06453331121363405\n",
      "resKendall train 0.36918332599555354\n",
      "resKendall test 0.328056240313013\n",
      "(296, 62) (296, 8)\n",
      "(296, 62) (296, 8)\n",
      "******* Feature select: PCA9999  Feature type: ST-F Regression model: mlp ******\n",
      "Best estimator: MultiOutputRegressor(estimator=MLPWrapper(activation='tanh', layer1=40,\n",
      "                                          layer2=20, max_iter=5000))\n",
      "R2 of the best estimator (training dataset):  0.25888325961530056\n",
      "R2 Best score (validation) val. score :  0.02219162899745888\n",
      "R2 of the best estimator (testing dataset):  -0.1074454971309797\n",
      "resKendall train 0.39242583946216153\n",
      "resKendall test 0.21615651642169137\n",
      "(296, 31) (296, 8)\n",
      "(296, 31) (296, 8)\n",
      "******* Feature select: FS_P  Feature type: ST-F Regression model: mlp ******\n",
      "Best estimator: MultiOutputRegressor(estimator=MLPWrapper(activation='tanh', layer1=46,\n",
      "                                          layer2=20, max_iter=1000))\n",
      "R2 of the best estimator (training dataset):  0.68353338880677\n",
      "R2 Best score (validation) val. score :  0.402365536606204\n",
      "R2 of the best estimator (testing dataset):  0.2521054570393325\n",
      "resKendall train 0.6577097330380005\n",
      "resKendall test 0.4575027583899284\n",
      "(296, 40) (296, 8)\n",
      "(296, 40) (296, 8)\n",
      "******* Feature select: FS_K  Feature type: ST-F Regression model: mlp ******\n",
      "Best estimator: MultiOutputRegressor(estimator=MLPWrapper(activation='tanh', layer1=49,\n",
      "                                          layer2=20, max_iter=1000))\n",
      "R2 of the best estimator (training dataset):  0.6491764597785161\n",
      "R2 Best score (validation) val. score :  0.3859805156735134\n",
      "R2 of the best estimator (testing dataset):  0.23184326546250933\n",
      "resKendall train 0.6383187704689717\n",
      "resKendall test 0.4507691146828518\n",
      "(296, 14) (296, 8)\n",
      "(296, 14) (296, 8)\n",
      "******* Feature select: LASSO  Feature type: ST-F Regression model: mlp ******\n",
      "Best estimator: MultiOutputRegressor(estimator=MLPWrapper(layer1=45, layer2=24, max_iter=1000))\n",
      "R2 of the best estimator (training dataset):  0.6779423409555424\n",
      "R2 Best score (validation) val. score :  0.3817396775383507\n",
      "R2 of the best estimator (testing dataset):  -0.10103580464445551\n",
      "resKendall train 0.6577773992961138\n",
      "resKendall test 0.4116287866628858\n",
      "(296, 28) (296, 8)\n",
      "(296, 28) (296, 8)\n",
      "******* Feature select: ELASTICNET  Feature type: ST-F Regression model: mlp ******\n",
      "Best estimator: MultiOutputRegressor(estimator=MLPWrapper(layer1=40, layer2=20))\n",
      "R2 of the best estimator (training dataset):  0.6577402226276012\n",
      "R2 Best score (validation) val. score :  0.33168603814136155\n",
      "R2 of the best estimator (testing dataset):  0.17390126568018272\n",
      "resKendall train 0.641271166818905\n",
      "resKendall test 0.4804233606921186\n"
     ]
    }
   ],
   "source": [
    "dir_path = '../datasets/results/regression/februarie2025-v4/'\n",
    "\n",
    "ft_type=['ST-F']\n",
    "ft_select=['all','LR10','LR20', 'LR30', 'LR40', 'FS_S','RF','PCA99', 'PCA999', 'PCA9999','FS_P','FS_K', 'LASSO', 'ELASTICNET']\n",
    "regression_types = ['svr', 'gbr', 'mlp']\n",
    "\n",
    "regression_tuning(dir_path, ft_type, ft_select, regression_types, \n",
    "                  feature_path='../datasets/results/features/februarie2025-v4/',\n",
    "                  #ranks_path='../datasets/results/ranks/runTime_1min_sa_ts_agregated_filtered')\n",
    "                  ranks_path='../datasets/results/ranks/runTime_1min_sa_ts_filtered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regression_type rfr\n",
      "(296, 17) (296, 8)\n",
      "******* Feature select: all  Feature type: ST-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.826416702934804\n",
      "R2 Best score (validation) val. score :  0.5517003729515654\n",
      "R2 of the best estimator (testing dataset):  0.28685148352739925\n",
      "(296, 10) (296, 8)\n",
      "******* Feature select: LR10  Feature type: ST-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.7872924925513877\n",
      "R2 Best score (validation) val. score :  0.4891042280318397\n",
      "R2 of the best estimator (testing dataset):  0.3442263001153031\n",
      "(296, 12) (296, 8)\n",
      "******* Feature select: FS_S  Feature type: ST-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.815027264549436\n",
      "R2 Best score (validation) val. score :  0.5476367804557845\n",
      "R2 of the best estimator (testing dataset):  0.3288490645960237\n",
      "(296, 17) (296, 8)\n",
      "******* Feature select: RF  Feature type: ST-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8260291564593368\n",
      "R2 Best score (validation) val. score :  0.5512463562665516\n",
      "R2 of the best estimator (testing dataset):  0.284705128882381\n",
      "(296, 11) (296, 8)\n",
      "******* Feature select: PCA99  Feature type: ST-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8117382484223927\n",
      "R2 Best score (validation) val. score :  0.4950356908190804\n",
      "R2 of the best estimator (testing dataset):  -0.008180650654317181\n",
      "(296, 12) (296, 8)\n",
      "******* Feature select: PCA999  Feature type: ST-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8053328789329259\n",
      "R2 Best score (validation) val. score :  0.4957580557338176\n",
      "R2 of the best estimator (testing dataset):  -0.00439460001371518\n",
      "(296, 13) (296, 8)\n",
      "******* Feature select: PCA9999  Feature type: ST-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8091651292159581\n",
      "R2 Best score (validation) val. score :  0.4987334212567148\n",
      "R2 of the best estimator (testing dataset):  0.02936176707923159\n",
      "(296, 12) (296, 8)\n",
      "******* Feature select: FS_P  Feature type: ST-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8049344166766419\n",
      "R2 Best score (validation) val. score :  0.5458557455076068\n",
      "R2 of the best estimator (testing dataset):  0.3308994996840363\n",
      "(296, 14) (296, 8)\n",
      "******* Feature select: FS_K  Feature type: ST-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8166617594233997\n",
      "R2 Best score (validation) val. score :  0.5489647448736749\n",
      "R2 of the best estimator (testing dataset):  0.29874862313227446\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dir_path = '../datasets/results/regression/ianuarie2025/'\n",
    "\n",
    "ft_type=['ST-F']\n",
    "ft_select=['all','LR10','FS_S','RF','PCA99', 'PCA999', 'PCA9999','FS_P','FS_K']\n",
    "regression_types = ['rfr']\n",
    "\n",
    "regression_tuning(dir_path, ft_type, ft_select, regression_types, \n",
    "                  feature_path='../datasets/results/features/februarie2025/',\n",
    "                  ranks_path='../datasets/results/ranks/runTime_1min_sa_ts_filtered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dir_path = '../datasets/results/regression/ianuarie2025/'\n",
    "\n",
    "ft_type=['ST-F']\n",
    "ft_select=['all','LR10','FS_S','RF','PCA99', 'PCA999', 'PCA9999','FS_P','FS_K']\n",
    "regression_types = ['rfr']\n",
    "\n",
    "regression_tuning(dir_path, ft_type, ft_select, regression_types, \n",
    "                  feature_path='../datasets/results/features/februarie2025/',\n",
    "                  ranks_path='../datasets/results/ranks/runTime_1min_sa_ts_filtered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regression_type rfr\n",
      "(296, 490) (296, 6)\n",
      "******* Feature select: all  Feature type: HG-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8785052622996864\n",
      "R2 Best score (validation) val. score :  0.6315493780768507\n",
      "R2 of the best estimator (testing dataset):  0.48408904626635874\n",
      "pred [4.45642092 4.4534887  4.50892685 4.52391972 4.41304323 4.6333517 ]\n",
      "pred [5.09624913 3.86813076 4.40930639 4.67926163 4.37386123 4.77639967]\n",
      "pred [3.85812071 5.17841158 4.10080381 4.9374888  3.45994457 5.46156752]\n",
      "pred [3.69991919 5.23943925 4.51724837 4.50023601 5.6275044  3.38953813]\n",
      "pred [4.55783554 4.60885559 3.38570518 5.59792118 3.56710517 5.33857672]\n",
      "pred [5.24375809 3.72046658 4.38447312 4.70048436 5.23018028 3.77268138]\n",
      "pred [4.37446972 4.63867275 4.4263197  4.63354026 4.44097759 4.5282693 ]\n",
      "pred [3.51831236 5.39925136 4.24690886 4.78056817 4.2138552  4.82935625]\n",
      "pred [4.57852435 4.44789047 4.51183985 4.570879   4.45535721 4.6332082 ]\n",
      "pred [4.5707265  4.38108582 4.47277798 4.55932695 4.36085478 4.71160039]\n",
      "pred [4.6267335  4.39590768 4.45631715 4.53493316 4.31502545 4.76605049]\n",
      "pred [4.17223944 4.79561046 4.44504161 4.54743099 4.56216762 4.35668293]\n",
      "pred [3.55015052 5.40109667 4.56105314 4.47847278 5.46740323 3.45770308]\n",
      "pred [3.37915426 5.56750985 4.19062965 4.89398115 3.77664981 5.16758622]\n",
      "pred [4.40884356 4.6140377  4.45826759 4.55549859 4.42196807 4.57268875]\n",
      "pred [4.61631948 4.5368635  3.96134491 5.04554702 3.92407618 5.0392358 ]\n",
      "pred [4.16358109 5.04339346 4.56067498 4.47748754 4.46943125 4.60496237]\n",
      "pred [4.21402737 4.82294044 4.42470243 4.55532801 4.63138011 4.4126713 ]\n",
      "pred [3.4142645  5.59800356 4.18753622 4.9097003  3.73692155 5.25491923]\n",
      "pred [4.78738565 4.22444895 4.48321623 4.49639118 4.22161659 5.08473009]\n",
      "pred [3.76489611 5.27950463 4.20037744 4.71579528 3.84706579 4.96630291]\n",
      "pred [4.09688017 4.84328487 4.45665228 4.51082485 4.34361709 4.62049016]\n",
      "pred [4.14509861 4.90350082 4.41768365 4.55538167 4.64777714 4.4522246 ]\n",
      "pred [4.14746726 4.70085643 4.31483961 4.74503322 5.63460771 3.62010478]\n",
      "pred [3.45509004 5.57204218 4.48216441 4.57581086 4.08901296 4.85354139]\n",
      "pred [3.82173269 5.09496959 4.2481411  4.73509394 4.32051834 4.62130876]\n",
      "pred [4.42398418 4.69111249 4.52671856 4.48405445 4.20111335 4.87717693]\n",
      "pred [4.66434375 4.37533646 4.43168716 4.52698319 4.30418169 4.76930327]\n",
      "pred [3.51879459 5.59467138 4.28712517 4.71713723 4.10981084 4.992308  ]\n",
      "pred [4.29698102 4.70175567 3.39464471 5.74495143 3.29419363 5.60546261]\n",
      "pred [4.59267894 4.61949324 3.33693584 5.86186104 3.75974288 5.11797598]\n",
      "pred [3.53721115 5.36039408 4.36345837 4.61533343 4.21609706 4.73372222]\n",
      "pred [4.27383733 4.9345935  4.04179294 5.00394821 3.67655967 5.3965623 ]\n",
      "pred [5.38977407 3.59454164 4.41385839 4.74100461 5.21292092 3.72198898]\n",
      "pred [4.03967117 4.87628046 4.46243954 4.60468997 4.01645989 4.90906662]\n",
      "pred [3.6117375  5.47683306 3.98759703 5.07037839 3.57711727 5.41412723]\n",
      "pred [3.31537585 5.80677983 4.38217572 4.66185902 4.09718599 4.89440751]\n",
      "pred [3.63467173 5.38150789 4.37177911 4.60344072 4.26996051 4.61501534]\n",
      "pred [4.28873028 4.76607316 4.48591521 4.4897165  4.2512924  4.74028234]\n",
      "pred [3.95719352 5.17568901 4.47842249 4.49788122 4.02058926 5.03263079]\n",
      "pred [4.9859509  4.06488809 4.33763212 4.82320166 5.16704319 3.99658506]\n",
      "pred [3.65755624 5.23719873 4.29437511 4.69043478 3.88545598 5.11835685]\n",
      "pred [4.48196357 4.59155091 4.50355273 4.55355137 4.93324485 4.38021069]\n",
      "pred [4.33566153 4.79066504 4.57639589 4.63459108 4.39987973 4.61360355]\n",
      "pred [3.71835064 5.02540407 4.43284654 4.49614304 4.04782712 5.08329246]\n",
      "pred [3.76789611 5.2466713  4.20521932 4.71579528 3.84706579 4.96630291]\n",
      "pred [4.66776657 4.2738751  4.40940188 4.58969017 4.42000725 4.54812659]\n",
      "pred [5.1862177  3.80886289 4.35422224 4.69443411 4.61639994 4.41844318]\n",
      "pred [4.14126119 4.97401152 4.37351282 4.614636   4.35616455 4.52988939]\n",
      "pred [4.44478783 4.68876825 4.59310092 4.51927759 4.41496288 4.56348486]\n",
      "pred [4.58208772 4.36263074 4.42482111 4.54580939 4.41716863 4.57381608]\n",
      "pred [3.1864991  5.70872317 4.42963545 4.63090645 3.99339201 4.98126475]\n",
      "pred [4.39288072 4.50984634 4.51440523 4.50891622 4.46668108 4.60540007]\n",
      "pred [3.85921371 5.07152471 4.31031531 4.74776262 3.62566888 5.4275438 ]\n",
      "pred [3.38876703 5.52410659 4.06311097 4.92962365 3.92701708 5.1576163 ]\n",
      "pred [3.61827878 5.34196879 4.24272576 4.78830866 3.73653061 5.35211992]\n",
      "pred [4.44203632 4.70041379 4.47626778 4.55002125 4.36118703 4.5846568 ]\n",
      "pred [3.38227128 5.47628032 4.31310227 4.78256516 3.9282949  5.00559616]\n",
      "pred [3.20272062 5.80795546 4.39101365 4.65238186 4.06774005 4.9012525 ]\n",
      "pred [4.05870601 5.05757868 4.19867508 4.74968981 4.19060411 4.72736493]\n",
      "pred [4.35977142 4.58838604 4.57569319 4.5021136  4.4161331  4.61230194]\n",
      "pred [3.51906345 5.27015336 4.35186874 4.73695392 4.05919603 4.91065359]\n",
      "(296, 302) (296, 6)\n",
      "******* Feature select: all  Feature type: OG-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8621735387491185\n",
      "R2 Best score (validation) val. score :  0.5865632842474167\n",
      "R2 of the best estimator (testing dataset):  0.444654680427312\n",
      "pred [4.66976371 4.32346429 4.4340644  4.57334063 4.38440548 4.62178762]\n",
      "pred [5.17338435 3.79167408 4.41981594 4.54842185 4.77583755 4.37084432]\n",
      "pred [3.88280927 5.0987491  4.04980929 5.05504334 3.4209761  5.66306835]\n",
      "pred [3.65014211 5.27893426 4.53951754 4.48767251 5.60587391 3.37046304]\n",
      "pred [4.2805021  4.81331891 3.71117045 5.43899516 3.46257035 5.66804068]\n",
      "pred [5.29049114 3.67483403 4.31542066 4.60431929 5.27952785 3.86241811]\n",
      "pred [4.12693091 4.78914871 4.38347132 4.60898592 4.40373392 4.59850457]\n",
      "pred [3.81508485 5.19989014 4.38604878 4.61975684 4.45806867 4.56649127]\n",
      "pred [4.16290144 4.72410875 4.22336748 4.81409401 4.28802171 4.65733041]\n",
      "pred [4.77336092 4.25034736 4.45027792 4.56231572 4.37029531 4.63213404]\n",
      "pred [4.71463546 4.27900894 4.40576366 4.55970189 4.25540208 4.73344601]\n",
      "pred [4.25560165 4.7926037  4.40922651 4.57313348 4.47030941 4.58138178]\n",
      "pred [3.5281629  5.32927623 4.54972805 4.46791132 5.50513053 3.40802041]\n",
      "pred [3.92511969 5.08622918 3.84471723 5.11406281 3.94135359 5.06864124]\n",
      "pred [4.41250375 4.55376641 4.12618507 4.84634983 4.27611173 4.67105421]\n",
      "pred [4.59251378 4.48920155 3.67542312 5.38582684 3.64796079 5.44444246]\n",
      "pred [3.95934695 5.05216722 4.46745878 4.5701561  4.41617041 4.59555659]\n",
      "pred [4.23830465 4.87664242 4.35325714 4.61209354 4.44553743 4.5045654 ]\n",
      "pred [3.89389747 5.09923057 3.84344693 5.11803677 3.98826957 5.07940641]\n",
      "pred [4.54958583 4.46764158 4.48963516 4.49460292 3.50027601 5.44587518]\n",
      "pred [3.87079136 5.27761278 4.36707927 4.61749324 4.0797906  4.83614553]\n",
      "pred [4.00730127 4.92128081 4.44304052 4.56444921 4.42470419 4.57090653]\n",
      "pred [4.19234162 4.93619398 4.34893143 4.62015174 4.43833014 4.51973765]\n",
      "pred [4.48690308 4.56228691 4.38665218 4.60226755 5.41269134 3.51420003]\n",
      "pred [3.68387832 5.32241158 4.3866199  4.56522167 4.27285252 4.78157666]\n",
      "pred [4.04923732 5.07930041 4.36256557 4.62102417 4.46861534 4.5388383 ]\n",
      "pred [4.23733451 4.70182498 4.48292514 4.51140194 4.19545237 4.75486037]\n",
      "pred [4.81073326 4.22847283 4.40632028 4.5713598  4.26155751 4.73587834]\n",
      "pred [3.4392308  5.72383998 4.07091745 4.84986715 4.06184212 4.99280233]\n",
      "pred [4.34756676 4.82682832 3.69575599 5.32756786 3.24689197 5.83271268]\n",
      "pred [4.66184698 4.41917246 3.19369657 5.89475303 3.66690226 5.19589035]\n",
      "pred [3.61442561 5.34711168 4.36827809 4.60761535 4.4315224  4.61175286]\n",
      "pred [4.0822852  4.80566252 3.99289669 4.97544986 3.52004125 5.56567526]\n",
      "pred [5.42899103 3.60678885 4.41677308 4.55132559 5.44291703 3.70514186]\n",
      "pred [4.05052418 4.98244233 4.25619759 4.73835654 3.6945147  5.39531346]\n",
      "pred [3.84409685 5.17863733 3.79944689 5.19007435 3.66086452 5.37922032]\n",
      "pred [3.54652086 5.59261388 4.32324326 4.64151283 4.23032692 4.84260898]\n",
      "pred [3.66693273 5.34744911 4.44220476 4.59399305 4.39503706 4.60275336]\n",
      "pred [4.25078528 4.73656933 4.50967703 4.5248493  4.14781473 4.83917205]\n",
      "pred [3.9534522  5.05255605 4.42394956 4.63372006 4.09329126 4.90899681]\n",
      "pred [5.03538619 4.03298371 4.37581587 4.5837256  5.06062349 4.15950206]\n",
      "pred [3.72513511 5.32696327 4.32306627 4.6558995  3.96958449 5.03963996]\n",
      "pred [4.37008165 4.65429048 4.50456127 4.49052242 4.2590239  4.64414329]\n",
      "pred [4.02871319 5.00571147 4.00091382 5.00153989 4.20205104 4.81525532]\n",
      "pred [3.88135382 5.10391944 4.41299902 4.60356128 4.21189965 4.78503812]\n",
      "pred [3.87939255 5.27539419 4.35875234 4.61749324 4.0797906  4.83614553]\n",
      "pred [4.36657947 4.52425304 4.35524881 4.60216852 4.39635606 4.56232797]\n",
      "pred [5.25416534 3.75895583 4.33456769 4.60081979 4.85508362 4.22155298]\n",
      "pred [4.3579329  4.57684473 4.37178972 4.6076597  4.49320136 4.56985171]\n",
      "pred [4.15787094 4.81829558 4.4395864  4.52121041 4.29597321 4.61818653]\n",
      "pred [4.33432904 4.57831186 4.38385374 4.57558256 4.40350319 4.58348661]\n",
      "pred [3.46649184 5.63046358 4.35632802 4.58587671 4.01009078 4.96058772]\n",
      "pred [4.87802864 4.15644623 4.44082224 4.56527549 4.42286236 4.5937856 ]\n",
      "pred [3.99447301 4.98179854 4.24776262 4.85053158 3.52385007 5.62592793]\n",
      "pred [3.45152729 5.66838606 3.80400041 5.1349459  3.98641497 5.12046232]\n",
      "pred [3.87430433 5.17200811 4.00425847 5.05862233 3.67308499 5.43162954]\n",
      "pred [4.12471214 4.78268298 4.46641292 4.51015455 4.20182071 4.78607166]\n",
      "pred [3.82774854 5.10723069 3.9620756  5.05201316 4.06461514 4.9543296 ]\n",
      "pred [3.4098034  5.61853957 4.39266322 4.57408996 4.12511231 4.94484184]\n",
      "pred [4.02037679 4.98234137 4.43485264 4.60561887 4.35879009 4.63398956]\n",
      "pred [4.0663068  4.94620367 4.1156343  4.85233147 4.24379074 4.73151466]\n",
      "pred [3.51741734 5.44838088 4.40536253 4.57405687 4.27156731 4.7990929 ]\n",
      "(296, 119) (296, 6)\n",
      "******* Feature select: all  Feature type: ST-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8690080584220615\n",
      "R2 Best score (validation) val. score :  0.6207129318390253\n",
      "R2 of the best estimator (testing dataset):  0.407303613747717\n",
      "pred [4.60711584 4.36887584 4.49406929 4.50666539 4.38416716 4.65665418]\n",
      "pred [5.09735323 3.9008892  4.48020818 4.55133394 4.37091471 4.52344575]\n",
      "pred [3.77185428 5.38878806 4.18996979 4.8487058  3.41281932 5.64286806]\n",
      "pred [3.60936188 5.46408512 4.54852976 4.45492208 5.24601331 3.62142825]\n",
      "pred [4.42282896 4.71644911 4.0632314  5.15139204 3.26333361 5.69572528]\n",
      "pred [5.16634957 3.82190193 4.42344977 4.53439592 5.09640628 3.91519762]\n",
      "pred [4.27194171 4.76963079 4.30530714 4.65797772 4.37199334 4.58728025]\n",
      "pred [3.87528603 5.17579581 4.2295951  4.83549881 4.17408912 4.87060465]\n",
      "pred [4.33256882 4.8769041  4.46505602 4.62692232 4.36834809 4.50845127]\n",
      "pred [4.67355823 4.34552359 4.4754879  4.521765   4.37105571 4.57733469]\n",
      "pred [4.62027861 4.4165225  4.48110244 4.53907939 4.33169052 4.66494968]\n",
      "pred [4.22815558 4.79618255 4.4414216  4.5520765  4.43038126 4.52961374]\n",
      "pred [3.44672786 5.52898315 4.57822726 4.42363091 4.4526631  4.31845704]\n",
      "pred [3.42623243 5.534911   4.22800943 4.72724479 3.9896994  4.9884146 ]\n",
      "pred [4.21542264 4.93723046 4.46326406 4.66203428 4.3628405  4.62059281]\n",
      "pred [4.32300492 4.74698913 4.3055499  4.69305461 4.10716986 4.88315096]\n",
      "pred [3.45534179 5.61632512 4.44580915 4.561188   4.38886573 4.64945452]\n",
      "pred [4.25033053 4.63495966 4.4736668  4.56749264 4.55255642 4.38842576]\n",
      "pred [3.44190944 5.51802484 4.21572125 4.72340307 4.03259856 4.9361401 ]\n",
      "pred [5.03254551 4.0166182  4.4681497  4.54220377 3.696544   5.2781377 ]\n",
      "pred [4.03975044 5.03601838 4.20242694 4.89067431 3.90865413 5.16461724]\n",
      "pred [3.73368488 5.41923837 4.28848026 4.67865609 4.21160771 4.81501316]\n",
      "pred [4.09248492 4.71738447 4.46884457 4.543882   4.39492666 4.53065225]\n",
      "pred [4.75509525 4.1844041  4.47758679 4.53191296 5.58760333 3.64343068]\n",
      "pred [3.68436069 5.27688274 4.46474256 4.57014381 4.18963763 4.7299151 ]\n",
      "pred [3.94588295 5.04223104 4.18617484 4.82525317 4.30978474 4.72633646]\n",
      "pred [4.23824658 4.80460956 4.47595624 4.55268359 4.15137683 4.91614567]\n",
      "pred [4.4870885  4.45523131 4.48350567 4.53388997 4.32479677 4.66932074]\n",
      "pred [3.78473656 5.29941127 4.16730571 4.91236596 4.10598291 4.89025848]\n",
      "pred [4.32230006 4.76061238 3.60493071 5.51725981 3.16286031 5.88511964]\n",
      "pred [4.24184224 4.83773308 3.35466588 5.62290328 3.46740295 5.54422912]\n",
      "pred [3.38037075 5.72753148 4.3976905  4.55216276 4.14971171 4.87985668]\n",
      "pred [4.34309343 4.76305682 4.07111126 5.10365696 3.50070166 5.38979631]\n",
      "pred [5.22070753 3.74897046 4.42609474 4.55442784 5.02731555 4.13297697]\n",
      "pred [4.12067419 4.81121361 4.34302417 4.64051824 4.12633324 4.9586978 ]\n",
      "pred [3.5608798  5.50386403 4.17540184 4.77517484 3.87874133 5.14813548]\n",
      "pred [3.36029455 5.60866598 4.46567462 4.54701878 4.091694   4.88116738]\n",
      "pred [3.73210313 5.33382663 4.43885457 4.57726662 4.28290566 4.71885991]\n",
      "pred [4.38845364 4.71164333 4.46274807 4.56997457 4.25343003 4.82878446]\n",
      "pred [3.68135772 5.38399938 4.52199646 4.54326259 4.19479531 4.91829749]\n",
      "pred [5.11999966 3.97719789 4.41662467 4.57386474 4.89779784 4.32259299]\n",
      "pred [4.042536   5.02266881 4.2837175  4.78350129 3.79542411 5.20106739]\n",
      "pred [4.78769406 4.3495552  4.48839977 4.51962722 3.7205183  5.14777144]\n",
      "pred [4.11271092 4.93733695 4.48217121 4.56206327 4.27964589 4.73127024]\n",
      "pred [3.60866561 5.48973388 4.30082319 4.73923692 4.16273355 4.9716393 ]\n",
      "pred [4.06229913 5.03845237 4.18652577 4.92152653 3.90441924 5.16461724]\n",
      "pred [4.33698337 4.66977644 4.43693428 4.57107774 4.30434443 4.53520566]\n",
      "pred [5.18512913 3.88260628 4.42668249 4.55255659 4.54788791 4.37687576]\n",
      "pred [4.24005666 4.77000478 4.45108586 4.52532045 4.50599545 4.5219502 ]\n",
      "pred [4.13874465 4.88615101 4.56567178 4.47868161 4.26885793 4.75358922]\n",
      "pred [4.33754472 4.72558761 4.415653   4.60464393 4.39388477 4.4810294 ]\n",
      "pred [3.38517637 5.5565591  4.44838038 4.61287062 4.11278068 4.83154104]\n",
      "pred [4.58580851 4.32256744 4.49442785 4.49748609 4.34957548 4.64127611]\n",
      "pred [3.43774949 5.56236531 4.22734693 4.79007602 3.48758717 5.50126433]\n",
      "pred [3.72227047 5.39761036 4.03897863 5.00673457 3.88807646 4.98728068]\n",
      "pred [3.65099214 5.53960413 4.14337364 4.75854699 3.65736815 5.35973626]\n",
      "pred [4.47074655 4.6290707  4.42851168 4.58140411 4.18399362 4.83389254]\n",
      "pred [3.53206563 5.52215609 4.23141165 4.74007622 4.04354884 4.85088765]\n",
      "pred [3.39640615 5.53485845 4.4854864  4.52099055 4.12215313 4.8559224 ]\n",
      "pred [4.14648982 4.92171874 4.18740734 4.9713371  4.10003898 4.96819636]\n",
      "pred [4.14845887 4.84650588 4.46727662 4.55862945 4.34034515 4.64640982]\n",
      "pred [3.90964462 5.22345299 4.30314209 4.8218792  3.83963341 5.1157879 ]\n",
      "(296, 124) (296, 6)\n",
      "******* Feature select: PCA999  Feature type: HG-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8369937113781085\n",
      "R2 Best score (validation) val. score :  0.4725238983682088\n",
      "R2 of the best estimator (testing dataset):  0.039478012417764365\n",
      "pred [4.08325404 4.90256474 4.20769206 4.88849121 4.1810881  4.80264973]\n",
      "pred [4.44228779 4.6586573  4.0431373  5.0109598  4.13701463 4.66756052]\n",
      "pred [3.91365187 4.98695684 3.93415399 4.94331187 4.05943285 4.93790173]\n",
      "pred [3.9546288  5.03425701 4.01985796 5.049998   4.90320089 4.13642392]\n",
      "pred [4.18977684 4.86107253 3.78852035 5.1050218  4.00458442 4.93140953]\n",
      "pred [4.51767948 4.62581195 4.12586152 4.90735105 4.39728921 4.40625352]\n",
      "pred [4.1602607  4.87395938 4.10651757 4.8937119  4.2894552  4.59022761]\n",
      "pred [3.94143142 5.03175716 4.01991175 4.98804254 4.213983   4.7219842 ]\n",
      "pred [3.8766698  5.05011304 4.01335875 5.02382118 4.07991712 4.63375068]\n",
      "pred [4.15427346 4.76358634 4.19400595 4.87715871 4.12947136 4.84255   ]\n",
      "pred [4.23313412 4.76790026 4.14905051 4.89295798 4.1872524  4.71564355]\n",
      "pred [3.97495078 4.92022497 4.07245846 4.82092863 4.29550383 4.6130582 ]\n",
      "pred [3.94025242 4.9749794  4.16786654 4.97619864 4.68434583 4.15356591]\n",
      "pred [3.7809236  5.0715592  4.1715597  4.87904807 4.04903234 4.84299052]\n",
      "pred [4.11055821 4.87140422 4.041465   5.03968474 4.06205446 4.80042927]\n",
      "pred [4.07114718 4.94128795 4.04391573 4.94294146 4.03112399 4.76029421]\n",
      "pred [4.02441876 4.98778283 4.07896711 4.97712392 4.23587162 4.74316031]\n",
      "pred [4.07412889 4.83202459 4.18133308 4.91266831 4.28996484 4.59513985]\n",
      "pred [3.73612041 5.07564367 4.12194143 4.9140044  4.09046825 4.79262802]\n",
      "pred [4.41813204 4.62397043 4.03631751 5.08636294 4.24157092 4.77839815]\n",
      "pred [4.03080372 4.81515214 4.04753221 4.82173981 3.93839949 4.85455912]\n",
      "pred [4.12368774 5.06281508 4.10667125 4.91131801 4.16881319 4.54220243]\n",
      "pred [4.07342628 4.84734728 4.3034403  4.77212613 4.33718497 4.59954368]\n",
      "pred [3.91290959 4.88864153 3.99441766 5.00987775 4.67663499 4.23500734]\n",
      "pred [3.72966653 5.17627824 4.24397162 4.84736719 4.09192839 4.64518277]\n",
      "pred [3.99000097 4.85508785 4.02000239 4.89986274 4.31441791 4.56291519]\n",
      "pred [4.16189912 4.72503941 4.17429386 4.90754707 4.43368715 4.49444212]\n",
      "pred [4.08093494 4.74455812 4.19342375 4.85449466 4.15678907 4.76962228]\n",
      "pred [3.82460159 5.19038247 4.17741284 4.80933068 4.26541093 4.66862948]\n",
      "pred [4.14402423 4.91964524 3.77679963 5.25006486 3.73389668 5.03082112]\n",
      "pred [4.10902821 4.88012512 3.74895845 5.14300171 4.25370148 4.82833433]\n",
      "pred [4.04900957 4.74533413 3.96563529 5.04205524 4.26128414 4.63378226]\n",
      "pred [4.00903486 4.85610174 3.90698397 4.98397143 3.98080614 4.84062863]\n",
      "pred [4.55941312 4.60524886 4.12282868 4.80710822 4.5221276  4.06239972]\n",
      "pred [4.0223045  4.94047783 4.07196182 5.01009086 4.09508525 4.78985838]\n",
      "pred [3.71267712 5.10344281 4.06039685 4.9849694  3.93635411 5.041665  ]\n",
      "pred [3.76597523 5.18543005 4.17960589 4.83096376 4.19187867 4.66046318]\n",
      "pred [3.91901512 4.91499301 4.03516789 5.00407221 4.15778051 4.62958491]\n",
      "pred [4.16489418 4.81915781 4.10985808 4.90479639 4.23886787 4.65159808]\n",
      "pred [3.83753828 5.11080524 4.10705696 4.83683809 4.05243516 4.7991976 ]\n",
      "pred [4.43175    4.72358513 4.13246045 4.92805404 4.40077538 4.41143471]\n",
      "pred [3.8049329  4.99416824 4.10275121 4.88450403 3.88650099 5.02440106]\n",
      "pred [4.1235417  4.83927881 4.18627062 4.94713105 4.1477338  4.78218722]\n",
      "pred [4.05484594 4.96210217 4.14446774 4.99850757 4.32744046 4.52985964]\n",
      "pred [3.9986305  4.94350322 4.14191932 4.83299083 4.20484753 4.73437839]\n",
      "pred [3.98746093 4.78015154 4.02944465 4.88285785 3.89567328 4.88461669]\n",
      "pred [4.15227722 4.70874368 4.01054524 5.0180561  4.14888938 4.7723277 ]\n",
      "pred [4.50586877 4.65580578 4.05465447 5.00637514 4.28517983 4.51247603]\n",
      "pred [3.90080374 4.97055798 3.9547332  5.02625623 4.34948218 4.58174448]\n",
      "pred [4.01799149 4.91567616 4.15828437 4.86014194 4.11941376 4.71159799]\n",
      "pred [4.25378775 4.87827814 4.07057521 4.98380416 4.27242836 4.64739639]\n",
      "pred [3.53855647 5.33526472 4.15255035 4.87379337 3.98500409 4.88869852]\n",
      "pred [4.11019873 4.90781336 4.13644881 4.94394341 4.17336083 4.77539236]\n",
      "pred [3.97601599 5.11769374 4.09654343 4.89991762 4.11179605 4.75036065]\n",
      "pred [3.87127106 5.07975991 4.04793342 5.01826588 4.12962274 4.81276266]\n",
      "pred [3.92607417 4.99450541 3.86544893 5.17188021 4.19981033 4.69831279]\n",
      "pred [4.29542354 4.80980708 4.10987892 4.88205934 4.31461669 4.59215974]\n",
      "pred [3.69696095 5.2023181  4.17841467 4.87192583 4.08927837 4.82322603]\n",
      "pred [3.72674252 5.13951845 4.14856017 4.80924265 4.0912527  4.87577507]\n",
      "pred [3.90907207 4.95593413 3.95757647 5.00191491 4.13187635 4.70807588]\n",
      "pred [4.12351374 4.89788155 4.08595708 4.9077137  4.11747958 4.68741912]\n",
      "pred [3.88465042 5.14388579 4.16227372 4.79771843 4.02323541 4.88021249]\n",
      "(296, 81) (296, 6)\n",
      "******* Feature select: PCA999  Feature type: OG-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8389737495572556\n",
      "R2 Best score (validation) val. score :  0.4599735048990873\n",
      "R2 of the best estimator (testing dataset):  0.14484230206769627\n",
      "pred [4.3497679  4.77077264 4.27931763 4.87809468 4.4830539  4.40138007]\n",
      "pred [4.51246927 4.55708853 4.20853429 4.97939703 4.48691694 4.63549909]\n",
      "pred [3.89172182 4.90279556 4.17891146 5.00575088 4.20286673 4.96419508]\n",
      "pred [4.06332315 4.86822634 4.37532489 4.71584803 4.93231678 4.04121087]\n",
      "pred [4.17700083 4.84218568 3.85088665 5.26011656 4.08845227 4.97596748]\n",
      "pred [4.49451537 4.46333145 4.22608488 4.91141406 5.04490658 3.94802163]\n",
      "pred [4.12914194 4.78529106 4.11014402 5.00692718 4.43886012 4.64754953]\n",
      "pred [4.0910082  5.03182686 4.23139851 4.81694774 4.3688337  4.67942866]\n",
      "pred [4.21431682 4.83007153 4.27957984 4.76373421 4.61097974 4.53414829]\n",
      "pred [4.30832881 4.73176932 4.38520631 4.76247469 4.49685492 4.52392827]\n",
      "pred [4.23792466 4.72433283 4.30130556 4.80315743 4.41835338 4.64908215]\n",
      "pred [4.07709435 4.76999053 4.30165283 4.73655206 4.43823427 4.6773544 ]\n",
      "pred [3.90566997 5.0899953  4.3888071  4.70468455 4.82451203 4.19918199]\n",
      "pred [3.78854642 5.13677743 4.19245585 4.91262338 4.33009279 4.68865574]\n",
      "pred [4.08812436 4.90242757 4.26689039 4.84645972 4.35575094 4.77763861]\n",
      "pred [4.10479373 4.83918003 4.22442719 4.8360904  4.18435218 4.8234066 ]\n",
      "pred [3.96648542 4.87126686 4.29946932 4.71861603 4.27835364 4.89564468]\n",
      "pred [3.98746032 4.91537655 4.29591021 4.7355884  4.49190176 4.6471982 ]\n",
      "pred [3.72708769 5.17481757 4.15339421 4.88434066 4.31343311 4.70479502]\n",
      "pred [4.31985524 4.57012989 4.26584493 4.9185437  4.20098998 4.9934092 ]\n",
      "pred [3.89867226 4.945391   4.36692246 4.73949344 4.29322056 4.8050531 ]\n",
      "pred [3.98490547 4.92883166 4.3090488  4.75637729 4.41533456 4.50612906]\n",
      "pred [3.94703455 5.03352595 4.28653688 4.7461126  4.46476908 4.61593003]\n",
      "pred [4.31583145 4.76381328 4.17913561 4.94316245 4.99997368 3.9369736 ]\n",
      "pred [3.73749982 5.24705201 4.31510046 4.92004998 4.48438606 4.52329209]\n",
      "pred [4.2425239  4.9383415  4.22356693 4.87295344 4.68220335 4.41106092]\n",
      "pred [3.90307621 5.0045087  4.09684374 4.92585882 4.39286866 4.59525461]\n",
      "pred [4.24106046 4.74406974 4.32670989 4.79812574 4.41740281 4.66859023]\n",
      "pred [3.78795926 5.22056046 4.12570255 4.9955658  4.31960746 4.70649165]\n",
      "pred [4.09107454 4.7868347  3.78266406 5.3249008  4.23771422 4.94703159]\n",
      "pred [4.18108791 4.87034824 3.88168475 5.17298036 4.20011504 4.87090989]\n",
      "pred [3.99256287 5.09654189 4.24381448 4.74908192 4.48793203 4.56884111]\n",
      "pred [3.93800701 5.06986834 4.15536924 5.13457092 4.06792083 5.0553664 ]\n",
      "pred [4.47600281 4.47532875 4.26725239 4.944304   5.1164857  3.97426203]\n",
      "pred [4.09415562 4.91169241 4.23935805 4.94202715 4.26595859 4.85875807]\n",
      "pred [3.74858356 5.11282916 4.10411803 4.97518273 4.31991942 4.69490533]\n",
      "pred [3.70334904 5.16869025 4.2694137  4.87136573 4.57888268 4.54738811]\n",
      "pred [4.04129288 5.0222004  4.22483485 4.87126066 4.5069433  4.60016469]\n",
      "pred [4.01396365 4.99391921 4.30651194 4.74929331 4.40538055 4.70370994]\n",
      "pred [3.92108075 4.96026824 4.25315052 4.77095209 4.27458116 4.86315922]\n",
      "pred [4.46003012 4.51163393 4.26238551 4.87848363 4.92989954 4.20023711]\n",
      "pred [3.79803597 5.02523165 4.30103835 4.75729839 4.15878071 4.84123891]\n",
      "pred [4.16581187 4.77760297 4.25926009 4.88593856 4.33176683 4.65892249]\n",
      "pred [3.94868183 4.99963182 4.07110938 4.91872829 4.43773622 4.71877919]\n",
      "pred [3.96311102 4.93318652 4.24682462 4.82657108 4.30367095 4.79712549]\n",
      "pred [3.90274702 4.96805219 4.35950066 4.75245129 4.31564738 4.77810299]\n",
      "pred [4.16220573 4.63733448 4.39046344 4.79907983 4.53922471 4.59663555]\n",
      "pred [4.45914522 4.47031889 4.17729996 4.96530325 4.63192212 4.48035815]\n",
      "pred [4.15423379 4.88410754 4.12035025 4.78364693 4.40229252 4.66745884]\n",
      "pred [4.0715103  4.92793693 4.2779457  4.83092407 4.49299111 4.54919967]\n",
      "pred [4.37026172 4.61214613 4.28368168 4.8262984  4.67148898 4.3969113 ]\n",
      "pred [3.82778148 5.2706755  4.3286635  4.85304245 4.35280848 4.62736909]\n",
      "pred [4.36979982 4.7495437  4.36646133 4.7500482  4.48145171 4.59333456]\n",
      "pred [3.89726371 5.05509473 4.10082073 4.97449828 4.09916912 4.97240162]\n",
      "pred [3.87087346 5.25103192 4.06077087 5.08379131 4.45966536 4.57475793]\n",
      "pred [4.01636182 4.86464602 4.14333058 5.00536981 4.27805514 4.7117956 ]\n",
      "pred [4.14183325 4.96468768 4.29227792 4.78290291 4.54685326 4.53304641]\n",
      "pred [3.85775285 4.96611411 4.26745603 4.83093699 4.35297608 4.69262878]\n",
      "pred [3.75932245 5.26382199 4.25188067 4.81961077 4.39795294 4.58236452]\n",
      "pred [3.89687781 4.99551485 4.26916926 4.89736011 4.31341776 4.63018297]\n",
      "pred [4.02601322 4.93534441 4.30753821 4.79626523 4.3367445  4.68167508]\n",
      "pred [3.82675579 5.20260499 4.30782522 4.78839    4.30781506 4.6062783 ]\n",
      "(296, 60) (296, 6)\n",
      "******* Feature select: PCA999  Feature type: ST-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8042871784884232\n",
      "R2 Best score (validation) val. score :  0.3912912240503505\n",
      "R2 of the best estimator (testing dataset):  0.08304391990241122\n",
      "pred [4.1570529  5.01043565 4.00698289 4.87330927 4.35689671 4.740566  ]\n",
      "pred [4.67869796 4.30004333 4.20864794 4.81366301 4.07683266 4.98479894]\n",
      "pred [3.78093793 4.88782049 3.99658725 5.10478186 3.86132421 5.03610805]\n",
      "pred [3.88810936 5.09773138 4.04361215 4.99519342 4.60735456 4.3562519 ]\n",
      "pred [3.95680261 4.84676489 3.87359816 5.1154673  3.92040984 5.05234338]\n",
      "pred [4.69171282 4.45988013 4.09509398 4.71287864 4.64100505 4.45961183]\n",
      "pred [4.26944827 4.86966767 3.99609234 5.09097486 4.27210609 4.95691598]\n",
      "pred [4.03348621 4.84915209 3.87910131 5.00849702 4.20394397 4.99863278]\n",
      "pred [4.26108894 4.73582235 3.91439649 4.97535453 4.48430367 4.71784149]\n",
      "pred [4.12929192 4.89826482 4.07127095 4.84142003 4.12488389 4.97320747]\n",
      "pred [4.14643224 4.92261458 4.20503234 4.77616872 4.23022023 4.9554244 ]\n",
      "pred [4.05905479 4.89040468 3.98761304 5.05253669 4.29694395 4.84355216]\n",
      "pred [3.80565264 5.04896731 4.15220876 4.86836262 4.65173682 4.59102262]\n",
      "pred [3.71237807 4.91546672 3.96786041 4.97818981 4.03381944 4.9859826 ]\n",
      "pred [4.30244177 4.69890259 4.27757813 4.7899282  4.1973544  4.77803471]\n",
      "pred [4.23186193 4.72674721 4.04135971 5.09944687 4.13555685 4.90619357]\n",
      "pred [3.66966918 5.33984258 3.96882263 4.98734795 4.13243868 4.86354894]\n",
      "pred [4.1589139  4.65929662 4.16162788 4.71746515 4.30579923 4.55235832]\n",
      "pred [3.71822573 4.96855273 4.01935363 4.85694584 3.99223627 4.9579984 ]\n",
      "pred [4.61436225 4.5328782  4.0529312  4.86042055 4.06530224 4.87355846]\n",
      "pred [3.86963046 5.09884171 4.1215214  4.89875782 4.16979977 5.00586388]\n",
      "pred [3.91572115 5.09035132 4.04101058 4.92260092 3.94608817 5.21565455]\n",
      "pred [4.15425    4.72583102 4.21524035 4.58469994 4.32425798 4.67366869]\n",
      "pred [4.0948797  4.94478326 3.99892046 5.11296952 4.50368106 4.55689801]\n",
      "pred [4.08360846 5.05671572 4.02397967 4.88928983 4.16335945 4.87530312]\n",
      "pred [3.7895068  4.88539783 4.19752383 4.75750941 4.23329138 4.7288259 ]\n",
      "pred [3.99055712 4.97312723 4.15523372 4.87581604 4.24357333 4.74422889]\n",
      "pred [4.13911374 4.88420712 4.19825556 4.79601946 4.28569666 4.92997942]\n",
      "pred [3.57621387 5.49482394 4.08500719 4.99784122 4.1603963  4.92517739]\n",
      "pred [3.76827135 5.14866314 3.72997668 5.11297392 3.7628985  5.48283995]\n",
      "pred [4.09930001 4.95954294 3.62034414 5.25775673 4.24073191 4.84384836]\n",
      "pred [3.7315588  5.09930523 3.92977712 4.89676995 3.94337291 5.10374894]\n",
      "pred [3.98111058 4.85568695 3.79512411 5.07544219 4.05980415 4.95257601]\n",
      "pred [4.64053968 4.35601748 3.90817922 4.83932384 4.95903802 4.15315836]\n",
      "pred [3.79421264 5.07279402 4.05641422 5.11055789 3.98568052 5.04921764]\n",
      "pred [3.77413923 4.99589753 3.92996642 4.99770609 3.91452484 5.20411088]\n",
      "pred [3.58735383 5.31933376 4.39271997 4.67470276 4.0448575  4.80190671]\n",
      "pred [3.91759716 4.82502188 3.99597086 4.76108871 3.96654901 5.09549683]\n",
      "pred [4.00680629 4.96590796 3.95003768 4.79781949 4.12163095 4.69903674]\n",
      "pred [3.72025945 4.98944584 4.24336601 4.70894649 3.93001764 5.14733511]\n",
      "pred [4.14876393 4.50757719 4.0716222  4.94157614 4.43277951 4.62600859]\n",
      "pred [3.82175979 5.0367403  4.13332753 5.07589469 3.9470329  5.08042431]\n",
      "pred [4.19947833 4.68407728 4.0446798  4.95745572 4.26881194 4.74921122]\n",
      "pred [3.80668494 5.0913425  4.11531323 5.14344823 3.90633198 4.87960069]\n",
      "pred [3.69063489 4.91849575 4.10573856 5.01531423 4.04615541 5.14519661]\n",
      "pred [3.71875024 5.06322052 4.00080878 5.0487668  4.1380465  4.98585762]\n",
      "pred [4.3441927  4.70211485 4.16602357 4.9389849  4.37690157 4.70476372]\n",
      "pred [4.74735776 4.37144756 4.22050924 4.79839841 4.41142595 4.81807035]\n",
      "pred [4.07229852 4.71795357 4.03533623 5.07714346 4.25332002 4.59009942]\n",
      "pred [3.82074897 4.72952137 3.98048737 5.33754764 3.99817912 4.88783329]\n",
      "pred [4.36176715 4.66795653 4.11465381 4.92684947 4.37083205 4.511866  ]\n",
      "pred [3.65892204 5.17331776 4.2913269  4.60597334 4.12376165 4.79835143]\n",
      "pred [4.09973254 4.79054332 4.0942465  5.01597579 4.15375703 4.90216498]\n",
      "pred [3.76582075 4.90799328 4.06960933 5.02479229 3.91304584 4.99315778]\n",
      "pred [3.59626076 5.12559609 4.0595393  4.97838569 4.10701607 4.9381781 ]\n",
      "pred [4.11746914 5.07421019 3.83056995 5.38599828 3.99230841 4.9028562 ]\n",
      "pred [3.98543166 4.95032193 4.03965201 4.82817206 4.11628526 4.70664329]\n",
      "pred [3.81680094 4.97180082 3.97492317 4.97881446 3.97645253 4.97075931]\n",
      "pred [3.61364154 5.19109395 4.3468729  4.71226752 4.11847806 4.69981487]\n",
      "pred [3.94573831 5.17608712 3.92718538 5.07317633 4.13232452 4.90546785]\n",
      "pred [4.12326038 4.88031568 4.15409335 4.79312463 4.2964566  4.90151743]\n",
      "pred [3.69722881 5.15923938 4.14176645 4.85383825 4.09876581 4.82150846]\n",
      "(296, 10) (296, 6)\n",
      "******* Feature select: LR10  Feature type: HG-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.7735211765804612\n",
      "R2 Best score (validation) val. score :  0.49781998456026777\n",
      "R2 of the best estimator (testing dataset):  0.40754026138698923\n",
      "pred [4.35390772 4.6530175  4.40140806 4.56320358 4.26518031 4.73075422]\n",
      "pred [5.24450433 3.79699467 4.47080806 4.52789146 4.48122174 4.51225323]\n",
      "pred [4.25120792 4.7903846  3.30652071 5.71290812 3.50864665 5.50506087]\n",
      "pred [3.69125652 5.22050186 4.53860184 4.46019498 5.56647274 3.47415091]\n",
      "pred [4.41817552 4.54398608 3.37221673 5.72502099 3.09051134 5.93844193]\n",
      "pred [5.27904844 3.74103112 4.51090481 4.481235   5.02938606 3.88488051]\n",
      "pred [4.05094331 4.99802666 4.366444   4.66750393 4.39501631 4.62364904]\n",
      "pred [3.91462204 5.04348607 4.2921733  4.75005416 4.01563587 4.92461323]\n",
      "pred [4.52322505 4.36245848 4.40542377 4.57964408 4.41519781 4.56616188]\n",
      "pred [4.43096216 4.4335425  4.4659787  4.5531463  4.31675107 4.7304688 ]\n",
      "pred [4.46765524 4.43743106 4.45379739 4.57009924 4.24800407 4.77717414]\n",
      "pred [3.84612594 5.06913231 4.35995937 4.6601189  4.23821168 4.78262244]\n",
      "pred [3.52681151 5.3890919  4.50072382 4.48239334 5.45936556 3.48852174]\n",
      "pred [3.31521085 5.68912333 3.91684028 5.00362222 3.6982654  5.36241111]\n",
      "pred [4.43395448 4.60256989 4.44374793 4.60017519 4.43442193 4.60571396]\n",
      "pred [4.30269656 4.6651756  4.31098479 4.67412445 4.16857053 4.82751538]\n",
      "pred [3.60250597 5.38788015 4.5021091  4.49078101 4.22981954 4.78098528]\n",
      "pred [3.94166454 5.02064401 4.37952337 4.61191977 4.59611283 4.37648665]\n",
      "pred [3.30222109 5.71111134 3.92322144 5.06834702 3.41127596 5.59175164]\n",
      "pred [5.02745175 3.97319216 4.53293425 4.46659986 4.41996754 4.73306894]\n",
      "pred [4.12328628 4.87632315 4.04794534 5.03657199 3.98285663 4.9963577 ]\n",
      "pred [4.13819875 4.83523643 4.36220005 4.64790836 4.07770504 4.87126671]\n",
      "pred [3.43750443 5.54680028 4.46756752 4.57786339 4.35750266 4.64979088]\n",
      "pred [4.2480539  4.81328427 4.49767515 4.51493489 5.53064102 3.57999074]\n",
      "pred [3.21264882 5.75658733 4.44138234 4.54721689 4.11903903 4.79993715]\n",
      "pred [3.84115893 5.10186461 4.33329161 4.74919596 3.99642898 4.95636168]\n",
      "pred [4.17044884 4.80131629 4.49324933 4.49300709 4.20834042 4.7874595 ]\n",
      "pred [4.30653659 4.70430833 4.43129642 4.59203924 4.17043326 4.85199095]\n",
      "pred [3.30806762 5.62035705 4.26366474 4.72853359 4.10612608 4.84759292]\n",
      "pred [4.01859432 4.82055671 3.71331625 5.34579511 3.15997314 5.88450411]\n",
      "pred [3.77169616 5.30829977 4.18698691 4.74225184 3.76085685 5.28101406]\n",
      "pred [3.51154006 5.46529215 4.3492978  4.69393136 3.86811052 5.02416751]\n",
      "pred [4.53882934 4.51956065 3.8927575  5.06191179 3.27275987 5.73664609]\n",
      "pred [5.415397   3.6176772  4.48232156 4.53115532 5.10257146 3.72277487]\n",
      "pred [4.02267687 4.96951511 4.46240814 4.54922136 3.90416956 5.07793834]\n",
      "pred [3.29537865 5.68334176 3.90182844 5.13501742 3.47621885 5.48506721]\n",
      "pred [2.91804491 5.94149601 4.34086398 4.61078564 3.84050816 5.11725416]\n",
      "pred [3.39926887 5.60388587 4.3160885  4.71497836 3.88395836 5.09962663]\n",
      "pred [4.30525979 4.77655931 4.47199455 4.54594295 4.19852123 4.86126326]\n",
      "pred [4.18296597 4.75848789 3.80066596 5.28366283 3.42509698 5.53300812]\n",
      "pred [4.82285733 4.05789804 4.48965448 4.50970459 4.87998815 4.23912795]\n",
      "pred [4.16460641 4.8043882  3.9392963  5.09454799 3.64766136 5.29003523]\n",
      "pred [4.21408207 4.63869919 4.536342   4.44365578 4.90239495 4.15697079]\n",
      "pred [4.37910538 4.62669275 4.51866578 4.45475167 4.35733335 4.61361038]\n",
      "pred [4.21715156 4.85255071 4.21424189 4.72814993 3.7183234  5.22851302]\n",
      "pred [4.17231808 4.78544675 4.00879159 5.03708726 3.93302367 4.99038793]\n",
      "pred [4.52894497 4.39957765 4.48237403 4.52286804 4.41814548 4.59895914]\n",
      "pred [5.2555842  3.7340411  4.443735   4.56117184 4.76877355 4.39125879]\n",
      "pred [4.15160747 5.00721515 4.24318494 4.73225711 4.35623982 4.62289188]\n",
      "pred [4.36791332 4.67610888 4.52471664 4.4780339  4.37286707 4.61209635]\n",
      "pred [4.47091361 4.42922084 4.49627639 4.53420448 4.43061429 4.53527132]\n",
      "pred [3.01086392 6.06907469 4.36180302 4.61835497 4.02167007 5.02488995]\n",
      "pred [4.70465232 4.22825225 4.48902606 4.50591431 4.32918668 4.70654581]\n",
      "pred [4.13822334 4.82370655 3.7167835  5.17250114 3.33679961 5.60631974]\n",
      "pred [3.249226   5.74290799 3.92731905 5.10794104 3.80371022 5.14955605]\n",
      "pred [4.17064898 4.84739459 4.20594067 4.79562271 4.03752431 4.82718789]\n",
      "pred [4.29414105 4.66103218 4.48765615 4.54284129 4.28970195 4.73027289]\n",
      "pred [3.37562213 5.59814918 3.80909742 5.26410471 3.8097767  5.1725322 ]\n",
      "pred [2.99101644 5.99078102 4.41361946 4.56271855 3.91924148 5.09273417]\n",
      "pred [4.18098684 4.71789816 3.9545292  5.05008423 3.94824836 5.03930911]\n",
      "pred [4.47470275 4.54147963 4.55672551 4.43714273 4.41841671 4.59176736]\n",
      "pred [4.06140704 5.12339281 4.26217398 4.76796729 3.73716231 5.15221432]\n",
      "(296, 10) (296, 6)\n",
      "******* Feature select: LR10  Feature type: OG-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8020517724217697\n",
      "R2 Best score (validation) val. score :  0.5477385036444131\n",
      "R2 of the best estimator (testing dataset):  0.18530099614297826\n",
      "pred [4.6142186  4.24290383 4.36467841 4.63099183 4.42259374 4.55445874]\n",
      "pred [4.94334774 4.18499266 4.50118718 4.53131724 4.99707425 4.02374189]\n",
      "pred [4.32470484 4.52284811 3.20018229 5.75187096 3.60806784 5.31245499]\n",
      "pred [3.7906008  5.31911874 4.46299051 4.56338761 5.15639935 3.71153219]\n",
      "pred [4.41346935 4.48644193 3.29738346 5.5824475  3.55019328 5.43723573]\n",
      "pred [5.00599957 4.09078384 4.45494042 4.53887857 5.53370182 3.4767794 ]\n",
      "pred [4.52561358 4.35728929 4.31030706 4.63883644 4.37711803 4.56919988]\n",
      "pred [3.6328524  5.27707576 4.40018329 4.59295173 3.98747689 4.83958504]\n",
      "pred [4.45061129 4.48589885 4.46044957 4.52962086 4.31368357 4.63535919]\n",
      "pred [4.53920607 4.50366125 4.23844784 4.79466193 4.2307415  4.81396977]\n",
      "pred [4.53248847 4.4882754  4.028531   4.95864201 3.94843093 5.05426785]\n",
      "pred [4.00633935 4.99500542 4.29613383 4.71034952 4.35550711 4.71816228]\n",
      "pred [3.72737874 5.404845   4.46300144 4.55832254 5.15639935 3.69949283]\n",
      "pred [4.37163589 4.77270132 3.70581271 5.24882717 3.81136064 5.08769327]\n",
      "pred [4.44183346 4.63639661 3.95227906 5.04149799 4.01573671 4.8481924 ]\n",
      "pred [4.34881638 4.5237798  4.06308337 4.97749925 3.96402672 4.88300934]\n",
      "pred [4.09189769 4.83009411 4.46578451 4.49432746 4.43873724 4.53663623]\n",
      "pred [4.23920407 4.86456213 4.35323963 4.62516822 4.48495624 4.61036479]\n",
      "pred [4.37427461 4.77270132 3.70581271 5.25113272 3.81108276 5.10614602]\n",
      "pred [4.76179637 4.10501962 4.52808064 4.46947431 3.74133406 5.12631024]\n",
      "pred [4.27064117 4.61213881 3.88148166 5.0094126  4.28450498 4.81229793]\n",
      "pred [4.34646503 4.52238433 4.32166009 4.59539079 4.18431173 4.67399797]\n",
      "pred [4.17046941 4.90511049 4.25975726 4.68044169 4.48623185 4.6320054 ]\n",
      "pred [4.22484226 4.9256685  4.45307557 4.61516856 5.6272797  3.41529562]\n",
      "pred [3.88829593 5.07358156 4.24633119 4.71422694 4.34598397 4.8128417 ]\n",
      "pred [3.54265191 5.53766638 4.44125133 4.58954588 4.01315531 4.78567033]\n",
      "pred [4.28766011 4.65447603 4.23083783 4.7460346  4.25873005 4.68811909]\n",
      "pred [4.52969347 4.47989346 4.027456   4.95882093 3.95410223 5.0420234 ]\n",
      "pred [3.89182017 5.03774018 4.06937229 4.9093197  4.12509399 4.85399934]\n",
      "pred [4.32497054 4.54244255 3.68381586 5.31179763 3.72199256 5.31569056]\n",
      "pred [4.14374524 4.84061539 3.25878864 5.66198046 3.51161873 5.3960021 ]\n",
      "pred [3.4322928  5.39724927 4.39647212 4.55921411 3.95314792 4.94944054]\n",
      "pred [4.59584098 4.09272106 3.45633535 5.53660164 3.48928404 5.5019405 ]\n",
      "pred [5.28970964 3.74887934 4.47670242 4.53856685 5.45947618 3.53308612]\n",
      "pred [4.39176489 4.54446487 4.14735218 4.82455271 3.8050184  4.93565026]\n",
      "pred [4.33998035 4.75869103 3.70643979 5.25141745 3.4285503  5.40824732]\n",
      "pred [3.89133433 5.07620544 4.22512951 4.73381328 4.29365736 4.78970073]\n",
      "pred [3.68915107 5.23201451 4.39256787 4.56702957 3.9765141  4.92914914]\n",
      "pred [4.34237166 4.62913416 4.21248618 4.79213391 4.19055601 4.69358036]\n",
      "pred [4.29511029 4.57494968 3.46026386 5.58137392 3.67219828 5.26879196]\n",
      "pred [4.40530356 4.76036547 4.43838683 4.5691879  5.47289132 3.46357459]\n",
      "pred [4.26292473 4.58359732 3.3514616  5.6106218  3.70943521 5.2491356 ]\n",
      "pred [4.22307977 4.82925635 4.47422279 4.53559688 5.0349673  3.87281936]\n",
      "pred [4.32395215 4.59793275 4.14205488 4.84593035 4.18598683 4.69503106]\n",
      "pred [4.32839682 4.55596134 3.85734273 5.10396829 4.1475824  4.85318423]\n",
      "pred [4.28073283 4.61213881 3.88148166 5.00873615 4.28082939 4.81418682]\n",
      "pred [4.42048339 4.44956359 4.27497537 4.66408754 4.31723191 4.6163117 ]\n",
      "pred [5.01566415 4.14390499 4.46990672 4.54431223 5.20100216 3.85301359]\n",
      "pred [4.60073324 4.22806087 4.42770823 4.56354351 4.43883492 4.56206143]\n",
      "pred [4.36413781 4.53706359 4.23966038 4.80685729 4.20253485 4.74073747]\n",
      "pred [4.45778276 4.43254443 4.30964769 4.64918786 4.40332636 4.56206766]\n",
      "pred [3.70095033 5.26499861 4.25624103 4.68730377 4.32257772 4.80861863]\n",
      "pred [4.72831949 4.21665453 4.36264958 4.63851268 4.37806137 4.60644787]\n",
      "pred [4.39884911 4.54565825 3.63151206 5.36086667 3.4935315  5.39148413]\n",
      "pred [3.88291761 5.06370398 3.99770625 5.01311572 4.12002983 4.9283841 ]\n",
      "pred [4.2861783  4.62398339 3.27751109 5.72396074 3.64527463 5.26751718]\n",
      "pred [4.32312711 4.66033798 4.38440805 4.60522011 4.24444675 4.70111373]\n",
      "pred [4.39614758 4.77249575 3.87539602 5.09844872 3.98338627 4.93734494]\n",
      "pred [3.90568482 5.13419321 4.21500742 4.73251617 4.33853778 4.82892691]\n",
      "pred [4.21990144 4.64814401 4.44879051 4.54523674 4.44698226 4.55751536]\n",
      "pred [4.2935883  4.59297237 4.09246376 4.91487994 4.17993574 4.78143087]\n",
      "pred [4.14863681 4.87198374 3.64224048 5.2832149  3.49849904 5.38788629]\n",
      "(296, 10) (296, 6)\n",
      "******* Feature select: LR10  Feature type: ST-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8060805075638738\n",
      "R2 Best score (validation) val. score :  0.560992173351429\n",
      "R2 of the best estimator (testing dataset):  0.4268141994077941\n",
      "pred [4.87201726 4.05990533 4.3820192  4.59308145 4.16027962 4.78476942]\n",
      "pred [5.22653984 3.79608607 4.41971001 4.57003029 4.16111575 4.83697656]\n",
      "pred [4.23238525 4.82442204 3.03071075 5.87559036 3.13842674 5.78607042]\n",
      "pred [3.44832349 5.45670824 4.55180369 4.45981382 5.63093733 3.42639669]\n",
      "pred [4.50686006 4.4614353  3.41892499 5.60682272 3.27074491 5.8658349 ]\n",
      "pred [4.8795109  4.07196102 4.51239873 4.514462   4.96981815 3.91795232]\n",
      "pred [4.50901822 4.57521877 4.44905742 4.49687324 4.42529025 4.57128885]\n",
      "pred [3.55549718 5.42799903 4.41239423 4.57585485 4.25564932 4.75067292]\n",
      "pred [4.53474213 4.44261323 4.49261104 4.51775437 4.49154981 4.51127284]\n",
      "pred [4.87564107 4.1084155  4.38746908 4.59254228 4.21443112 4.70935433]\n",
      "pred [4.90458307 4.09811805 4.42108995 4.53777158 4.20484785 4.73810513]\n",
      "pred [4.00641026 4.9859345  4.34383544 4.63295244 4.18645821 4.77964081]\n",
      "pred [3.44586959 5.58656592 4.55745857 4.44884776 5.6309592  3.41711444]\n",
      "pred [3.33606615 5.69096339 3.65070441 5.34113329 3.78793291 5.28952545]\n",
      "pred [4.47127321 4.58531319 4.35789561 4.59794141 4.45890061 4.55198496]\n",
      "pred [4.17043929 4.72138341 4.05059632 5.03199611 3.90542385 5.03792892]\n",
      "pred [3.4484905  5.53937771 4.43706037 4.53980156 4.28389041 4.73390766]\n",
      "pred [4.16825404 4.83984853 4.37388044 4.60003062 4.62137398 4.31693533]\n",
      "pred [3.24799484 5.77673266 3.74620822 5.18290096 3.6809088  5.3397235 ]\n",
      "pred [5.03117527 3.92390915 4.32629484 4.73811566 3.42143514 5.65464543]\n",
      "pred [3.88746175 5.08726055 3.82131806 5.24120633 3.55949043 5.49323342]\n",
      "pred [3.54308305 5.5354005  4.39070793 4.5506746  3.95907659 5.04633879]\n",
      "pred [3.73611186 5.41559758 4.49349645 4.51483373 4.43584641 4.56637049]\n",
      "pred [4.59116871 4.5352356  4.5002501  4.50696521 5.21582899 3.82797052]\n",
      "pred [3.49617938 5.48701691 4.46429525 4.52106707 4.25488757 4.71479288]\n",
      "pred [3.65091999 5.37027498 4.2733709  4.75918248 4.25749946 4.73366986]\n",
      "pred [4.43586643 4.68871505 4.48421295 4.50064371 4.30333512 4.6303789 ]\n",
      "pred [4.69714192 4.21003836 4.42190646 4.54203586 4.21318675 4.73319725]\n",
      "pred [3.57180942 5.43005219 4.15157929 4.86184259 3.97637219 5.0173747 ]\n",
      "pred [4.3587845  4.60886901 3.47750394 5.44929318 2.97362891 6.05838604]\n",
      "pred [3.98909911 5.00942487 3.289539   5.74984323 3.06523336 5.89674332]\n",
      "pred [3.25675775 5.83710984 4.28029955 4.77322144 4.14565096 4.84575998]\n",
      "pred [4.75986915 4.37624043 3.31494117 5.76661294 3.15405037 5.74869978]\n",
      "pred [5.13033993 3.84669244 4.43939988 4.54901721 4.13033052 4.95890113]\n",
      "pred [4.20145071 4.74959436 4.21524317 4.8467137  3.84124297 5.24293718]\n",
      "pred [3.62186027 5.31412194 3.62362773 5.37262938 3.7877584  5.30957164]\n",
      "pred [3.29184296 5.63874776 4.4292358  4.54904168 4.14743279 4.82253793]\n",
      "pred [3.73705735 5.2551113  4.24800428 4.81114114 4.49701395 4.57816428]\n",
      "pred [4.30393264 4.68444856 4.44879963 4.55239899 4.17146152 4.81583743]\n",
      "pred [3.45084395 5.51832482 4.34127217 4.60784136 3.42424138 5.59237137]\n",
      "pred [4.74173281 4.26317981 4.49216237 4.51868637 4.88697934 4.18076215]\n",
      "pred [4.14121322 4.82657569 3.95052333 5.03485731 3.39431557 5.60769103]\n",
      "pred [4.60216979 4.45448065 4.46484734 4.53030468 3.96664845 4.94422892]\n",
      "pred [3.92525237 5.19985372 4.37190969 4.57214403 4.09421736 4.86896615]\n",
      "pred [3.65868021 5.35748038 4.1784743  4.82562828 3.44848201 5.4919718 ]\n",
      "pred [3.95030754 5.03002711 3.69732772 5.31774793 3.57510571 5.43856847]\n",
      "pred [4.57868582 4.45117837 4.46149541 4.56138808 4.46846667 4.52015555]\n",
      "pred [4.96350373 3.87501213 4.4326263  4.55603487 4.43457771 4.3927867 ]\n",
      "pred [4.18105641 4.83571678 4.48733585 4.51193014 4.44165523 4.59645048]\n",
      "pred [4.28930016 4.71717308 4.41342425 4.53984727 4.10371808 4.92956755]\n",
      "pred [4.78698679 4.18183262 4.53037503 4.4759595  4.52446288 4.47820121]\n",
      "pred [2.95921702 6.03868705 4.37033522 4.64430935 3.91893177 5.06230287]\n",
      "pred [4.85267413 4.0678268  4.40421319 4.56929754 4.15992741 4.81029397]\n",
      "pred [3.94078953 5.06553658 3.61192132 5.33407305 3.01773866 5.92446344]\n",
      "pred [3.77948382 5.28381323 4.05318572 5.04885952 3.75471514 5.17648114]\n",
      "pred [4.11660439 4.90769548 3.44437411 5.61628186 3.3436325  5.60731027]\n",
      "pred [4.38291063 4.60664608 4.33094851 4.68597733 4.1165456  4.87660734]\n",
      "pred [3.06863521 5.95263951 3.5632383  5.40330673 3.86520871 5.21817473]\n",
      "pred [3.29193882 5.70452405 4.4863907  4.52083665 3.94751736 5.05020887]\n",
      "pred [4.19335125 4.91690764 3.90581607 5.15874589 3.64182521 5.33041182]\n",
      "pred [4.37195236 4.65398604 4.44786322 4.51855358 4.3740516  4.58008735]\n",
      "pred [3.95086251 5.02830081 3.91210636 5.01297395 3.29685752 5.68060687]\n",
      "(296, 189) (296, 6)\n",
      "******* Feature select: FS_S  Feature type: HG-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8858261286635009\n",
      "R2 Best score (validation) val. score :  0.6325590985492683\n",
      "R2 of the best estimator (testing dataset):  0.5015738977869035\n",
      "pred [4.34534361 4.46425327 4.49355444 4.53287236 4.43085553 4.61337188]\n",
      "pred [5.11309577 3.88228427 4.42576175 4.59524093 4.58687008 4.60897353]\n",
      "pred [3.89206164 5.13979249 3.9832412  5.0058521  3.5425794  5.50235593]\n",
      "pred [3.8265272  5.21679255 4.52748511 4.47195445 5.61658081 3.33040972]\n",
      "pred [4.51186993 4.7009946  3.36255425 5.61906711 3.54323358 5.44831458]\n",
      "pred [5.23964529 3.74546864 4.40117613 4.64352419 5.15752252 3.71708573]\n",
      "pred [4.36502886 4.72925658 4.36402086 4.64033309 4.41977817 4.52020464]\n",
      "pred [3.48848053 5.33181027 4.13740953 4.74891241 3.96999604 4.8001986 ]\n",
      "pred [4.46065582 4.50104734 4.47909614 4.50750071 4.4463855  4.56452295]\n",
      "pred [4.45479248 4.37665416 4.44527674 4.55367812 4.35072438 4.61012708]\n",
      "pred [4.45394608 4.3825538  4.45367857 4.56713364 4.33258865 4.68206346]\n",
      "pred [4.13657036 4.74951566 4.42022119 4.53456249 4.57944056 4.45788353]\n",
      "pred [3.63222387 5.38051406 4.53584613 4.47320812 5.5302487  3.41742351]\n",
      "pred [3.40558799 5.64649102 4.13258784 4.90535873 3.73104625 5.11931461]\n",
      "pred [4.39643057 4.62556382 4.4560413  4.45613795 4.40691596 4.59846553]\n",
      "pred [4.38480148 4.49333463 3.91029978 5.10473216 3.89128348 5.13361617]\n",
      "pred [3.79796737 5.19969634 4.51190462 4.46337067 4.47275492 4.57889069]\n",
      "pred [4.15612588 4.69488558 4.439555   4.59403511 4.66316173 4.37496105]\n",
      "pred [3.39597132 5.6636867  4.11330328 4.96703589 3.67439865 5.14476868]\n",
      "pred [4.76043201 4.14715291 4.49348394 4.47301958 4.00593865 4.98808125]\n",
      "pred [3.7422599  5.4000255  4.21319336 4.84468235 3.86474819 5.07225583]\n",
      "pred [4.05454069 4.913073   4.52022325 4.47366546 4.31083202 4.68161173]\n",
      "pred [3.99500203 4.84179527 4.44695422 4.577143   4.61324669 4.43571542]\n",
      "pred [4.21010607 4.7361894  4.29688141 4.71557061 5.54061731 3.40797665]\n",
      "pred [3.39766475 5.55944649 4.41554296 4.59004633 4.17813294 4.84560196]\n",
      "pred [3.65756693 5.32014152 4.31005314 4.61882396 4.2475113  4.5744314 ]\n",
      "pred [4.2577891  4.64239867 4.52016699 4.49347495 4.12162448 4.84044621]\n",
      "pred [4.42569773 4.35311411 4.42558881 4.60885899 4.27253658 4.71407638]\n",
      "pred [3.39756861 5.60382693 4.21324822 4.8172145  3.99895073 4.9343429 ]\n",
      "pred [4.09984067 4.84437548 3.46574474 5.48452948 3.21820783 5.81455723]\n",
      "pred [4.23539285 4.68815506 3.09173975 5.86074914 3.64945341 5.33578114]\n",
      "pred [3.47804046 5.53011262 4.26953849 4.68637601 4.0774262  4.92177749]\n",
      "pred [4.22930367 5.0047132  4.01259727 4.9779146  3.66578544 5.36742278]\n",
      "pred [5.38211532 3.60412449 4.42857812 4.59261419 5.25590218 3.6680671 ]\n",
      "pred [4.14802056 4.90875751 4.31133217 4.67829727 3.97882889 5.02635118]\n",
      "pred [3.54302688 5.5912349  3.87322764 5.17123183 3.51834031 5.40980699]\n",
      "pred [3.1922997  5.76794813 4.25177091 4.73089695 4.0183499  4.92783933]\n",
      "pred [3.58637484 5.24897752 4.33631965 4.65541304 4.19316797 4.72106702]\n",
      "pred [4.19028598 4.73922549 4.48656621 4.48889012 4.20619341 4.71632796]\n",
      "pred [3.7732071  5.12195039 4.46445922 4.52568019 4.01236686 4.93784165]\n",
      "pred [4.85443803 4.12633136 4.38907338 4.65220768 4.93913707 4.04584193]\n",
      "pred [3.71685634 5.40226702 4.30530746 4.63052524 3.78039249 5.16596809]\n",
      "pred [4.37837341 4.54428401 4.56612835 4.41154802 4.83559189 4.23369894]\n",
      "pred [4.24542025 4.70115608 4.35089763 4.6355684  4.2957034  4.72420191]\n",
      "pred [3.78194173 5.02583223 4.39866338 4.51471389 3.99005813 5.02878582]\n",
      "pred [3.76100664 5.38718788 4.21319336 4.84666599 3.86580295 5.07786353]\n",
      "pred [4.67654926 4.38405208 4.38910056 4.53654344 4.4499899  4.51881362]\n",
      "pred [5.22111658 3.76906373 4.3998588  4.62163597 4.80249758 4.41026104]\n",
      "pred [4.09195201 4.87689568 4.30835588 4.65513232 4.41849083 4.60544637]\n",
      "pred [4.342239   4.73997866 4.38369889 4.4906173  4.33855582 4.69762094]\n",
      "pred [4.50545284 4.38368239 4.46491687 4.54196307 4.48241972 4.51445695]\n",
      "pred [3.21147216 5.70884007 4.31652642 4.72247272 4.05606238 4.92905023]\n",
      "pred [4.41247176 4.4108334  4.48360588 4.51592571 4.52877972 4.54551345]\n",
      "pred [3.92581627 5.12298392 4.28108353 4.74261092 3.67205813 5.35774903]\n",
      "pred [3.413912   5.61471282 4.04056923 5.00882222 3.81400523 5.08631138]\n",
      "pred [3.70686942 5.34443982 4.26208315 4.77333627 3.71169085 5.30130052]\n",
      "pred [4.12422267 4.69783176 4.40643174 4.58284011 4.30662896 4.69318788]\n",
      "pred [3.32173307 5.62254008 4.18797316 4.83869499 3.85657943 5.03427762]\n",
      "pred [3.18137277 5.81527454 4.29137467 4.67257309 4.0296941  4.91050874]\n",
      "pred [3.79028793 5.17556781 4.32416467 4.62093446 4.1959631  4.75880118]\n",
      "pred [4.36677916 4.72789235 4.5543151  4.41381325 4.46245849 4.59362137]\n",
      "pred [3.51158848 5.50877979 4.28957149 4.67325395 3.92878149 5.03444623]\n",
      "(296, 99) (296, 6)\n",
      "******* Feature select: FS_S  Feature type: OG-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8592701918235842\n",
      "R2 Best score (validation) val. score :  0.5819624389893062\n",
      "R2 of the best estimator (testing dataset):  0.43703399484307953\n",
      "pred [4.49426476 4.52290735 4.42083472 4.58303958 4.3024047  4.66840315]\n",
      "pred [5.14709678 3.92668325 4.36877872 4.58162038 4.40585366 4.34278999]\n",
      "pred [4.02209883 4.94882505 3.87869886 5.11832107 3.44417702 5.5749144 ]\n",
      "pred [3.71236067 5.2932378  4.43800752 4.51211459 5.37747599 3.44258367]\n",
      "pred [4.52708806 4.57730967 3.41956591 5.57778268 3.50307147 5.52889352]\n",
      "pred [5.2510448  3.81561462 4.33156118 4.63548646 5.06817263 3.6803219 ]\n",
      "pred [4.21183995 4.8746598  4.38938316 4.60624154 4.37703205 4.63504471]\n",
      "pred [3.76614603 5.20444822 4.26524161 4.88476775 4.33743999 4.6883159 ]\n",
      "pred [4.35847704 4.66699207 4.41634682 4.63168071 4.37245114 4.76026642]\n",
      "pred [4.4901422  4.47176299 4.4565806  4.56650536 4.3324695  4.64519531]\n",
      "pred [4.61359709 4.40765165 4.41984561 4.57567968 4.40523698 4.77797209]\n",
      "pred [4.20383701 4.86170349 4.31833502 4.67001336 4.39024927 4.44839713]\n",
      "pred [3.68368544 5.34197481 4.47102167 4.51097163 5.36033088 3.43785964]\n",
      "pred [4.0116948  5.13663267 3.92880136 4.92431185 4.08769236 5.03716229]\n",
      "pred [4.5611632  4.53869919 4.39282615 4.58091908 4.29343238 4.72504489]\n",
      "pred [4.45518725 4.53793933 3.81586771 5.28165544 3.83221094 5.11180926]\n",
      "pred [4.0729815  4.92539645 4.37256919 4.71733578 4.43345565 4.68766277]\n",
      "pred [4.13452581 4.86903757 4.2952264  4.72484769 4.44768677 4.49850035]\n",
      "pred [4.03290069 5.17150925 3.90888366 4.93462446 4.14902796 4.94077805]\n",
      "pred [4.88688782 4.14323185 4.47541818 4.49176151 3.71093597 5.23327678]\n",
      "pred [3.96973327 5.12914371 4.3078697  4.70597334 4.18377486 4.92911049]\n",
      "pred [3.98432336 4.96816348 4.38207704 4.58042363 4.32677236 4.66769478]\n",
      "pred [4.12480578 4.91614472 4.30378875 4.71530343 4.4891703  4.46481104]\n",
      "pred [4.52189633 4.6703451  4.34568404 4.60955243 5.21125367 3.50751504]\n",
      "pred [3.71984982 5.42488593 4.34541895 4.69293203 4.13408187 4.84035693]\n",
      "pred [3.98987641 4.87434089 4.25792626 4.82369077 4.30215305 4.72977096]\n",
      "pred [4.48180457 4.66342283 4.46540594 4.5365638  4.26436109 4.81186049]\n",
      "pred [4.67192654 4.27579581 4.46099852 4.56293229 4.39587819 4.7856365 ]\n",
      "pred [3.62160827 5.51499973 4.00183517 4.86701791 4.21386846 4.8093395 ]\n",
      "pred [4.22484749 4.66026799 3.52818052 5.49112373 3.44629789 5.63357574]\n",
      "pred [4.30691794 4.54810333 3.24748794 5.83771849 3.76377616 5.1945932 ]\n",
      "pred [3.80347327 5.22960165 4.30245753 4.83876567 4.26845628 4.79371932]\n",
      "pred [4.48354704 4.76082041 3.85237666 5.17070192 3.58151532 5.46017409]\n",
      "pred [5.36898138 3.62186892 4.34957168 4.61571771 5.15157826 3.70977004]\n",
      "pred [4.06135769 4.96155346 4.2473692  4.7253222  3.83530962 5.1204328 ]\n",
      "pred [3.96043635 5.22517685 3.90750916 4.99781298 3.73902352 5.3807957 ]\n",
      "pred [3.70984826 5.56814196 4.28780992 4.68249907 4.39801679 4.77307097]\n",
      "pred [3.81525568 5.22124032 4.25127133 4.71840459 4.29800783 4.82859862]\n",
      "pred [4.46767837 4.69249521 4.45855667 4.51216591 4.2212976  4.7960782 ]\n",
      "pred [4.08423171 4.9821888  4.29563505 4.61204244 3.99923264 5.10770988]\n",
      "pred [4.89770468 4.21275495 4.39962924 4.57057704 4.68842911 3.89947054]\n",
      "pred [3.83923296 5.24289147 4.24580083 4.76006296 3.99182535 5.15999482]\n",
      "pred [4.35594501 4.70993194 4.48881527 4.48150479 4.24804612 4.68526783]\n",
      "pred [4.2611065  4.72350051 4.27824181 4.69903901 4.2704382  4.8523263 ]\n",
      "pred [3.87726108 5.16423219 4.30785024 4.64960535 4.08736439 4.9306284 ]\n",
      "pred [3.96973327 5.12914371 4.3078697  4.70597334 4.18812903 4.92911049]\n",
      "pred [4.50549755 4.46458761 4.41541724 4.63628025 4.3535252  4.6362835 ]\n",
      "pred [5.21911125 3.85304347 4.35147148 4.60605798 4.70282658 4.13396645]\n",
      "pred [4.21918312 4.87073829 4.34531608 4.62072633 4.52328263 4.54399645]\n",
      "pred [4.2754471  4.69970113 4.43486355 4.60595725 4.3462021  4.73663623]\n",
      "pred [4.497189   4.4569397  4.43991026 4.6210715  4.40995825 4.6582303 ]\n",
      "pred [3.62487992 5.52695986 4.29261864 4.72965841 3.94917726 5.02818194]\n",
      "pred [4.73112215 4.23046584 4.46893204 4.53877836 4.32342811 4.69348047]\n",
      "pred [4.12965256 4.91060858 3.94374449 4.97357329 3.50029432 5.43737742]\n",
      "pred [3.58466216 5.59291948 3.94211813 5.01241132 4.05842925 4.9494745 ]\n",
      "pred [3.87846655 4.95273073 3.87121036 5.0807131  3.81215764 5.18879788]\n",
      "pred [4.27730794 4.81388488 4.43942842 4.53189261 4.19299883 4.80523653]\n",
      "pred [4.06935897 5.29848356 4.0682098  4.81541641 4.20610624 4.9901631 ]\n",
      "pred [3.61565798 5.55309623 4.3273878  4.69884847 4.17538812 4.88371439]\n",
      "pred [4.04162146 4.96998928 4.34749941 4.751898   4.33260873 4.76398129]\n",
      "pred [4.34229201 4.75824184 4.41598415 4.55912677 4.26390268 4.87571649]\n",
      "pred [3.6487143  5.33611881 4.30822984 4.70906024 4.06555793 5.00738405]\n",
      "(296, 58) (296, 6)\n",
      "******* Feature select: FS_S  Feature type: ST-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8544259574878122\n",
      "R2 Best score (validation) val. score :  0.6045400870662186\n",
      "R2 of the best estimator (testing dataset):  0.4542570929070869\n",
      "pred [4.68702456 4.34398155 4.45489493 4.53221207 4.37739508 4.61985943]\n",
      "pred [5.17921498 3.95906966 4.37786075 4.62326912 4.56895    4.53578776]\n",
      "pred [3.86463176 5.18810369 3.9255788  5.12837687 3.52366149 5.48306376]\n",
      "pred [3.67074566 5.27969747 4.51248593 4.47975535 5.31296594 3.68069986]\n",
      "pred [4.2857298  4.68676055 3.68281083 5.23483204 3.52360379 5.41376347]\n",
      "pred [5.14569581 3.94290633 4.49296256 4.52565906 5.35881475 3.80820407]\n",
      "pred [4.17017277 4.71463037 4.33185696 4.645867   4.35178303 4.59430649]\n",
      "pred [3.72569559 5.27700617 4.33773496 4.68231182 4.05117202 4.82340177]\n",
      "pred [4.30953126 4.69445001 4.40884506 4.54409679 4.3659508  4.59432505]\n",
      "pred [4.67354302 4.28158896 4.45667848 4.55359075 4.41338373 4.61161506]\n",
      "pred [4.6980343  4.30544914 4.45440388 4.53654951 4.28056873 4.7125649 ]\n",
      "pred [4.24054995 4.74107827 4.39660085 4.59042446 4.46173894 4.55527625]\n",
      "pred [3.57747023 5.34083524 4.52803561 4.47485266 4.87601104 4.09913699]\n",
      "pred [3.49688066 5.47329072 4.08995837 4.85460443 3.87978585 5.11483448]\n",
      "pred [4.19476866 4.86171176 4.30404596 4.60688585 4.34217549 4.65213508]\n",
      "pred [4.22802619 4.75195679 4.18983943 4.78336315 4.02117406 4.88727396]\n",
      "pred [3.57110866 5.49106075 4.40171608 4.54181062 4.31474845 4.69668848]\n",
      "pred [4.32612785 4.66010317 4.42690895 4.56971685 4.63654344 4.39805549]\n",
      "pred [3.43277491 5.53146208 4.13705826 4.83573884 3.90902482 5.12750177]\n",
      "pred [5.13689348 3.91860348 4.44906852 4.55656112 3.46922305 5.4758722 ]\n",
      "pred [3.87704442 5.01985364 4.04136817 4.96025483 3.86352465 5.12043956]\n",
      "pred [3.92878103 5.09181715 4.43044847 4.54128921 4.19600742 4.86411298]\n",
      "pred [4.17114085 4.8117173  4.43733824 4.55201219 4.38962343 4.57768445]\n",
      "pred [4.64911228 4.45440455 4.347692   4.65296001 5.5967015  3.41665365]\n",
      "pred [3.64010611 5.21688602 4.41564775 4.52881367 4.25577176 4.72461998]\n",
      "pred [3.81350038 5.16210651 4.37454906 4.67133164 4.38724339 4.69120321]\n",
      "pred [4.3217403  4.68366644 4.49277546 4.5441262  4.23129375 4.83007197]\n",
      "pred [4.57685949 4.3565752  4.45037539 4.54554998 4.27306158 4.72404617]\n",
      "pred [3.53159594 5.42551911 4.07818348 4.88360078 4.11573877 4.85284327]\n",
      "pred [4.12145672 4.94374159 3.62292436 5.29266209 3.40563276 5.60571628]\n",
      "pred [4.07524264 5.02729599 3.46973788 5.53950695 3.54240592 5.52093016]\n",
      "pred [3.53054514 5.49443908 4.4543581  4.56457846 4.13008313 4.83316026]\n",
      "pred [4.17231951 4.68541257 3.84390583 5.1977323  3.69584241 5.30582728]\n",
      "pred [5.2753364  3.89239855 4.44383189 4.55819456 5.13672469 3.96322334]\n",
      "pred [4.25511279 4.8337253  4.3262114  4.71737222 3.98571726 4.92908498]\n",
      "pred [3.65117671 5.34178222 4.07332988 4.8894556  3.69813585 5.39768539]\n",
      "pred [3.24730652 5.56797276 4.44541478 4.56935047 4.12512091 4.85487672]\n",
      "pred [3.78349213 5.15335149 4.41605203 4.55779262 4.39053138 4.59276906]\n",
      "pred [4.40349582 4.43756067 4.51146471 4.50633948 4.35581673 4.68774883]\n",
      "pred [3.88304732 5.1134785  4.49100168 4.49422576 4.00269467 4.96704881]\n",
      "pred [5.04385853 4.01313522 4.42349823 4.59405376 4.95676322 4.30552251]\n",
      "pred [3.80770358 5.05243938 4.14851742 4.79980127 3.72648708 5.24252943]\n",
      "pred [4.80863248 4.13413027 4.45326759 4.55865265 4.11214119 5.22088127]\n",
      "pred [3.97982917 4.808924   4.36876468 4.52324992 4.1862467  4.86870806]\n",
      "pred [3.52315541 5.39214537 4.26200003 4.71531823 3.96240523 5.00451286]\n",
      "pred [3.90539241 5.00067127 3.98774526 4.97830409 3.86990588 5.12127555]\n",
      "pred [4.34951091 4.5882874  4.3779323  4.5593854  4.29286551 4.69740768]\n",
      "pred [5.23085508 3.88967341 4.42925784 4.54157949 4.67502152 4.55939523]\n",
      "pred [4.11407071 4.94032741 4.44658435 4.58320165 4.43633144 4.52285762]\n",
      "pred [4.10415382 4.85156722 4.37304075 4.48642842 4.17806977 4.79913763]\n",
      "pred [4.30738277 4.53003154 4.40061957 4.56143561 4.33164999 4.61835092]\n",
      "pred [3.46757117 5.43867341 4.39494375 4.55663574 4.13701615 4.86913954]\n",
      "pred [4.65899035 4.3472399  4.48314379 4.53361575 4.37956317 4.64411248]\n",
      "pred [3.97346645 5.01611387 4.1110417  4.80293569 3.39399435 5.56301404]\n",
      "pred [3.50927413 5.3720521  3.90060032 5.0833571  3.87745294 5.17211168]\n",
      "pred [3.99746906 4.95681337 4.03384009 4.9997594  3.63964244 5.43275996]\n",
      "pred [4.4336198  4.4744222  4.42272751 4.55383088 4.22110543 4.76704623]\n",
      "pred [3.44595417 5.47950809 4.07021272 4.87727545 4.07249304 4.96526294]\n",
      "pred [3.380658   5.57343598 4.44837261 4.51924855 4.15190855 4.82322182]\n",
      "pred [3.95236671 5.05583091 4.16528067 4.85269585 4.04851605 4.90911734]\n",
      "pred [4.18254319 4.80995265 4.38898795 4.53507308 4.30576011 4.67175045]\n",
      "pred [3.66210393 5.19100823 4.17755009 4.75914713 3.73165098 5.1968972 ]\n",
      "(296, 15) (296, 6)\n",
      "******* Feature select: RF  Feature type: HG-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.7900885734861367\n",
      "R2 Best score (validation) val. score :  0.5478588353953937\n",
      "R2 of the best estimator (testing dataset):  0.37025001653803663\n",
      "pred [4.48407655 4.53003572 4.43071699 4.59125669 4.4054505  4.56336026]\n",
      "pred [5.31404159 3.78132307 4.54165341 4.44332127 4.58737264 4.47620926]\n",
      "pred [3.89912055 4.96824215 3.73411139 5.27043675 3.67537584 5.37257531]\n",
      "pred [3.77558484 5.32818776 4.54310535 4.45194097 5.52639956 3.39255135]\n",
      "pred [4.82824253 4.21800848 3.13290549 5.77951243 3.40355311 5.62985393]\n",
      "pred [5.42495782 3.65295046 4.37430988 4.60810417 5.39346664 3.83907483]\n",
      "pred [4.39544252 4.81100429 4.45963091 4.50512303 4.43817593 4.49739649]\n",
      "pred [3.07326327 5.98074923 4.20085023 4.86077735 3.52058334 5.66392258]\n",
      "pred [4.60514467 4.38904793 4.45952007 4.55120009 4.43979348 4.55906013]\n",
      "pred [4.59405756 4.29941484 4.43488347 4.51948338 4.37611265 4.59136051]\n",
      "pred [4.65456016 4.30447218 4.43993733 4.52669415 4.21934333 4.74005283]\n",
      "pred [4.28334139 4.7825196  4.39237218 4.58976285 4.44818838 4.53372171]\n",
      "pred [3.63160522 5.42614455 4.55021368 4.45247271 5.48845651 3.39660244]\n",
      "pred [2.97864993 5.98547146 4.07873239 4.83734066 3.5004447  5.46917222]\n",
      "pred [4.28078803 4.65327123 4.43578293 4.48538188 4.29920608 4.61808929]\n",
      "pred [4.34277559 4.51413947 3.94895292 5.15356979 3.93123765 5.1098337 ]\n",
      "pred [3.98441783 5.05080035 4.49754685 4.53920659 4.18154074 4.74981071]\n",
      "pred [4.21842437 4.85722002 4.29177949 4.67379073 4.42663792 4.70294126]\n",
      "pred [2.95572933 5.99830999 4.06415942 4.87204552 3.47078745 5.53252472]\n",
      "pred [5.0334019  3.96458843 4.47676422 4.49325339 3.55829066 5.46553601]\n",
      "pred [4.51568643 4.41976941 3.65031409 5.36922074 3.61490128 5.37479643]\n",
      "pred [4.12412913 4.97582494 4.37959746 4.726317   4.05061027 4.86513402]\n",
      "pred [4.02717866 5.05380519 4.37745884 4.58573565 4.47956658 4.50892589]\n",
      "pred [4.76423598 4.44233805 4.45204164 4.60840667 5.4938708  3.48519908]\n",
      "pred [3.4492058  5.54104706 4.48323122 4.52542256 4.10762244 4.93651193]\n",
      "pred [3.57198929 5.31069411 4.20151727 4.74661005 3.84618175 5.27025323]\n",
      "pred [3.95765989 4.87575303 4.35967359 4.67770975 4.09917766 4.866864  ]\n",
      "pred [4.70470526 4.20381621 4.45888771 4.51224741 4.39173323 4.57199942]\n",
      "pred [3.49734427 5.22799541 4.40033395 4.5808657  4.2555809  4.66358341]\n",
      "pred [4.31128526 4.66292994 3.26195881 5.72061341 2.93498112 6.01113884]\n",
      "pred [3.72071323 5.44120305 3.87949951 5.17220384 3.50886462 5.49199101]\n",
      "pred [3.35209113 5.67224814 4.35939621 4.71671404 3.79293942 5.37016642]\n",
      "pred [4.32970272 4.54780923 3.53538394 5.51724664 3.18629179 5.72409033]\n",
      "pred [5.46075626 3.54217067 4.38546564 4.58611411 5.39473932 3.5889292 ]\n",
      "pred [4.12373387 4.77620675 4.319316   4.64553374 4.00357887 4.92837039]\n",
      "pred [3.389844   5.62000811 3.96091538 4.99187784 3.49866682 5.58783649]\n",
      "pred [3.04578448 5.80842023 4.44551984 4.53825707 4.12388634 4.77618096]\n",
      "pred [3.22505806 5.71803806 4.30438183 4.7894018  3.56256878 5.6583437 ]\n",
      "pred [3.98011703 4.81693883 4.46231245 4.56325372 4.16299107 4.76189256]\n",
      "pred [4.01443694 4.87863874 4.23339099 4.76538581 3.88396214 5.01958235]\n",
      "pred [5.36603558 3.78817341 4.37645712 4.61815477 5.26255265 4.11990731]\n",
      "pred [4.22911923 4.75040404 3.66482213 5.46780717 3.1746414  5.75309843]\n",
      "pred [4.75383795 4.2484847  4.54726526 4.46439834 4.60830556 4.51174386]\n",
      "pred [4.52689465 4.31070204 4.4466317  4.59733954 4.41781122 4.57491957]\n",
      "pred [4.05130544 5.07849415 4.41405919 4.64536757 4.0332502  4.8308223 ]\n",
      "pred [4.51568643 4.41976941 3.65031409 5.36922074 3.61490128 5.37479643]\n",
      "pred [4.59854562 4.34509543 4.42369003 4.42475826 4.43886247 4.55773895]\n",
      "pred [5.3684967  3.74527987 4.47800588 4.55490827 5.18679217 4.23295611]\n",
      "pred [4.12338607 4.88841064 4.38346922 4.57369067 4.42921943 4.57166879]\n",
      "pred [4.36468537 4.65143549 4.51765793 4.56548408 4.41368114 4.57756281]\n",
      "pred [4.6266039  4.29639892 4.43458836 4.5447687  4.47738653 4.51647809]\n",
      "pred [2.73159108 6.20880618 4.47016168 4.54982451 3.89530814 5.13871492]\n",
      "pred [4.54859714 4.49611253 4.45080142 4.52661446 4.30152587 4.69626822]\n",
      "pred [3.83195073 5.33889505 4.1900983  4.66135726 3.73563648 5.34627803]\n",
      "pred [3.12986186 5.77171834 4.17677912 4.84219733 3.73527209 5.3443238 ]\n",
      "pred [4.11224676 4.75244036 4.36356635 4.81054048 3.88314448 5.08874997]\n",
      "pred [3.93734615 4.84920464 4.45972011 4.55651459 4.11622379 4.7587328 ]\n",
      "pred [2.92570712 5.990647   4.18729258 4.70179825 3.67516295 5.31713742]\n",
      "pred [2.93672231 6.14113729 4.49492094 4.5145236  3.88852924 5.09342793]\n",
      "pred [4.39532336 4.61689922 3.54675977 5.37238688 3.54076942 5.45559086]\n",
      "pred [4.43439077 4.56110242 4.48113088 4.56787446 4.3959302  4.5864616 ]\n",
      "pred [3.41210728 5.52496345 4.12923565 4.89458137 3.0874566  5.8440075 ]\n",
      "(296, 23) (296, 6)\n",
      "******* Feature select: RF  Feature type: OG-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8160002590223625\n",
      "R2 Best score (validation) val. score :  0.5478288246601467\n",
      "R2 of the best estimator (testing dataset):  0.38100576560653\n",
      "pred [4.43650302 4.5627784  4.46569527 4.57853901 4.3488265  4.6801313 ]\n",
      "pred [5.08231486 3.85835874 4.54273807 4.47844783 4.80591358 4.09839315]\n",
      "pred [3.8774129  5.12363873 3.81772107 5.10629402 3.3124184  5.71343003]\n",
      "pred [3.6040643  5.15799153 4.56255471 4.43585557 5.73715445 3.32707976]\n",
      "pred [4.33637564 4.54579542 3.63291434 5.45264956 3.4464767  5.55301826]\n",
      "pred [5.30059802 3.67893913 4.49006504 4.48550311 5.4086995  3.5343085 ]\n",
      "pred [4.5536441  4.39084042 4.43029419 4.59559572 4.41280504 4.54605622]\n",
      "pred [4.03498954 4.82224748 4.17156363 4.81629675 3.7627144  5.0834197 ]\n",
      "pred [4.31427903 4.68402072 4.50282388 4.51541141 4.27054807 4.80030061]\n",
      "pred [4.54057136 4.40707484 4.37598365 4.60375353 4.37501861 4.61942902]\n",
      "pred [4.58419842 4.41306955 4.40273483 4.58003548 3.949707   4.98657391]\n",
      "pred [4.30670052 4.60346186 4.42741574 4.55415276 4.39113175 4.60565257]\n",
      "pred [3.52588532 5.32148016 4.59570465 4.41617681 5.42233839 3.66065163]\n",
      "pred [3.84651866 5.18319067 4.06878199 4.89683058 3.91165958 5.10202184]\n",
      "pred [4.34351326 4.6342345  4.45537016 4.5468029  4.24675238 4.69350389]\n",
      "pred [4.39837745 4.53554491 4.14935772 4.9385658  4.04972507 4.97826323]\n",
      "pred [3.67032895 5.29059692 4.41175465 4.61857145 4.30232047 4.72579613]\n",
      "pred [3.87515626 5.11831087 4.43135732 4.55030358 4.44229215 4.53254592]\n",
      "pred [3.7070155  5.33180536 4.01429156 4.99527223 3.88302302 5.1799939 ]\n",
      "pred [4.80885755 4.30134267 4.53389045 4.46573224 3.37086172 5.56094703]\n",
      "pred [4.39247567 4.49531405 3.89419642 5.21016073 4.06909717 4.91900538]\n",
      "pred [3.92574555 5.0626744  4.35639423 4.61700074 4.07978427 4.90618907]\n",
      "pred [3.85904049 5.10875752 4.4176753  4.59251663 4.46292228 4.50316018]\n",
      "pred [4.29837056 4.4791863  4.49966071 4.49324967 5.79193924 3.20689712]\n",
      "pred [3.16083506 5.5760737  4.46334271 4.53616438 4.11651635 4.85010448]\n",
      "pred [4.08076976 4.76963066 4.25734267 4.80213676 4.05149644 4.93986588]\n",
      "pred [4.38092879 4.64042473 4.43598895 4.51966018 4.16131723 4.85201162]\n",
      "pred [4.53913288 4.39811474 4.40320397 4.56391579 3.9541032  4.98657391]\n",
      "pred [3.53250563 5.5373011  4.2054938  4.80346293 4.04479119 4.88252749]\n",
      "pred [4.31992686 4.49160197 3.46560423 5.47427732 3.25468045 5.69743826]\n",
      "pred [3.68392806 5.34012749 3.85721454 5.11948463 3.67152504 5.56002298]\n",
      "pred [3.40362521 5.52182524 4.35282838 4.69061719 3.83698853 5.04945478]\n",
      "pred [4.46562155 4.41257226 4.07610624 5.07172975 3.52349327 5.47282307]\n",
      "pred [5.37237549 3.66311449 4.49482809 4.46407546 5.41499626 3.53539793]\n",
      "pred [4.15458503 4.84539146 4.4839947  4.5093664  4.12609613 4.90803927]\n",
      "pred [3.77132438 5.13866601 3.9843679  5.0326212  3.28253801 5.71423417]\n",
      "pred [3.3471842  5.65860021 4.44326525 4.56461438 4.02739951 4.96461378]\n",
      "pred [3.28760152 5.61579538 4.23136228 4.76573643 3.63535365 5.19364558]\n",
      "pred [4.42093089 4.54705535 4.44305831 4.54455702 4.0800097  4.9489092 ]\n",
      "pred [3.85416661 5.10654694 4.3086249  4.67674184 4.0774214  5.04365091]\n",
      "pred [4.96275995 4.07814142 4.45732011 4.53714122 5.29151808 3.74292202]\n",
      "pred [4.17368862 4.77831854 4.10079782 5.0636229  3.65240682 5.35289925]\n",
      "pred [4.50697794 4.55149301 4.52223509 4.4882916  4.46890029 4.44856612]\n",
      "pred [4.12956245 4.78483497 4.4021675  4.61087573 4.24115116 4.81631303]\n",
      "pred [3.78021482 5.12778812 4.43628858 4.57690834 4.20299987 4.79010057]\n",
      "pred [4.39247567 4.49531405 3.89419642 5.21016073 4.06909717 4.91900538]\n",
      "pred [4.49786767 4.49322474 4.50027375 4.49264356 4.31512907 4.6794276 ]\n",
      "pred [5.23840222 3.75036183 4.51231196 4.49497558 4.95337132 3.94564952]\n",
      "pred [4.33378838 4.54400724 4.37570757 4.60095101 4.41826085 4.55579485]\n",
      "pred [4.09678286 4.84909065 4.5618748  4.43939938 4.26095434 4.73335252]\n",
      "pred [4.48330182 4.39374617 4.45710943 4.51569371 4.36294881 4.66893567]\n",
      "pred [2.89487824 5.98024356 4.46077623 4.53720573 4.03090629 4.94729403]\n",
      "pred [4.45089018 4.43123671 4.45374253 4.55476516 4.31294027 4.72009375]\n",
      "pred [3.67818612 5.3184531  4.30650646 4.69448723 3.47036129 5.54445184]\n",
      "pred [3.43358813 5.57441534 3.88895508 5.17949664 3.91084586 4.98565446]\n",
      "pred [4.04273463 4.99405999 4.07023695 4.94817959 3.80974184 5.15912023]\n",
      "pred [4.14547004 4.91191176 4.37066177 4.51580125 4.12155182 4.81336816]\n",
      "pred [3.72075157 5.24400967 4.26529472 4.73466409 4.14373322 4.88774655]\n",
      "pred [3.01898402 5.83342101 4.43724379 4.57834359 4.02500131 4.96799328]\n",
      "pred [4.22128776 4.76325604 3.9507307  5.15162844 3.83832213 4.93360215]\n",
      "pred [4.2218505  4.65658754 4.49763366 4.54358602 4.22333819 4.84558282]\n",
      "pred [3.9815335  4.90020795 4.27318322 4.77185105 3.74233595 5.15202634]\n",
      "(296, 32) (296, 6)\n",
      "******* Feature select: RF  Feature type: ST-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8159673997786167\n",
      "R2 Best score (validation) val. score :  0.5506924925913907\n",
      "R2 of the best estimator (testing dataset):  0.3208561765215688\n",
      "pred [4.6321  4.3713  4.4709  4.5276  4.2388  4.67505]\n",
      "pred [5.2107  3.7571  4.1488  4.78385 4.73775 4.1597 ]\n",
      "pred [4.2028  4.8459  3.6268  5.47625 3.36275 5.7229 ]\n",
      "pred [3.60125 5.40185 4.517   4.474   5.5474  3.37405]\n",
      "pred [4.3002  4.7626  3.41995 5.56365 2.9671  5.97425]\n",
      "pred [5.2759  3.6248  4.43765 4.5375  5.57865 3.36095]\n",
      "pred [4.04265 5.09105 4.2138  4.8328  4.24635 4.8004 ]\n",
      "pred [3.56825 5.43675 4.19435 4.8176  3.79415 5.1396 ]\n",
      "pred [4.00535 5.26145 4.33975 4.65605 4.16785 4.86465]\n",
      "pred [4.76805 4.34565 4.4539  4.5419  4.19515 4.6864 ]\n",
      "pred [4.65785 4.3948  4.4574  4.5637  4.18655 4.72085]\n",
      "pred [4.09485 4.90755 4.46785 4.50615 4.3208  4.6955 ]\n",
      "pred [3.49115 5.60315 4.5274  4.43935 4.9115  4.0731 ]\n",
      "pred [3.70695 5.36575 3.84135 5.15725 3.9259  5.10835]\n",
      "pred [3.77625 5.19415 4.18605 4.7526  4.197   4.8198 ]\n",
      "pred [3.9672  5.0385  4.00025 5.0073  3.87445 5.08975]\n",
      "pred [3.55105 5.5475  4.40605 4.63835 4.20035 4.7728 ]\n",
      "pred [4.10895 4.9995  4.4792  4.5599  4.5734  4.45825]\n",
      "pred [3.6499  5.49195 3.84275 5.1608  3.9118  5.1122 ]\n",
      "pred [4.98635 4.06195 4.49055 4.50555 3.571   5.498  ]\n",
      "pred [3.96765 5.1316  3.6765  5.19435 3.6762  5.3231 ]\n",
      "pred [3.8404  5.1745  4.41385 4.6206  4.2007  4.856  ]\n",
      "pred [3.75125 5.2387  4.48345 4.54295 4.4411  4.6182 ]\n",
      "pred [4.58495 4.37465 4.0713  4.9039  5.70015 3.17015]\n",
      "pred [3.71125 5.46065 4.3662  4.5617  4.24715 4.7742 ]\n",
      "pred [3.7143  5.26485 3.82915 5.1898  3.8388  5.0545 ]\n",
      "pred [3.882   5.0309  4.4452  4.50635 4.0654  4.97855]\n",
      "pred [4.6585  4.3903  4.4574  4.5571  4.19215 4.71965]\n",
      "pred [3.2562  5.726   3.8474  5.18775 3.93735 5.0861 ]\n",
      "pred [4.09385 4.9627  3.39565 5.6976  2.90205 5.95845]\n",
      "pred [3.90145 5.05625 3.51665 5.45035 3.6744  5.35075]\n",
      "pred [3.16135 6.00265 4.43525 4.5702  4.0841  4.94605]\n",
      "pred [4.3292  4.4176  3.44625 5.5803  3.29285 5.7049 ]\n",
      "pred [5.2919  3.6877  4.43775 4.55325 5.56475 3.4257 ]\n",
      "pred [4.13875 4.7476  3.97275 5.05175 3.849   5.04575]\n",
      "pred [3.6302  5.4916  3.7815  5.22085 3.6297  5.27025]\n",
      "pred [3.36055 5.70605 4.45715 4.56965 4.21345 4.77595]\n",
      "pred [3.38655 5.7935  4.39325 4.60275 4.02515 4.99915]\n",
      "pred [4.22625 4.67135 4.4874  4.52555 4.1588  4.8635 ]\n",
      "pred [4.09465 5.05315 4.4721  4.4906  4.0066  4.9856 ]\n",
      "pred [5.11735 3.79815 4.4017  4.5807  5.27175 3.56055]\n",
      "pred [4.13635 4.65745 3.83155 5.20855 3.2854  5.70055]\n",
      "pred [4.6388 4.263  4.5134 4.47   3.9967 4.8729]\n",
      "pred [3.92775 5.1014  4.31365 4.6719  4.1742  4.79315]\n",
      "pred [3.80945 5.3244  3.9218  5.08595 3.97105 5.15795]\n",
      "pred [3.99175 5.1013  3.6811  5.18275 3.67115 5.32515]\n",
      "pred [4.25215 4.8391  4.43715 4.5604  4.2524  4.75105]\n",
      "pred [5.25835 3.68645 4.42625 4.5696  4.8616  4.04265]\n",
      "pred [4.07385 4.9148  4.4323  4.5168  4.4825  4.59735]\n",
      "pred [3.94155 5.03925 4.3901  4.5983  4.11135 4.8411 ]\n",
      "pred [4.2201  4.99555 4.40815 4.54485 4.26235 4.79375]\n",
      "pred [3.5662  5.6593  4.32105 4.6595  4.08325 4.8404 ]\n",
      "pred [4.66975 4.32005 4.46875 4.5265  4.218   4.69545]\n",
      "pred [3.85615 5.22085 4.25925 4.84355 3.50915 5.5018 ]\n",
      "pred [3.18655 5.69825 3.75505 5.26325 3.81465 5.1598 ]\n",
      "pred [4.1338 4.8809 3.6471 5.4534 3.663  5.2135]\n",
      "pred [4.14815 4.705   4.36725 4.67945 4.12835 4.84885]\n",
      "pred [3.68025 5.4592  3.84375 5.27    4.059   4.95575]\n",
      "pred [3.42315 5.68085 4.38955 4.53025 4.2604  4.7664 ]\n",
      "pred [4.15915 4.8347  3.24185 5.82345 3.67415 5.18245]\n",
      "pred [3.86    5.14095 4.4156  4.6245  4.1249  4.8618 ]\n",
      "pred [3.6387  5.36385 3.8654  5.09195 3.1217  5.8374 ]\n",
      "(296, 20) (296, 6)\n",
      "******* Feature select: LR20  Feature type: HG-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8304689452335609\n",
      "R2 Best score (validation) val. score :  0.5724116609242236\n",
      "R2 of the best estimator (testing dataset):  0.4475465605586306\n",
      "pred [4.355375   4.60320833 4.45720833 4.53254167 4.27875    4.72458333]\n",
      "pred [5.24808333 3.78320833 4.50891667 4.49408333 4.73108333 4.111     ]\n",
      "pred [4.030875   4.91004167 3.62529167 5.36445833 3.63166667 5.53208333]\n",
      "pred [3.592      5.34333333 4.54479167 4.46516667 5.69908333 3.37441667]\n",
      "pred [4.43020833 4.56754167 3.39095833 5.60008333 3.02858333 5.91525   ]\n",
      "pred [5.20091667 3.777375   4.53908333 4.46241667 5.428      3.55308333]\n",
      "pred [4.12370833 4.87475    4.43925    4.544625   4.43683333 4.56325   ]\n",
      "pred [3.758875   5.12920833 3.92966667 5.04104167 3.73558333 5.23429167]\n",
      "pred [4.50516667 4.52725    4.45433333 4.52583333 4.374875   4.59745833]\n",
      "pred [4.688875   4.261625   4.45541667 4.52545833 4.308125   4.769625  ]\n",
      "pred [4.63554167 4.30341667 4.49979167 4.495125   4.254875   4.812625  ]\n",
      "pred [3.953625   5.16279167 4.33591667 4.63254167 4.215      4.72358333]\n",
      "pred [3.469375   5.52645833 4.52645833 4.44854167 5.30016667 3.58566667]\n",
      "pred [3.50341667 5.325625   4.06970833 4.88779167 3.77916667 5.194625  ]\n",
      "pred [4.31304167 4.64704167 4.406125   4.60916667 4.46320833 4.516375  ]\n",
      "pred [4.40966667 4.601375   4.035125   4.81166667 4.05091667 4.98504167]\n",
      "pred [3.63258333 5.510625   4.48725    4.54275    4.32029167 4.719125  ]\n",
      "pred [4.01620833 4.930375   4.40308333 4.604375   4.57754167 4.446875  ]\n",
      "pred [3.39708333 5.537375   4.060875   4.87691667 3.66929167 5.35420833]\n",
      "pred [4.68166667 4.369125   4.48558333 4.51829167 3.75058333 5.43745833]\n",
      "pred [3.69866667 5.30829167 3.916375   5.065125   3.76341667 5.24145833]\n",
      "pred [4.16116667 4.85504167 4.36320833 4.71783333 3.90558333 5.14379167]\n",
      "pred [3.766625   5.30025    4.45720833 4.557      4.390875   4.59591667]\n",
      "pred [4.45725    4.40279167 4.42091667 4.57766667 5.72133333 3.28429167]\n",
      "pred [3.24025    5.68041667 4.47229167 4.54870833 4.225125   4.80970833]\n",
      "pred [3.592625   5.31366667 4.402625   4.55025    4.13425    4.93416667]\n",
      "pred [4.290375   4.56395833 4.5355     4.47983333 4.12320833 4.94429167]\n",
      "pred [4.51791667 4.36416667 4.49108333 4.49795833 4.15925    4.86154167]\n",
      "pred [3.25716667 5.74495833 4.23575    4.754875   4.0485     4.87183333]\n",
      "pred [4.14916667 4.92895833 3.67525    5.44075    3.06016667 5.957875  ]\n",
      "pred [3.87025    5.08716667 3.98033333 5.22875    3.45608333 5.57983333]\n",
      "pred [3.49916667 5.54629167 4.05241667 5.06104167 3.676625   5.29666667]\n",
      "pred [4.176625   4.76391667 3.97645833 4.98716667 3.40470833 5.56816667]\n",
      "pred [5.39895833 3.56283333 4.510875   4.5        5.429375   3.52908333]\n",
      "pred [3.96675    5.016875   4.50254167 4.49166667 4.068125   4.79570833]\n",
      "pred [3.37554167 5.67520833 3.935875   5.08520833 3.67695833 5.339375  ]\n",
      "pred [2.903875   6.0515     4.41395833 4.62695833 3.8735     5.05704167]\n",
      "pred [3.37979167 5.64275    4.40891667 4.65566667 3.81008333 5.12595833]\n",
      "pred [4.35229167 4.64329167 4.48979167 4.53125    4.08079167 4.905125  ]\n",
      "pred [4.07520833 5.035625   4.24158333 4.845125   3.46070833 5.421625  ]\n",
      "pred [4.74641667 4.18941667 4.42641667 4.544875   4.96520833 4.00945833]\n",
      "pred [3.71183333 5.15120833 4.03716667 4.959125   3.81116667 5.219875  ]\n",
      "pred [4.3255     4.66183333 4.52466667 4.48566667 4.51816667 4.23583333]\n",
      "pred [4.134375   4.754625   4.493625   4.46120833 4.58366667 4.369625  ]\n",
      "pred [3.91383333 5.01545833 4.35241667 4.68629167 3.758      5.14941667]\n",
      "pred [3.74545833 5.26258333 3.904625   5.12979167 3.78391667 5.20775   ]\n",
      "pred [4.630625   4.413      4.51075    4.47945833 4.4565     4.54845833]\n",
      "pred [5.281625   3.75054167 4.47808333 4.51429167 4.98020833 4.01775   ]\n",
      "pred [3.90891667 5.11520833 4.39833333 4.57154167 4.29233333 4.66008333]\n",
      "pred [4.14004167 4.79229167 4.586875   4.3965     4.51004167 4.46341667]\n",
      "pred [4.59858333 4.43641667 4.496625   4.50829167 4.46370833 4.578375  ]\n",
      "pred [3.10658333 5.83416667 4.42670833 4.58429167 4.026      4.94691667]\n",
      "pred [4.80029167 4.20154167 4.50404167 4.46808333 4.34725    4.67575   ]\n",
      "pred [4.015125   4.993125   4.06825    4.803625   3.35154167 5.53545833]\n",
      "pred [3.10070833 5.83966667 3.92       5.10441667 3.79804167 5.14425   ]\n",
      "pred [3.94891667 5.146625   4.32029167 4.77020833 3.71470833 5.22341667]\n",
      "pred [4.45779167 4.508625   4.48783333 4.49754167 4.18929167 4.78675   ]\n",
      "pred [3.40329167 5.60416667 3.94825    5.01191667 3.915125   5.08754167]\n",
      "pred [3.01325    5.99654167 4.480375   4.57795833 3.84391667 5.10645833]\n",
      "pred [4.0405     4.989875   3.90970833 5.00441667 3.797125   5.272     ]\n",
      "pred [4.3985     4.52325    4.525875   4.49191667 4.54125    4.423375  ]\n",
      "pred [3.40408333 5.48516667 4.07283333 4.8695     3.78845833 5.20779167]\n",
      "(296, 20) (296, 6)\n",
      "******* Feature select: LR20  Feature type: OG-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8111881197018129\n",
      "R2 Best score (validation) val. score :  0.5662454224574904\n",
      "R2 of the best estimator (testing dataset):  0.39614653550831136\n",
      "pred [4.11664911 4.93184604 4.30314945 4.68422953 4.37745558 4.68831711]\n",
      "pred [5.23471868 3.66580057 4.44693129 4.52507201 4.68958128 4.50890478]\n",
      "pred [4.23988585 4.75049167 3.33920558 5.70508681 3.40828097 5.64409003]\n",
      "pred [4.03492623 4.91820108 4.50873424 4.51741863 5.24779747 3.58521319]\n",
      "pred [4.2210177  4.8016591  3.41037411 5.60973773 3.34573523 5.67449885]\n",
      "pred [5.26147842 3.66256763 4.27367248 4.63080579 5.5547199  3.28707139]\n",
      "pred [4.2344724  4.55575378 4.28893998 4.67160376 4.39593918 4.62396016]\n",
      "pred [3.46601542 5.60824379 4.38535745 4.59109512 4.12966824 4.88253322]\n",
      "pred [4.16540236 4.7448388  4.40360646 4.55665506 4.34542542 4.62703406]\n",
      "pred [3.91781234 5.04786114 4.28262873 4.76502016 4.21076213 4.77841333]\n",
      "pred [4.18375619 4.75314515 4.27232328 4.84159237 4.00498439 5.00594192]\n",
      "pred [3.61351966 5.26454302 4.30444172 4.73449873 4.32027396 4.66266317]\n",
      "pred [3.94969324 5.02098953 4.52905415 4.50888336 5.22168101 3.62482369]\n",
      "pred [3.55385735 5.36066546 3.6340667  5.27615405 3.5475534  5.43416283]\n",
      "pred [4.21482823 4.81526349 4.01323067 5.04367586 3.98891426 4.9148271 ]\n",
      "pred [4.37482048 4.5823382  3.90974181 5.03101935 4.13156267 4.93123611]\n",
      "pred [3.61449692 5.38855629 4.42051402 4.51640644 4.28259844 4.66670232]\n",
      "pred [3.87727534 5.0987575  4.38279787 4.6697337  4.58516222 4.46664073]\n",
      "pred [3.48614445 5.39108026 3.63928051 5.27615405 3.51827187 5.46141008]\n",
      "pred [4.63559108 4.5292066  4.53825829 4.49694755 4.02980409 4.88813819]\n",
      "pred [4.01882313 4.81205661 3.96971359 5.03682746 3.83941536 5.15360711]\n",
      "pred [4.12301903 4.8228663  4.39563582 4.54591823 4.39765035 4.62127867]\n",
      "pred [3.83430761 5.23237159 4.32511807 4.7425493  4.53951239 4.51682647]\n",
      "pred [4.16958291 4.63719038 4.29540622 4.68971994 5.42627512 3.47021657]\n",
      "pred [2.98998459 5.79509965 4.29965007 4.76301446 4.2396156  4.74397609]\n",
      "pred [3.66201916 5.33619055 4.42231522 4.68301115 4.32561701 4.6918149 ]\n",
      "pred [4.43548951 4.64050322 4.42227862 4.57823699 4.29458411 4.72708518]\n",
      "pred [4.28806587 4.63792369 4.32637522 4.80811907 4.02455774 4.94108334]\n",
      "pred [3.19446055 5.80200415 3.99994392 4.97762711 3.99606107 5.15097017]\n",
      "pred [4.31252313 4.6963594  3.43008374 5.5762504  3.39316909 5.62672764]\n",
      "pred [4.09516002 4.97161573 3.42544119 5.58071375 3.38344153 5.54933359]\n",
      "pred [3.5778206  5.33648376 4.50584301 4.47327143 4.33865566 4.76540096]\n",
      "pred [4.6541965  4.23255044 3.24565378 5.5850797  3.43941227 5.52496057]\n",
      "pred [5.29787977 3.66317871 4.43813603 4.5239276  5.4397899  3.42549035]\n",
      "pred [4.07216891 4.87724641 4.20473455 4.78813017 3.87035782 5.09011018]\n",
      "pred [3.5788114  5.38873655 3.60947382 5.3438709  3.2854715  5.63389305]\n",
      "pred [3.07552347 5.8607798  4.27055896 4.79339809 3.99179503 4.99949447]\n",
      "pred [3.5076364  5.50540066 4.45759583 4.535351   4.06680783 4.9346171 ]\n",
      "pred [4.44507495 4.64710648 4.42997629 4.58626351 4.3356577  4.6540331 ]\n",
      "pred [3.94226076 5.00110555 4.08411133 5.0266289  3.69692836 5.35341303]\n",
      "pred [4.67560678 4.11568862 4.36818389 4.59587243 5.41253369 3.43517493]\n",
      "pred [4.02873867 4.89836495 3.87555922 5.24715402 3.44740445 5.498775  ]\n",
      "pred [4.47023196 4.40594822 4.49100686 4.50858032 4.85187582 4.05300581]\n",
      "pred [4.0773478  4.83123799 4.33699477 4.65259297 4.32910721 4.75032428]\n",
      "pred [3.97568578 5.02936865 4.24465529 4.77269967 3.88656101 5.15714378]\n",
      "pred [4.00155813 4.81530789 3.96971359 5.03436496 3.84954994 5.14065649]\n",
      "pred [4.20361722 4.66831288 4.30345288 4.64124291 4.38820752 4.63086344]\n",
      "pred [5.23808514 3.62288258 4.33073197 4.5943946  4.91021173 4.08238166]\n",
      "pred [3.91974214 5.05914542 4.27768952 4.70184717 4.4222513  4.64704095]\n",
      "pred [4.1322378  4.83479539 4.34459748 4.65081512 4.27318508 4.73994483]\n",
      "pred [4.26653869 4.69719248 4.29142346 4.62594405 4.49375805 4.5130999 ]\n",
      "pred [2.98398045 6.01959893 4.18967597 4.81107577 4.02912084 5.02033768]\n",
      "pred [4.65346367 4.37981326 4.33461444 4.67350876 4.36533017 4.67064119]\n",
      "pred [4.11135948 4.921454   4.06072669 5.01876442 3.51422325 5.60366783]\n",
      "pred [3.21673005 5.74305276 3.94704392 5.05873154 3.99065376 5.10951427]\n",
      "pred [3.96965286 5.15260469 3.67281159 5.36308332 3.76294403 5.24032469]\n",
      "pred [4.43175472 4.63828297 4.46290923 4.5487068  4.26620902 4.66872073]\n",
      "pred [3.5296814  5.44010687 3.89100372 5.12406276 3.77274487 5.06833575]\n",
      "pred [3.03122163 5.89839296 4.26741319 4.74457355 4.07590728 4.93319662]\n",
      "pred [3.91064611 5.00414619 4.1194414  4.81438672 4.20881295 4.76088292]\n",
      "pred [4.1321643  4.88067933 4.25843749 4.77799711 4.12642563 4.91491286]\n",
      "pred [3.82135381 5.21902582 4.25865614 4.82849227 3.59366407 5.40549205]\n",
      "(296, 20) (296, 6)\n",
      "******* Feature select: LR20  Feature type: ST-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8243062817596883\n",
      "R2 Best score (validation) val. score :  0.5781424879072633\n",
      "R2 of the best estimator (testing dataset):  0.3558737517006958\n",
      "pred [4.76793122 4.05800686 4.46347463 4.57371907 4.35759965 4.60729768]\n",
      "pred [4.7477299  4.12792666 4.34422691 4.52838314 4.9547195  4.13776434]\n",
      "pred [4.14031599 4.79128708 3.37586061 5.87134897 3.0468448  5.9449265 ]\n",
      "pred [3.56302556 5.22624473 4.53781668 4.46175529 5.54903294 3.44241173]\n",
      "pred [4.5189085  4.53356854 3.2531226  5.68889527 3.19201047 5.77903433]\n",
      "pred [4.55035679 4.55865836 4.50654327 4.467788   5.74261182 3.53569688]\n",
      "pred [4.35620117 4.56313691 4.43626202 4.50980497 4.45551257 4.55174285]\n",
      "pred [3.65694097 5.36895221 4.03019447 4.92657788 3.92797755 5.05830176]\n",
      "pred [4.36427496 4.65488941 4.51045172 4.50673332 4.45035258 4.5418701 ]\n",
      "pred [4.89218937 3.99852427 4.40513637 4.63362346 4.35085664 4.61739331]\n",
      "pred [4.79034646 4.09750073 4.44931506 4.58600469 4.36131013 4.65190687]\n",
      "pred [4.01463872 4.99646954 4.36382957 4.61579135 4.27539959 4.69345818]\n",
      "pred [3.51350848 5.41943997 4.53963569 4.44129002 5.3894634  3.55608602]\n",
      "pred [3.43927882 5.57556412 3.81803699 5.18894479 3.73336987 5.38451833]\n",
      "pred [4.38352027 4.62313858 4.43338684 4.66457905 4.43253243 4.54471428]\n",
      "pred [4.24369977 4.78791915 4.1782833  4.85869311 4.07462335 4.8530801 ]\n",
      "pred [3.50255962 5.35688221 4.38887522 4.54872014 4.24054399 4.79753433]\n",
      "pred [4.29834911 4.65317954 4.41440563 4.58532299 4.55494659 4.37702578]\n",
      "pred [3.24555668 5.69302113 3.94137621 5.14682846 3.77117263 5.37456862]\n",
      "pred [4.7375982  4.21758442 4.42639101 4.48475015 3.52901927 5.62310183]\n",
      "pred [4.03322799 4.89330515 3.592252   5.46247226 3.50475178 5.58177589]\n",
      "pred [3.83312378 5.20359955 4.17818306 5.0114876  3.99259485 5.01442175]\n",
      "pred [4.14340668 4.89111419 4.46301972 4.51498513 4.47453378 4.42359793]\n",
      "pred [4.55334908 4.53452379 4.33121596 4.48787591 5.65458979 3.33042762]\n",
      "pred [3.20394926 6.09188895 4.4464768  4.51210972 3.9733422  4.98203116]\n",
      "pred [3.6506934  5.26354426 4.22792367 4.64016105 4.01970995 5.03361611]\n",
      "pred [4.29862276 4.93995648 4.48531932 4.53655725 4.20565922 4.84087017]\n",
      "pred [4.74929442 4.22568187 4.44888164 4.58863051 4.39086195 4.68797318]\n",
      "pred [3.54383945 5.43019146 4.06225609 4.85406074 3.89632052 5.1237797 ]\n",
      "pred [4.24668971 4.74088205 3.41038226 5.58048505 3.07974469 5.9103266 ]\n",
      "pred [3.96714282 5.15924019 3.37394243 5.73351792 3.28580638 5.72545384]\n",
      "pred [3.33372833 5.62842565 4.33332739 4.60088122 3.93459292 5.12967499]\n",
      "pred [4.61273787 4.36908456 3.13299238 5.89826336 3.14632382 5.88992872]\n",
      "pred [4.63238205 4.25158777 4.4528495  4.53445646 5.0907022  4.24498978]\n",
      "pred [4.37181589 4.76185626 4.18646903 4.77075428 3.89536005 5.0812918 ]\n",
      "pred [3.53451605 5.50458109 3.78331153 5.25497115 3.65270872 5.42648536]\n",
      "pred [2.91312605 6.18022461 4.25885455 4.61610857 3.73710529 5.15681681]\n",
      "pred [3.75633814 5.41346054 4.36800012 4.60241488 4.13004319 4.81185805]\n",
      "pred [4.18497633 4.87027807 4.48782289 4.51616873 4.20018258 4.81352044]\n",
      "pred [3.65339322 5.52876956 4.39821853 4.58972265 3.76878099 5.31600764]\n",
      "pred [4.7906871  4.19905614 4.46161073 4.52540511 5.33568482 3.6072206 ]\n",
      "pred [4.13655315 4.91162343 3.58118101 5.34106617 3.24025086 5.62831886]\n",
      "pred [4.40049984 4.67839767 4.47420475 4.50182648 4.60799418 4.56735663]\n",
      "pred [3.99969139 4.98067118 4.32919342 4.61761395 4.09520039 4.88866905]\n",
      "pred [3.70951517 5.42714296 4.05185292 5.09621761 3.62639545 5.38089215]\n",
      "pred [4.0523138  4.89807703 3.56279607 5.4752785  3.54387923 5.54935889]\n",
      "pred [4.42888596 4.61611658 4.48293625 4.49695716 4.41955629 4.53694064]\n",
      "pred [4.78074637 4.1329252  4.42298849 4.568568   5.15181197 4.17431422]\n",
      "pred [4.18540325 4.92716187 4.40063265 4.51461095 4.42843961 4.58937623]\n",
      "pred [4.1650266  4.75296174 4.46807013 4.60822777 4.13083745 4.8828393 ]\n",
      "pred [4.60637846 4.39613922 4.52970572 4.43680946 4.50613631 4.50994102]\n",
      "pred [3.07224434 6.05891557 4.26893559 4.61919139 3.84846302 5.10618824]\n",
      "pred [4.70697235 4.13264638 4.43514527 4.60505539 4.2417307  4.75831886]\n",
      "pred [3.91914363 4.99225421 3.48693186 5.48289591 3.13212157 5.91769816]\n",
      "pred [3.67919795 5.25764679 3.86779225 5.18661    3.66904198 5.33100101]\n",
      "pred [4.20050425 4.90137933 3.35318128 5.80324244 3.53901504 5.44150151]\n",
      "pred [4.2070961  4.75897433 4.40957084 4.60009692 4.13660931 4.86933031]\n",
      "pred [3.31861645 5.76722379 3.7870576  5.1856279  3.79091575 5.32601213]\n",
      "pred [3.07250791 6.14162206 4.43237219 4.55325726 3.81005917 5.13523475]\n",
      "pred [4.18181891 4.87407109 3.62804638 5.55239056 3.64383465 5.56210427]\n",
      "pred [4.17540585 4.80877772 4.51966359 4.50801926 4.35729154 4.67395556]\n",
      "pred [3.96877605 5.1173172  3.8933194  5.12450423 3.29221934 5.81315857]\n",
      "(296, 30) (296, 6)\n",
      "******* Feature select: LR30  Feature type: HG-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8326013728115562\n",
      "R2 Best score (validation) val. score :  0.5701808627709049\n",
      "R2 of the best estimator (testing dataset):  0.46382510255220194\n",
      "pred [4.6042994  4.56465494 4.44464709 4.57853673 4.31929109 4.73827888]\n",
      "pred [5.21931572 3.84889395 4.44767955 4.53598731 4.60764311 4.57777524]\n",
      "pred [4.05520586 4.93151703 3.37106984 5.73230917 3.39298179 5.59540617]\n",
      "pred [3.58995955 5.44958346 4.5348205  4.47514401 5.46669679 3.5740029 ]\n",
      "pred [4.45202518 4.53065951 3.48439406 5.50605607 3.07854103 5.91177043]\n",
      "pred [5.2758843  3.75170326 4.47358517 4.50540926 5.29390485 3.74833691]\n",
      "pred [4.09813553 4.97728082 4.46331123 4.53922632 4.45153159 4.56235437]\n",
      "pred [3.63366004 5.22591997 4.21988931 4.78631261 4.01729195 5.03443007]\n",
      "pred [4.52962252 4.44119744 4.51803545 4.50216251 4.42552634 4.56947892]\n",
      "pred [4.64396627 4.52997633 4.44923597 4.55852973 4.29423184 4.76255305]\n",
      "pred [4.6306666  4.49017879 4.47601453 4.53045766 4.16189542 4.78314052]\n",
      "pred [4.06998935 4.94389093 4.43594966 4.57538644 4.30191955 4.62493516]\n",
      "pred [3.470062   5.57541082 4.52366891 4.47594379 5.28081987 3.7412141 ]\n",
      "pred [3.59455585 5.3987797  3.88113937 5.07704572 3.73148646 5.21734295]\n",
      "pred [4.29011092 4.61903092 4.42051141 4.58326513 4.36540649 4.65538559]\n",
      "pred [4.45388043 4.47118397 4.25640652 4.58393759 4.16083743 4.85323448]\n",
      "pred [3.72968219 5.33495189 4.40636181 4.50412569 4.23732526 4.82240226]\n",
      "pred [4.31726142 4.76372259 4.37581866 4.64305534 4.76626661 4.26482723]\n",
      "pred [3.32441814 5.70794944 3.95534401 5.06223118 3.56772286 5.37571874]\n",
      "pred [4.89027785 3.97359724 4.42127083 4.51885177 3.64087945 5.55229802]\n",
      "pred [3.8257864  5.08576478 3.84891455 5.09530504 3.69125458 5.38006916]\n",
      "pred [3.96676158 5.02784124 4.37720508 4.58340108 3.93348212 5.12210221]\n",
      "pred [4.17104543 4.96500544 4.37032663 4.61947641 4.65498917 4.37979733]\n",
      "pred [4.35829493 4.69546652 4.46589007 4.53403649 5.50889438 3.4713241 ]\n",
      "pred [3.10967742 5.83625492 4.4271422  4.55773105 4.33293438 4.76050431]\n",
      "pred [3.68622979 4.95179263 4.43257098 4.61392883 4.12013016 4.93214348]\n",
      "pred [4.4333736  4.55480024 4.52680163 4.45459306 4.1764163  4.86094511]\n",
      "pred [4.49812556 4.65401813 4.4670157  4.54179127 4.14197147 4.83181874]\n",
      "pred [3.2804694  5.66331901 4.20032177 4.74987179 3.96060869 4.96784998]\n",
      "pred [4.30875529 4.76864029 3.51236907 5.52171103 3.08965136 5.86389983]\n",
      "pred [4.0202375  4.98986498 3.69163449 5.35899895 3.30149748 5.57159036]\n",
      "pred [3.45752074 5.54629753 4.17942502 4.73052326 4.02237051 5.09270058]\n",
      "pred [4.14459427 4.65383789 3.95215832 5.09061171 3.3120446  5.69258222]\n",
      "pred [5.41203286 3.56511364 4.42212042 4.47400659 5.18201004 3.83169888]\n",
      "pred [3.94445566 4.99953799 4.42269203 4.57463573 4.0013548  4.94143678]\n",
      "pred [3.36578947 5.63033594 3.77650705 5.19519025 3.56703214 5.33030708]\n",
      "pred [2.98631274 5.98403336 4.28020935 4.76447926 4.08910422 5.04122621]\n",
      "pred [3.5308986  5.46140076 4.34181775 4.60074849 4.2414227  5.02261431]\n",
      "pred [4.44387172 4.63719573 4.52411207 4.49299799 4.1504894  4.69572105]\n",
      "pred [3.87400107 5.01912097 4.31322695 4.76627362 3.70062722 5.33857208]\n",
      "pred [4.8423277  4.23951714 4.47113919 4.51143647 5.12914994 3.97070784]\n",
      "pred [3.92319121 5.04152777 4.06915793 4.96412221 3.56268372 5.33809215]\n",
      "pred [4.51361048 4.53804581 4.48007768 4.52089076 4.63925133 4.66917661]\n",
      "pred [4.16019096 4.76489225 4.4809967  4.49274662 4.33919283 4.71750751]\n",
      "pred [3.89711595 5.0553114  4.32805852 4.67728379 3.81614246 5.21213604]\n",
      "pred [3.83255392 5.00677295 3.80828763 5.17419797 3.67146525 5.39172278]\n",
      "pred [4.56339812 4.42220184 4.46562149 4.48868374 4.3972364  4.57504219]\n",
      "pred [5.27207336 3.76709887 4.40494502 4.559262   4.75791534 4.36431005]\n",
      "pred [4.15495385 4.88920242 4.39754205 4.65382177 4.31040448 4.7010186 ]\n",
      "pred [4.19376935 4.75509553 4.56214448 4.44754461 4.38971862 4.54947286]\n",
      "pred [4.56371304 4.39933534 4.50126648 4.47911141 4.51500771 4.50172457]\n",
      "pred [2.95587043 5.94329285 4.37345778 4.61973353 4.14689872 4.89057637]\n",
      "pred [4.72383634 4.4791351  4.45875226 4.55338241 4.29362212 4.74244523]\n",
      "pred [3.96234229 5.10868717 3.87746211 5.37102745 3.51346888 5.5890224 ]\n",
      "pred [3.25805061 5.7440098  3.80243015 5.15354095 3.70037342 5.20408833]\n",
      "pred [3.87990586 5.17767057 4.17965405 4.96074448 3.68487726 5.23208639]\n",
      "pred [4.4013594  4.53531915 4.51852578 4.48816965 4.22902692 4.60805806]\n",
      "pred [3.53498112 5.47620569 3.82872866 5.13776131 3.79690439 5.18037099]\n",
      "pred [2.94027511 6.04543155 4.35814468 4.63613718 4.10289029 5.0034701 ]\n",
      "pred [3.97946338 4.97405556 3.87483082 5.09414126 3.7259157  5.2688414 ]\n",
      "pred [4.45368735 4.56183559 4.50051957 4.46939848 4.45364803 4.61111488]\n",
      "pred [3.54199032 5.31005756 3.91080346 5.07649309 3.64002191 5.42383232]\n",
      "(296, 30) (296, 6)\n",
      "******* Feature select: LR30  Feature type: OG-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8247969618232839\n",
      "R2 Best score (validation) val. score :  0.5647760533496886\n",
      "R2 of the best estimator (testing dataset):  0.40780542750493565\n",
      "pred [4.62153234 4.41779612 4.24687743 4.71641653 4.30930609 4.67491433]\n",
      "pred [5.3005113  3.67983242 4.45922468 4.5585025  4.57785988 4.35570479]\n",
      "pred [3.92775757 5.06431142 3.47044003 5.59131902 3.40357399 5.62107102]\n",
      "pred [3.90540219 5.19672464 4.5202307  4.51386239 5.2619432  3.73383073]\n",
      "pred [4.34869226 4.65602526 3.32979953 5.60787812 3.52872939 5.64348585]\n",
      "pred [5.30085495 3.67764712 4.36013552 4.6216417  5.65212431 3.21854462]\n",
      "pred [4.2205643  4.73152528 4.28899737 4.71318151 4.41295482 4.60539576]\n",
      "pred [3.88153156 5.24965655 4.1898719  4.89035781 3.92006413 5.04887984]\n",
      "pred [4.27198325 4.71310827 4.43683093 4.61298602 4.41376809 4.56164202]\n",
      "pred [4.70351575 4.47990363 4.24582471 4.71663358 4.29893071 4.7092954 ]\n",
      "pred [4.51622552 4.51478413 4.17657759 4.83648589 4.0588703  4.89905332]\n",
      "pred [4.03903213 5.01178917 4.38770179 4.57057    4.31779018 4.5882967 ]\n",
      "pred [3.73237097 5.33809913 4.53059773 4.49479871 5.2451834  3.69297279]\n",
      "pred [3.78176301 5.29366345 3.71702473 5.28456308 3.67515414 5.3127308 ]\n",
      "pred [4.26956463 4.6586984  4.05471664 4.94546047 4.20069047 4.76923694]\n",
      "pred [4.17729177 4.75094013 4.14727407 4.82522676 4.03739144 4.87845054]\n",
      "pred [3.75130027 5.30361945 4.45467185 4.55981482 4.30018326 4.71386388]\n",
      "pred [4.17542196 4.85374706 4.44042931 4.56354656 4.60480762 4.40232082]\n",
      "pred [3.63952892 5.37322643 3.67577813 5.34832945 3.62871067 5.39017237]\n",
      "pred [4.64730513 4.3104666  4.49143108 4.50647382 4.09907737 4.98430447]\n",
      "pred [3.89022097 5.19933893 4.03317396 4.9592104  3.87954771 5.16090022]\n",
      "pred [4.03420259 4.99142487 4.40381666 4.53908192 4.38236282 4.59201213]\n",
      "pred [4.10808661 5.03011101 4.40973421 4.60742248 4.52000951 4.44217182]\n",
      "pred [4.26929176 4.80718604 4.36935699 4.58961674 5.55680832 3.38389461]\n",
      "pred [3.51690764 5.45748017 4.38837627 4.60190678 4.20242867 4.757354  ]\n",
      "pred [3.94775152 5.19777246 4.25968446 4.76183541 4.22412797 4.8247324 ]\n",
      "pred [4.44773823 4.57012571 4.49445218 4.53298466 4.33114675 4.7200009 ]\n",
      "pred [4.53242543 4.49144959 4.1941351  4.80145267 4.07344632 4.87107287]\n",
      "pred [3.33563065 5.57263872 3.98948626 4.95644982 3.97741944 5.06878866]\n",
      "pred [4.25195863 4.70244871 3.38429397 5.65570527 3.46598544 5.57120373]\n",
      "pred [3.80895833 5.05556096 3.73719755 5.28902591 3.55298315 5.49448319]\n",
      "pred [3.48416516 5.34273724 4.23438258 4.74065334 3.96359613 4.9447942 ]\n",
      "pred [4.8090926  4.1418474  3.39036463 5.66498057 3.40744893 5.54762356]\n",
      "pred [5.30614644 3.68973784 4.43800622 4.52121111 5.38592378 3.34321427]\n",
      "pred [4.13537289 4.89256256 4.31172708 4.68201737 3.83428733 5.15300095]\n",
      "pred [3.69231916 5.32088726 3.59723956 5.3846391  3.30194155 5.73582226]\n",
      "pred [3.43231535 5.43933672 4.29559014 4.64327243 4.03481461 4.95362576]\n",
      "pred [3.46606486 5.43405252 4.27158908 4.73085678 3.83353221 5.117834  ]\n",
      "pred [4.34006016 4.71288887 4.48289456 4.55763605 4.43668096 4.70338168]\n",
      "pred [4.05953826 5.02301603 4.20360935 4.84701016 3.81541661 5.16914165]\n",
      "pred [4.89988552 4.17944159 4.42692435 4.57544425 5.52033696 3.46851512]\n",
      "pred [4.05856648 5.05717892 3.84342404 5.18627591 3.51390144 5.47235034]\n",
      "pred [4.74760081 4.33941657 4.50318433 4.52607104 4.49546023 4.39711915]\n",
      "pred [4.0511275  4.96475383 4.39626797 4.64679483 4.28441663 4.64001889]\n",
      "pred [3.87490241 5.19086469 4.33741578 4.72580433 4.13398653 4.86644833]\n",
      "pred [3.93044869 5.15831769 3.98072411 5.0611781  3.8779239  5.15892784]\n",
      "pred [4.3088276  4.58647492 4.31653445 4.72638957 4.3773826  4.52666131]\n",
      "pred [5.32014934 3.67060858 4.37214885 4.61000914 4.874207   3.90497758]\n",
      "pred [4.09135982 4.93668677 4.43808319 4.57460999 4.39177597 4.59846275]\n",
      "pred [4.09992901 4.93311516 4.41049157 4.67785686 4.29082637 4.61587325]\n",
      "pred [4.38771252 4.61626839 4.33296384 4.71335355 4.44478006 4.42271979]\n",
      "pred [3.34763429 5.70208608 4.33486145 4.6515656  3.96635086 4.90686938]\n",
      "pred [4.66417317 4.38066992 4.24784878 4.68070668 4.2521938  4.66487864]\n",
      "pred [4.18801255 4.81965964 3.87469668 5.1052434  3.37437926 5.70641745]\n",
      "pred [3.39853781 5.54976825 3.90132032 5.07378487 4.03774577 5.00871674]\n",
      "pred [3.94086595 5.00098541 3.81756386 5.14763296 3.80690455 5.26438294]\n",
      "pred [4.25035618 4.75518312 4.46637043 4.54151563 4.21933222 4.84149373]\n",
      "pred [3.2887207  5.55025288 3.9705259  5.03591924 4.00835264 5.06676077]\n",
      "pred [3.2523142  5.77978597 4.39820271 4.58746561 4.05861557 4.9405307 ]\n",
      "pred [3.95292949 5.05874133 4.28100694 4.76603897 4.10719918 4.78222895]\n",
      "pred [4.05162339 5.00605385 4.37620569 4.72876276 4.19200233 4.68925049]\n",
      "pred [3.82263469 5.18380999 4.17317107 4.85013827 3.50900396 5.39291946]\n",
      "(296, 30) (296, 6)\n",
      "******* Feature select: LR30  Feature type: ST-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8306416988558142\n",
      "R2 Best score (validation) val. score :  0.5704780583800162\n",
      "R2 of the best estimator (testing dataset):  0.35858899836910313\n",
      "pred [4.80116462 4.10998111 4.43174448 4.57902334 4.37088176 4.71250062]\n",
      "pred [4.70216339 4.09613625 4.33196768 4.73724444 5.0394736  4.20586935]\n",
      "pred [4.07043833 4.83218622 3.33014009 5.60967677 3.14383794 5.75098437]\n",
      "pred [3.83777184 5.21563283 4.52724467 4.48256087 5.44964507 3.51708735]\n",
      "pred [4.44749061 4.39189324 3.31093205 5.6670684  3.29898226 5.69382481]\n",
      "pred [4.65339517 4.2432642  4.51891944 4.54296835 5.5105447  3.57089958]\n",
      "pred [4.34056449 4.79692075 4.43917135 4.62579529 4.40999348 4.56912541]\n",
      "pred [3.72335768 5.37759817 4.06523809 5.01232731 3.84191002 5.13101511]\n",
      "pred [4.33802434 4.56186176 4.4770566  4.52420309 4.5134853  4.5151332 ]\n",
      "pred [4.9448519  4.02997056 4.43380869 4.5836584  4.35888341 4.66173783]\n",
      "pred [4.83493433 4.16082362 4.43931975 4.56057182 4.36667815 4.64470076]\n",
      "pred [4.10891912 4.84727724 4.42514995 4.57549135 4.44068882 4.53177702]\n",
      "pred [3.51185264 5.46620145 4.52865425 4.46977849 5.19990527 3.81802737]\n",
      "pred [3.46942644 5.56799802 3.84355132 5.16636588 3.68685728 5.38924641]\n",
      "pred [4.29750936 4.73484094 4.35400257 4.63791915 4.42823044 4.58669887]\n",
      "pred [4.37970606 4.80049859 4.20554699 4.69691    4.17123797 4.84325456]\n",
      "pred [3.44306735 5.63881264 4.44372002 4.52218497 4.26233732 4.75786248]\n",
      "pred [4.36737913 4.75283508 4.41368298 4.58840102 4.65791654 4.34741954]\n",
      "pred [3.29530119 5.71698714 3.88658194 5.13032164 3.70278488 5.29325719]\n",
      "pred [4.83849002 4.07595958 4.42101945 4.59779987 3.54500488 5.39714184]\n",
      "pred [4.07228862 4.95306896 3.54990893 5.5366844  3.62642983 5.43878216]\n",
      "pred [3.72571592 5.09051716 4.05591463 4.99357236 3.95503174 5.00605148]\n",
      "pred [4.01969643 4.9792309  4.44747514 4.56207464 4.45878329 4.49767393]\n",
      "pred [4.41399288 4.48002712 4.37285716 4.64060679 5.68273908 3.41500455]\n",
      "pred [2.9885155  6.04006614 4.40769857 4.57024575 4.0182739  4.97968528]\n",
      "pred [3.91838355 5.11150708 4.01584872 4.90369849 3.88518873 5.12972798]\n",
      "pred [4.21355202 4.7880011  4.51070176 4.50961679 4.16769589 4.70445763]\n",
      "pred [4.79869265 4.19905131 4.43790486 4.57527659 4.35332037 4.63981998]\n",
      "pred [3.44948278 5.56401035 4.14088911 4.84847219 3.86403337 5.15128174]\n",
      "pred [4.24870219 4.73651305 3.38214073 5.63165501 3.19325081 5.74992865]\n",
      "pred [3.82478431 5.12712935 3.36668104 5.5638669  3.41828433 5.54676486]\n",
      "pred [3.29419455 5.73953468 4.28082231 4.66642061 3.91386507 5.13855719]\n",
      "pred [4.63706821 4.30406489 3.24374349 5.84736034 3.22369756 5.69519186]\n",
      "pred [4.89097854 3.98041426 4.41838695 4.56054253 4.98977134 4.03549823]\n",
      "pred [4.18051269 4.79111033 4.20871149 4.75656017 3.86853846 5.06445558]\n",
      "pred [3.53805524 5.50660891 3.82516263 5.20278974 3.63162305 5.35976101]\n",
      "pred [2.88516533 6.21777111 4.39889855 4.60588309 3.81745424 5.11765539]\n",
      "pred [3.54281385 5.48263517 4.34646345 4.6140237  4.06736569 4.80552361]\n",
      "pred [4.40087654 4.73777002 4.4503556  4.53001824 4.24379628 4.78185905]\n",
      "pred [3.59982556 5.34892612 4.40749196 4.62511168 3.74212433 5.18974933]\n",
      "pred [4.59501099 4.14905459 4.49093218 4.5095623  5.36351181 3.76877912]\n",
      "pred [4.18574148 4.78004749 3.74673852 5.42935218 3.33315953 5.6849752 ]\n",
      "pred [4.34232567 4.58649224 4.49325585 4.52484786 4.3108014  4.52334783]\n",
      "pred [4.03222337 4.98039668 4.42260661 4.57349959 4.13673588 4.85521496]\n",
      "pred [3.62159022 5.23304029 3.94709431 5.07156882 3.73834702 5.3016695 ]\n",
      "pred [4.08400854 4.9575011  3.50838822 5.56611862 3.62557108 5.42397236]\n",
      "pred [4.48955197 4.51123997 4.49157236 4.46383384 4.40068486 4.55768512]\n",
      "pred [4.86864733 3.88704163 4.41269937 4.59146246 5.11956014 4.13382155]\n",
      "pred [4.12795266 4.85827874 4.3954638  4.58695668 4.40966339 4.52032248]\n",
      "pred [4.19745359 4.73865934 4.4886159  4.46849403 4.15644829 4.89081901]\n",
      "pred [4.44712478 4.52228314 4.55718214 4.53393647 4.58399191 4.49106677]\n",
      "pred [2.93287591 6.10722567 4.32504548 4.65938077 3.90808382 5.14006844]\n",
      "pred [4.84033668 4.08780485 4.42707763 4.57918233 4.29734563 4.78702451]\n",
      "pred [3.88533362 5.10611931 3.61424595 5.50340133 3.18751626 5.7005654 ]\n",
      "pred [3.54144717 5.42116664 3.8865891  5.07574199 3.70814797 5.26259491]\n",
      "pred [3.90676778 4.98016186 3.49438757 5.50702061 3.53360306 5.38089232]\n",
      "pred [4.30098337 4.82198167 4.43144169 4.59049314 4.07683714 4.84294855]\n",
      "pred [3.25084109 5.69489454 3.77581746 5.15000839 3.75099893 5.21800579]\n",
      "pred [2.98135865 6.07081699 4.40769309 4.58556294 3.86624167 5.12258846]\n",
      "pred [4.08654084 4.87613035 3.58322291 5.46928986 3.63407584 5.25163253]\n",
      "pred [4.17836423 4.88302689 4.46403896 4.48713923 4.35164368 4.65789912]\n",
      "pred [3.96405984 5.09687959 3.77091296 5.15757711 3.25162785 5.72423176]\n",
      "(296, 40) (296, 6)\n",
      "******* Feature select: LR40  Feature type: HG-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8490789704883781\n",
      "R2 Best score (validation) val. score :  0.6065997111326237\n",
      "R2 of the best estimator (testing dataset):  0.4605834703823879\n",
      "pred [4.77918901 4.29746646 4.47291225 4.54853443 4.35581344 4.6659362 ]\n",
      "pred [5.20527892 3.89707246 4.42574746 4.56811804 4.41978036 4.34941235]\n",
      "pred [4.01366372 4.94079368 3.6289388  5.3785311  3.59456216 5.48655598]\n",
      "pred [3.59485453 5.30391513 4.545027   4.45037545 5.50096708 3.45780744]\n",
      "pred [4.48303403 4.44825609 3.31827467 5.68234879 3.05136435 5.96411535]\n",
      "pred [5.17568373 3.85770842 4.43576018 4.49728664 5.23912657 3.65683069]\n",
      "pred [4.2577478  4.78453512 4.43126936 4.59179143 4.42396618 4.55687341]\n",
      "pred [3.64378972 5.37702713 3.97815689 4.99909871 3.77260815 5.10722465]\n",
      "pred [4.59190919 4.40256532 4.46911572 4.50728034 4.49320254 4.5162276 ]\n",
      "pred [4.90832453 4.13641317 4.46350939 4.53820196 4.307622   4.64295313]\n",
      "pred [4.95515479 4.16081672 4.48522126 4.50178356 4.32843811 4.68676222]\n",
      "pred [3.92536773 5.09456726 4.41361119 4.5722172  4.35682396 4.69143778]\n",
      "pred [3.40340305 5.43225365 4.54973921 4.43482543 5.31110917 3.57472737]\n",
      "pred [3.45155973 5.62579913 4.03053965 4.94200459 3.74776372 5.29515671]\n",
      "pred [4.20120474 4.76147956 4.4078463  4.58211359 4.3975217  4.62100916]\n",
      "pred [4.39415136 4.6089482  4.22431674 4.78393042 4.02582062 4.95241885]\n",
      "pred [3.65384935 5.42953531 4.50135373 4.48779445 4.30725575 4.66248518]\n",
      "pred [4.41748477 4.58331953 4.37553961 4.59257311 4.71023156 4.27060294]\n",
      "pred [3.34955212 5.70248394 3.92110785 5.11367244 3.50085897 5.45889222]\n",
      "pred [4.9577276  4.05071834 4.41502321 4.54226335 3.44791514 5.46295339]\n",
      "pred [3.87705212 5.10347846 3.7345618  5.19965969 3.58057618 5.30956458]\n",
      "pred [4.03416822 4.81551677 4.18314577 4.96674293 4.03183426 5.05657345]\n",
      "pred [4.28480268 4.68552099 4.39166316 4.60355218 4.64064047 4.3922029 ]\n",
      "pred [4.27163263 4.64126039 4.44031892 4.51906823 5.49629108 3.32155549]\n",
      "pred [3.02159979 5.97500225 4.40552589 4.56778881 4.07231916 4.86736467]\n",
      "pred [3.8213251  5.13052844 4.31199974 4.64500407 4.05608055 4.84410507]\n",
      "pred [4.34537453 4.71173483 4.48854318 4.52489291 4.13324803 4.84652472]\n",
      "pred [4.86685258 4.29814782 4.47181722 4.5162242  4.33695261 4.63019085]\n",
      "pred [3.23183866 5.64756985 4.31622057 4.72569036 3.9851219  4.90648771]\n",
      "pred [4.2816925  4.70542206 3.3842783  5.62949346 3.10371865 5.95351099]\n",
      "pred [3.92835827 5.09827091 3.33042051 5.62706394 3.46864265 5.54034266]\n",
      "pred [3.47574467 5.40379349 4.14103243 4.86454431 3.72733085 5.12974015]\n",
      "pred [4.19120597 4.69847279 3.73453964 5.43296981 3.24643132 5.70911491]\n",
      "pred [5.4090878  3.63917259 4.4038726  4.57592736 5.10262061 3.96929451]\n",
      "pred [4.00042545 4.92347234 4.36020127 4.62829498 3.97748826 5.03575894]\n",
      "pred [3.47167368 5.60271252 3.71280616 5.30916844 3.55746859 5.48356764]\n",
      "pred [2.87289781 6.0908077  4.27702675 4.67734364 3.97011724 4.94249692]\n",
      "pred [3.52663413 5.41849673 4.40459312 4.6376929  4.12188966 5.00082034]\n",
      "pred [4.21777154 4.66095673 4.48661767 4.49575093 4.20112741 4.80979768]\n",
      "pred [3.8303699  5.18658017 4.36906336 4.67100352 3.63476169 5.27597337]\n",
      "pred [4.75129206 4.42388993 4.45279405 4.5019645  5.11911774 3.8228887 ]\n",
      "pred [3.79221355 5.22295587 3.99469422 4.96168358 3.56061871 5.42876404]\n",
      "pred [4.40324834 4.71616183 4.55193467 4.48259649 4.58358007 4.28169507]\n",
      "pred [4.23396865 4.91556267 4.47426346 4.58345786 4.38557292 4.61162712]\n",
      "pred [3.91703109 5.08638074 4.11842801 4.91343854 3.86410607 5.21158343]\n",
      "pred [3.91070667 5.06956568 3.6758915  5.23257485 3.59544003 5.33050227]\n",
      "pred [4.65274588 4.4446276  4.42705068 4.57675894 4.4086124  4.54720737]\n",
      "pred [5.22691578 3.83665666 4.36001885 4.5936419  4.7623158  4.21444974]\n",
      "pred [4.04220129 4.79952947 4.41848926 4.63047482 4.30021068 4.66325737]\n",
      "pred [4.25517901 4.71759326 4.51165156 4.50500807 4.41059033 4.58927447]\n",
      "pred [4.66996007 4.36225871 4.44626835 4.52140188 4.55300389 4.43474048]\n",
      "pred [2.90481882 6.08898177 4.31758014 4.59816762 3.93639473 4.99465772]\n",
      "pred [4.86928231 4.25071823 4.48294643 4.50940678 4.38793602 4.65075723]\n",
      "pred [4.13712649 4.90982611 3.67000706 5.43124908 3.44458124 5.49766113]\n",
      "pred [3.19672773 5.81932714 3.99649966 5.06392475 3.70974066 5.27826164]\n",
      "pred [3.7471432  5.07417484 3.95895469 5.04726904 3.66463326 5.3593848 ]\n",
      "pred [4.36901832 4.5693812  4.2112496  4.81667087 4.23032645 4.75721274]\n",
      "pred [3.12950957 5.95198806 4.0267883  4.95260034 3.78517499 5.23300401]\n",
      "pred [2.86989146 6.13100149 4.33341899 4.59022576 3.87685148 5.05646387]\n",
      "pred [3.88697849 5.00422698 3.76579452 5.19108419 3.74415302 5.21713177]\n",
      "pred [4.3873758  4.59515034 4.49993015 4.52541523 4.44340255 4.5228514 ]\n",
      "pred [3.62981522 5.3593793  3.94649552 4.9397983  3.55932887 5.46293251]\n",
      "(296, 40) (296, 6)\n",
      "******* Feature select: LR40  Feature type: OG-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8334437508903719\n",
      "R2 Best score (validation) val. score :  0.5783375525947351\n",
      "R2 of the best estimator (testing dataset):  0.42174085908348063\n",
      "pred [4.41617594 4.5281069  4.34858835 4.68310339 4.24617681 4.71639143]\n",
      "pred [5.21863539 3.86158635 4.54024424 4.49469678 4.80032003 4.0110289 ]\n",
      "pred [3.98445469 5.00720086 3.7657441  5.2557664  3.36887116 5.64557304]\n",
      "pred [3.79715069 5.02207607 4.53082894 4.48384701 5.48354019 3.33806416]\n",
      "pred [4.39924972 4.71693658 3.54890594 5.39981181 3.50711568 5.56366982]\n",
      "pred [5.26518623 3.82999945 4.39716964 4.56704603 5.47311139 3.3548196 ]\n",
      "pred [4.25051946 4.73350695 4.26573677 4.71527247 4.3911683  4.60526012]\n",
      "pred [3.78915836 5.2821837  4.27987696 4.75641413 4.13594598 4.82715896]\n",
      "pred [4.23761564 4.86842227 4.3312283  4.57206939 4.39330414 4.65103215]\n",
      "pred [4.42248723 4.51942027 4.29452675 4.70550234 4.21129751 4.76946053]\n",
      "pred [4.67778718 4.17566615 4.20590164 4.78831746 4.00189987 4.97925921]\n",
      "pred [4.15115016 4.87002531 4.28080204 4.80468939 4.6117401  4.33805091]\n",
      "pred [3.73689617 5.08132245 4.5591483  4.45699765 5.47687864 3.33614298]\n",
      "pred [3.87672813 5.08167372 3.79566484 5.19651337 3.61048365 5.31032649]\n",
      "pred [4.35237819 4.64101971 4.157442   4.83328019 4.14326808 4.81264229]\n",
      "pred [4.35445154 4.76928429 3.96636294 5.06468854 3.91250304 5.02815182]\n",
      "pred [3.8683994  5.27084558 4.39584107 4.55602797 4.35748954 4.68024825]\n",
      "pred [4.0884318  4.85967286 4.26234061 4.75808873 4.52781422 4.41255822]\n",
      "pred [3.62767189 5.21580144 3.7984909  5.22264714 3.57268636 5.33454599]\n",
      "pred [4.64673466 4.42196054 4.56004212 4.47586524 4.16046855 4.72625229]\n",
      "pred [3.95003791 5.13017003 4.16416847 4.7994529  4.003072   5.01788725]\n",
      "pred [4.01465656 4.94376283 4.42182192 4.59387014 4.36768058 4.60121088]\n",
      "pred [3.91224738 4.98120549 4.2470587  4.77099655 4.4831082  4.53854392]\n",
      "pred [4.3085056  4.69984326 4.39185427 4.58223233 5.55734031 3.36669706]\n",
      "pred [3.30501596 5.71137693 4.27036328 4.75782871 4.27157546 4.7425161 ]\n",
      "pred [3.88484252 5.20938415 4.18472346 4.8559501  4.16875485 4.72897422]\n",
      "pred [4.37665183 4.59233347 4.46491    4.59188527 4.24085521 4.7108918 ]\n",
      "pred [4.67904596 4.10342542 4.25316019 4.73928341 4.0143466  4.97925921]\n",
      "pred [3.31146381 5.71291573 3.94209016 4.99298521 3.87293688 5.07181945]\n",
      "pred [4.3863682  4.83892192 3.63052971 5.35194921 3.3685667  5.65183038]\n",
      "pred [4.0630289  5.031594   3.47104798 5.55713155 3.51614216 5.57570942]\n",
      "pred [3.81912915 5.31532242 4.31246869 4.7251653  4.06290368 4.89142763]\n",
      "pred [4.60091902 4.35322723 3.70128652 5.24488399 3.453055   5.49272818]\n",
      "pred [5.2650552  3.77550997 4.50840902 4.49057243 5.42971619 3.4187622 ]\n",
      "pred [4.21924278 4.81849918 4.29464118 4.72667224 3.78116196 5.29415765]\n",
      "pred [3.72735368 5.17916647 3.65599968 5.29457091 3.30330071 5.70491081]\n",
      "pred [3.29187718 5.63442288 4.1846136  4.79114896 4.02554919 4.94734996]\n",
      "pred [3.69567346 5.4289447  4.34196744 4.60100938 4.05580119 4.95404872]\n",
      "pred [4.45118039 4.66066603 4.46607804 4.58579509 4.17346466 4.77707469]\n",
      "pred [3.85709966 5.06344667 4.28964274 4.79967445 3.84002205 5.22427692]\n",
      "pred [4.54709167 4.38609452 4.49367448 4.49256926 5.38581646 3.57884833]\n",
      "pred [3.77910818 5.15492167 4.09825209 4.80489569 3.65092744 5.3771257 ]\n",
      "pred [4.34632629 4.58111897 4.54407892 4.48250626 5.01496008 3.9261437 ]\n",
      "pred [4.11631613 4.97610887 4.35024807 4.56790136 4.26567936 4.71166297]\n",
      "pred [3.82769302 5.19555776 4.39480072 4.69029449 4.17177992 4.86371624]\n",
      "pred [3.98961455 5.08310261 4.09968386 4.81995398 4.003072   5.02726434]\n",
      "pred [4.328544   4.73813019 4.26391877 4.68606529 4.40981366 4.60268277]\n",
      "pred [5.26924481 3.8115618  4.45360501 4.54037462 4.8491298  3.8500733 ]\n",
      "pred [4.03199913 4.90319009 4.23504024 4.72468401 4.38909761 4.59054016]\n",
      "pred [4.21358499 4.95188408 4.38462903 4.55934367 4.32752374 4.66501123]\n",
      "pred [4.39059947 4.6537428  4.27703799 4.66838766 4.48816966 4.53712444]\n",
      "pred [3.08206883 5.97457979 4.17027888 4.76335903 4.00583167 4.99095108]\n",
      "pred [4.72654405 4.17383882 4.31888681 4.66413488 4.28077089 4.70275918]\n",
      "pred [4.057447   4.87305002 4.19082376 4.82725619 3.3086814  5.70050696]\n",
      "pred [3.35785544 5.61646551 3.84948825 5.09577865 3.95922041 5.08401201]\n",
      "pred [3.93350086 5.18139518 3.92243597 5.02394527 3.77590082 5.13057203]\n",
      "pred [4.34605473 4.72744859 4.47305287 4.56694397 4.21158357 4.85034881]\n",
      "pred [3.43850618 5.51628441 4.03979638 4.98491314 3.92238022 5.08349628]\n",
      "pred [3.08826595 5.89222378 4.25640956 4.76998165 4.07223243 5.00063734]\n",
      "pred [3.79046347 5.13129932 4.33585074 4.70862745 4.18102117 4.81598747]\n",
      "pred [4.10977669 4.97257012 4.36975249 4.56737523 4.22919958 4.80114108]\n",
      "pred [3.55968607 5.38247849 4.28464418 4.66997004 3.746346   5.16005791]\n",
      "(296, 40) (296, 6)\n",
      "******* Feature select: LR40  Feature type: ST-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8306653143052546\n",
      "R2 Best score (validation) val. score :  0.5612182192217928\n",
      "R2 of the best estimator (testing dataset):  0.3567723034185661\n",
      "pred [4.77090166 4.11581701 4.43406333 4.50204223 4.30195391 4.61264948]\n",
      "pred [4.84941574 4.12263786 4.27127292 4.59103339 5.04502441 4.50962162]\n",
      "pred [4.00555639 4.88862088 3.27354335 5.7139446  3.12665906 5.90543597]\n",
      "pred [3.82785707 5.09771793 4.52190591 4.48830467 5.39331231 3.47219923]\n",
      "pred [4.58670532 4.46466704 3.38264397 5.74196167 3.34101824 5.55910052]\n",
      "pred [4.66778197 4.27059268 4.49304012 4.54164302 5.4046382  3.73286556]\n",
      "pred [4.21767114 4.71619258 4.43296548 4.58736002 4.39155381 4.67399348]\n",
      "pred [3.94817067 5.21801896 4.21751605 4.9324984  3.95044028 5.03716974]\n",
      "pred [4.36320569 4.43364334 4.55743088 4.51128149 4.3519606  4.52035641]\n",
      "pred [4.78450782 4.11012988 4.43101367 4.55128486 4.29277118 4.55777081]\n",
      "pred [4.71350968 4.15509148 4.44282666 4.55666584 4.30533353 4.60984378]\n",
      "pred [4.23272317 4.71550218 4.3664368  4.58240823 4.47669495 4.52360392]\n",
      "pred [3.54345392 5.43178578 4.54960005 4.44916066 5.1333806  3.84916526]\n",
      "pred [3.65878979 5.52043575 3.87153896 5.21013022 3.65944562 5.25815676]\n",
      "pred [4.3316998  4.72760083 4.39345922 4.59788688 4.38404497 4.58073409]\n",
      "pred [4.23371542 4.69072607 4.24914141 4.75634736 4.20689761 4.93748392]\n",
      "pred [3.49409946 5.63249878 4.48237394 4.54106159 4.34602882 4.80368927]\n",
      "pred [4.31698948 4.58915834 4.41071264 4.49515334 4.6622039  4.41769158]\n",
      "pred [3.55570197 5.64467475 3.89530819 5.12758012 3.72501716 5.23140569]\n",
      "pred [4.93901789 4.07631987 4.39333168 4.51117412 3.54948489 5.4819664 ]\n",
      "pred [4.08507624 4.82718803 3.56226292 5.4894753  3.62877962 5.30270919]\n",
      "pred [3.67715368 5.20377472 4.04089029 5.01536328 3.95949834 5.16664353]\n",
      "pred [4.08237462 4.72632031 4.42779056 4.50023517 4.37915814 4.63784071]\n",
      "pred [4.4782203  4.56950026 4.30738441 4.52398786 5.80829624 3.29547436]\n",
      "pred [3.39774206 5.57784854 4.47581004 4.51448614 4.04229384 4.91323069]\n",
      "pred [3.94131863 4.89586787 4.28340717 4.91607034 3.97924109 4.98486646]\n",
      "pred [4.17237605 4.76252604 4.50914349 4.51802936 4.18621777 4.77066981]\n",
      "pred [4.67094955 4.23277748 4.43693606 4.54939077 4.3026311  4.61133347]\n",
      "pred [3.7031887  5.08871851 4.10814656 4.86271598 3.94894933 4.96624313]\n",
      "pred [4.30931302 4.61625354 3.52916627 5.64394712 3.14485803 5.65565246]\n",
      "pred [3.73470421 5.22491332 3.39740688 5.58859351 3.34008593 5.62937283]\n",
      "pred [3.44620468 5.66305894 4.40378725 4.80556669 3.93611931 5.09113934]\n",
      "pred [4.53520657 4.42111828 3.2619551  5.67694374 3.26961765 5.49380186]\n",
      "pred [4.83247254 3.90892195 4.47123343 4.54954628 4.93197414 4.24408398]\n",
      "pred [4.19435474 4.95692402 4.18970771 4.80625385 3.93824871 5.0625221 ]\n",
      "pred [3.65977496 5.44556897 3.87332467 5.17413447 3.68920263 5.33089123]\n",
      "pred [3.37163237 5.77129045 4.38814738 4.60083676 3.89646848 5.1105939 ]\n",
      "pred [3.48686378 5.49054747 4.41474628 4.70142133 4.14989796 4.75204387]\n",
      "pred [4.36937534 4.88833846 4.42740533 4.53803696 4.13748913 4.76307062]\n",
      "pred [3.68453863 5.25680969 4.35294625 4.6092375  3.73847637 5.3713201 ]\n",
      "pred [4.77641174 4.26801854 4.47306607 4.52886926 5.39001783 3.91920325]\n",
      "pred [4.27258909 4.79823547 3.70755253 5.4445107  3.34818984 5.53453097]\n",
      "pred [4.18935415 4.532642   4.47646172 4.51685868 4.32074346 4.80147699]\n",
      "pred [4.10686395 4.76886323 4.3361559  4.66043151 4.15018821 4.88522759]\n",
      "pred [3.51314369 5.48862842 4.08751511 5.05289252 3.71447973 5.36980418]\n",
      "pred [4.13260825 4.70338413 3.43804383 5.63451617 3.62181296 5.29254894]\n",
      "pred [4.41790804 4.47058225 4.55620476 4.53044155 4.41508305 4.52066108]\n",
      "pred [5.02022295 4.0205183  4.43838706 4.56918745 5.0700794  4.43743872]\n",
      "pred [4.12188341 4.80424165 4.44284599 4.55806411 4.45699147 4.58404132]\n",
      "pred [4.25115641 4.73466399 4.52664371 4.42962969 4.24417498 4.8024302 ]\n",
      "pred [4.42035864 4.30513868 4.5316977  4.52673226 4.41381043 4.44018029]\n",
      "pred [3.43507053 5.56765581 4.3588968  4.55169708 3.93225777 5.06432217]\n",
      "pred [4.78255979 4.14796779 4.4334258  4.51611239 4.32751265 4.64531346]\n",
      "pred [3.84894939 5.14330757 3.70843308 5.47997772 3.13287082 5.79194479]\n",
      "pred [3.77335805 5.0193529  3.80232153 5.05063782 3.76304669 5.23123996]\n",
      "pred [3.82422672 4.98871215 3.43215047 5.48160977 3.42551892 5.52641216]\n",
      "pred [4.52106081 4.60266201 4.38792598 4.61450458 4.12087048 4.96288519]\n",
      "pred [3.59073712 5.65218716 3.87359005 5.20415081 3.67136678 5.23943659]\n",
      "pred [3.2681156  5.77916764 4.41939931 4.56602848 3.92758396 5.11800619]\n",
      "pred [4.32317638 4.73432974 3.63579417 5.17981876 3.7211069  5.30562438]\n",
      "pred [4.09301759 4.79610904 4.44107476 4.48877966 4.27288503 4.69156989]\n",
      "pred [3.91270548 4.95924198 3.97955866 5.15909132 3.2922986  5.58341841]\n",
      "(296, 61) (296, 6)\n",
      "******* Feature select: PCA99  Feature type: HG-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8459313647086861\n",
      "R2 Best score (validation) val. score :  0.530100663430823\n",
      "R2 of the best estimator (testing dataset):  0.09260403177135501\n",
      "pred [4.1881617  4.91962032 4.10481501 4.83688677 4.17447194 4.85005533]\n",
      "pred [4.40362352 4.61163926 4.01984602 4.999345   4.3958864  4.73356557]\n",
      "pred [4.00014236 5.11374477 4.13853721 4.96277669 3.79177011 5.25015371]\n",
      "pred [3.95343176 4.98933893 4.09809452 5.00217382 4.87686235 3.89653815]\n",
      "pred [4.0984045  4.85241552 3.73766001 5.25590391 4.10159985 5.09303594]\n",
      "pred [4.45353758 4.5684     4.00155424 4.84763036 4.71284618 4.26763318]\n",
      "pred [4.40273987 4.76041415 4.20381313 4.87779223 4.27909544 4.91539346]\n",
      "pred [3.81962222 5.05215189 4.13791836 4.84080907 4.20137588 4.78964171]\n",
      "pred [4.09405269 5.01034168 4.1094939  4.92336829 4.2859546  4.73348558]\n",
      "pred [4.26689033 4.86983482 4.13418691 4.81207802 4.21553924 4.94241912]\n",
      "pred [4.15298342 4.9115196  4.16068052 4.79938174 4.18025005 4.86692049]\n",
      "pred [4.08409257 4.9764354  4.18434854 4.7827389  4.39222371 4.80083359]\n",
      "pred [3.95308794 5.03631691 4.05267133 4.91054615 4.84468901 3.92495861]\n",
      "pred [3.89257184 5.20212937 4.05899395 4.88067458 4.31817475 5.00027684]\n",
      "pred [4.27478996 4.93467665 4.04721073 4.96523797 4.13746466 4.86922192]\n",
      "pred [4.08978727 4.93286747 3.91928832 5.04472304 4.17840946 5.03093389]\n",
      "pred [4.1247515  5.05010908 4.18802862 4.87443894 4.34506382 4.68421162]\n",
      "pred [4.22064984 4.65946084 4.22028378 4.79906009 4.40556244 4.67602993]\n",
      "pred [3.84769638 5.16166549 4.07157042 4.88766501 4.30250653 4.99907955]\n",
      "pred [4.42343364 4.57614938 4.02004952 4.89032576 4.25267143 4.91530117]\n",
      "pred [4.05563861 4.93518304 3.96657933 5.0847778  4.05253611 5.06864339]\n",
      "pred [4.20818366 4.80814491 4.07601963 4.84998515 4.46068529 4.63076758]\n",
      "pred [4.06286957 4.80546941 4.20702853 4.87409692 4.44540712 4.72058396]\n",
      "pred [4.20302464 5.00096083 4.05734979 4.984661   5.16255005 4.12837851]\n",
      "pred [3.73087921 5.24197816 4.11349411 4.84373742 4.35592723 4.83882894]\n",
      "pred [4.15540281 4.98851343 4.09919895 4.8555142  4.49151969 4.76172054]\n",
      "pred [4.26564014 4.87165218 4.12340854 4.85520771 4.76697633 4.48598015]\n",
      "pred [4.21358848 4.84788021 4.1728015  4.79648217 4.14462452 4.93630303]\n",
      "pred [3.79010682 5.22601736 4.12890262 4.83134543 4.29825669 4.89310752]\n",
      "pred [4.04509872 4.84989307 3.74667542 5.31672956 3.84047685 5.27496504]\n",
      "pred [3.94701296 4.87617572 3.78958182 5.23093196 4.01334658 4.88588995]\n",
      "pred [3.93178111 4.95835206 4.08775497 4.9288406  4.53034106 4.78047613]\n",
      "pred [3.9206221  5.08089165 3.82993811 5.15107748 3.98344462 5.09668222]\n",
      "pred [4.48005052 4.52557262 4.18949529 4.82220051 4.81359062 4.23059703]\n",
      "pred [3.9335998  4.96888467 4.0836437  4.88813107 4.33399905 4.82343916]\n",
      "pred [3.78441867 5.21380137 3.98361889 4.96291186 3.97888516 5.10931204]\n",
      "pred [3.61073803 5.30803599 4.14719528 4.84824894 4.18654098 4.9365558 ]\n",
      "pred [3.82722818 5.07906321 4.09466173 4.87662666 4.28154891 4.75528117]\n",
      "pred [4.27631503 4.77192337 4.16576313 4.87774325 4.43373847 4.68711911]\n",
      "pred [4.02292286 5.01341397 4.17860614 4.81404678 3.96069244 5.04289312]\n",
      "pred [4.46066752 4.58170912 4.09544895 4.80598928 4.75478654 4.22665966]\n",
      "pred [3.71016949 5.17683125 4.00592196 5.02895193 3.89717511 5.14563672]\n",
      "pred [4.18822062 4.83555241 4.08362298 4.84481645 4.28202861 4.90390031]\n",
      "pred [4.28840321 4.81101733 4.15529608 4.94826512 4.47049253 4.50538032]\n",
      "pred [4.1389074  5.03565589 4.1666653  4.80188096 4.1095352  4.95228067]\n",
      "pred [4.07925069 4.92844913 3.94297666 5.10191483 4.03032493 5.06721603]\n",
      "pred [4.28424372 4.81421891 4.04593711 4.95122156 4.29526576 4.77949996]\n",
      "pred [4.43534051 4.47505978 3.99647937 4.94647088 4.56554743 4.54031443]\n",
      "pred [4.13388657 5.13769522 4.10552662 4.98624454 4.43682428 4.71084175]\n",
      "pred [4.18817115 4.76273117 4.15000444 4.88528377 4.19146172 4.81175405]\n",
      "pred [4.3150857  4.80812298 4.10904771 4.94609414 4.38241759 4.71630826]\n",
      "pred [3.60940974 5.29274242 4.11421349 4.90967919 4.13621481 4.96482723]\n",
      "pred [4.19956462 4.90097749 4.11309726 4.83702133 4.19952385 4.74903685]\n",
      "pred [3.95664881 4.88728    4.13218355 4.84274989 4.23607034 4.92593144]\n",
      "pred [3.89012408 5.15661361 4.00955925 5.04161278 4.19044434 4.85677603]\n",
      "pred [4.01008446 4.98305405 3.85980677 5.09260848 4.24270412 4.96296574]\n",
      "pred [4.35744293 4.67275611 4.17313836 4.87201979 4.4879458  4.65512795]\n",
      "pred [3.80924884 5.08063867 4.11780989 4.87772006 4.15916078 5.0673122 ]\n",
      "pred [3.64797776 5.32412225 4.11164826 4.90293867 4.12868563 4.96284401]\n",
      "pred [3.77456249 5.07218023 4.04273286 4.90220952 4.27946158 4.6734804 ]\n",
      "pred [4.11673251 4.88885381 4.13820192 4.85957911 4.27313096 4.8073288 ]\n",
      "pred [3.67929666 5.24134333 4.06956796 4.91355951 4.0198072  5.0453859 ]\n",
      "(296, 39) (296, 6)\n",
      "******* Feature select: PCA99  Feature type: OG-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8269214820617653\n",
      "R2 Best score (validation) val. score :  0.5077099397657584\n",
      "R2 of the best estimator (testing dataset):  0.09977254753982452\n",
      "pred [4.21828701 4.87171026 4.21891104 4.8380967  4.63318139 4.43423578]\n",
      "pred [4.73864508 4.11360364 3.98394822 5.11591297 4.26864002 4.45138444]\n",
      "pred [3.91984558 4.95876225 4.12203351 4.86552499 4.21355472 4.98810456]\n",
      "pred [4.21192791 4.51912494 4.47795541 4.80991478 4.98649916 3.89321306]\n",
      "pred [3.81834757 4.9266515  3.9164303  5.31048956 4.07218891 4.63852354]\n",
      "pred [4.55012172 4.18188682 4.21703281 4.94217519 5.3646357  4.16810381]\n",
      "pred [4.09907029 4.99755402 4.33816793 4.76301895 4.38563828 4.679485  ]\n",
      "pred [4.25774701 4.77279786 4.20962959 4.74974184 4.40423571 4.85936493]\n",
      "pred [4.41694753 4.62837397 4.41868713 4.89467983 4.6219849  4.25983094]\n",
      "pred [4.09767447 4.59700307 4.21010135 4.70252444 4.52913306 4.41207696]\n",
      "pred [4.20624276 4.58726612 4.21881489 4.9008193  4.56203941 4.38379142]\n",
      "pred [4.58910918 4.78251432 4.39502102 4.78588839 4.44771367 4.63390433]\n",
      "pred [4.36638871 4.58368357 4.39940061 4.8090145  4.93344827 3.92056818]\n",
      "pred [3.89945121 5.18315059 4.09368893 5.01212782 4.44355396 4.80236152]\n",
      "pred [3.98815799 4.90856219 4.25650558 4.90318515 4.46378245 4.30854745]\n",
      "pred [3.99442889 4.88964527 4.21337951 4.687246   4.35831102 4.82190332]\n",
      "pred [3.97701545 4.64424747 4.51778902 4.77346456 4.19050579 5.04079461]\n",
      "pred [4.26814297 4.67288357 4.1777666  4.87299986 4.4604936  4.42964184]\n",
      "pred [3.88727372 5.26177917 4.17659051 5.07832642 4.51221065 4.76319247]\n",
      "pred [4.63097216 3.93719356 4.28812992 5.10738001 3.90484819 4.95893575]\n",
      "pred [3.9167461  4.93285805 4.29283147 4.78921019 4.40963335 4.46285678]\n",
      "pred [3.73916155 4.96601391 4.42382753 4.86468335 4.29662128 4.57941772]\n",
      "pred [4.368172   4.55033281 4.18860549 4.85673861 4.42431972 4.40169451]\n",
      "pred [4.44425018 4.50001014 4.2587357  4.90490311 5.54819031 3.72418674]\n",
      "pred [3.73031976 5.08032667 4.28204315 4.94847053 4.43208808 4.63267057]\n",
      "pred [4.37210494 4.63717073 4.40325423 4.85985996 4.66644493 4.2441349 ]\n",
      "pred [4.00060188 5.34803594 4.28214425 4.93472916 4.52766219 4.33496485]\n",
      "pred [4.22138562 4.55069794 4.18272583 4.83226194 4.56590191 4.38379142]\n",
      "pred [3.6754854  5.27812558 3.93155121 5.15502901 4.20107238 4.72386954]\n",
      "pred [4.03933069 4.95811373 3.52668598 5.32442542 4.23374166 4.87033399]\n",
      "pred [4.00398857 4.60955629 3.94588422 5.35857061 4.17570606 5.0863197 ]\n",
      "pred [4.19549943 4.83805177 4.10732506 4.75713369 4.48894561 4.42110998]\n",
      "pred [3.92531584 5.25880862 4.18340325 4.98501543 3.85813835 4.78216356]\n",
      "pred [4.60409196 3.92882705 4.27594012 4.93380019 5.30889278 4.28266001]\n",
      "pred [3.91029687 5.10398436 4.22423066 4.87869417 4.20368286 4.95655919]\n",
      "pred [3.93730656 5.10081521 4.05703853 5.07344512 4.47139219 4.76348492]\n",
      "pred [3.71762267 5.50760039 4.1901715  4.98785678 4.56075891 4.52032798]\n",
      "pred [4.43261031 4.6993302  4.01030021 4.99088418 4.35188109 4.64967846]\n",
      "pred [3.93694507 4.84595196 4.22413673 4.68298074 4.4600197  4.52457204]\n",
      "pred [3.92129852 4.96725275 4.15275551 4.88517119 3.97105028 4.76152081]\n",
      "pred [4.68941243 4.28945651 4.17165656 4.93050099 5.14250291 4.70252974]\n",
      "pred [3.79592656 5.18827311 4.19882796 4.72042394 4.27810974 4.79368157]\n",
      "pred [4.33366105 4.52715403 3.96552731 5.09687487 4.72581037 4.68463469]\n",
      "pred [3.88776074 4.86039881 3.99143903 4.82486967 4.26764874 4.70420414]\n",
      "pred [4.03583451 4.9370058  4.14366825 4.97188032 4.0130155  4.7671558 ]\n",
      "pred [3.9167461  4.89453452 4.29283147 4.78921019 4.40963335 4.46285678]\n",
      "pred [4.26662199 4.4796061  4.37687252 4.80244999 4.14946936 4.60723871]\n",
      "pred [4.65229204 4.05334954 3.97104822 5.03365403 4.7454785  4.51595944]\n",
      "pred [4.32973289 4.65831069 3.99191822 5.05995151 4.2029184  4.46612606]\n",
      "pred [3.87660315 4.86399855 4.30417344 4.94008787 4.39350252 4.51826661]\n",
      "pred [4.15173498 4.65680113 4.36509241 4.73619468 4.57628678 4.45495263]\n",
      "pred [3.48299039 5.31577694 4.34064681 4.91768763 4.34598117 4.732238  ]\n",
      "pred [4.45041411 4.36662363 4.3333198  4.80126841 4.55472109 4.33775415]\n",
      "pred [3.78032373 5.08087592 3.9778448  5.11764938 3.85656096 5.13144221]\n",
      "pred [3.6080547  5.46777696 4.05875929 5.016437   4.57120107 4.32224375]\n",
      "pred [3.98065268 5.06681107 4.38977694 4.68577152 4.19337883 5.06831455]\n",
      "pred [4.11263174 4.87706219 4.19764663 4.76837814 4.47047644 4.65587287]\n",
      "pred [4.11233552 4.72274822 4.16717285 5.04241733 4.42191133 4.70614247]\n",
      "pred [3.66348121 5.12387338 4.15254585 4.90059805 4.56658062 4.67886635]\n",
      "pred [3.74280434 5.13143595 4.22166992 4.85659287 4.32086758 4.8907905 ]\n",
      "pred [3.96545554 5.00122928 4.4413451  4.82630408 4.20722573 4.69031471]\n",
      "pred [3.65479261 5.23122573 4.35703144 4.85844824 4.4299026  4.495589  ]\n",
      "(296, 32) (296, 6)\n",
      "******* Feature select: PCA99  Feature type: ST-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8131491799002175\n",
      "R2 Best score (validation) val. score :  0.4389141664408103\n",
      "R2 of the best estimator (testing dataset):  0.14846235747883638\n",
      "pred [4.09423615 4.91575856 4.15149885 4.78736158 4.39269525 4.44049683]\n",
      "pred [4.59591732 4.24023003 4.06979674 4.78263481 4.30947679 4.65619115]\n",
      "pred [3.82976817 5.24556001 4.0547676  4.89158071 4.06345234 4.95736138]\n",
      "pred [3.77549236 5.18507929 4.14989857 4.77424613 4.64883973 4.37438383]\n",
      "pred [4.02875496 5.03117646 3.80987948 5.07590112 3.99223246 4.95936655]\n",
      "pred [4.67524818 4.1091204  4.0621969  4.87293448 4.62496012 4.1813074 ]\n",
      "pred [4.26796581 4.73490542 4.08528114 4.85589364 4.19564391 4.72075226]\n",
      "pred [3.62035363 5.01169867 4.03047531 4.99132302 4.00725995 5.14537224]\n",
      "pred [4.36518176 4.76333416 4.33491082 4.71630219 4.31927621 4.66611589]\n",
      "pred [3.93786054 5.04508994 4.080508   4.85616601 4.26584252 4.66309749]\n",
      "pred [3.86467959 4.98987122 4.10114905 4.84516837 4.23916099 4.64809424]\n",
      "pred [4.21765009 4.88974016 4.12557421 4.83658429 4.39653451 4.60377512]\n",
      "pred [3.79346772 5.37290369 4.09183275 4.78912598 4.61130666 4.49688466]\n",
      "pred [3.74650633 5.32983068 3.97267769 5.00034993 4.12916122 4.98926229]\n",
      "pred [4.43959803 4.82867072 4.36892728 4.60088411 4.3738671  4.75948227]\n",
      "pred [4.13345074 4.71363207 4.12480536 4.83405642 4.27707499 4.92600616]\n",
      "pred [3.50869074 5.53532956 4.01636347 4.89899696 4.010785   4.85244554]\n",
      "pred [4.16735081 4.7880518  4.39544897 4.67629288 4.44717196 4.55272871]\n",
      "pred [3.8051804  5.30185712 3.95956892 5.05942423 4.15557575 4.89576206]\n",
      "pred [4.48076706 4.43038351 4.04618999 4.95325495 4.09972923 4.86799287]\n",
      "pred [3.61329068 5.28924351 4.08421846 4.8025655  4.05684773 4.97689464]\n",
      "pred [4.04647591 5.22034287 4.08314701 4.89949325 4.13358305 5.02393093]\n",
      "pred [4.11723899 4.7675059  4.33983492 4.65406238 4.51034978 4.52792711]\n",
      "pred [4.00401905 4.91953248 3.92147945 5.09373006 4.59272971 4.48930127]\n",
      "pred [4.00019519 4.83577704 4.28899935 4.74465868 4.34179746 4.84798428]\n",
      "pred [4.0551986  5.13696752 4.14916964 4.89069353 4.30589694 4.87160182]\n",
      "pred [4.07435388 4.91674744 4.18001165 4.73964776 4.28804342 4.542205  ]\n",
      "pred [3.85106051 5.00659795 4.11219918 4.85433969 4.25438702 4.62391328]\n",
      "pred [3.73042281 5.329243   4.10226542 4.95021714 4.23035685 4.92236842]\n",
      "pred [3.77187548 5.3938195  3.69737039 5.29582116 3.71263434 5.32079434]\n",
      "pred [4.06831013 4.96650898 3.5639744  5.31484399 4.10131252 4.95302549]\n",
      "pred [3.81575509 5.29373164 4.20109578 4.76760166 4.0143536  4.9954876 ]\n",
      "pred [4.09740799 5.12260538 3.89126309 5.00310742 4.02694426 4.97777881]\n",
      "pred [4.7285577  4.22778619 4.14202474 4.88602316 4.99910976 3.69447958]\n",
      "pred [3.92718461 5.0597781  4.07227169 4.8603341  4.10068013 4.98261726]\n",
      "pred [3.70520694 5.33612003 3.96005511 5.10798142 4.00751127 5.05451298]\n",
      "pred [3.63616297 5.24614615 4.33350999 4.74959313 4.32134098 4.8397036 ]\n",
      "pred [3.93737691 5.16146293 4.226336   4.80565559 3.92722173 5.16850817]\n",
      "pred [4.07112552 4.81050031 4.0041343  4.93881864 4.3204071  4.59461399]\n",
      "pred [3.82528227 5.13503228 4.3524796  4.78420532 3.97406266 5.03822644]\n",
      "pred [4.35603836 4.64108299 3.99839088 4.88403545 4.3151611  4.79399148]\n",
      "pred [3.9322877  5.11472279 4.25545606 4.65939362 4.02957434 4.98489125]\n",
      "pred [4.24809505 4.85026847 4.02225844 4.76951962 4.23169274 4.91101822]\n",
      "pred [3.94913697 4.9564322  4.15080626 4.83306475 4.24309223 4.88968006]\n",
      "pred [3.89355529 5.20513591 4.00752329 4.95507223 4.03566762 4.98359086]\n",
      "pred [3.66215959 5.28277205 4.08232048 4.84239756 4.06699568 4.99383683]\n",
      "pred [4.40445364 4.63539005 4.34412103 4.59965037 4.33227608 4.65777288]\n",
      "pred [4.60628662 4.13589576 4.01568625 4.77614283 4.2740486  4.58903298]\n",
      "pred [4.03475741 4.95047834 4.10015036 4.76098241 4.43200766 4.70354788]\n",
      "pred [4.001875   4.93186417 4.21685295 4.74321415 4.25416231 4.84147522]\n",
      "pred [4.34054501 4.69990186 4.34212059 4.61450462 4.36482173 4.61685326]\n",
      "pred [3.69100663 5.43622747 4.32491847 4.68364004 4.35635234 4.9371517 ]\n",
      "pred [3.90375956 5.08740468 4.10953929 4.8136748  4.23863529 4.66552182]\n",
      "pred [3.93499498 4.9920177  4.10674668 4.96265384 4.00556042 5.07559917]\n",
      "pred [3.72598618 5.31538246 4.00317693 4.92348956 4.14467734 5.02013203]\n",
      "pred [3.97262236 5.11133884 3.897422   5.11793157 4.23528439 5.00485924]\n",
      "pred [4.11917527 4.75173073 4.04436445 4.89646941 4.2576192  4.70971615]\n",
      "pred [3.73828145 5.36390242 3.98373743 4.97216437 4.19100602 4.89582338]\n",
      "pred [3.81276636 5.23545829 4.27571552 4.76467498 4.33702059 4.85417303]\n",
      "pred [3.67010581 5.38359938 3.95079807 5.02480232 3.96651244 5.16026482]\n",
      "pred [4.23309578 4.64914252 4.20203413 4.69399711 4.18787269 4.87665253]\n",
      "pred [3.95061036 5.05866016 4.03835253 4.97412489 4.09066371 4.99413123]\n",
      "(296, 183) (296, 6)\n",
      "******* Feature select: PCA9999  Feature type: HG-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8310377168993482\n",
      "R2 Best score (validation) val. score :  0.4050415745669474\n",
      "R2 of the best estimator (testing dataset):  0.018236384686185676\n",
      "pred [4.04202885 5.04902315 4.0496188  4.791931   4.16154745 4.76875683]\n",
      "pred [4.60191834 4.56923362 4.04281718 4.92599965 4.21666972 4.86362679]\n",
      "pred [4.01402521 5.11881912 3.9423813  4.99076175 4.04865378 4.99705191]\n",
      "pred [4.01052598 4.99989856 4.07200258 4.90944806 4.86650342 4.35299954]\n",
      "pred [4.30542864 4.8531754  3.771629   5.09555555 4.11982759 5.00883536]\n",
      "pred [4.38821541 4.78272074 4.0605067  4.89533192 4.33033217 4.66722496]\n",
      "pred [4.16973217 5.03941605 3.94114243 4.83266961 4.38375541 4.64569568]\n",
      "pred [4.01206258 4.98411625 4.06979856 4.91615545 4.22548966 4.72502198]\n",
      "pred [4.00390092 5.02274436 3.98258416 4.90188883 4.32348524 4.78904541]\n",
      "pred [4.10102292 4.86184206 4.08953903 4.81022577 4.24353647 4.82983147]\n",
      "pred [4.20056445 4.93702216 4.18094401 4.75004895 4.18310815 4.74261899]\n",
      "pred [4.00089951 5.01449848 3.96545538 4.91733653 4.46397677 4.62815116]\n",
      "pred [4.05208716 4.97323552 4.08498135 4.84153657 4.76316029 4.37257965]\n",
      "pred [3.85656796 5.10390921 4.03099017 4.82540994 4.1609609  4.91636559]\n",
      "pred [4.03925661 4.9883806  3.89315671 4.93246373 4.27120588 4.86572028]\n",
      "pred [4.17210187 4.82610261 3.90984655 4.97652822 4.2384406  4.81226869]\n",
      "pred [4.03294176 5.06320954 4.04340799 4.88729992 4.28807642 4.77157783]\n",
      "pred [4.09473295 4.74663531 4.00196527 4.84298067 4.51953017 4.64437683]\n",
      "pred [3.9411778  5.11432013 4.07006605 4.79134915 4.17378266 4.86834011]\n",
      "pred [4.2731095  4.66750805 4.06773359 4.96335251 4.21698429 4.8903753 ]\n",
      "pred [4.15453457 4.89125093 4.04369067 4.98313478 4.18782695 5.00779187]\n",
      "pred [4.1318709  4.9450343  4.05116489 5.03938466 4.34727181 4.87583066]\n",
      "pred [4.13141815 4.92163395 4.13102177 4.76302782 4.48594614 4.78246274]\n",
      "pred [3.99577934 4.97411057 4.00025762 5.0485163  4.77138508 4.27966136]\n",
      "pred [3.91936592 5.28171282 4.04581545 4.76476733 4.18902487 4.64099037]\n",
      "pred [4.30401131 5.06641264 4.05740562 4.88272065 4.32996428 4.82780868]\n",
      "pred [4.17842891 4.73572111 4.19713775 4.83906722 4.52917177 4.63285653]\n",
      "pred [4.14347752 4.90802041 4.22320435 4.81099641 4.26293963 4.73565353]\n",
      "pred [3.85172174 5.20206899 4.15505438 4.80696874 4.2928908  4.74467752]\n",
      "pred [4.05652402 4.80292983 3.68476559 5.16666037 3.92478189 5.17634769]\n",
      "pred [4.25577937 4.70229972 3.75017665 5.11869032 4.27629704 4.91713737]\n",
      "pred [4.19026177 5.05144512 4.0314072  4.87560632 4.4108758  4.74054352]\n",
      "pred [4.0957385  4.93994813 3.83624372 5.13884515 4.28542547 5.10238188]\n",
      "pred [4.32875898 4.67787573 4.08840019 4.92477679 4.58543223 4.60259475]\n",
      "pred [3.8854675  5.07647451 3.98713364 4.96729415 4.2306437  4.84869257]\n",
      "pred [3.93829098 5.16021776 3.90522319 4.87371911 4.02018898 5.10505873]\n",
      "pred [3.87894422 5.32984801 4.04957558 4.80543369 4.26299817 4.74242646]\n",
      "pred [3.98832845 4.95113003 3.93707738 4.96481969 4.27808226 4.743385  ]\n",
      "pred [4.12999027 4.89763631 4.06866791 4.79975932 4.3353636  4.56450334]\n",
      "pred [4.12793602 5.14121912 3.99411965 4.86231226 4.12382007 4.96446509]\n",
      "pred [4.33358176 4.51088407 4.16804264 4.81542935 4.42138351 4.55572779]\n",
      "pred [3.94385705 5.25935768 3.95345451 4.85040703 4.01059833 5.22170994]\n",
      "pred [4.40364591 4.83903148 4.12295693 4.83435894 4.15545461 4.92673324]\n",
      "pred [4.0351333  4.92696497 4.00621559 5.01810157 4.46005802 4.70744217]\n",
      "pred [4.07431936 5.05931605 4.10223399 4.84683092 4.05128692 4.99827676]\n",
      "pred [4.17308901 4.96027441 3.91444373 4.9560178  4.19513663 4.95097912]\n",
      "pred [4.08491824 4.78865481 3.98691861 4.90241474 4.28688674 4.75711706]\n",
      "pred [4.50020437 4.5761837  4.05407578 4.93318986 4.36792224 4.68994626]\n",
      "pred [4.0806774  4.9454513  4.06062962 4.96810704 4.38734146 4.55223582]\n",
      "pred [4.08543211 4.99696561 3.86088574 4.96763409 4.32385311 4.85825549]\n",
      "pred [4.04297161 4.69957528 4.01145837 5.04978913 4.42763685 4.63308315]\n",
      "pred [3.77985738 5.30222434 4.00412566 4.76006624 4.19855084 4.89242199]\n",
      "pred [4.02221798 4.92978273 4.04070216 4.88032342 4.2132126  4.76624415]\n",
      "pred [4.11823256 5.12469807 4.06643915 4.88334607 4.27074825 4.85476289]\n",
      "pred [3.91641216 5.11245837 3.93837835 4.95428305 4.1801606  4.91029131]\n",
      "pred [3.97459008 4.99264035 3.94014274 5.12243221 4.35395107 4.83574865]\n",
      "pred [4.18708692 4.75557355 4.12489455 4.79638352 4.57134787 4.53234938]\n",
      "pred [3.89423552 5.18254783 4.0418413  4.83273394 4.23633059 4.89126867]\n",
      "pred [3.95022377 5.37294685 4.01313636 4.75023844 4.20424088 4.98280012]\n",
      "pred [4.12366485 4.99561112 3.94494035 4.86700946 4.2790127  4.83255758]\n",
      "pred [4.21029573 4.89174277 3.99215648 4.86905867 4.29363627 4.7453546 ]\n",
      "pred [3.81547459 5.09581395 4.06715944 4.7264542  4.13685066 5.13180252]\n",
      "(296, 124) (296, 6)\n",
      "******* Feature select: PCA9999  Feature type: OG-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8245122044527092\n",
      "R2 Best score (validation) val. score :  0.4063720302983028\n",
      "R2 of the best estimator (testing dataset):  0.12264805349826914\n",
      "pred [4.26154347 4.75567085 4.2858771  4.75438041 4.50231422 4.53869927]\n",
      "pred [4.55889722 4.58178736 4.25380295 4.89991599 4.49290699 4.56316265]\n",
      "pred [3.83661171 5.10486112 3.94902331 5.00907066 4.22639669 4.78234505]\n",
      "pred [4.15705915 4.92439167 4.33712628 4.70024751 4.85625055 4.14479539]\n",
      "pred [4.04051144 5.05518731 3.8068557  5.1647782  4.15508107 4.85885309]\n",
      "pred [4.49272758 4.41062001 4.18806601 4.82798256 4.9702999  3.96370896]\n",
      "pred [4.145386   4.87818494 4.06352079 4.95430434 4.44760308 4.50956468]\n",
      "pred [4.19482063 5.09033138 4.16808349 4.90533401 4.46956912 4.52432948]\n",
      "pred [4.1404409  4.91550961 4.28732476 4.76928356 4.49772103 4.49500803]\n",
      "pred [4.32060376 4.7052195  4.33988126 4.7072881  4.4969074  4.55746437]\n",
      "pred [4.22314032 4.65483311 4.31120878 4.81374783 4.53069056 4.55872715]\n",
      "pred [4.04820021 4.89819001 4.19417693 4.81241865 4.39414875 4.64541871]\n",
      "pred [4.02308846 5.00627281 4.33041409 4.67635477 4.75337309 4.24570072]\n",
      "pred [3.86214436 5.10385805 4.2172602  4.85332168 4.35502487 4.59140925]\n",
      "pred [4.13057639 5.05877592 4.22805011 4.71604435 4.42133081 4.58738392]\n",
      "pred [4.21960111 4.81630546 4.17590192 4.81217233 4.26240348 4.78361717]\n",
      "pred [4.1874317  4.91830488 4.3229989  4.69093728 4.38235826 4.71514484]\n",
      "pred [4.05625046 5.07325518 4.20945227 4.86311848 4.31032347 4.43691512]\n",
      "pred [3.87178444 5.12944603 4.30050008 4.84775054 4.34757215 4.59395406]\n",
      "pred [4.32376342 4.59667742 4.246944   4.81256951 4.19501231 4.78746184]\n",
      "pred [3.99001732 5.09973507 4.25266092 4.73297273 4.28753081 4.71589606]\n",
      "pred [3.98324257 4.94075079 4.23918612 4.86724824 4.38975941 4.56396675]\n",
      "pred [4.0201877  5.02320277 4.29719958 4.67683803 4.3989061  4.45207489]\n",
      "pred [4.20066822 4.91790305 4.21586445 4.86180761 4.80493414 4.1341304 ]\n",
      "pred [3.79530201 5.20061888 4.2622012  4.81972182 4.54901025 4.42297026]\n",
      "pred [4.29989816 4.87130076 4.18033366 4.85160992 4.78781997 4.41407264]\n",
      "pred [3.93524271 5.20452901 4.19284387 4.80542015 4.42300391 4.4888149 ]\n",
      "pred [4.26533038 4.67144864 4.3003094  4.74401938 4.46065372 4.52767157]\n",
      "pred [3.91306955 5.15755437 4.04781863 5.0372172  4.38689587 4.62146251]\n",
      "pred [4.14375687 4.91103107 3.86142763 5.14961229 4.15960409 4.83689712]\n",
      "pred [4.0856094  4.8148399  3.85581956 5.17294246 4.13702218 4.78054894]\n",
      "pred [4.05396814 4.9551267  4.25047697 4.86751405 4.52209899 4.51129024]\n",
      "pred [3.87838275 5.10403736 3.99332436 5.09045365 4.17243679 4.91200629]\n",
      "pred [4.58882841 4.55053973 4.24095376 4.81524371 4.93247764 3.94724181]\n",
      "pred [3.93755531 5.09451357 4.08385415 4.90687514 4.24363    4.76776919]\n",
      "pred [3.95300879 5.10194462 4.14597309 4.97716087 4.30803751 4.60484281]\n",
      "pred [3.67636472 5.26292515 4.21168344 4.81264493 4.52479318 4.45472099]\n",
      "pred [3.98608364 5.04004634 4.11922325 4.84746643 4.40991486 4.50041508]\n",
      "pred [4.09306886 4.91723627 4.21482718 4.75220373 4.4202833  4.60197138]\n",
      "pred [3.94959032 5.15518723 4.2452761  4.77876649 4.18817404 4.76769259]\n",
      "pred [4.46788705 4.59450153 4.22226603 4.80842959 4.82553178 4.10211786]\n",
      "pred [3.84786619 5.12900324 4.27259191 4.80333481 4.31340073 4.69372085]\n",
      "pred [4.24580914 4.77454372 4.27765343 4.75661389 4.46230988 4.66224948]\n",
      "pred [3.86429119 5.09308469 4.08121312 4.89945396 4.31310082 4.59282273]\n",
      "pred [4.02344083 5.07367287 4.16876129 4.88791777 4.17416179 4.7815001 ]\n",
      "pred [4.0426522  5.03214172 4.23664993 4.78767685 4.29339249 4.74747702]\n",
      "pred [4.23177228 4.76695093 4.26636444 4.72348455 4.35897324 4.57140142]\n",
      "pred [4.49755549 4.55130794 4.24187238 4.82949868 4.56796925 4.40507051]\n",
      "pred [4.15225759 4.83371123 4.18101568 4.79519686 4.29610621 4.61311824]\n",
      "pred [4.14084052 4.83960851 4.18677537 4.85331854 4.59992324 4.55709552]\n",
      "pred [4.34845361 4.77290017 4.21487272 4.70148317 4.57792988 4.45077846]\n",
      "pred [3.89159132 5.1982003  4.14293843 4.78244738 4.48377724 4.5330167 ]\n",
      "pred [4.31762631 4.7622978  4.09952224 4.81528409 4.48292442 4.523408  ]\n",
      "pred [3.90407258 5.06141672 4.1106341  4.98550441 4.06345999 4.87473025]\n",
      "pred [3.78753798 5.14880189 4.10997996 4.97182674 4.61990554 4.55053602]\n",
      "pred [4.04049845 4.93724633 4.10457542 4.77074825 4.26946528 4.68064504]\n",
      "pred [4.10037767 4.81608273 4.24266801 4.72632279 4.47080172 4.426508  ]\n",
      "pred [3.96127744 4.9738715  4.22859166 4.81836592 4.30732175 4.47153593]\n",
      "pred [3.81572204 5.2049258  4.21981261 4.80819293 4.48638413 4.48572181]\n",
      "pred [3.98443242 4.92847393 4.32856255 4.82475606 4.32060167 4.63920275]\n",
      "pred [4.07191352 4.92195576 4.24403212 4.81466308 4.24582112 4.6062214 ]\n",
      "pred [3.79930446 5.12757509 4.35953765 4.73749854 4.3788722  4.73770797]\n",
      "(296, 86) (296, 6)\n",
      "******* Feature select: PCA9999  Feature type: ST-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.7981202641548993\n",
      "R2 Best score (validation) val. score :  0.3378539377416895\n",
      "R2 of the best estimator (testing dataset):  0.05701805422231713\n",
      "pred [4.13264243 4.920932   4.20000961 4.91546651 4.29215372 4.6512724 ]\n",
      "pred [4.41216276 4.58080016 4.24526927 4.81814279 4.33786718 4.57350266]\n",
      "pred [3.84913727 5.15291623 3.96178227 5.04782487 4.08072216 4.90107475]\n",
      "pred [3.82134861 5.20529274 4.12577551 4.89533964 4.60486538 4.41890883]\n",
      "pred [3.98873237 4.91949889 3.81118796 5.08592447 3.97177816 5.07099718]\n",
      "pred [4.32262902 4.60783949 4.21043634 4.83458098 4.54115356 4.53219803]\n",
      "pred [4.08265806 4.79419651 3.93202523 5.06759016 4.26658609 4.82578241]\n",
      "pred [3.86403396 5.14830902 3.88081308 5.1196558  4.19159348 4.74338829]\n",
      "pred [4.21605065 4.89368532 4.06509572 5.0342212  4.21697024 4.84898043]\n",
      "pred [4.13601158 4.87442956 4.20119354 4.809857   4.20374628 4.8225721 ]\n",
      "pred [4.15112323 4.86082285 4.21324002 4.81216836 4.20213131 4.83610344]\n",
      "pred [4.0664284  4.93385012 4.10557553 4.92543589 4.14617014 4.76579465]\n",
      "pred [3.79016467 5.28845925 4.14080352 4.8512122  4.53840127 4.46194982]\n",
      "pred [3.8927161  5.25562386 4.0191407  5.0085403  4.05847037 4.87634893]\n",
      "pred [4.25187095 4.74962985 4.15287898 4.78479474 4.28646101 4.79767218]\n",
      "pred [4.38618908 4.77467346 3.98424109 5.11882963 4.14038385 4.90875647]\n",
      "pred [3.73316388 5.34874061 4.03646254 4.96977708 4.29065613 4.86182697]\n",
      "pred [4.22068585 4.8813075  4.26241433 4.71149937 4.40802248 4.64660691]\n",
      "pred [3.9485487  5.10855305 4.04249196 4.99187089 4.01990559 4.93273821]\n",
      "pred [4.42053519 4.63387082 4.13926011 4.88088314 4.07423458 4.87908   ]\n",
      "pred [3.8381475  5.19011714 3.97899546 4.93159651 4.04468243 4.97919683]\n",
      "pred [4.00531984 5.0297304  4.08234096 4.87078423 4.04558246 4.88512816]\n",
      "pred [4.2887639  4.75003083 4.34369559 4.64286428 4.4089902  4.55294853]\n",
      "pred [4.10558438 4.86114146 3.7695678  5.23760934 4.24867005 4.58867785]\n",
      "pred [4.03876682 5.13552618 4.16454175 4.83797331 4.28041252 4.80219177]\n",
      "pred [3.97884137 5.02925494 4.08517875 4.78800739 4.14423036 4.7326263 ]\n",
      "pred [4.00607365 4.93801953 4.22289687 4.84290147 4.25618573 4.79746266]\n",
      "pred [4.20043837 4.89980872 4.21174577 4.81646435 4.24051505 4.77756141]\n",
      "pred [3.83610947 5.0848376  3.94126874 5.04504075 4.05045464 4.88856661]\n",
      "pred [3.80812117 5.10289805 3.78472823 5.15931507 3.78203524 5.20014795]\n",
      "pred [3.97580953 5.14720336 3.61077079 5.37031692 4.28729581 4.77503678]\n",
      "pred [3.87214117 5.02046994 4.03229966 4.95595938 4.00072967 4.93363944]\n",
      "pred [3.888769   5.03494394 3.8639313  5.23408714 4.11659565 4.87850634]\n",
      "pred [4.34806162 4.41388449 3.98632437 5.00277137 4.67124132 4.43120613]\n",
      "pred [3.94230742 4.95615675 4.20763389 4.91969054 4.09868231 4.853234  ]\n",
      "pred [4.01128314 5.04719782 3.93257375 5.07030864 3.95839139 5.11006785]\n",
      "pred [3.757456   5.23198951 4.2012673  4.68999477 4.25829977 4.87809305]\n",
      "pred [4.06185972 4.95934473 3.99093492 4.93881099 4.18154136 4.93621583]\n",
      "pred [3.9793167  4.9147371  4.10865396 5.04985802 4.31954418 4.71332129]\n",
      "pred [4.05733042 4.98024463 4.13125247 4.82618253 4.04762243 5.00266033]\n",
      "pred [4.15011544 4.99663967 4.1461901  4.96114737 4.33515787 4.68352422]\n",
      "pred [3.9797601  5.08659265 3.95391661 5.06170907 3.89852182 4.99975078]\n",
      "pred [4.13988911 4.90219527 4.23122924 4.87541258 4.31469287 4.84331139]\n",
      "pred [3.90955327 5.08541922 4.09116914 4.8662302  4.14059852 4.83832243]\n",
      "pred [4.1353953  4.94621457 4.05331542 4.98841039 4.06579791 4.79382087]\n",
      "pred [3.8819144  5.27562412 3.83065377 5.01927256 4.0638586  4.97518923]\n",
      "pred [4.1590217  4.81895232 4.10968089 4.82261003 4.3251387  4.68107265]\n",
      "pred [4.53028949 4.58533011 4.21959707 4.81254108 4.35156126 4.63303718]\n",
      "pred [4.00600911 4.92492539 4.08102406 4.95073937 4.36789389 4.64493392]\n",
      "pred [4.0803795  4.93092333 4.03796244 5.02102949 4.15239038 4.80761387]\n",
      "pred [4.17041002 4.89933043 4.18295528 4.86715872 4.34608876 4.66998826]\n",
      "pred [3.90090774 5.12224911 4.3181698  4.73178125 4.05365796 4.87406673]\n",
      "pred [4.10133401 4.9638334  4.1472641  4.8398961  4.22943985 4.78133662]\n",
      "pred [4.13474729 4.79407767 4.05856912 4.95956192 4.02362733 4.90505796]\n",
      "pred [4.03560726 5.00251293 3.93522114 5.10575944 4.14375417 4.9076463 ]\n",
      "pred [4.11894811 4.86983392 3.79631281 5.2321014  4.08796011 4.8588348 ]\n",
      "pred [4.04988983 4.97239964 4.1646936  4.9969031  4.30490682 4.71833051]\n",
      "pred [3.85909834 5.11120855 4.07702555 5.01090539 4.02804409 4.85304762]\n",
      "pred [3.85142322 5.21591947 4.31431506 4.68467123 4.11375419 4.90395323]\n",
      "pred [3.88547639 5.00869303 3.89010087 5.12770118 4.03390075 5.02303172]\n",
      "pred [4.00652999 4.87325745 4.15363261 4.8048746  4.29457997 4.71651818]\n",
      "pred [3.93033839 5.2367817  4.05949925 4.96565315 4.02815139 4.97044028]\n",
      "(296, 183) (296, 6)\n",
      "******* Feature select: FS_P  Feature type: HG-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8852751817789369\n",
      "R2 Best score (validation) val. score :  0.6302902200849916\n",
      "R2 of the best estimator (testing dataset):  0.4635057330288983\n",
      "pred [4.47043127 4.49045353 4.4718214  4.53085084 4.38268985 4.67054477]\n",
      "pred [5.03721015 4.09123063 4.39848365 4.56623271 4.35788043 4.63726087]\n",
      "pred [3.89814537 5.22265308 3.86275789 5.21878426 3.58462143 5.55276746]\n",
      "pred [3.73994228 5.17529707 4.55916634 4.49767465 5.59673437 3.33047109]\n",
      "pred [4.63842475 4.56873913 3.25331094 5.68927102 3.53828091 5.46821069]\n",
      "pred [5.27942422 3.67481343 4.40626293 4.57559202 4.99860096 3.97834929]\n",
      "pred [4.40070063 4.43712246 4.33272452 4.67060429 4.46072368 4.5889133 ]\n",
      "pred [3.66560261 5.32712145 3.96605317 4.91642966 3.91634526 5.12999381]\n",
      "pred [4.65662476 4.34209597 4.55961635 4.47782209 4.44883569 4.49092892]\n",
      "pred [4.4064212  4.36610587 4.41868609 4.61182851 4.38516448 4.72632762]\n",
      "pred [4.45964722 4.428909   4.41361379 4.5840514  4.37966414 4.64260787]\n",
      "pred [4.2213433  4.98037437 4.4291823  4.55051882 4.4749263  4.49767065]\n",
      "pred [3.52151929 5.35850732 4.56211202 4.46167714 5.52163832 3.60345984]\n",
      "pred [3.24150011 5.97483488 4.06049941 4.99279323 3.83051481 5.16891459]\n",
      "pred [4.46635274 4.51210153 4.49569569 4.46070592 4.41125219 4.53527404]\n",
      "pred [4.43978539 4.48531913 3.91134162 5.05811492 4.04143258 5.09277853]\n",
      "pred [4.03319777 5.19413687 4.54769475 4.45898157 4.42476854 4.57379324]\n",
      "pred [4.35379824 4.73245994 4.42230227 4.61091706 4.7524255  4.45863709]\n",
      "pred [3.32387279 5.8564651  3.98980848 5.01798705 3.7591531  5.30314059]\n",
      "pred [4.67955568 4.29305063 4.41121893 4.55961077 3.82698981 4.58669896]\n",
      "pred [3.90846251 5.12984035 3.9092148  4.94784855 3.94148721 5.11899561]\n",
      "pred [4.16250295 4.9868684  4.37472447 4.5423461  4.30543197 4.64773953]\n",
      "pred [4.12699933 4.75491071 4.43192026 4.63184991 4.67225091 4.39943717]\n",
      "pred [4.2991138  4.52115278 4.27419122 4.71257386 5.37661712 3.57010831]\n",
      "pred [3.31113964 5.95480752 4.46518354 4.56807012 4.17886338 4.89085502]\n",
      "pred [3.86147985 5.32400703 4.23272711 4.67703912 4.27445681 4.73377978]\n",
      "pred [4.48564489 4.5290498  4.5214141  4.54274823 3.97601744 4.9271867 ]\n",
      "pred [4.37908769 4.36905305 4.40484453 4.59855158 4.35746407 4.70843793]\n",
      "pred [3.46156113 5.67636716 4.20720856 4.79747087 3.98948994 5.00998473]\n",
      "pred [4.15595757 4.89105932 3.2985306  5.67360492 3.30520009 5.78584918]\n",
      "pred [4.30826592 4.68850034 3.29747015 5.83181412 3.81707457 5.15391023]\n",
      "pred [3.53476394 5.44711928 4.21665212 4.74578346 4.04180388 4.98546439]\n",
      "pred [4.20911997 4.88938221 3.98805261 5.03456284 3.58502652 5.40557104]\n",
      "pred [5.39301158 3.60820816 4.45495265 4.556473   5.43769313 3.63432069]\n",
      "pred [4.0195153  4.88200657 4.28316549 4.72098425 3.89725424 4.92415299]\n",
      "pred [3.4272778  5.68094086 3.78317713 5.23419427 3.70120421 5.40910939]\n",
      "pred [3.10426277 5.98454194 4.1285158  4.88986538 4.08783939 4.98859713]\n",
      "pred [3.74601468 5.44985474 4.33394385 4.61833084 4.03835366 4.81215515]\n",
      "pred [4.39996719 4.63941769 4.52126478 4.51840376 4.14240788 4.7839922 ]\n",
      "pred [3.91683037 5.16637365 4.43822715 4.53515345 3.98020754 5.01559588]\n",
      "pred [5.02614953 4.0867277  4.29487683 4.67674722 5.033822   4.00938197]\n",
      "pred [3.74958344 5.32064329 4.16795831 4.82155301 3.91642424 5.23748796]\n",
      "pred [4.53186356 4.62170853 4.56667776 4.46624508 4.63912337 3.96996599]\n",
      "pred [4.28211305 4.79022709 4.34221878 4.79423903 4.27458482 4.62827222]\n",
      "pred [3.91257926 4.97941083 4.34839211 4.69497333 4.03088901 4.92519515]\n",
      "pred [3.90846251 5.14152368 3.9092148  4.97762796 3.94148721 5.12795715]\n",
      "pred [4.85330918 4.20627081 4.37934399 4.59043913 4.48328649 4.55496695]\n",
      "pred [5.21788766 3.74000947 4.39860377 4.56691868 4.54110542 4.32371685]\n",
      "pred [4.01043199 4.54931843 4.35921872 4.81230264 4.39568734 4.57641899]\n",
      "pred [4.44272213 4.72367449 4.47327154 4.5774456  4.31508722 4.60171636]\n",
      "pred [4.84164142 4.24112335 4.415432   4.54916504 4.48417548 4.53193274]\n",
      "pred [3.10526359 6.06804473 4.21707799 4.80079359 4.10255268 4.95967644]\n",
      "pred [4.46037625 4.46473199 4.50063534 4.52027137 4.369253   4.66632956]\n",
      "pred [3.88053831 5.07525337 4.14461842 4.84664287 3.73285871 5.23421609]\n",
      "pred [3.29442519 5.79494919 3.96751526 5.03326969 3.90799194 5.18233105]\n",
      "pred [3.70424568 5.31456371 4.10888313 4.85223052 3.7129812  5.20461138]\n",
      "pred [4.30067228 4.58741316 4.45026015 4.63873003 4.23731819 4.81903972]\n",
      "pred [3.13133498 5.9278962  4.14315841 4.94643139 3.92560889 5.04781189]\n",
      "pred [3.13120099 5.98795545 4.15279964 4.76472311 4.13976475 4.9484399 ]\n",
      "pred [3.97680894 5.19570657 3.99111977 4.92195752 4.13191494 4.86270328]\n",
      "pred [4.42896256 4.72513696 4.57686595 4.40048158 4.38633105 4.55271131]\n",
      "pred [3.68407699 5.47599488 4.06762085 4.88178719 3.9916198  5.04957835]\n",
      "(296, 91) (296, 6)\n",
      "******* Feature select: FS_P  Feature type: OG-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8590645535921239\n",
      "R2 Best score (validation) val. score :  0.5912935954082765\n",
      "R2 of the best estimator (testing dataset):  0.4565564910608715\n",
      "pred [4.62356104 4.59050883 4.43607247 4.63418662 4.3741235  4.66047624]\n",
      "pred [5.15804786 3.91967623 4.46436825 4.572381   4.5112271  4.30634239]\n",
      "pred [4.14023471 5.04603349 3.95363077 5.03961859 3.54885093 5.56134386]\n",
      "pred [3.78430244 5.31830904 4.52792655 4.44020165 5.50000952 3.55907841]\n",
      "pred [4.42686628 4.62393154 3.64807138 5.41091149 3.60682501 5.52656179]\n",
      "pred [5.21916313 3.74529126 4.40535601 4.62830669 5.21876618 3.72496014]\n",
      "pred [4.43391062 4.79488533 4.42322805 4.56406581 4.45340731 4.58784604]\n",
      "pred [3.84715636 5.24174605 4.43141318 4.65560669 4.54406355 4.5625327 ]\n",
      "pred [4.30101413 4.72531646 4.3833167  4.56576115 4.30485541 4.75683748]\n",
      "pred [4.54127026 4.50649816 4.44041957 4.58438769 4.3511265  4.6495893 ]\n",
      "pred [4.57270283 4.27993598 4.46663116 4.55976208 4.25831445 4.78873717]\n",
      "pred [4.30823933 4.82269284 4.37247874 4.63398584 4.56437872 4.56423564]\n",
      "pred [3.69709418 5.28494926 4.5551508  4.42958209 5.50211469 3.55764438]\n",
      "pred [3.87131502 5.32489344 4.06643635 4.91486603 3.92326052 5.10737686]\n",
      "pred [4.43458154 4.5732611  4.28985985 4.61925848 4.29029814 4.72520971]\n",
      "pred [4.48341053 4.40767208 3.87681639 5.28419204 3.88370368 5.18270746]\n",
      "pred [4.10242699 4.95568863 4.45725691 4.53044468 4.37517673 4.65344589]\n",
      "pred [4.10091758 4.85640933 4.35533653 4.69879756 4.57884713 4.51888985]\n",
      "pred [3.82825877 5.36177006 4.0564766  4.92175452 3.96328145 5.07987028]\n",
      "pred [4.91138798 4.25742738 4.50265716 4.4981211  3.84910495 5.26822585]\n",
      "pred [3.97981516 5.06775089 4.47980019 4.59795355 4.13197715 4.90235944]\n",
      "pred [4.12188932 4.98556029 4.46278479 4.55400748 4.40255663 4.67015146]\n",
      "pred [4.01482971 4.97514892 4.34988205 4.63779711 4.63743979 4.44680566]\n",
      "pred [4.35210364 4.55861559 4.43232241 4.5893771  5.38474362 3.51681698]\n",
      "pred [3.7261601  5.39830192 4.43230381 4.58086683 4.24691602 4.77530656]\n",
      "pred [4.17825327 5.03841879 4.3014788  4.68911462 4.43798562 4.51035453]\n",
      "pred [4.35090548 4.65780844 4.49554088 4.51887764 4.18353497 4.73379904]\n",
      "pred [4.68137347 4.21113389 4.47979803 4.55704997 4.27280986 4.781556  ]\n",
      "pred [3.39278378 5.64120648 4.17398915 4.77399715 4.11778887 4.89120439]\n",
      "pred [4.37306549 4.6858712  3.64935721 5.33705408 3.43023714 5.44258914]\n",
      "pred [4.42519542 4.49700349 3.31479107 5.69310662 3.83947239 5.20748491]\n",
      "pred [3.7886879  5.3412445  4.35713323 4.72769143 4.38265354 4.63785163]\n",
      "pred [4.28122195 4.72077373 3.86529787 5.12664592 3.57739265 5.44236146]\n",
      "pred [5.40392753 3.58534281 4.41671407 4.62021664 5.41901939 3.5769785 ]\n",
      "pred [4.01358004 4.83221666 4.23340253 4.72619496 3.98843659 5.19665044]\n",
      "pred [3.86661655 5.4306327  3.97181174 4.98847724 3.70953904 5.3595305 ]\n",
      "pred [3.63158189 5.47891801 4.37149649 4.63007734 4.30054289 4.90824981]\n",
      "pred [3.768518   5.2839796  4.47075083 4.66725554 4.40332916 4.62345545]\n",
      "pred [4.34098191 4.63178189 4.49068293 4.54187264 4.13846122 4.73816121]\n",
      "pred [4.02923818 4.97838688 4.38675173 4.59075032 3.9241776  5.04682995]\n",
      "pred [4.90829902 4.01837888 4.44631847 4.59441646 4.80650271 3.98690487]\n",
      "pred [3.83408383 5.23049546 4.37169318 4.64507022 3.93087359 5.20974034]\n",
      "pred [4.44082491 4.46192893 4.51571248 4.46307703 4.24877266 4.73476827]\n",
      "pred [4.12070783 4.85533189 4.27831586 4.71461407 4.26184079 4.80040578]\n",
      "pred [3.8053712  5.16957923 4.4743579  4.53186116 4.15598204 4.81037342]\n",
      "pred [3.97981516 5.06775089 4.48195808 4.59795355 4.13197715 4.90235944]\n",
      "pred [4.46923967 4.56173703 4.35620771 4.58889476 4.49957469 4.5875675 ]\n",
      "pred [5.20189095 3.8485756  4.43070214 4.59026121 4.68436035 4.20627155]\n",
      "pred [4.359933   4.78893931 4.31402714 4.61131224 4.48531055 4.58341861]\n",
      "pred [4.23523665 4.77350044 4.53613613 4.54169201 4.28936221 4.76214742]\n",
      "pred [4.4957147  4.55452542 4.41814145 4.55020267 4.42184862 4.64108071]\n",
      "pred [3.49988614 5.63973991 4.45877756 4.5792477  4.02086738 4.92040587]\n",
      "pred [4.81406826 4.32654136 4.46167947 4.60258864 4.33415501 4.65678255]\n",
      "pred [4.08249244 4.96751038 4.14289303 4.83304116 3.63529144 5.47523549]\n",
      "pred [3.38084895 5.63207226 3.95407131 5.04179931 3.96801301 5.11833371]\n",
      "pred [3.8079938  5.04052308 4.02593706 5.1029248  3.88346634 5.18877947]\n",
      "pred [4.14284768 4.86401407 4.44730231 4.54408146 4.14781528 4.80055518]\n",
      "pred [3.77796687 5.40137851 4.16561905 4.82795208 4.06948406 4.96460515]\n",
      "pred [3.53383692 5.59789751 4.42855185 4.58484924 4.14617757 4.9512671 ]\n",
      "pred [4.18748457 5.00437446 4.50226851 4.53671824 4.35723114 4.69882311]\n",
      "pred [4.23565897 4.7808046  4.39088712 4.48253471 4.23189818 4.84910146]\n",
      "pred [3.60870428 5.40033238 4.42788855 4.631073   4.11348333 5.01441503]\n",
      "(296, 56) (296, 6)\n",
      "******* Feature select: FS_P  Feature type: ST-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8630089306335389\n",
      "R2 Best score (validation) val. score :  0.6120723318882086\n",
      "R2 of the best estimator (testing dataset):  0.4414794513753641\n",
      "pred [4.76408333 4.3635     4.476125   4.53254167 4.37179167 4.61075   ]\n",
      "pred [4.91520833 4.13991667 4.26808333 4.63929167 4.34720833 4.52220833]\n",
      "pred [3.65554167 5.36008333 3.95295833 5.08533333 3.35279167 5.58908333]\n",
      "pred [3.70583333 5.175125   4.51154167 4.49458333 4.94620833 3.88345833]\n",
      "pred [4.36258333 4.754625   3.62358333 5.35233333 3.33191667 5.57704167]\n",
      "pred [4.96420833 4.15470833 4.394375   4.567875   4.99820833 3.81991667]\n",
      "pred [4.39729167 4.6065     4.32570833 4.667375   4.35354167 4.61054167]\n",
      "pred [3.66704167 5.40804167 4.105625   4.70154167 4.09820833 4.792375  ]\n",
      "pred [4.51729167 4.50520833 4.4645     4.52195833 4.429875   4.61525   ]\n",
      "pred [4.74829167 4.32708333 4.44479167 4.56275    4.380375   4.55945833]\n",
      "pred [4.72020833 4.33554167 4.45625    4.55183333 4.28695833 4.6635    ]\n",
      "pred [4.13970833 4.77170833 4.41916667 4.54004167 4.41370833 4.53045833]\n",
      "pred [3.57808333 5.365875   4.53566667 4.478625   4.65158333 4.164125  ]\n",
      "pred [3.39441667 5.61208333 4.064      4.90645833 3.88983333 5.015     ]\n",
      "pred [4.21479167 4.74608333 4.38695833 4.56695833 4.33591667 4.59495833]\n",
      "pred [4.304125   4.70320833 4.23333333 4.77795833 4.06816667 4.793     ]\n",
      "pred [3.38275    5.60945833 4.400375   4.63454167 4.33325    4.63458333]\n",
      "pred [4.34745833 4.65445833 4.41025    4.52895833 4.57016667 4.454875  ]\n",
      "pred [3.35208333 5.65275    4.08308333 4.89525    3.92879167 5.05545833]\n",
      "pred [5.08629167 4.05541667 4.37375    4.611125   3.558625   5.57283333]\n",
      "pred [3.813625   5.29520833 3.88991667 5.01833333 3.71825    5.202625  ]\n",
      "pred [3.83270833 5.28804167 4.15575    4.76729167 4.22504167 4.83733333]\n",
      "pred [4.27616667 4.83229167 4.4425     4.53879167 4.36883333 4.57220833]\n",
      "pred [4.43858333 4.444125   4.22733333 4.6825     5.59695833 3.33279167]\n",
      "pred [3.560125   5.51633333 4.437125   4.55333333 4.186875   4.825375  ]\n",
      "pred [3.92391667 5.30725    4.30620833 4.598125   4.32229167 4.70995833]\n",
      "pred [4.26583333 4.60804167 4.48779167 4.490375   4.177      4.78466667]\n",
      "pred [4.69725    4.34995833 4.45183333 4.54729167 4.28829167 4.662625  ]\n",
      "pred [3.4875     5.49429167 4.05625    4.96491667 4.10170833 4.89404167]\n",
      "pred [4.10954167 4.85133333 3.51875    5.37229167 3.12816667 5.73195833]\n",
      "pred [3.83654167 5.16133333 3.08825    5.844      3.390875   5.47195833]\n",
      "pred [3.69229167 5.43058333 4.36991667 4.61820833 4.145125   4.89179167]\n",
      "pred [4.15283333 4.99908333 3.72970833 5.19375    3.514875   5.4145    ]\n",
      "pred [5.0865     4.04854167 4.42275    4.59225    4.95575    4.0715    ]\n",
      "pred [4.235875   4.86433333 4.29154167 4.68391667 4.05579167 4.89508333]\n",
      "pred [3.52833333 5.48958333 4.00683333 4.96325    3.77141667 5.12220833]\n",
      "pred [3.31875    5.85995833 4.44604167 4.52033333 4.03525    4.94808333]\n",
      "pred [3.90133333 5.16391667 4.44545833 4.53891667 4.35616667 4.59825   ]\n",
      "pred [4.437625   4.59383333 4.47875    4.51841667 4.238875   4.72233333]\n",
      "pred [3.78125    5.31754167 4.47225    4.52816667 4.14658333 4.89795833]\n",
      "pred [4.85704167 4.15158333 4.394      4.56916667 4.55825    3.99729167]\n",
      "pred [3.88295833 5.26775    4.12479167 4.8035     3.62770833 5.22      ]\n",
      "pred [4.77183333 4.28525    4.45691667 4.48775    3.68433333 5.16766667]\n",
      "pred [4.0935     4.99795833 4.42183333 4.52275    4.18233333 4.82504167]\n",
      "pred [3.563125   5.414875   3.88920833 5.01358333 4.09591667 4.90741667]\n",
      "pred [3.811125   5.27429167 3.88883333 5.03716667 3.71041667 5.20866667]\n",
      "pred [4.46716667 4.469125   4.43466667 4.593125   4.32775    4.659     ]\n",
      "pred [5.03879167 4.05770833 4.41295833 4.62979167 4.38004167 4.50516667]\n",
      "pred [4.17833333 4.88483333 4.42316667 4.518875   4.42266667 4.52591667]\n",
      "pred [4.16016667 4.830625   4.46779167 4.52691667 4.25725    4.81783333]\n",
      "pred [4.49675    4.48270833 4.39366667 4.56258333 4.47433333 4.572625  ]\n",
      "pred [3.40075    5.701      4.4345     4.56829167 4.06775    4.92304167]\n",
      "pred [4.71875    4.34604167 4.46070833 4.53879167 4.32995833 4.641625  ]\n",
      "pred [3.76991667 5.22720833 4.01675    4.996125   3.39245833 5.63308333]\n",
      "pred [3.49620833 5.52420833 3.91183333 5.07770833 3.8485     5.17675   ]\n",
      "pred [3.9715     5.41641667 3.77758333 5.11745833 3.67008333 5.461125  ]\n",
      "pred [4.537125   4.43141667 4.45120833 4.58345833 4.14104167 4.84833333]\n",
      "pred [3.37991667 5.67404167 4.05404167 4.97729167 4.02341667 4.946375  ]\n",
      "pred [3.33404167 5.76629167 4.46533333 4.499375   4.05333333 4.930875  ]\n",
      "pred [3.77933333 5.19933333 3.94804167 4.90158333 3.99454167 4.99925   ]\n",
      "pred [4.24979167 4.77541667 4.43629167 4.57491667 4.34579167 4.60670833]\n",
      "pred [3.73866667 5.3925     4.177375   4.81833333 3.81529167 5.09504167]\n",
      "(296, 296) (296, 6)\n",
      "******* Feature select: FS_K  Feature type: HG-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.891415321176293\n",
      "R2 Best score (validation) val. score :  0.6381284767566126\n",
      "R2 of the best estimator (testing dataset):  0.4705107387150716\n",
      "pred [4.42674634 4.3315063  4.4917215  4.51515    4.30299079 4.49322476]\n",
      "pred [5.00624426 4.01487697 4.32416687 4.58347677 4.69093231 4.63251672]\n",
      "pred [3.85537062 5.13302698 3.94712921 5.09324137 3.52069363 5.63387073]\n",
      "pred [3.8189071  5.05159902 4.52635195 4.43730393 5.48432735 3.25347311]\n",
      "pred [4.33833786 4.64080715 3.21961094 5.64961462 3.61878902 5.42999338]\n",
      "pred [5.18435338 3.83656541 4.25846184 4.68684326 4.98838121 3.61772871]\n",
      "pred [4.34700233 4.44353256 4.22678383 4.61099368 4.42528601 4.55173359]\n",
      "pred [3.68648695 5.2271576  4.06849017 4.90766381 4.11277094 4.79646712]\n",
      "pred [4.48433653 4.3911172  4.47473976 4.46650861 4.47783896 4.50490416]\n",
      "pred [4.52563836 4.34207433 4.49587238 4.55911796 4.38452453 4.60745764]\n",
      "pred [4.55445113 4.39852957 4.48528878 4.61865751 4.36760584 4.73226582]\n",
      "pred [4.07061236 4.7426294  4.46052255 4.52180128 4.38831831 4.44341161]\n",
      "pred [3.49271218 5.1859053  4.55239258 4.43178798 5.37952379 3.40115086]\n",
      "pred [3.30198544 5.53994628 4.0104475  4.95831428 3.83931523 5.13743923]\n",
      "pred [4.29621565 4.61249805 4.49532579 4.47791207 4.4331598  4.58830185]\n",
      "pred [4.50165904 4.6633543  3.96083656 5.04659873 3.8472784  5.33294511]\n",
      "pred [3.81725941 5.00385093 4.55866854 4.42538249 4.47610787 4.49489753]\n",
      "pred [4.1250923  4.66535355 4.41225351 4.5699838  4.58004169 4.3269602 ]\n",
      "pred [3.21047082 5.5802498  4.00799683 4.95632823 3.80258647 5.15183139]\n",
      "pred [4.76005573 4.35373232 4.42001664 4.52158714 4.05139295 4.86695316]\n",
      "pred [3.77772601 5.10204851 3.98580531 5.0020275  3.9786812  5.02452522]\n",
      "pred [4.00319056 4.84778979 4.4498182  4.53232737 4.36854609 4.68921392]\n",
      "pred [4.08857006 4.85013364 4.44024611 4.62546138 4.53634657 4.43146003]\n",
      "pred [4.27024501 4.68600905 4.12152288 4.77671356 5.49735509 3.31971531]\n",
      "pred [3.16909623 5.44301531 4.43771836 4.61709512 4.2968108  4.81072413]\n",
      "pred [3.84930175 5.29090489 4.37418507 4.6174973  4.2816908  4.67615503]\n",
      "pred [4.46123261 4.595844   4.49871993 4.48654107 4.19275873 4.73103045]\n",
      "pred [4.53468443 4.44288756 4.44763275 4.63810163 4.36663883 4.71407612]\n",
      "pred [3.42283401 5.56211861 4.17826202 4.88479094 4.06291391 5.00984662]\n",
      "pred [4.23800564 4.81880904 3.24435333 5.74619117 3.2880105  5.68989745]\n",
      "pred [4.38524083 4.71211373 2.99760488 5.81134758 3.71101964 5.23322738]\n",
      "pred [3.54747685 5.41520194 4.30166288 4.69271049 4.19512755 4.81206977]\n",
      "pred [4.16807433 4.68541643 3.84396035 5.16047267 3.73626499 5.39219127]\n",
      "pred [5.24947653 3.74366867 4.30242102 4.61270196 4.8830917  3.67145365]\n",
      "pred [4.06796378 4.89707438 4.32559086 4.64447415 4.02619602 4.89302805]\n",
      "pred [3.3944529  5.45812048 3.88056906 5.21849155 3.44974788 5.4312075 ]\n",
      "pred [3.01159834 5.72429004 4.20353377 4.81193175 4.18133364 4.83087713]\n",
      "pred [3.62397408 5.20742148 4.39944553 4.59144741 4.22895845 4.76155203]\n",
      "pred [4.38638824 4.59340287 4.48913538 4.47982271 4.24748455 4.67079512]\n",
      "pred [3.90750923 5.13870378 4.47427797 4.50157218 3.96167492 4.97510073]\n",
      "pred [4.66461999 4.10487864 4.13277162 4.77542503 4.8351427  3.80072171]\n",
      "pred [3.73235528 5.29524428 4.24556452 4.71923094 3.89213295 5.13262587]\n",
      "pred [4.3285295  4.52498222 4.39266825 4.57196614 4.81587489 3.96556685]\n",
      "pred [4.32041037 4.57287954 4.31788207 4.52671805 4.39628079 4.67631661]\n",
      "pred [3.86259679 5.10461675 4.46607894 4.60359762 3.88713063 5.07221817]\n",
      "pred [3.77772601 5.1260128  3.94980639 5.0020275  3.9786812  5.02775047]\n",
      "pred [4.42819652 4.34732435 4.43959055 4.56128929 4.41383018 4.4900217 ]\n",
      "pred [5.1129571  3.87556263 4.27268222 4.66155711 4.77886678 4.42152845]\n",
      "pred [4.09919393 4.92036928 4.26734175 4.59797147 4.37549472 4.5822357 ]\n",
      "pred [4.4090835  4.62158988 4.44793739 4.43795303 4.44008552 4.60122232]\n",
      "[4.44460504 4.36827966 4.45847099 4.50897218 4.47894149 4.45392156]\n",
      "pred [2.99469093 5.64392909 4.25202565 4.76639583 4.08653668 4.88001234]\n",
      "pred [4.48162518 4.29616524 4.52088196 4.49719325 4.38235455 4.50595975]\n",
      "pred [3.91057573 5.2888792  4.13881085 4.85510106 3.68899917 5.38543773]\n",
      "pred [3.3529568  5.52174025 3.98197719 5.0946253  3.92068462 5.20738676]\n",
      "pred [3.72201341 5.33492639 4.15697661 4.86157223 3.67224102 5.38913293]\n",
      "pred [4.36015171 4.62165785 4.37945742 4.60163134 4.38030779 4.57093182]\n",
      "pred [3.23153475 5.52173812 4.12801118 4.81580394 4.05021684 5.01962148]\n",
      "pred [2.97908798 5.73453468 4.29743178 4.77233752 4.14996314 4.84091342]\n",
      "pred [3.84195249 5.10626841 4.140314   4.74266693 4.25373098 4.71177487]\n",
      "pred [4.1526273  4.72359794 4.59888882 4.38863386 4.43125988 4.53559878]\n",
      "pred [3.57441577 5.3322822  4.19212809 4.74428794 4.09077646 4.89184952]\n",
      "(296, 151) (296, 6)\n",
      "******* Feature select: FS_K  Feature type: OG-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.867405536920205\n",
      "R2 Best score (validation) val. score :  0.5942156371655795\n",
      "R2 of the best estimator (testing dataset):  0.4451775614830827\n",
      "pred [4.51075566 4.47479266 4.4527106  4.57515556 4.31092403 4.66362375]\n",
      "pred [5.23079166 3.83710791 4.39230186 4.62278627 4.61998328 4.52700632]\n",
      "pred [4.05160768 5.05867253 4.00183389 4.94151941 3.48864072 5.53307283]\n",
      "pred [3.54739897 5.29240741 4.48041888 4.48088654 5.47102237 3.39755292]\n",
      "pred [4.41943371 4.53166946 3.66709457 5.32364168 3.52078228 5.43282654]\n",
      "pred [5.34577657 3.73509625 4.31708913 4.7083873  5.17053547 3.64984608]\n",
      "pred [4.26924828 4.7789208  4.39467632 4.56198172 4.37588059 4.55803563]\n",
      "pred [3.80850537 5.26320547 4.35576849 4.69706445 4.46700271 4.73371975]\n",
      "pred [4.28539293 4.66773003 4.35760879 4.67104377 4.24766201 4.72595744]\n",
      "pred [4.51594166 4.43445569 4.47698623 4.55963247 4.31126349 4.69648509]\n",
      "pred [4.48007416 4.42175437 4.45051892 4.569061   4.19082843 4.7973925 ]\n",
      "pred [4.14230261 4.6778471  4.36748318 4.62760721 4.48698771 4.61486027]\n",
      "pred [3.54271773 5.39597279 4.48589426 4.45322898 5.40224624 3.42435293]\n",
      "pred [3.71221518 5.18272524 3.97063793 5.14119651 3.87408966 5.22067899]\n",
      "pred [4.37787091 4.6162524  4.23480968 4.83930831 4.16371119 4.74294223]\n",
      "pred [4.4496602  4.56065045 3.77936623 5.28898418 3.81350773 5.30990309]\n",
      "pred [3.99431179 4.88536314 4.46229009 4.53708727 4.39781613 4.56772595]\n",
      "pred [4.09733091 4.84319682 4.29671913 4.6385388  4.53458583 4.59872392]\n",
      "pred [3.71361083 5.2221964  3.96457335 5.13603556 3.9651868  5.14728882]\n",
      "pred [4.73115863 4.11342601 4.50193305 4.49271558 3.49224569 5.3364743 ]\n",
      "pred [3.96940019 5.07252892 4.24805765 4.63518708 4.06246735 4.87093609]\n",
      "pred [4.03907765 5.05036561 4.45505379 4.50086641 4.41611523 4.53000897]\n",
      "pred [3.93461158 4.88344734 4.28455674 4.63383498 4.49533069 4.50368815]\n",
      "pred [4.5440606  4.61075122 4.28939563 4.7372211  5.51616021 3.38470135]\n",
      "pred [3.55916453 5.54649607 4.28471332 4.61539728 4.19137774 4.8517985 ]\n",
      "pred [3.9566717  5.06123951 4.33845658 4.63714378 4.47888379 4.56990854]\n",
      "pred [4.36568832 4.6754531  4.47009862 4.52972803 4.31948413 4.68998106]\n",
      "pred [4.574286   4.38303921 4.4424864  4.56677464 4.17443617 4.82189061]\n",
      "pred [3.43220557 5.53167727 4.15743153 4.835206   4.05797936 4.969054  ]\n",
      "pred [4.18837921 4.76301758 3.67337546 5.3288803  3.34734764 5.53401314]\n",
      "pred [4.3847129  4.51896688 3.28433127 5.72856482 3.90374043 5.16061348]\n",
      "pred [3.79483989 5.30734588 4.34138526 4.63374358 4.46138642 4.71111446]\n",
      "pred [4.3981018  4.49238768 3.88697374 4.91201473 3.62564463 5.39867881]\n",
      "pred [5.41485954 3.62356788 4.36176984 4.61401028 5.39128234 3.44183596]\n",
      "pred [4.172237   4.90938794 4.18891191 4.78333258 3.78489251 5.23806111]\n",
      "pred [3.71415608 5.21496467 3.96361901 5.17434776 3.59113369 5.5148638 ]\n",
      "pred [3.44340787 5.45818188 4.20914148 4.70281137 4.23117265 4.88961102]\n",
      "pred [3.71314027 5.35791023 4.41165399 4.56362541 4.45036765 4.74516964]\n",
      "pred [4.34008973 4.6586845  4.50824678 4.50923762 4.2521952  4.7314731 ]\n",
      "pred [4.04754405 4.95301923 4.30194184 4.56471663 3.98583649 5.12608637]\n",
      "pred [4.9828192  4.08484494 4.33344572 4.67996486 4.95484142 3.88253392]\n",
      "pred [3.88840431 5.17333664 4.21539421 4.57961836 3.8155589  5.15099193]\n",
      "pred [4.51688129 4.45874509 4.48135456 4.52366812 4.28596738 4.72237057]\n",
      "pred [4.27601279 4.84032695 4.14024742 4.90184229 4.13258243 4.91732644]\n",
      "pred [3.80848235 5.07487157 4.33804454 4.61164213 4.17346966 4.94375399]\n",
      "pred [3.97720626 5.05827243 4.24805765 4.63518708 4.06352872 4.87093609]\n",
      "pred [4.44945126 4.55191911 4.40589038 4.58790524 4.35476491 4.62583451]\n",
      "pred [5.2794156  3.80315298 4.3478753  4.68148822 4.7434458  4.3462348 ]\n",
      "pred [4.31648115 4.73847514 4.37966089 4.57887335 4.45903457 4.53508565]\n",
      "pred [4.22195539 4.83558946 4.41950304 4.47697381 4.21849434 4.7498884 ]\n",
      "pred [4.40844563 4.54770142 4.44360505 4.56267951 4.32616113 4.60892422]\n",
      "pred [3.37413593 5.66593795 4.23001238 4.72357665 3.96196257 5.00629431]\n",
      "pred [4.77520009 4.20577951 4.46730181 4.52941832 4.35261242 4.57320841]\n",
      "pred [3.95517402 4.99747786 4.13385135 4.78136882 3.58505945 5.38817258]\n",
      "pred [3.38861314 5.49273789 3.9158517  5.10567526 4.01550669 5.15954768]\n",
      "pred [3.8707397  5.00757665 4.01267814 4.99774712 3.66743976 5.1812233 ]\n",
      "pred [4.17832965 4.79197385 4.4910304  4.52254094 4.23691631 4.78477813]\n",
      "pred [3.72608275 5.19629798 4.05904774 4.99266762 3.92128904 5.06130856]\n",
      "pred [3.28624153 5.64183659 4.25883397 4.61776946 4.14036185 4.91460371]\n",
      "pred [4.07454244 4.95542771 4.42345481 4.57908829 4.37370343 4.71955142]\n",
      "pred [4.23983261 4.80669161 4.38001992 4.62358348 4.18563907 4.83890133]\n",
      "pred [3.68068272 5.27705083 4.34609797 4.57139426 4.10442684 5.03311595]\n",
      "(296, 87) (296, 6)\n",
      "******* Feature select: FS_K  Feature type: ST-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8672493997054486\n",
      "R2 Best score (validation) val. score :  0.6139008898113544\n",
      "R2 of the best estimator (testing dataset):  0.38405556952407377\n",
      "pred [4.69575  4.469625 4.491    4.475875 4.436    4.583625]\n",
      "pred [5.14325  3.965375 4.41     4.600375 4.218375 4.402875]\n",
      "pred [3.714125 5.39     4.03425  4.985    3.480625 5.44875 ]\n",
      "pred [3.769375 5.382125 4.498    4.501    5.20775  3.783   ]\n",
      "pred [4.239375 4.75575  3.878375 5.052625 3.352    5.9155  ]\n",
      "pred [5.154    3.838375 4.500125 4.532125 5.18075  3.6805  ]\n",
      "pred [4.538125 4.74075  4.345375 4.627375 4.43825  4.573625]\n",
      "pred [3.957625 5.2345   3.86525  4.98025  4.200125 4.75725 ]\n",
      "pred [4.26725  4.602375 4.468625 4.5085   4.43875  4.593125]\n",
      "pred [4.75175  4.495125 4.459    4.50225  4.439375 4.6245  ]\n",
      "pred [4.7425   4.46275  4.470625 4.498625 4.36975  4.709375]\n",
      "pred [4.258125 4.81575  4.406375 4.57225  4.4885   4.50725 ]\n",
      "pred [3.51525  5.649375 4.525    4.47025  5.0935   4.568375]\n",
      "pred [3.539    5.805625 4.10125  4.887    3.963875 5.092375]\n",
      "pred [4.14775  4.85625  4.28775  4.567625 4.367375 4.824   ]\n",
      "pred [4.151    4.721375 4.22275  4.715125 4.147875 4.74775 ]\n",
      "pred [3.685    5.684    4.480625 4.557    4.402625 4.584375]\n",
      "pred [4.3625   4.646625 4.469125 4.533    4.6035   4.308625]\n",
      "pred [3.459625 5.659625 4.121    4.876    4.01025  5.0145  ]\n",
      "pred [5.121125 3.8755   4.42125  4.622125 3.2035   5.759125]\n",
      "pred [4.02525  5.140625 3.726125 4.83875  3.62525  5.209375]\n",
      "pred [3.873125 5.23625  4.08025  4.760375 4.26675  4.733125]\n",
      "pred [4.15725  4.7085   4.437125 4.564    4.469125 4.597875]\n",
      "pred [4.66675  4.29325  4.454875 4.5965   5.464    3.405875]\n",
      "pred [3.744875 5.349875 4.457375 4.58175  4.20675  4.740375]\n",
      "pred [3.96625  5.1695   4.378375 4.6135   4.3995   4.628625]\n",
      "pred [4.237375 4.611875 4.55     4.652875 4.13925  4.885125]\n",
      "pred [4.7475   4.485375 4.468875 4.49625  4.37125  4.707125]\n",
      "pred [3.592375 5.367625 4.111    4.997    4.02775  4.892625]\n",
      "pred [4.1615   4.804    3.578625 5.1435   3.135875 5.84075 ]\n",
      "pred [4.00625  4.980875 3.432375 5.897    3.14375  5.709875]\n",
      "pred [3.584875 5.625125 4.45     4.52975  4.096375 4.740125]\n",
      "pred [4.077125 4.74075  3.63575  5.175125 3.54325  5.376625]\n",
      "pred [5.265375 3.88625  4.467125 4.553875 5.2035   3.558   ]\n",
      "pred [4.2195   4.76125  4.262    4.700625 4.31375  5.033375]\n",
      "pred [3.603625 5.492375 4.0565   4.878    3.755    5.216625]\n",
      "pred [3.51075  5.593875 4.483875 4.536125 3.965625 4.96325 ]\n",
      "pred [3.782875 5.312875 4.559125 4.5445   4.43225  4.5795  ]\n",
      "pred [4.31875  4.529125 4.50425  4.63975  4.33675  4.676   ]\n",
      "pred [3.916625 5.059625 4.4205   4.479    4.213    4.804875]\n",
      "pred [5.1685   4.078    4.491875 4.506625 4.782125 3.948375]\n",
      "pred [4.047625 5.221    4.206    4.646875 3.585625 5.275625]\n",
      "pred [4.707875 4.25375  4.51275  4.49075  3.776875 5.229375]\n",
      "pred [4.06575  4.876625 4.400875 4.60775  4.28425  4.79025 ]\n",
      "pred [3.843625 5.436375 3.91525  4.79125  4.232625 4.770625]\n",
      "pred [4.06775  5.140625 3.753625 4.83975  3.64475  5.205375]\n",
      "pred [4.217125 4.7625   4.48025  4.54475  4.416625 4.836375]\n",
      "pred [5.29125  3.89875  4.461125 4.579375 4.477    4.44175 ]\n",
      "pred [4.491125 4.935875 4.445875 4.579875 4.4895   4.517875]\n",
      "pred [4.1235   4.810875 4.336875 4.5325   4.307875 4.6635  ]\n",
      "pred [4.305    4.851125 4.462625 4.5705   4.42275  4.623125]\n",
      "pred [3.587375 5.565    4.473625 4.549625 4.081875 4.873625]\n",
      "pred [4.637875 4.489    4.459875 4.497625 4.424875 4.63475 ]\n",
      "pred [3.78575  5.40925  3.810125 4.898875 3.592125 5.579   ]\n",
      "pred [3.62925  5.35725  3.95625  5.1175   3.871125 5.1175  ]\n",
      "pred [3.751625 5.344875 3.6355   5.0305   3.52075  5.37825 ]\n",
      "pred [4.400125 4.604875 4.493    4.647875 4.15925  4.771625]\n",
      "pred [3.420625 5.725625 4.1005   4.831875 4.130125 4.933375]\n",
      "pred [3.538625 5.52475  4.429125 4.526    4.026875 4.868875]\n",
      "pred [4.17925  4.978625 3.7055   4.812625 4.076375 4.99975 ]\n",
      "pred [4.1205   4.7255   4.515875 4.507125 4.3655   4.825125]\n",
      "pred [3.79375  5.339125 4.25     4.664    3.76425  5.204125]\n",
      "regression_type gbr\n",
      "(296, 490) (296, 6)\n",
      "******* Feature select: all  Feature type: HG-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.983294702339159\n",
      "R2 Best score (validation) val. score :  0.6232634359946825\n",
      "R2 of the best estimator (testing dataset):  0.4159119601073466\n",
      "pred [4.47787386 4.55810614 4.60035378 4.39964622 4.23870109 4.73178186]\n",
      "pred [5.14281161 3.85718839 4.33282221 4.66717779 4.5828439  4.33630365]\n",
      "pred [3.89209777 5.10790223 3.95539793 5.0549096  3.4831037  5.5168963 ]\n",
      "pred [3.5282214  5.4717786  4.56394    4.43606    5.64940666 3.18041263]\n",
      "pred [4.27853064 4.72146936 3.29204314 5.75486616 3.34134721 5.63490293]\n",
      "pred [5.0675835  3.83003625 4.37338061 4.62661939 5.55606516 3.27143974]\n",
      "pred [4.26395185 4.78733626 4.28996679 4.71003321 4.48791764 4.51208236]\n",
      "pred [3.5984353  5.47246207 3.21042643 5.8122933  4.14217664 4.84310293]\n",
      "pred [4.75938782 4.19841975 4.58371207 4.40930417 4.46858873 4.59881244]\n",
      "pred [4.65876187 4.34123813 4.50689432 4.49310568 4.33091446 4.66908554]\n",
      "pred [4.68602006 4.31397994 4.34617204 4.65382796 4.05677958 4.91370337]\n",
      "pred [3.95558077 5.04441923 4.45055829 4.54944171 4.60702216 4.39297784]\n",
      "pred [3.35334142 5.64665858 4.67061591 4.32938409 5.43766077 3.58426631]\n",
      "pred [3.14705646 5.85294354 4.06673363 4.86785022 3.4914899  5.53043718]\n",
      "pred [4.36150375 4.66172774 4.6043781  4.3956219  4.51819652 4.56388542]\n",
      "pred [4.19187413 4.80812587 4.07220199 4.92779801 4.05550861 4.98228067]\n",
      "pred [3.86593735 5.06947159 4.58864024 4.42813626 4.75391733 4.24608267]\n",
      "pred [4.23711319 4.76288681 4.41001129 4.57321221 4.9334269  4.0665731 ]\n",
      "pred [3.25835476 5.74164524 4.03054749 4.90403636 3.50982905 5.51209804]\n",
      "pred [5.10411106 3.89588894 4.55804902 4.44195098 3.42516351 5.59676358]\n",
      "pred [3.40546151 5.59453849 3.78149894 5.25137367 4.09837068 4.87787945]\n",
      "pred [4.5158011  4.59712478 4.11729341 4.89210371 4.53386852 4.46613148]\n",
      "pred [3.98694065 4.86643297 4.24569613 4.75430387 4.53996029 4.4765976 ]\n",
      "pred [4.36547677 4.63452323 4.4863319  4.58720969 5.7574379  3.04286434]\n",
      "pred [3.18994769 5.81005231 4.52860818 4.47139182 3.88740565 5.11259435]\n",
      "pred [3.54745641 5.44887342 4.03890322 4.99396939 4.46290851 4.53709149]\n",
      "pred [4.51363159 4.48636841 4.44817585 4.55182415 4.25062831 4.73422009]\n",
      "pred [4.63611014 4.36388986 4.33931421 4.66068579 4.06885814 4.90162482]\n",
      "pred [3.35004036 5.64995964 4.20998875 4.75435365 4.11990994 4.88009006]\n",
      "pred [3.79574846 5.16737027 2.74416361 6.03177488 2.90224032 6.09775968]\n",
      "pred [3.87951858 5.19195458 2.78164351 6.2249801  3.75963919 5.24036081]\n",
      "pred [3.73966699 5.26033301 4.52528787 4.47471213 3.84600863 5.15399137]\n",
      "pred [4.19670772 4.80329228 3.22572403 5.81377219 3.42276315 5.55348698]\n",
      "pred [5.50699492 3.49300508 4.13302926 4.7031182  4.65441138 4.36751571]\n",
      "pred [3.84734624 5.15265376 4.50421047 4.49578953 3.81518894 5.18481106]\n",
      "pred [3.43516442 5.6468527  3.78861094 5.10876578 3.2506126  5.80910377]\n",
      "pred [2.93351596 5.95583766 4.24252315 4.77095684 3.66012072 5.33987928]\n",
      "pred [4.10257055 4.89742945 4.61673555 4.38326445 3.98957777 4.98090518]\n",
      "pred [4.3248037  4.63730391 4.51453462 4.48546538 4.50387129 4.52992306]\n",
      "pred [3.85887426 5.14112574 4.44268616 4.56393746 3.76962592 5.23037408]\n",
      "pred [4.80301051 4.19698949 4.44895707 4.55104293 4.9680044  3.842082  ]\n",
      "pred [3.43602372 5.58758212 3.9545449  5.07832771 3.93282135 5.06717865]\n",
      "pred [4.5860991  4.4139009  4.62353908 4.37646092 3.83729636 5.1408879 ]\n",
      "pred [3.99261067 4.98817598 4.53490092 4.39990311 4.32941083 4.73799033]\n",
      "pred [4.13204997 4.98087591 4.09567253 4.91095108 3.66321689 5.33678311]\n",
      "pred [3.40546151 5.59453849 3.7739865  5.25888611 4.10704496 4.86920518]\n",
      "pred [4.86177894 4.19763236 4.45414618 4.54918915 4.45747203 4.60992914]\n",
      "pred [5.23107676 3.71378349 4.39743647 4.60256353 4.73841989 4.30500384]\n",
      "pred [4.06955937 4.93044063 4.19612905 4.83674356 4.21523076 4.78476924]\n",
      "pred [4.56427448 4.51252657 4.8875145  4.10216642 4.35332398 4.64667602]\n",
      "pred [4.75766106 4.30175024 4.38884808 4.62095068 4.70803606 4.3593651 ]\n",
      "pred [3.22524504 5.77475496 4.34204168 4.62053102 3.82980369 5.17019631]\n",
      "pred [4.6526571  4.3473429  4.60738485 4.40939165 4.38175466 4.5887283 ]\n",
      "pred [3.77614693 5.22385307 3.86096226 5.13903774 3.62268965 5.37731035]\n",
      "pred [3.43537789 5.59966467 4.04266659 4.99088002 3.49715242 5.50284758]\n",
      "pred [3.7714896  5.27440632 3.8669448  5.17255143 3.35200192 5.68965806]\n",
      "pred [3.94911162 5.08945312 4.51606452 4.48393548 4.47122169 4.52118835]\n",
      "pred [3.34091075 5.65908925 4.14694015 4.86830953 3.83096294 5.19096414]\n",
      "pred [2.87435485 6.12564515 4.39115704 4.60884296 3.9238205  5.0761795 ]\n",
      "pred [3.78580477 5.21419523 3.88080629 5.15868993 4.50706605 4.46434948]\n",
      "pred [4.15030219 4.88822966 4.54930381 4.45069619 4.58463479 4.45418191]\n",
      "pred [3.32113653 5.67886347 3.98303993 5.04983268 4.07949525 4.89675489]\n",
      "(296, 302) (296, 6)\n",
      "******* Feature select: all  Feature type: OG-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.8999313656308755\n",
      "R2 Best score (validation) val. score :  0.5654391623993836\n",
      "R2 of the best estimator (testing dataset):  0.38912632631260274\n",
      "pred [4.92257747 4.01752641 4.39809896 4.60971816 4.42709171 4.54816132]\n",
      "pred [5.12091909 3.87645433 4.46959345 4.58526648 5.06548255 3.73568146]\n",
      "pred [4.21469498 4.80705211 4.25568916 4.8029658  3.40578226 5.65530864]\n",
      "pred [3.53774694 5.39198387 4.46763416 4.57712222 5.90393279 3.05265274]\n",
      "pred [4.39636209 4.67569315 3.24846045 5.74718366 3.69896087 5.42599536]\n",
      "pred [4.93311649 4.0339985  4.36505819 4.63337175 5.47779205 3.39196969]\n",
      "pred [4.36206217 4.33096213 4.39360216 4.70913399 4.50302809 4.452363  ]\n",
      "pred [3.73394569 5.25277749 4.39989118 4.67581987 4.56642463 4.55502598]\n",
      "pred [4.70253413 4.17220518 4.23404812 4.95965812 4.46657073 4.58989519]\n",
      "pred [5.0368188  3.9800306  4.38231053 4.62000413 4.39101717 4.61222167]\n",
      "pred [5.00450456 3.9928774  4.41459688 4.58231718 4.31981946 4.66294953]\n",
      "pred [4.51249422 4.44332606 4.4589577  4.52574369 4.51745336 4.24239628]\n",
      "pred [3.52394958 5.38528038 4.51620438 4.5182322  5.75058953 3.22907677]\n",
      "pred [4.26967576 4.89773067 3.91838097 5.07118727 4.01113223 4.95016742]\n",
      "pred [4.67966913 4.28524113 4.31573151 4.7429514  4.32771817 4.63077989]\n",
      "pred [4.68832827 4.40447845 3.97443579 5.086918   3.79104033 5.13392936]\n",
      "pred [4.55939685 4.46812083 4.42025019 4.62296269 4.50971116 4.60562651]\n",
      "pred [4.25951335 4.64099105 4.46771317 4.54174366 4.66985357 4.36372369]\n",
      "pred [4.26967576 4.89773067 3.91838097 5.07118727 4.03336104 4.78874078]\n",
      "pred [4.74470131 4.13588595 4.50206137 4.50956497 3.51888287 5.4444598 ]\n",
      "pred [3.80030673 5.1261351  4.45780116 4.54102513 4.24646823 4.81855174]\n",
      "pred [4.23501712 4.63760119 4.44202448 4.59838651 4.50353263 4.53219344]\n",
      "pred [4.27922401 4.66347725 4.45501388 4.56030694 4.44808764 4.59543469]\n",
      "pred [4.34828815 4.64731996 4.33392502 4.71207939 5.84700765 3.40094775]\n",
      "pred [4.11770706 4.99260398 4.46631286 4.57054483 4.3641555  4.66862762]\n",
      "pred [3.89675941 5.11898162 4.48152229 4.51176702 4.60996961 4.52496824]\n",
      "pred [4.16299674 4.87822342 4.52970716 4.48007176 4.18443044 4.97146902]\n",
      "pred [5.02306507 3.9928774  4.46433374 4.52592916 4.30551763 4.71626449]\n",
      "pred [3.61821995 5.34149116 4.22349811 4.94663374 4.38695678 4.61349422]\n",
      "pred [4.19832278 4.88270992 3.68864802 5.40183648 3.52146169 5.53940968]\n",
      "pred [4.40167445 4.65548321 3.70562265 5.3719802  3.79590686 5.35533732]\n",
      "pred [3.44922961 5.48118015 4.33553969 4.70535527 4.39168304 4.72546738]\n",
      "pred [4.51065996 4.58301567 4.217536   4.80009526 3.83202891 5.44915994]\n",
      "pred [5.12091909 3.87645433 4.46959345 4.57718805 5.45908883 3.29229738]\n",
      "pred [4.209792   4.6322326  4.40734206 4.60140209 3.79993248 5.24485321]\n",
      "pred [4.21335559 4.97581985 3.92749923 5.05507847 3.49439483 5.42604138]\n",
      "pred [3.77432248 5.11600515 4.36568048 4.61127892 4.30017303 4.4757215 ]\n",
      "pred [3.53577557 5.34952896 4.38678977 4.68817594 4.30739522 4.7818445 ]\n",
      "pred [4.32791749 4.7379695  4.50239734 4.50682885 4.22213319 4.86875865]\n",
      "pred [4.24849786 4.65898909 4.41121293 4.63432963 3.94983946 5.0825418 ]\n",
      "pred [4.69017449 4.29810052 4.44701881 4.54806121 4.76924897 4.1193929 ]\n",
      "pred [3.63846777 5.38258089 4.34271084 4.6754244  4.10549874 4.95374906]\n",
      "pred [4.50939026 4.40687993 4.48735162 4.56785668 3.64229749 5.43666744]\n",
      "pred [4.46560201 4.59373618 4.24613944 4.67456051 4.37104523 4.62789092]\n",
      "pred [3.69271378 5.18641864 4.49433573 4.50711151 4.17358554 4.82724662]\n",
      "pred [3.80030673 5.1261351  4.45780116 4.54102513 4.24646823 4.81855174]\n",
      "pred [4.79892107 4.09667378 4.44946409 4.60092701 4.49946301 4.41349362]\n",
      "pred [5.16145492 3.83593007 4.45232726 4.5985124  5.2363224  3.74359776]\n",
      "pred [4.7245076  4.16554885 4.37255739 4.6342537  4.48134265 4.46529445]\n",
      "pred [4.39434401 4.46859102 4.4698317  4.50583344 4.35723685 4.69858232]\n",
      "pred [4.80978589 4.05748773 4.44851136 4.54436488 4.61422266 4.45458808]\n",
      "pred [3.94409329 5.03746479 4.38715169 4.60459715 3.89512348 5.26304198]\n",
      "pred [4.96235023 3.97936158 4.42521782 4.58126081 4.41278988 4.54816132]\n",
      "pred [4.3901452  4.59232392 4.34594265 4.73837322 3.64498368 5.62186168]\n",
      "pred [3.60386889 5.4216632  3.96230665 4.98098682 4.22539981 4.85032491]\n",
      "pred [3.85316432 5.07055198 4.26976219 4.79823058 3.74910485 5.23434768]\n",
      "pred [4.12558636 4.84416737 4.51645252 4.50060814 4.44441692 4.62722307]\n",
      "pred [4.23624917 4.96648615 3.9126271  5.04006079 4.1375709  4.93643826]\n",
      "pred [3.76909329 5.27617157 4.35238455 4.62203506 4.14443484 4.76396539]\n",
      "pred [4.12427515 4.79640741 4.45641877 4.55031408 4.5390906  4.51627267]\n",
      "pred [4.56318843 4.62921331 4.13141683 4.87541009 4.08221755 4.83244079]\n",
      "pred [3.48363909 5.46025644 4.40130201 4.60406284 4.44116092 4.60614972]\n",
      "(296, 119) (296, 6)\n",
      "******* Feature select: all  Feature type: ST-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.9384768180148165\n",
      "R2 Best score (validation) val. score :  0.6134899473382148\n",
      "R2 of the best estimator (testing dataset):  0.3927804664294854\n",
      "pred [5.038231   3.961769   4.50896539 4.49103461 4.30877979 4.70999766]\n",
      "pred [5.15673796 3.84326204 4.63774114 4.36225886 4.26910965 4.73089035]\n",
      "pred [3.49671225 5.50328775 4.21121018 4.76811115 3.11460224 5.90417521]\n",
      "pred [3.56490689 5.43509311 4.63649871 4.36350129 5.18149874 3.81850126]\n",
      "pred [4.08254431 4.91745569 3.75914849 5.24085151 2.7900746  6.2099254 ]\n",
      "pred [5.05010571 3.94989429 4.551298   4.41491615 5.9124387  3.12540473]\n",
      "pred [4.69392087 4.30607913 4.16641714 4.83358286 4.27025343 4.75601108]\n",
      "pred [4.13446553 4.86553447 3.76770125 5.17940969 4.31706921 4.68293079]\n",
      "pred [4.83381363 4.29352869 4.45759577 4.49847301 4.45690495 4.54309505]\n",
      "pred [5.0067605  3.9932395  4.48824947 4.51175053 4.39483814 4.62393931]\n",
      "pred [5.10670326 3.89329674 4.56096049 4.43903951 3.96667455 5.0521029 ]\n",
      "pred [4.2092496  4.7907504  4.42151981 4.57848019 4.31517551 4.68482449]\n",
      "pred [3.41452933 5.58547067 4.6304006  4.3695994  5.21114602 3.78885398]\n",
      "pred [3.31471047 5.68528953 4.20793457 4.79206543 4.29366244 4.70633756]\n",
      "pred [3.93429419 5.11450454 4.35304937 4.64695063 4.09681325 4.90318675]\n",
      "pred [4.73767366 4.32449041 4.36435594 4.63564406 3.81381244 5.18618756]\n",
      "pred [3.49767447 5.50232553 4.34850208 4.65149792 4.33255826 4.66744174]\n",
      "pred [4.48987362 4.51012638 4.4674845  4.5325155  4.54601209 4.45398791]\n",
      "pred [3.34688433 5.65311567 4.21394762 4.78605238 4.29366244 4.70633756]\n",
      "pred [5.14955021 3.85044979 4.58353224 4.41646776 3.3535949  5.6464051 ]\n",
      "pred [3.92282511 5.07717489 3.86688286 5.13311714 3.71884733 5.28115267]\n",
      "pred [4.20866737 4.79133263 4.01270668 4.98729332 4.32486363 4.67513637]\n",
      "pred [4.32624544 4.67375456 4.48303909 4.51696091 4.39210664 4.60789336]\n",
      "pred [5.3430582  3.6569418  4.55930105 4.44069895 6.36884491 2.73996371]\n",
      "pred [3.21281808 5.78718192 4.45742305 4.54257695 4.17759441 4.82240559]\n",
      "pred [4.2478471  4.7521529  3.94405448 5.05594552 4.511839   4.488161  ]\n",
      "pred [3.53235964 5.46764036 4.40407133 4.59592867 3.88264408 5.11735592]\n",
      "pred [5.10392604 3.89607396 4.56096049 4.43903951 3.96667455 5.0521029 ]\n",
      "pred [3.39627929 5.60372071 4.05092188 4.94907812 3.95209342 5.04790658]\n",
      "pred [4.25638584 4.74361416 3.63979767 5.36020233 3.04645382 5.986689  ]\n",
      "pred [4.37335777 4.62664223 2.9557491  6.0442509  3.63260309 5.30171186]\n",
      "pred [3.61970593 5.38029407 4.41611934 4.58388066 4.14783451 4.82296186]\n",
      "pred [4.05132266 4.94867734 3.16170866 5.83829134 3.68218357 5.31781643]\n",
      "pred [5.2713972  3.7286028  4.58560314 4.41439686 5.36521329 3.70577388]\n",
      "pred [4.50212456 4.49787544 4.45219885 4.54780115 3.76165281 5.23834719]\n",
      "pred [3.47372287 5.52627713 4.09235515 4.90764485 4.02255046 4.97744954]\n",
      "pred [3.05016367 5.94983633 4.35399223 4.64600777 4.05845549 4.94154451]\n",
      "pred [4.16103676 4.83896324 4.44444606 4.55555394 4.45002402 4.52077234]\n",
      "pred [3.46321965 5.53678035 4.53358732 4.46641268 4.60005255 4.39994745]\n",
      "pred [3.62234913 5.37765087 4.56903507 4.43096493 4.09378156 4.93055829]\n",
      "pred [5.48942631 3.51057369 4.56539772 4.43460228 5.15181278 4.03261382]\n",
      "pred [3.35123193 5.64876807 4.26466971 4.73533029 3.70716568 5.29283432]\n",
      "pred [5.04909118 3.95090882 4.65621027 4.34378973 3.52998928 5.47001072]\n",
      "pred [3.90370142 5.07493078 4.43954129 4.56045871 4.01540683 4.98459317]\n",
      "pred [3.52787774 5.47212226 3.99927093 5.00072907 4.05746193 4.94810047]\n",
      "pred [3.92282511 5.07717489 3.85572176 5.14427824 3.6877939  5.3122061 ]\n",
      "pred [4.77917231 4.31343688 4.4293115  4.5706885  4.12968325 4.87031675]\n",
      "pred [5.1124174  3.8875826  4.64667512 4.35332488 4.19674202 4.80325798]\n",
      "pred [4.44628392 4.55371608 4.30854327 4.69145673 4.55483378 4.44516622]\n",
      "pred [4.17256934 4.88959473 4.44829298 4.55170702 4.33790396 4.68087349]\n",
      "pred [5.05745395 4.03515524 4.66042814 4.33957186 4.34728308 4.65271692]\n",
      "pred [3.25767183 5.74232817 4.33917261 4.66082739 4.17770214 4.84107531]\n",
      "pred [4.98410737 4.01589263 4.50896539 4.49103461 4.31705943 4.70171802]\n",
      "pred [3.5847439  5.4152561  3.91431338 5.08568662 3.43596981 5.56403019]\n",
      "pred [3.28059796 5.71940204 3.9232294  5.0767706  3.60549888 5.39450112]\n",
      "pred [4.12369669 4.87630331 3.81146719 5.18853281 3.59530739 5.42347005]\n",
      "pred [4.33371482 4.66628518 4.46541886 4.53458114 4.42774544 4.57225456]\n",
      "pred [3.12870145 5.87129855 4.1802038  4.8197962  4.00076178 4.99923822]\n",
      "pred [3.43654881 5.56345119 4.45085772 4.54914228 4.09845484 4.88276771]\n",
      "pred [3.94955265 5.05044735 4.10142658 4.89857342 4.03863111 4.96136889]\n",
      "pred [4.04714459 5.01501947 4.3269527  4.6730473  4.23896526 4.78729925]\n",
      "pred [3.5553247  5.4446753  4.45968108 4.54031892 3.39858862 5.60141138]\n",
      "(296, 124) (296, 6)\n",
      "******* Feature select: PCA999  Feature type: HG-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.926087961237335\n",
      "R2 Best score (validation) val. score :  0.565142743028565\n",
      "R2 of the best estimator (testing dataset):  0.2976121706899458\n",
      "pred [4.36962142 4.64989495 4.66148632 4.49769979 4.04098184 4.9815137 ]\n",
      "pred [5.0999167  3.9164701  4.50225839 4.66174724 4.33431135 4.75509822]\n",
      "pred [3.36298681 5.60885156 4.31027717 4.63099584 3.79619269 5.12200792]\n",
      "pred [3.64953608 5.28380268 4.32299359 4.59649152 5.0085976  4.04283736]\n",
      "pred [4.34207249 4.67002362 3.96431944 5.01465121 3.9733018  5.02332873]\n",
      "pred [5.15909666 3.86746161 4.61091476 4.41063035 4.91943885 4.09943537]\n",
      "pred [4.63138146 4.37611431 4.54064113 4.4479073  4.66507706 4.38288898]\n",
      "pred [3.93678409 5.09399275 4.30066014 4.72821628 4.10939896 5.01555216]\n",
      "pred [3.80086109 5.18317625 4.41818015 4.57877272 4.19466016 4.82095931]\n",
      "pred [4.33946549 4.67144605 4.46282668 4.59506102 4.06132394 5.0239285 ]\n",
      "pred [4.50184569 4.47010573 4.52532211 4.59919909 4.12270252 4.93316949]\n",
      "pred [3.95912281 4.98131578 4.49575261 4.42518368 4.36227269 4.58626752]\n",
      "pred [3.44698037 5.51330797 4.44550531 4.66492986 4.47377171 4.5414747 ]\n",
      "pred [3.73646613 5.19200391 4.34815251 4.75504151 4.07201467 4.97766316]\n",
      "pred [4.13371253 4.89686727 4.50836506 4.411533   4.16132642 4.82766171]\n",
      "pred [3.90316266 5.08004162 4.39109293 4.64915386 4.09518954 4.88983508]\n",
      "pred [4.1248173  4.87203738 4.48360383 4.50252267 3.95179128 5.03964201]\n",
      "pred [4.34724046 4.63800103 4.4962122  4.57915021 4.32838818 4.64592879]\n",
      "pred [3.56780755 5.38308191 4.2872158  4.75347111 4.02205609 4.96630134]\n",
      "pred [4.81059187 4.16781254 4.28774893 4.53737231 4.16636066 4.86989998]\n",
      "pred [4.11053155 4.87504756 4.33170738 4.69292997 3.85968755 5.16247578]\n",
      "pred [4.09691999 4.82676974 4.51060625 4.59223471 4.14485505 4.9111301 ]\n",
      "pred [4.11429176 4.81691798 4.49795164 4.62007367 4.45568655 4.56490502]\n",
      "pred [4.37889975 4.65117986 4.2455345  4.54312398 5.42120758 3.53838346]\n",
      "pred [3.31223999 5.69696393 4.51803829 4.65420064 4.10116411 4.92921966]\n",
      "pred [3.89911377 5.03895146 4.48378605 4.52935757 4.43459269 4.49733395]\n",
      "pred [4.80950977 4.15961932 4.46641566 4.57339941 4.40795832 4.6222187 ]\n",
      "pred [4.51680942 4.45341084 4.47770197 4.62619919 4.17765535 4.80493238]\n",
      "pred [3.42393876 5.59242545 4.55457874 4.57694432 4.28027274 4.74915893]\n",
      "pred [4.49123314 4.50219551 4.08028727 4.91949143 3.46845442 5.63367649]\n",
      "pred [4.71120149 4.35648267 3.91143324 4.99359454 3.74192706 5.22921984]\n",
      "pred [4.01828801 4.95002292 4.36926022 4.59593259 4.16839908 4.757868  ]\n",
      "pred [3.68002333 5.33670157 4.16082937 4.96343731 3.93726842 5.07784763]\n",
      "pred [5.03213312 3.96324066 4.50271528 4.48081014 4.95825012 4.0471817 ]\n",
      "pred [3.81516118 5.18276789 4.28684139 4.60717306 4.42217885 4.58090951]\n",
      "pred [3.53280688 5.39622484 4.38043647 4.72421206 3.80060824 5.19049813]\n",
      "pred [3.11249789 5.79386875 4.29361936 4.85320003 4.23818998 4.76394987]\n",
      "pred [3.64409145 5.36656268 4.54151435 4.59936408 4.28677753 4.74429503]\n",
      "pred [4.45257825 4.5903877  4.5469719  4.47955917 4.13767256 4.95192409]\n",
      "pred [3.66422024 5.24582063 4.46540885 4.47294077 3.9166704  5.10331177]\n",
      "pred [4.91754733 4.09410965 4.49499081 4.3218101  5.10544588 3.96433803]\n",
      "pred [3.21248538 5.74834551 4.43763944 4.61577538 3.85232381 5.19335199]\n",
      "pred [4.52567066 4.51829644 4.54094629 4.46564462 3.90067624 5.05249101]\n",
      "pred [4.16909825 4.78761819 4.39839603 4.59537547 4.73791454 4.29498923]\n",
      "pred [3.99626766 4.93397384 4.47165279 4.62718628 4.10857662 5.01134778]\n",
      "pred [4.10812268 4.86854625 4.37209757 4.67695465 3.86215628 5.1591809 ]\n",
      "pred [4.55838426 4.37709666 4.59920088 4.46695822 4.20698224 4.78761902]\n",
      "pred [5.06969282 3.88273691 4.48225769 4.68718173 4.59762626 4.50978538]\n",
      "pred [3.36078028 5.51173553 4.38100237 4.67413412 4.19315322 4.79717436]\n",
      "pred [4.19511495 4.77745083 4.46875753 4.51774802 4.25139651 4.79112072]\n",
      "pred [4.41675239 4.58295699 4.49062479 4.58432745 4.4899874  4.50123943]\n",
      "pred [3.14362087 5.8673158  4.40356709 4.68748519 4.06326709 5.02796495]\n",
      "pred [4.31041178 4.64675565 4.43550554 4.68182457 4.15363814 4.87169481]\n",
      "pred [3.89575387 5.02781879 4.45044318 4.50730928 4.17680346 4.84212192]\n",
      "pred [3.73570993 5.14007498 4.3264501  4.82956928 4.09875864 4.93352017]\n",
      "pred [4.26365094 4.74236971 4.49724353 4.57488168 4.00500422 4.90570694]\n",
      "pred [4.68871623 4.3492916  4.48976327 4.62827183 4.23554573 4.76893072]\n",
      "pred [3.47102854 5.48396913 4.35923938 4.7234608  4.02163851 5.00267141]\n",
      "pred [3.29616886 5.63948887 4.30627354 4.85105889 4.11606264 4.93757657]\n",
      "pred [3.89003768 5.13173396 4.23570071 4.77257524 4.2046431  4.87195373]\n",
      "pred [3.90399772 5.06357572 4.48152106 4.64650042 4.39365016 4.61002224]\n",
      "pred [3.20269686 5.80196861 4.41817593 4.63864332 3.86225045 5.18681815]\n",
      "(296, 81) (296, 6)\n",
      "******* Feature select: PCA999  Feature type: OG-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.9834999324990359\n",
      "R2 Best score (validation) val. score :  0.522133385964515\n",
      "R2 of the best estimator (testing dataset):  0.2717016274141952\n",
      "pred [4.44942322 4.55057678 4.4942813  4.5057187  4.79025955 4.20974045]\n",
      "pred [4.94636794 4.05363206 4.34917788 4.65082212 4.04325044 4.95674956]\n",
      "pred [4.00713291 4.99286709 4.34634933 4.65365067 4.03084764 4.96915236]\n",
      "pred [4.50205471 4.49794529 4.5031921  4.4968079  5.16331928 3.83668072]\n",
      "pred [4.09426449 4.90573551 3.73249582 5.26750418 3.68366018 5.31633982]\n",
      "pred [4.76617588 4.23382412 4.40022746 4.59977254 5.21597509 3.78402491]\n",
      "pred [5.15798477 3.84201523 4.52751364 4.47248636 4.38193626 4.61806374]\n",
      "pred [4.24891185 4.75108815 4.4938323  4.5061677  4.33996666 4.66003334]\n",
      "pred [4.85010128 4.14989872 4.63356881 4.36643119 4.38003013 4.61996987]\n",
      "pred [4.4399743  4.5600257  4.59239492 4.40760508 4.57266611 4.42733389]\n",
      "pred [4.44372275 4.55627725 4.60026537 4.39973463 4.48321514 4.51678486]\n",
      "pred [4.26487138 4.73512862 4.32135171 4.67864829 4.24153087 4.75846913]\n",
      "pred [3.91704302 5.08295698 4.52628876 4.47371124 4.99308648 4.00691352]\n",
      "pred [3.72001569 5.27998431 3.87191978 5.12808022 4.28003026 4.71996974]\n",
      "pred [4.22611485 4.77388515 4.64969336 4.35030664 4.27563337 4.72436663]\n",
      "pred [3.9849369 5.0150631 4.3998179 4.6001821 4.0573356 4.9426644]\n",
      "pred [4.57658495 4.42341505 4.36837628 4.63162372 3.98075871 5.01924129]\n",
      "pred [4.39146488 4.60853512 4.49510587 4.50489413 4.41314074 4.58685926]\n",
      "pred [3.62414886 5.37585114 4.0218901  4.9781099  4.1232681  4.8767319 ]\n",
      "pred [4.5988976  4.4011024  4.49883045 4.50116955 3.41348374 5.58651626]\n",
      "pred [3.65297033 5.34702967 4.83875542 4.16124458 4.1147255  4.8852745 ]\n",
      "pred [3.95065449 5.04934551 4.61360048 4.38639952 4.40528146 4.59471854]\n",
      "pred [3.90710467 5.09289533 4.44504418 4.55495582 4.57780915 4.42219085]\n",
      "pred [4.87345851 4.12654149 4.66233825 4.33766175 4.95431226 4.04568774]\n",
      "pred [3.47058792 5.52941208 4.33808319 4.66191681 4.32300412 4.67699588]\n",
      "pred [4.25678468 4.74321532 4.39237794 4.60762206 4.47008744 4.52991256]\n",
      "pred [3.86288739 5.13711261 4.46605779 4.53394221 4.14737867 4.85262133]\n",
      "pred [4.54475029 4.45524971 4.67632715 4.32367285 4.47664967 4.52335033]\n",
      "pred [3.57235373 5.42764627 3.95228682 5.04771318 4.14751389 4.85248611]\n",
      "pred [4.27933243 4.72066757 3.70469044 5.29530956 4.08004097 4.91995903]\n",
      "pred [3.79906452 5.20093548 4.05358183 4.94641817 4.09354349 4.90645651]\n",
      "pred [4.16275227 4.83724773 4.506471   4.493529   4.68292738 4.31707262]\n",
      "pred [3.49673068 5.50326932 4.42592428 4.57407572 3.34244547 5.65755453]\n",
      "pred [4.77881112 4.22118888 4.35510705 4.64489295 5.1883764  3.8116236 ]\n",
      "pred [4.09784714 4.90215286 4.45719946 4.54280054 3.96612712 5.03387288]\n",
      "pred [3.60394754 5.39605246 4.01362673 4.98637327 4.08567279 4.91432721]\n",
      "pred [3.20952752 5.79047248 4.33948186 4.66051814 4.22628407 4.77371593]\n",
      "pred [4.16012559 4.83987441 4.43830627 4.56169373 4.51162183 4.48837817]\n",
      "pred [3.86655565 5.13344435 4.34943797 4.65056203 4.2164656  4.7835344 ]\n",
      "pred [3.59320015 5.40679985 4.4215207  4.5784793  4.15824679 4.84175321]\n",
      "pred [4.81785525 4.18214475 4.51333634 4.48666366 5.3537004  3.6462996 ]\n",
      "pred [3.4122828  5.5877172  4.61488913 4.38511087 4.183728   4.816272  ]\n",
      "pred [4.73463258 4.26536742 4.59921043 4.40078957 4.23409897 4.76590103]\n",
      "pred [3.63254308 5.36745692 4.50501063 4.49498937 3.93926875 5.06073125]\n",
      "pred [3.77325516 5.22674484 4.23804014 4.76195986 3.95113671 5.04886329]\n",
      "pred [3.6659876  5.3340124  4.84376247 4.15623753 4.09383802 4.90616198]\n",
      "pred [4.63460801 4.36539199 4.56723432 4.43276568 4.5492404  4.4507596 ]\n",
      "pred [4.72768026 4.27231974 4.5050301  4.4949699  4.50540802 4.49459198]\n",
      "pred [4.64800286 4.35199714 4.18545102 4.81454898 4.74638854 4.25361146]\n",
      "pred [4.14598488 4.85401512 4.57727664 4.42272336 4.57104263 4.42895737]\n",
      "pred [4.88278107 4.11721893 4.46469917 4.53530083 4.48862642 4.51137358]\n",
      "pred [3.01372244 5.98627756 4.30622512 4.69377488 4.04172939 4.95827061]\n",
      "pred [4.618015   4.381985   4.31063961 4.68936039 4.6143894  4.3856106 ]\n",
      "pred [3.57378065 5.42621935 4.53987304 4.46012696 3.98605593 5.01394407]\n",
      "pred [3.52852102 5.47147898 3.96494835 5.03505165 4.36324224 4.63675776]\n",
      "pred [4.39944844 4.60055156 4.54401689 4.45598311 4.28375246 4.71624754]\n",
      "pred [4.21467926 4.78532074 4.46863019 4.53136981 4.39182003 4.60817997]\n",
      "pred [4.12033254 4.87966746 3.95616501 5.04383499 4.1303052  4.8696948 ]\n",
      "pred [3.14770546 5.85229454 4.3983725  4.6016275  4.35163571 4.64836429]\n",
      "pred [4.14606632 4.85393368 4.76396525 4.23603475 4.59214019 4.40785981]\n",
      "pred [4.19066205 4.80933795 4.59418688 4.40581312 4.22705959 4.77294041]\n",
      "pred [3.12642631 5.87357369 4.87523139 4.12476861 4.02780584 4.97219416]\n",
      "(296, 60) (296, 6)\n",
      "******* Feature select: PCA999  Feature type: ST-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.9636897779338166\n",
      "R2 Best score (validation) val. score :  0.5045730376603395\n",
      "R2 of the best estimator (testing dataset):  0.3052597235793905\n",
      "pred [4.80128837 4.19871163 4.48140756 4.51859244 4.05631803 4.94368197]\n",
      "pred [5.38916804 3.61083196 4.40212666 4.59787334 4.29125009 4.70874991]\n",
      "pred [3.83688558 5.16311442 4.14138096 4.85861904 3.46689136 5.53310864]\n",
      "pred [3.91225225 5.08774775 4.58461786 4.41538214 4.5510403  4.4489597 ]\n",
      "pred [4.00753021 4.99246979 4.08562485 4.91437515 3.80035253 5.19964747]\n",
      "pred [5.09883684 3.90116316 4.4804782  4.5195218  4.90336079 4.09663921]\n",
      "pred [4.40668155 4.59331845 4.44794057 4.55205943 4.15260051 4.84739949]\n",
      "pred [3.88654241 5.11345759 4.00503294 4.99496706 4.51295306 4.48704694]\n",
      "pred [4.61371697 4.38628303 4.83402041 4.16597959 3.86734386 5.13265614]\n",
      "pred [4.66287855 4.33712145 4.4901797  4.5098203  4.13274142 4.86725858]\n",
      "pred [4.70393382 4.29606618 4.41435902 4.58564098 4.04062513 4.95937487]\n",
      "pred [4.12057536 4.87942464 4.30587145 4.69412855 4.07614524 4.92385476]\n",
      "pred [3.91615831 5.08384169 4.46191303 4.53808697 4.1332731  4.8667269 ]\n",
      "pred [3.80018786 5.19981214 4.15424106 4.84575894 3.68420069 5.31579931]\n",
      "pred [5.09114417 3.90885583 4.69856591 4.30143409 4.11402141 4.88597859]\n",
      "pred [4.59257868 4.40742132 4.54377592 4.45622408 3.76846797 5.23153203]\n",
      "pred [3.07145903 5.92854097 4.35963354 4.64036646 4.27260785 4.72739215]\n",
      "pred [4.74336675 4.25663325 4.60622751 4.39377249 4.47344572 4.52655428]\n",
      "pred [3.87758613 5.12241387 4.40791774 4.59208226 3.69018667 5.30981333]\n",
      "pred [5.11094808 3.88905192 4.49120731 4.50879269 3.97013    5.02987   ]\n",
      "pred [4.08098869 4.91901131 4.36506999 4.63493001 4.12949823 4.87050177]\n",
      "pred [4.26206017 4.73793983 4.30577897 4.69422103 4.07351076 4.92648924]\n",
      "pred [4.68410196 4.31589804 4.50711425 4.49288575 4.50724978 4.49275022]\n",
      "pred [3.74658655 5.25341345 4.10794192 4.89205808 4.91044006 4.08955994]\n",
      "pred [4.59120985 4.40879015 4.26104068 4.73895932 3.93260421 5.06739579]\n",
      "pred [3.68613305 5.31386695 4.34358713 4.65641287 3.99183577 5.00816423]\n",
      "pred [4.10403279 4.89596721 4.49178546 4.50821454 4.78404105 4.21595895]\n",
      "pred [4.598653   4.401347   4.48592308 4.51407692 4.05765083 4.94234917]\n",
      "pred [2.99416509 6.00583491 4.23487518 4.76512482 4.26428718 4.73571282]\n",
      "pred [3.93026299 5.06973701 3.56395668 5.43604332 3.53479858 5.46520142]\n",
      "pred [3.2388849  5.7611151  3.23618615 5.76381385 3.52908007 5.47091993]\n",
      "pred [3.71839233 5.28160767 4.24247311 4.75752689 3.68091631 5.31908369]\n",
      "pred [4.17659402 4.82340598 3.64092736 5.35907264 3.96318707 5.03681293]\n",
      "pred [5.05317233 3.94682767 4.63432046 4.36567954 4.68260557 4.31739443]\n",
      "pred [3.65545796 5.34454204 4.56837539 4.43162461 4.15185555 4.84814445]\n",
      "pred [3.89227447 5.10772553 4.45272862 4.54727138 3.46336955 5.53663045]\n",
      "pred [2.5609153  6.4390847  4.61619221 4.38380779 4.31837894 4.68162106]\n",
      "pred [4.15004807 4.84995193 4.37155857 4.62844143 4.02037742 4.97962258]\n",
      "pred [4.13187615 4.86812385 4.49140165 4.50859835 4.57240144 4.42759856]\n",
      "pred [4.1544427  4.8455573  4.3373863  4.6626137  4.13735118 4.86264882]\n",
      "pred [4.0293266  4.9706734  4.52623459 4.47376541 4.99547607 4.00452393]\n",
      "pred [4.13777758 4.86222242 4.29895642 4.70104358 3.92489029 5.07510971]\n",
      "pred [4.53334065 4.46665935 4.58939771 4.41060229 3.26383649 5.73616351]\n",
      "pred [4.09138401 4.90861599 4.67518331 4.32481669 3.90899342 5.09100658]\n",
      "pred [3.90552779 5.09447221 4.15800677 4.84199323 3.94627116 5.05372884]\n",
      "pred [4.41131335 4.58868665 4.32587731 4.67412269 4.22015059 4.77984941]\n",
      "pred [4.72537807 4.27462193 4.53641337 4.46358663 4.82181732 4.17818268]\n",
      "pred [5.37139511 3.62860489 4.47211328 4.52788672 4.38142561 4.61857439]\n",
      "pred [4.57327838 4.42672162 4.69609221 4.30390779 4.33912417 4.66087583]\n",
      "pred [4.11777005 4.88222995 4.40557155 4.59442845 4.07284183 4.92715817]\n",
      "pred [4.89495781 4.10504219 4.56323365 4.43676635 4.5715779  4.4284221 ]\n",
      "pred [3.29707159 5.70292841 4.40062007 4.59937993 4.08407717 4.91592283]\n",
      "pred [4.61317753 4.38682247 4.45533888 4.54466112 3.93768381 5.06231619]\n",
      "pred [4.00930254 4.99069746 4.27340645 4.72659355 3.65912391 5.34087609]\n",
      "pred [3.45181168 5.54818832 4.3015786  4.6984214  4.08613468 4.91386532]\n",
      "pred [4.04483372 4.95516628 4.2514752  4.7485248  3.86266926 5.13733074]\n",
      "pred [4.30462798 4.69537202 4.58819372 4.41180628 4.80155072 4.19844928]\n",
      "pred [3.82639935 5.17360065 4.35102843 4.64897157 3.74040842 5.25959158]\n",
      "pred [3.180254   5.819746   4.58481114 4.41518886 3.9365313  5.0634687 ]\n",
      "pred [3.8505816  5.1494184  4.3679956  4.6320044  4.09031087 4.90968913]\n",
      "pred [4.28071352 4.71928648 4.67758544 4.32241456 4.66954671 4.33045329]\n",
      "pred [3.83994707 5.16005293 4.41270974 4.58729026 3.95935737 5.04064263]\n",
      "(296, 10) (296, 6)\n",
      "******* Feature select: LR10  Feature type: HG-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.8670471161099499\n",
      "R2 Best score (validation) val. score :  0.5216105963319855\n",
      "R2 of the best estimator (testing dataset):  0.3782275102672415\n",
      "pred [4.10521552 4.89478448 4.45183761 4.54816239 4.21269559 4.78730441]\n",
      "pred [5.06245786 3.88457888 4.47558857 4.52441143 4.1523334  4.8476666 ]\n",
      "pred [4.13207177 4.86792823 2.43311499 6.56688501 3.48866672 5.51133328]\n",
      "pred [3.75801299 5.24198701 4.55152414 4.44847586 5.93235188 3.06764812]\n",
      "pred [4.52945747 4.47054253 3.61511627 5.42161932 3.27286199 5.72713801]\n",
      "pred [5.06245786 3.88457888 4.48764738 4.51235262 5.60588739 3.39411261]\n",
      "pred [4.2534686  4.7465314  4.16596854 4.83403146 4.38273575 4.61726425]\n",
      "pred [4.18527869 4.81472131 4.5028124  4.4971876  4.38291296 4.61708704]\n",
      "pred [4.32469487 4.67530513 4.4864015  4.5135985  4.4221513  4.5778487 ]\n",
      "pred [4.48900081 4.51099919 4.5286123  4.4713877  4.23557185 4.76442815]\n",
      "pred [4.60756436 4.39243564 4.31559886 4.68440114 4.08412777 4.91587223]\n",
      "pred [4.31575308 4.68424692 4.37874305 4.62125695 4.24546879 4.75453121]\n",
      "pred [3.61401356 5.38598644 4.49252591 4.50747409 5.86684872 3.13315128]\n",
      "pred [3.02046376 5.97953624 4.04163142 4.95836858 3.66814368 5.33185632]\n",
      "pred [4.54559365 4.45440635 4.41147222 4.58852778 4.45826214 4.54173786]\n",
      "pred [4.5710678  4.4289322  4.34678038 4.65321962 4.26757149 4.73242851]\n",
      "pred [3.33957718 5.66042282 4.34303764 4.65696236 4.12216231 4.87783769]\n",
      "pred [4.65867555 4.34132445 4.32308796 4.67691204 4.63220247 4.36779753]\n",
      "pred [2.83512568 6.16487432 4.01011852 4.98988148 3.2516843  5.7483157 ]\n",
      "pred [4.97764608 4.05339948 4.53970774 4.46029226 4.18881295 4.81118705]\n",
      "pred [4.05617608 4.94382392 4.21319225 4.78680775 4.11438202 4.88561798]\n",
      "pred [4.25087985 4.74912015 4.46999211 4.53000789 4.1311811  4.8688189 ]\n",
      "pred [3.18787369 5.81212631 4.39553002 4.60446998 4.36266814 4.63733186]\n",
      "pred [4.26170083 4.73829917 4.50279462 4.49720538 6.28825608 2.71174392]\n",
      "pred [3.87289768 5.12710232 4.41386612 4.58613388 4.19509566 4.80490434]\n",
      "pred [4.05327132 4.94672868 4.33320757 4.66679243 4.40294775 4.59705225]\n",
      "pred [4.50576375 4.49423625 4.47586915 4.52413085 3.96571558 5.03428442]\n",
      "pred [4.24567202 4.75432798 4.43064785 4.56935215 4.02023225 4.97976775]\n",
      "pred [3.15898305 5.84101695 4.39691253 4.60308747 3.85398026 5.14601974]\n",
      "pred [4.03785381 4.96214619 3.78643449 5.21356551 3.2848003  5.7151997 ]\n",
      "pred [2.88016426 6.11983574 4.07411656 4.92588344 3.65360793 5.34639207]\n",
      "pred [3.59176189 5.40823811 4.5078941  4.4921059  4.31376125 4.68623875]\n",
      "pred [4.58627574 4.41372426 4.18712343 4.81287657 3.09640424 5.90359576]\n",
      "pred [5.34550669 3.65449331 4.53761139 4.46238861 5.89808635 3.10191365]\n",
      "pred [4.00828651 4.99171349 4.5844759  4.4155241  3.88452983 5.11547017]\n",
      "pred [2.83512568 6.16487432 3.99068277 5.00931723 3.3157521  5.6842479 ]\n",
      "pred [3.08145771 5.91854229 4.3973345  4.6026655  3.79366733 5.20633267]\n",
      "pred [3.44302177 5.55697823 4.52087924 4.47912076 4.01561894 4.98438106]\n",
      "pred [4.24119627 4.75880373 4.48666673 4.51333327 3.82487056 5.17512944]\n",
      "pred [4.04243103 4.95756897 3.35474296 5.64525704 3.33796524 5.66203476]\n",
      "pred [4.98056815 4.01943185 4.52704327 4.47295673 5.18996124 3.81003876]\n",
      "pred [4.46399204 4.53600796 3.95069206 5.04930794 3.5266423  5.4733577 ]\n",
      "pred [4.58339324 4.41660676 4.52600073 4.47399927 4.67991099 4.32008901]\n",
      "pred [4.62651822 4.37348178 4.59427636 4.40572364 4.36448861 4.63551139]\n",
      "pred [4.38325674 4.61674326 4.33220276 4.66779724 3.88261604 5.11738396]\n",
      "pred [4.10877634 4.89122366 4.21601433 4.78398567 4.11438202 4.88561798]\n",
      "pred [4.39410033 4.60589967 4.52082625 4.47917375 4.4221513  4.5778487 ]\n",
      "pred [5.06245786 3.88457888 4.46419588 4.53580412 4.78475808 4.21524192]\n",
      "pred [3.99229655 5.00770345 4.05340264 4.94659736 4.26326369 4.73673631]\n",
      "pred [4.67727543 4.32272457 4.52108266 4.47891734 4.4221513  4.5778487 ]\n",
      "pred [4.36441501 4.63558499 4.49578426 4.50421574 4.46431765 4.53568235]\n",
      "pred [2.64273336 6.35726664 4.24116313 4.75883687 3.87992806 5.12007194]\n",
      "pred [4.7746542  4.2253458  4.5286123  4.4713877  4.48259929 4.51740071]\n",
      "pred [4.06990021 4.93009979 3.9450027  5.0549973  3.15620029 5.84379971]\n",
      "pred [3.09551535 5.90448465 3.75333054 5.24666946 3.75233255 5.24766745]\n",
      "pred [4.26971185 4.73028815 4.08105858 4.91894142 4.28535194 4.71464806]\n",
      "pred [4.08568242 4.91431758 4.50321711 4.49678289 3.95350859 5.04649141]\n",
      "pred [3.02972598 5.97027402 3.64653124 5.35346876 3.85102323 5.14897677]\n",
      "pred [3.10654722 5.89345278 4.34292734 4.65707266 3.83649    5.16351   ]\n",
      "pred [4.21305307 4.78694693 3.95583112 5.04416888 4.09385973 4.90614027]\n",
      "pred [4.61859772 4.38140228 4.61093645 4.38906355 4.39382334 4.60617666]\n",
      "pred [3.75914283 5.24085717 4.55921038 4.44078962 4.0463878  4.9536122 ]\n",
      "(296, 10) (296, 6)\n",
      "******* Feature select: LR10  Feature type: OG-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.8810535473629965\n",
      "R2 Best score (validation) val. score :  0.590550323091552\n",
      "R2 of the best estimator (testing dataset):  -0.17338283360677983\n",
      "pred [5.40032248 3.65739002 4.35552476 4.64447524 4.40349857 4.59650143]\n",
      "pred [4.34249659 4.65750341 4.40634897 4.59365103 4.74468498 4.25531502]\n",
      "pred [4.86949645 4.13050355 2.65871341 6.34128659 3.45178194 5.54821806]\n",
      "pred [3.66071136 5.33928864 4.44301969 4.55698031 5.50969477 3.443422  ]\n",
      "pred [4.5959484  4.4040516  3.09034526 5.90965474 2.99435512 6.00564488]\n",
      "pred [4.24157942 4.75842058 4.45719373 4.54280627 6.12285143 3.19539272]\n",
      "pred [4.6058291  4.3941709  4.24911385 4.75088615 4.39532429 4.60467571]\n",
      "pred [3.50163138 5.49836862 4.56165792 4.43834208 3.83249496 5.16750504]\n",
      "pred [4.32989069 4.67010931 4.4600033  4.5399967  4.43463573 4.56536427]\n",
      "pred [5.38324775 3.61675225 4.13895053 4.86104947 4.23994696 4.76005304]\n",
      "pred [5.50214288 3.49785712 3.95278268 5.11712626 4.05357092 4.94642908]\n",
      "pred [4.80986761 4.19013239 4.35861636 4.64138364 4.65202152 4.34797848]\n",
      "pred [3.39974296 5.60025704 4.47355574 4.52644426 5.49500576 3.45811101]\n",
      "pred [5.33441361 3.66558639 3.73948    5.26052    3.79951504 5.20048496]\n",
      "pred [5.19837323 3.80162677 3.70876477 5.29123523 4.07107356 4.92892644]\n",
      "pred [4.6488393  4.3511607  4.04840424 4.95159576 3.97296922 5.02703078]\n",
      "pred [3.99613779 5.00386221 4.49291691 4.50708309 4.4713408  4.5286592 ]\n",
      "pred [5.13028008 3.86971992 4.39055454 4.60944546 4.76581096 4.23418904]\n",
      "pred [5.33441361 3.66558639 3.74254048 5.25745952 3.76814689 5.23185311]\n",
      "pred [5.34269483 3.53700097 4.31939519 4.68060481 3.4175254  5.54185344]\n",
      "pred [4.37708037 4.62291963 3.91666871 5.08333129 4.27375503 4.72624497]\n",
      "pred [4.58972487 4.41027513 4.41631881 4.58368119 3.56459901 5.43540099]\n",
      "pred [5.05540351 3.94459649 4.30092638 4.69907362 4.70018633 4.29981367]\n",
      "pred [4.12285856 4.87714144 4.4182088  4.5817912  6.82447643 2.20491736]\n",
      "pred [4.76042462 4.23957538 4.19515816 4.80484184 4.60214791 4.39785209]\n",
      "pred [3.144036   5.855964   4.59582896 4.40417104 4.00524922 4.99475078]\n",
      "pred [4.40828143 4.52100649 4.32121134 4.67878866 4.44227062 4.55772938]\n",
      "pred [5.50214288 3.49785712 3.95278268 5.11712626 4.05357092 4.94642908]\n",
      "pred [4.09187759 4.90812241 3.99400223 5.00599777 4.37098199 4.62901801]\n",
      "pred [4.47019711 4.52980289 3.32985869 5.67014131 3.40376501 5.59623499]\n",
      "pred [4.07178207 4.92821793 2.79297189 6.20702811 2.99351107 6.00648893]\n",
      "pred [3.90758362 5.09241638 4.4607392  4.5392608  4.11356375 4.88643625]\n",
      "pred [4.34130297 4.65869703 3.20157596 5.79842404 3.04389204 5.95610796]\n",
      "pred [5.49263051 3.50736949 4.57880854 4.42119146 6.10863012 3.20961403]\n",
      "pred [4.87138099 4.12861901 4.15387689 4.84612311 3.51714458 5.48285542]\n",
      "pred [5.39581524 3.60418476 3.74254048 5.25745952 3.27776768 5.72223232]\n",
      "pred [4.59111136 4.40888864 4.04562446 4.95437554 4.58653514 4.41346486]\n",
      "pred [4.36790943 4.63209057 4.43972834 4.56027166 4.04225859 4.95774141]\n",
      "pred [4.41815707 4.58226997 4.11487817 4.88512183 4.44227062 4.55772938]\n",
      "pred [4.77634617 4.22365383 3.35340159 5.64659841 3.35357781 5.64642219]\n",
      "pred [3.98778273 5.01221727 4.45946378 4.54053622 5.67520991 3.09990493]\n",
      "pred [4.42432454 4.57567546 2.82583841 6.17416159 3.57251072 5.42748928]\n",
      "pred [3.95168986 5.04831014 4.36538165 4.63461835 4.43143059 4.26740723]\n",
      "pred [4.74027858 4.25972142 4.0305416  4.9694584  3.76512839 5.23487161]\n",
      "pred [4.95829145 4.04170855 3.72809336 5.27190664 3.83582559 5.16417441]\n",
      "pred [4.37708037 4.62291963 3.91666871 5.08333129 4.27375503 4.72624497]\n",
      "pred [4.6058291  4.3941709  4.12495392 4.87504608 4.37375623 4.62624377]\n",
      "pred [4.34249659 4.65750341 4.42838084 4.57161916 4.74468498 4.25531502]\n",
      "pred [4.58285578 4.41714422 4.49837011 4.50162989 4.47445112 4.52554888]\n",
      "pred [4.53112589 4.46887411 4.11510688 4.88489312 4.053636   4.946364  ]\n",
      "pred [4.66225597 4.33774403 4.1216191  4.8783809  4.6160419  4.3839581 ]\n",
      "pred [4.34511254 4.65488746 4.4344769  4.5655231  4.3951459  4.6048541 ]\n",
      "pred [5.44274361 3.61496889 4.3539027  4.6460973  4.43587131 4.56412869]\n",
      "pred [4.95592389 4.04407611 3.65804215 5.34195785 3.34283606 5.65716394]\n",
      "pred [3.9581054  5.0418946  3.88664588 5.11335412 4.3409589  4.6590411 ]\n",
      "pred [4.74272987 4.25727013 2.55554738 6.44445262 3.45178194 5.54821806]\n",
      "pred [4.46116227 4.49887249 4.56621196 4.50369697 4.43020961 4.56979039]\n",
      "pred [5.33441361 3.66558639 3.74254048 5.25745952 3.90956902 5.09043098]\n",
      "pred [4.72570262 4.27429738 4.0433373  4.9566627  4.58534977 4.41465023]\n",
      "pred [4.13539599 4.92470155 4.44271721 4.55728279 4.50239303 4.49760697]\n",
      "pred [4.32865703 4.67134297 3.87744669 5.12255331 3.73811308 5.26188692]\n",
      "pred [4.09379545 4.90620455 3.28055733 5.71944267 2.80312333 6.19687667]\n",
      "(296, 10) (296, 6)\n",
      "******* Feature select: LR10  Feature type: ST-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.8719481002401753\n",
      "R2 Best score (validation) val. score :  0.5480904735591743\n",
      "R2 of the best estimator (testing dataset):  0.36442005909877023\n",
      "pred [4.57320325 4.42679675 4.40544173 4.59455827 4.40071595 4.59928405]\n",
      "pred [5.40509393 3.59490607 4.47811676 4.52188324 4.31727983 4.68272017]\n",
      "pred [4.27936947 4.72063053 3.02421393 5.97578607 3.32241314 5.67758686]\n",
      "pred [3.37114279 5.62885721 4.56851225 4.43148775 5.46628347 3.53371653]\n",
      "pred [4.51525225 4.48474775 2.9532492  6.0467508  3.153424   5.78500263]\n",
      "pred [5.25629185 3.74370815 4.5466579  4.4533421  5.23510676 3.76489324]\n",
      "pred [4.57078111 4.42921889 4.40268718 4.59731282 4.39046399 4.60953601]\n",
      "pred [3.8456128  5.1543872  4.10294456 4.89705544 4.63867046 4.36132954]\n",
      "pred [4.50681652 4.49318348 4.34841722 4.65158278 4.34864167 4.65135833]\n",
      "pred [5.04127958 3.95872042 4.30639793 4.69360207 4.40271336 4.59728664]\n",
      "pred [5.2649968  3.7350032  4.41971536 4.58028464 4.4797677  4.5202323 ]\n",
      "pred [3.97290078 5.02709922 4.42028078 4.57971922 4.30167284 4.69832716]\n",
      "pred [3.34716672 5.65283328 4.57807708 4.42192292 6.28862233 2.71137767]\n",
      "pred [3.33196513 5.66803487 3.50308367 5.42607744 3.77076913 5.16765749]\n",
      "pred [4.41113585 4.58886415 4.44811484 4.55188516 4.4682552  4.5317448 ]\n",
      "pred [4.24897964 4.75102036 3.96820509 5.03179491 3.92338999 5.07661001]\n",
      "pred [3.09602755 5.90397245 4.34621559 4.65378441 4.1914761  4.8085239 ]\n",
      "pred [4.14113547 4.85886453 4.50632551 4.49367449 4.63013732 4.36986268]\n",
      "pred [3.03649315 5.96350685 3.56920042 5.35996069 3.62988025 5.33034274]\n",
      "pred [4.97579202 4.02420798 3.86696032 5.13303968 3.24791317 5.75208683]\n",
      "pred [3.50696077 5.49303923 3.96200612 5.03799388 2.74809887 6.25190113]\n",
      "pred [3.26983611 5.73016389 4.19208167 4.80791833 3.53245996 5.46754004]\n",
      "pred [3.67942336 5.32057664 4.44392429 4.55607571 4.58627102 4.41372898]\n",
      "pred [4.79427898 4.20572102 4.54861663 4.45138337 5.28541879 3.71458121]\n",
      "pred [3.75204369 5.24795631 4.48993366 4.51006634 4.15252019 4.84747981]\n",
      "pred [3.84661913 5.15338087 4.2450592  4.7549408  4.52059034 4.47940966]\n",
      "pred [4.46368422 4.53631578 4.47561549 4.52438451 4.01576406 4.98423594]\n",
      "pred [4.91592742 4.08407258 4.41971536 4.58028464 4.50515307 4.49484693]\n",
      "pred [3.37007685 5.62992315 3.98777273 5.01222727 3.88634679 5.11365321]\n",
      "pred [4.26769014 4.73230986 3.42185239 5.57814761 2.95642653 5.9820001 ]\n",
      "pred [3.52973603 5.47026397 2.87151098 6.12848902 2.83534915 6.10307748]\n",
      "pred [2.99744029 6.00255971 4.25132458 4.74867542 4.3646278  4.6353722 ]\n",
      "pred [4.71691346 4.28308654 3.4446     5.5554     2.91742253 6.08257747]\n",
      "pred [5.35790537 3.64209463 4.48493186 4.51506814 3.7215967  5.2784033 ]\n",
      "pred [4.0413457  4.9586543  4.14201477 4.85798523 3.73662229 5.26337771]\n",
      "pred [3.85644758 5.14355242 3.50844393 5.42071719 3.91217907 5.02624756]\n",
      "pred [3.43997798 5.56002202 4.4241043  4.5758957  4.16319182 4.83680818]\n",
      "pred [4.3539618  4.6460382  4.19229569 4.80770431 4.61388523 4.38611477]\n",
      "pred [4.46672658 4.53327342 4.52231523 4.47768477 4.2438156  4.7561844 ]\n",
      "pred [3.37101456 5.62898544 4.35470251 4.64529749 3.51018696 5.48981304]\n",
      "pred [4.79747761 4.20252239 4.36292434 4.63707566 5.39802665 3.60197335]\n",
      "pred [4.35713597 4.64286403 4.37236209 4.62763791 3.62733633 5.37266367]\n",
      "pred [4.40308574 4.59691426 4.33789931 4.66210069 3.4521426  5.5478574 ]\n",
      "pred [3.5080026  5.4919974  4.44207571 4.55792429 3.81431354 5.18568646]\n",
      "pred [3.3593283  5.6406717  3.99691746 5.00308254 3.23776208 5.76223792]\n",
      "pred [3.50696077 5.49303923 3.6289708  5.3710292  2.88923961 6.11076039]\n",
      "pred [4.76557136 4.23442864 4.41168297 4.58831703 4.42449658 4.57550342]\n",
      "pred [5.26972153 3.73027847 4.48029489 4.51970511 4.40774105 4.59225895]\n",
      "pred [4.08974124 4.91025876 4.53542107 4.46457893 4.56418554 4.43581446]\n",
      "pred [4.3472884  4.6527116  4.49256387 4.50743613 3.90328625 5.09671375]\n",
      "pred [5.15135919 3.84864081 4.68648888 4.31351112 4.41044832 4.58955168]\n",
      "pred [2.75207012 6.24792988 4.3434161  4.6565839  3.90130923 5.09869077]\n",
      "pred [4.62034609 4.37965391 4.44109715 4.55890285 4.3193425  4.6806575 ]\n",
      "pred [3.47815074 5.52184926 3.69466181 5.30533819 3.09603037 5.90396963]\n",
      "pred [3.3674258  5.6325742  4.12803177 4.87196823 3.68832748 5.31167252]\n",
      "pred [4.35407755 4.64592245 3.48785552 5.51214448 3.54652386 5.45347614]\n",
      "pred [4.50498776 4.49501224 4.32528066 4.66853505 4.34549626 4.65450374]\n",
      "pred [2.9757967  6.0242033  3.49579831 5.50420169 4.05668853 4.94331147]\n",
      "pred [3.43394059 5.56605941 4.43126255 4.56873745 3.9214055  5.0785945 ]\n",
      "pred [3.87155942 5.12844058 3.74752208 5.25247792 3.14428475 5.85571525]\n",
      "pred [4.44599201 4.55400799 4.23748029 4.76251971 4.38748701 4.61251299]\n",
      "pred [3.96431055 5.03568945 4.14468899 4.85531101 3.18803703 5.81196297]\n",
      "(296, 189) (296, 6)\n",
      "******* Feature select: FS_S  Feature type: HG-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.9405052353820625\n",
      "R2 Best score (validation) val. score :  0.6410039490347398\n",
      "R2 of the best estimator (testing dataset):  0.4713617712577813\n",
      "pred [4.59365693 4.40634307 4.54965382 4.45034618 4.13827378 4.86172622]\n",
      "pred [4.93584217 4.06415783 4.42202879 4.57797121 4.85706335 3.97254301]\n",
      "pred [3.90051435 5.09948565 3.63341206 5.36658794 3.41511313 5.58488687]\n",
      "pred [3.95763786 5.0494685  4.57800799 4.42199201 5.56995433 3.29516581]\n",
      "pred [4.16554482 4.83445518 3.39030309 5.68719156 3.67519469 5.32480531]\n",
      "pred [4.83691109 4.02914277 4.3205295  4.75042601 5.52196798 3.37062564]\n",
      "pred [4.57127349 4.42872651 4.5372336  4.4627664  4.506715   4.493285  ]\n",
      "pred [3.27202402 5.72797598 4.01790299 4.98209701 4.1799305  4.8200695 ]\n",
      "pred [4.65764482 4.34235518 4.56346517 4.43653483 4.49744802 4.50255198]\n",
      "pred [4.78995259 4.29701225 4.48453067 4.51546933 4.31098588 4.68901412]\n",
      "pred [4.50084207 4.49915793 4.42840581 4.57159419 4.20822083 4.79177917]\n",
      "pred [4.37357373 4.58454034 4.4055221  4.5944779  4.84955997 4.11417391]\n",
      "pred [3.52010203 5.48700434 4.59921405 4.40078595 5.3874741  3.59872609]\n",
      "pred [2.9958661  6.0041339  4.26051705 4.73948295 3.44851178 5.51923706]\n",
      "pred [4.64174159 4.35825841 4.58884092 4.41115908 4.43474539 4.56525461]\n",
      "pred [4.41514652 4.58485348 4.09008274 4.90991726 3.91620642 5.08379358]\n",
      "pred [3.80170367 5.19829633 4.52408197 4.47591803 4.57657447 4.42342553]\n",
      "pred [4.19968201 4.80031799 4.40784397 4.59215603 4.48020903 4.51979097]\n",
      "pred [2.92440511 6.07559489 4.24414022 4.7771195  3.44851178 5.54322827]\n",
      "pred [4.84591648 4.15408352 4.55463098 4.44536902 3.47202209 5.44303948]\n",
      "pred [3.06779552 5.93220448 4.03365973 4.96634027 3.83238871 5.16761129]\n",
      "pred [4.65166308 4.40700614 4.57652893 4.42347107 4.22981506 4.77018494]\n",
      "pred [4.15392772 4.84607228 4.38110372 4.61889628 4.24420933 4.75579067]\n",
      "pred [4.34590159 4.65409841 4.21736627 4.85358924 5.86718091 2.99793922]\n",
      "pred [3.39666994 5.60333006 4.42835892 4.57164108 4.08316935 4.9085707 ]\n",
      "pred [3.25076738 5.74923262 4.24167851 4.75832149 4.55311371 4.44688629]\n",
      "pred [4.71613621 4.28386379 4.47683294 4.52316706 3.93394549 5.06605451]\n",
      "pred [4.64522058 4.35477942 4.44591494 4.55408506 4.22071142 4.77928858]\n",
      "pred [3.00715634 5.99284366 4.24876205 4.75123795 3.89755451 5.10244549]\n",
      "pred [3.75271937 5.24728063 3.29092868 5.70907132 3.05047284 5.94952716]\n",
      "pred [3.83576557 5.16423443 3.01944248 5.98055752 4.04556155 5.10684952]\n",
      "pred [3.32817583 5.67182417 4.29869989 4.70130011 4.0452176  4.9547824 ]\n",
      "pred [3.86054853 5.13945147 3.92252328 5.07147598 3.63267186 5.36732814]\n",
      "pred [5.13087542 3.86912458 4.48350726 4.51649274 5.05417244 3.76766082]\n",
      "pred [4.09967568 4.90032432 4.41473349 4.58526651 3.74753686 5.25246314]\n",
      "pred [3.35282506 5.64717494 4.24414022 4.7771195  3.35566774 5.67027266]\n",
      "pred [2.88567611 6.11432389 4.29467677 4.70532323 3.844295   5.1816454 ]\n",
      "pred [3.92059536 5.07940464 4.53469315 4.46530685 3.9582244  5.0417756 ]\n",
      "pred [4.50706104 4.49293896 4.54449424 4.45550576 4.26147153 4.73026852]\n",
      "pred [3.61745326 5.38254674 4.45658352 4.54341648 3.90300303 5.09699697]\n",
      "pred [4.59806789 4.40903848 4.24680766 4.82414785 4.95628938 3.93477115]\n",
      "pred [3.08636898 5.91363102 4.30402734 4.69597266 3.8995319  5.1004681 ]\n",
      "pred [4.4592719  4.5407281  4.38813586 4.68281964 4.49146959 4.53288296]\n",
      "pred [3.97098603 5.02901397 4.59595332 4.40404668 4.2674103  4.7325897 ]\n",
      "pred [4.38145516 4.61854484 4.576147   4.423853   3.75421186 5.24578814]\n",
      "pred [3.06779552 5.93220448 4.03365973 4.96634027 3.85038854 5.14961146]\n",
      "pred [4.94457169 4.05542831 4.49593071 4.50406929 4.46445676 4.53554324]\n",
      "pred [4.95999443 3.98427342 4.38877956 4.61122044 4.86720432 4.073612  ]\n",
      "pred [4.39450509 4.54682569 4.36143269 4.63856731 4.40214927 4.59785073]\n",
      "pred [4.38320208 4.61679792 4.63628626 4.36371374 4.37652385 4.62347615]\n",
      "pred [4.77391064 4.22608936 4.46883886 4.53116114 4.53448929 4.46551071]\n",
      "pred [3.2479001  5.7520999  4.37406756 4.62593244 3.93913598 5.05260406]\n",
      "pred [4.64704849 4.35295151 4.52577188 4.47422812 4.55762553 4.44237447]\n",
      "pred [3.5749926  5.4250074  4.23267541 4.76732459 3.61982693 5.38017307]\n",
      "pred [3.12528984 5.87471016 4.14801941 4.85198059 3.7417817  5.2582183 ]\n",
      "pred [3.81677535 5.18322465 4.24370775 4.75629225 3.78424476 5.21575524]\n",
      "pred [4.02829169 4.97170831 4.53173284 4.46826716 4.48634293 4.50539712]\n",
      "pred [3.40674605 5.59325395 4.30691008 4.69308992 3.52337254 5.4443763 ]\n",
      "pred [2.88567611 6.11432389 4.27117859 4.72882141 4.05359551 4.9723449 ]\n",
      "pred [3.11377415 5.88622585 4.35057725 4.64942275 4.42997991 4.57002009]\n",
      "pred [4.39577711 4.60422289 4.5588003  4.4411997  4.46445676 4.53554324]\n",
      "pred [2.90039236 6.09960764 4.12147616 4.87852384 4.09824826 4.90175174]\n",
      "(296, 99) (296, 6)\n",
      "******* Feature select: FS_S  Feature type: OG-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.9290954953973652\n",
      "R2 Best score (validation) val. score :  0.5755734172235272\n",
      "R2 of the best estimator (testing dataset):  0.3638960978568519\n",
      "pred [4.72226835 4.27773165 4.50260389 4.49739611 4.1240807  4.8759193 ]\n",
      "pred [5.20704838 3.79295162 4.4852892  4.5147108  5.05719146 3.94280854]\n",
      "pred [3.93222369 5.06777631 4.49570181 4.50429819 3.00445783 5.99554217]\n",
      "pred [3.41335758 5.58664242 4.60280994 4.39719006 4.27984147 4.72015853]\n",
      "pred [4.6842781  4.3157219  3.74038667 5.25961333 3.33921368 5.66078632]\n",
      "pred [5.08274058 3.91725942 4.44616154 4.55383846 5.58730027 3.41269973]\n",
      "pred [4.36905809 4.67601472 4.60015258 4.39984742 4.16792792 4.83207208]\n",
      "pred [4.13905115 4.86094885 4.4871762  4.5128238  4.31258532 4.68741468]\n",
      "pred [4.57819492 4.42180508 4.56660462 4.43339538 4.27256638 4.72743362]\n",
      "pred [4.62444807 4.37555193 4.47410882 4.52589118 4.45115341 4.54884659]\n",
      "pred [4.83582488 4.16417512 4.53086988 4.46913012 3.85781668 5.14218332]\n",
      "pred [4.55376122 4.44623878 4.57081439 4.42918561 4.18494883 4.81505117]\n",
      "pred [3.33363507 5.66636493 4.5605729  4.4394271  4.43525059 4.56474941]\n",
      "pred [4.12631204 4.87368796 4.0481123  4.9518877  3.36145309 5.63854691]\n",
      "pred [4.56516371 4.43483629 4.44023425 4.55976575 4.01592869 4.98407131]\n",
      "pred [4.65303622 4.31548286 3.78087388 5.21912612 3.74449378 5.25550622]\n",
      "pred [4.1326685  4.8673315  4.5310432  4.4689568  4.05904579 4.94095421]\n",
      "pred [4.62545445 4.37454555 4.44631733 4.55368267 4.51511632 4.48488368]\n",
      "pred [4.11315893 4.88684107 4.0345001  4.9654999  3.37423861 5.62576139]\n",
      "pred [5.08763233 3.91236767 4.46746234 4.53253766 3.38772891 5.61227109]\n",
      "pred [4.25979188 4.74020812 4.71463263 4.28536737 3.97968485 5.02031515]\n",
      "pred [4.16919875 4.83080125 4.69803024 4.30196976 3.97736915 5.02263085]\n",
      "pred [4.26318811 4.73681189 4.6224373  4.3775627  4.27884925 4.72115075]\n",
      "pred [4.86088625 4.10763284 4.40073826 4.59926174 5.66156419 3.33843581]\n",
      "pred [3.90612439 5.09387561 4.60382087 4.39617913 4.12087754 4.87912246]\n",
      "pred [4.26111962 4.73888038 4.54717102 4.45282898 4.26008289 4.73991711]\n",
      "pred [4.20678704 4.79321296 4.65012038 4.34987962 4.34150272 4.65849728]\n",
      "pred [4.84200159 4.15799841 4.64398056 4.35601944 3.84446478 5.15553522]\n",
      "pred [3.50389266 5.45103454 4.23040669 4.76959331 3.9491812  5.0508188 ]\n",
      "pred [4.37125366 4.59726543 3.95201416 5.04798584 3.28158347 5.71841653]\n",
      "pred [4.32188755 4.67811245 3.28826094 5.71173906 3.61938623 5.38061377]\n",
      "pred [3.91210037 5.13297243 4.41161309 4.58838691 3.54571906 5.45428094]\n",
      "pred [4.52991896 4.47008104 4.2719874  4.7280126  3.47570094 5.52429906]\n",
      "pred [5.23926406 3.76073594 4.44564663 4.55435337 5.67594995 3.32405005]\n",
      "pred [4.07913099 4.92086901 4.74159081 4.25840919 3.65097803 5.34902197]\n",
      "pred [3.88822227 5.11177773 4.10510525 4.89489475 3.12879773 5.87120227]\n",
      "pred [4.01632923 4.98367077 4.47015164 4.52984836 3.77011333 5.22988667]\n",
      "pred [4.20840393 4.79159607 4.4194192  4.5805808  3.85686501 5.14313499]\n",
      "pred [4.16902736 4.83097264 4.73534309 4.26465691 4.01703642 4.98296358]\n",
      "pred [4.43668394 4.56331606 4.6893395  4.3106605  3.34448254 5.65551746]\n",
      "pred [5.11949008 3.88050992 4.5115015  4.4884985  4.78571301 4.21428699]\n",
      "pred [4.03833471 4.96166529 4.35195453 4.64804547 3.55003861 5.44996139]\n",
      "pred [4.64923252 4.35076748 4.63687774 4.36312226 2.60597531 6.39402469]\n",
      "pred [4.3027829  4.6972171  4.30330877 4.69669123 4.00416765 4.99583235]\n",
      "pred [3.62608409 5.37391591 4.74674411 4.25325589 3.9441326  5.0558674 ]\n",
      "pred [4.25979188 4.74020812 4.71463263 4.28536737 3.98782497 5.01217503]\n",
      "pred [4.75650643 4.24349357 4.33470563 4.66529437 4.35952221 4.64047779]\n",
      "pred [5.34668366 3.65331634 4.4294527  4.5705473  5.08642838 3.91357162]\n",
      "pred [4.49674595 4.54832685 4.47237836 4.52762164 4.51079295 4.48920705]\n",
      "pred [4.35856155 4.64143845 4.61459925 4.38362408 4.10636644 4.89363356]\n",
      "pred [4.64569277 4.35430723 4.51052686 4.48947314 4.27628531 4.72371469]\n",
      "pred [3.7501097  5.2498903  4.58366252 4.41633748 3.85940624 5.14059376]\n",
      "pred [5.04375197 3.95624803 4.53517319 4.46482681 4.33500869 4.66499131]\n",
      "pred [4.15647963 4.84352037 4.30958974 4.69041026 2.86256124 6.13743876]\n",
      "pred [3.26240329 5.73759671 4.24634186 4.75365814 3.6361813  5.3638187 ]\n",
      "pred [4.10359557 4.89640443 4.12531722 4.87468278 3.91868241 5.08131759]\n",
      "pred [4.40969739 4.59030261 4.465163   4.534837   4.21405831 4.78594169]\n",
      "pred [4.05884335 4.94115665 4.23932769 4.76067231 3.56317957 5.43682043]\n",
      "pred [3.86796079 5.13203921 4.46264355 4.53735645 3.68697438 5.31302562]\n",
      "pred [4.34384637 4.65615363 4.47444845 4.52555155 4.17644763 4.82355237]\n",
      "pred [4.51366216 4.48633784 4.70167875 4.29832125 4.01895858 4.98104142]\n",
      "pred [3.65878393 5.34121607 4.59105065 4.40894935 3.99252719 5.00747281]\n",
      "(296, 58) (296, 6)\n",
      "******* Feature select: FS_S  Feature type: ST-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.9281525004705439\n",
      "R2 Best score (validation) val. score :  0.5892747276575833\n",
      "R2 of the best estimator (testing dataset):  0.38879694553351407\n",
      "pred [5.14155416 3.77772724 4.47335208 4.52664792 4.43818615 4.56181385]\n",
      "pred [4.90897815 4.04959182 4.48747693 4.51252307 4.89281615 4.10718385]\n",
      "pred [3.68722264 5.31277736 4.0302482  4.9697518  3.1901717  5.8098283 ]\n",
      "pred [3.89489949 5.10510051 4.5504943  4.4495057  5.4219125  3.5780875 ]\n",
      "pred [4.36972563 4.63027437 4.50521743 4.49478257 3.11454871 5.88545129]\n",
      "pred [5.00946122 3.99053878 4.47513284 4.52486716 6.30348517 2.74832285]\n",
      "pred [4.85850929 4.14149071 4.37129003 4.62870997 4.38408367 4.61591633]\n",
      "pred [3.92463697 5.07536303 4.36167815 4.63832185 4.23857232 4.76142768]\n",
      "pred [4.93613938 4.06386062 4.48510693 4.51489307 4.45946448 4.54053552]\n",
      "pred [4.95690822 3.96237318 4.46500786 4.53499214 4.54250631 4.45749369]\n",
      "pred [4.74829844 4.17098297 4.48155963 4.51844037 4.26373964 4.73626036]\n",
      "pred [4.64024418 4.35975582 4.47451509 4.52548491 4.56216817 4.43783183]\n",
      "pred [3.80503802 5.19496198 4.54492702 4.45507298 4.85985647 4.14014353]\n",
      "pred [3.09728907 5.90271093 4.4348021  4.5651979  3.7737763  5.2262237 ]\n",
      "pred [4.33082011 4.66917989 4.54284026 4.45715974 4.11991241 4.88008759]\n",
      "pred [4.79024371 4.20975629 4.53135896 4.46864104 3.73704372 5.26295628]\n",
      "pred [3.05917951 5.94082049 4.51933806 4.48066194 4.40798123 4.59201877]\n",
      "pred [4.47274317 4.44653824 4.41984841 4.58015159 4.74943248 4.25056752]\n",
      "pred [3.01744619 5.98255381 4.45524481 4.54475519 3.7737763  5.2262237 ]\n",
      "pred [5.05040802 3.90816195 4.46045685 4.53954315 2.76077533 6.23922467]\n",
      "pred [3.91768526 5.08231474 4.56618051 4.43381949 3.45794999 5.54205001]\n",
      "pred [3.72591851 5.27408149 4.47546586 4.52453414 4.0193149  4.9806851 ]\n",
      "pred [4.20253197 4.71674944 4.45522233 4.54477767 4.39409501 4.60590499]\n",
      "pred [4.84939077 4.15060923 4.5035352  4.4964648  6.27174519 2.72603148]\n",
      "pred [4.14056111 4.7787203  4.49728276 4.50271724 4.05423236 4.94576764]\n",
      "pred [4.15291346 4.84708654 4.29211278 4.70788722 4.37898228 4.62101772]\n",
      "pred [4.46603718 4.45324423 4.5121646  4.4878354  3.91884106 5.11466502]\n",
      "pred [4.73617372 4.18310768 4.48155963 4.51844037 4.26373964 4.73626036]\n",
      "pred [3.11327634 5.88672366 4.25543713 4.74456287 4.14058593 4.85941407]\n",
      "pred [4.1539353  4.8460647  3.77645085 5.22354915 2.81055455 6.18944545]\n",
      "pred [3.04655854 5.95344146 3.21290386 5.8386973  3.03071432 5.96928568]\n",
      "pred [3.37496934 5.62503066 4.39891789 4.60108211 3.96204903 5.03795097]\n",
      "pred [4.3384644  4.6615356  4.24459385 4.75540615 3.43785158 5.56214842]\n",
      "pred [4.95964099 4.04035901 4.41998855 4.58001145 6.14680867 2.85319133]\n",
      "pred [4.08654787 4.91345213 4.46784059 4.53215941 4.33800699 4.66199301]\n",
      "pred [3.26493472 5.73506528 4.41754083 4.58245917 3.48769043 5.51230957]\n",
      "pred [3.08297598 5.91702402 4.37494568 4.62505432 3.8247348  5.1752652 ]\n",
      "pred [4.37705717 4.54222424 4.41258405 4.58741595 4.43623971 4.56376029]\n",
      "pred [4.70187643 4.21740498 4.59400165 4.40599835 4.32927835 4.70422772]\n",
      "pred [3.42175621 5.57824379 4.53046382 4.46953618 3.92712792 5.07287208]\n",
      "pred [5.22956838 3.77043162 4.52937135 4.47062865 4.61418935 4.43761867]\n",
      "pred [3.88547814 5.11452186 4.5339678  4.4660322  3.79250359 5.20749641]\n",
      "pred [5.30941715 3.69058285 4.5333984  4.4666016  3.05376587 5.94623413]\n",
      "pred [3.9897436  5.0102564  4.62757562 4.37242438 4.05930667 4.94069333]\n",
      "pred [3.10043568 5.89956432 4.48154633 4.51845367 3.98375816 5.01624184]\n",
      "pred [3.91768526 5.08231474 4.45526157 4.54473843 3.45794999 5.54205001]\n",
      "pred [4.6855645  4.3144355  4.41436838 4.58563162 4.22577899 4.77422101]\n",
      "pred [4.98882456 3.96974541 4.43281384 4.56718616 4.68381888 4.31618112]\n",
      "pred [3.91206108 5.08793892 4.32359285 4.67640715 4.45734076 4.54265924]\n",
      "pred [3.97572018 5.02427982 4.60070964 4.39929036 4.3627852  4.6372148 ]\n",
      "pred [4.94913754 4.05086246 4.53917643 4.46082357 4.37208155 4.62791845]\n",
      "pred [3.21684861 5.78315139 4.44884333 4.55115667 3.90621903 5.09378097]\n",
      "pred [5.12649639 3.79278502 4.46597058 4.53402942 4.43818615 4.56181385]\n",
      "pred [3.48471865 5.51528135 4.23036417 4.76963583 2.64909122 6.35090878]\n",
      "pred [3.16531086 5.83468914 4.06873336 4.93126664 3.32373694 5.67626306]\n",
      "pred [4.40840939 4.59159061 4.2163011  4.7836989  3.88910613 5.11089387]\n",
      "pred [4.77728361 4.1419978  4.3270424  4.6729576  4.30895969 4.72454638]\n",
      "pred [2.92984297 6.07015703 4.43718579 4.56281421 3.85482164 5.14517836]\n",
      "pred [3.19167467 5.80832533 4.45522233 4.54477767 3.86849522 5.13150478]\n",
      "pred [4.28998978 4.71001022 4.4123472  4.5876528  3.94608899 5.05391101]\n",
      "pred [4.46684617 4.53315383 4.49520474 4.50479526 4.36106815 4.63893185]\n",
      "pred [3.76261733 5.23738267 4.4742417  4.5257583  3.5363854  5.4636146 ]\n",
      "(296, 15) (296, 6)\n",
      "******* Feature select: RF  Feature type: HG-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.9336040022372717\n",
      "R2 Best score (validation) val. score :  0.5847382141853972\n",
      "R2 of the best estimator (testing dataset):  0.30637909531400637\n",
      "pred [4.77439202 4.22560798 4.57268218 4.54497956 4.45508935 4.54491065]\n",
      "pred [5.17297061 3.82702939 4.47886267 4.52113733 4.00499938 4.99500062]\n",
      "pred [3.92802967 5.11743052 3.27750201 5.72249799 3.66026291 5.33973709]\n",
      "pred [3.8690349  5.1309651  4.54004577 4.45995423 6.06565739 2.93434261]\n",
      "pred [5.02809813 3.97190187 2.84228463 6.15771537 3.14380164 5.8953435 ]\n",
      "pred [5.31749215 3.68250785 4.3709     4.6291     6.18776124 2.93646866]\n",
      "pred [4.50916753 4.49083247 4.49230442 4.50769558 4.44970101 4.55029899]\n",
      "pred [3.198161   5.86093453 4.21783999 4.81506812 3.01374722 5.98625278]\n",
      "pred [4.66211386 4.33788614 4.52282676 4.47717324 4.58940239 4.41059761]\n",
      "pred [4.75466254 4.24533746 4.4142713  4.5857287  4.39731442 4.60268558]\n",
      "pred [5.04757543 4.0545395  4.4464334  4.5535666  4.34225494 4.65774506]\n",
      "pred [4.61851675 4.38148325 4.36055318 4.63944682 4.25702948 4.74297052]\n",
      "pred [3.54546776 5.45453224 4.54004577 4.45995423 5.9866067  3.0133933 ]\n",
      "pred [2.98941851 6.01058149 4.19322362 4.80677638 3.4563752  5.5436248 ]\n",
      "pred [4.63303439 4.36696561 4.61747731 4.38252269 4.45848742 4.54151258]\n",
      "pred [4.94660457 4.05339543 3.73007719 5.26992281 3.89837906 5.10162094]\n",
      "pred [3.99775689 5.00224311 4.60592404 4.39407596 4.52547328 4.47452672]\n",
      "pred [4.54224142 4.45775858 4.22431138 4.77568862 4.44436288 4.55563712]\n",
      "pred [2.8553692  6.1446308  4.19322362 4.80677638 3.50025595 5.49974405]\n",
      "pred [5.07277729 3.92722271 4.46083432 4.53916568 3.31443453 5.68556547]\n",
      "pred [4.3484303  4.63182605 3.68891888 5.31108112 3.70700737 5.29299263]\n",
      "pred [4.04803443 4.95196557 4.55852768 4.44147232 4.20755246 4.79244754]\n",
      "pred [4.01406491 4.98593509 4.38111008 4.61888992 4.74133755 4.25418425]\n",
      "pred [3.79195814 5.20804186 4.43855559 4.55892371 6.38977586 2.75162569]\n",
      "pred [2.79520449 6.20479551 4.54100912 4.45899088 4.19637066 4.80362934]\n",
      "pred [3.79449713 5.20550287 4.10553627 4.89446373 4.13685822 4.86314178]\n",
      "pred [4.45501926 4.54780538 4.18562955 4.78192296 4.11530853 4.88469147]\n",
      "pred [5.14351629 3.85648371 4.47347003 4.52652997 4.34225494 4.65774506]\n",
      "pred [4.0559529  4.9440471  4.42479401 4.57520599 4.40999932 4.59000068]\n",
      "pred [4.30381576 4.69618424 3.42411003 5.57588997 2.40986619 6.59013381]\n",
      "pred [3.17657172 5.82342828 4.01586652 4.98413348 3.38778774 5.61221226]\n",
      "pred [3.64062921 5.35937079 4.38782331 4.61217669 4.03613426 4.96386574]\n",
      "pred [4.43129175 4.56870825 3.34473069 5.65526931 3.01705741 6.01017579]\n",
      "pred [5.45264843 3.54735157 4.42203429 4.57796571 5.76203959 3.23796041]\n",
      "pred [4.34324051 4.65675949 4.05692795 4.94126843 3.81595465 5.18404535]\n",
      "pred [3.63916996 5.36083004 3.96564069 5.03435931 3.38125511 5.61874489]\n",
      "pred [3.56964617 5.43035383 4.22250343 4.77749657 4.25376589 4.74623411]\n",
      "pred [3.46660456 5.81250245 4.3651917  4.66075272 3.36155858 5.68799994]\n",
      "pred [4.6036089  4.39921574 4.494673   4.505327   4.28933833 4.71066167]\n",
      "pred [4.02022673 4.97977327 4.4942267  4.4733258  4.05652409 4.94347591]\n",
      "pred [5.08757095 3.91242905 4.42359613 4.57640387 5.95986838 3.16436152]\n",
      "pred [4.11997198 4.88002802 3.29124536 5.70875464 2.95969623 6.04030377]\n",
      "pred [4.50057278 4.49942722 4.56934799 4.43065201 3.88685903 5.11314097]\n",
      "pred [4.86025274 4.13974726 4.31033328 4.68966672 4.4264284  4.5735716 ]\n",
      "pred [3.96233017 5.03766983 4.5297497  4.4702503  4.21777974 4.78222026]\n",
      "pred [4.3484303  4.63182605 3.68891888 5.31108112 3.70700737 5.29299263]\n",
      "pred [4.38950524 4.61049476 4.4570338  4.5429662  4.43355568 4.56644432]\n",
      "pred [5.33220682 3.66779318 4.50103858 4.49896142 5.30262366 3.82160624]\n",
      "pred [4.07943865 4.92056135 4.36833762 4.63166238 4.51533528 4.48466472]\n",
      "pred [4.36242055 4.63757945 4.56297797 4.43702203 4.38241864 4.61758136]\n",
      "pred [4.49831003 4.50168997 4.15560351 4.84439649 4.42725378 4.57274622]\n",
      "pred [2.79527604 6.20472396 4.54020362 4.45979638 4.01839549 4.98160451]\n",
      "pred [4.56400809 4.48241443 4.50741472 4.49258528 4.41781281 4.58218719]\n",
      "pred [4.03679142 4.96320858 4.36123072 4.63876928 3.6981339  5.3018661 ]\n",
      "pred [3.39743256 5.60256744 4.10867933 4.89132067 3.81276393 5.18723607]\n",
      "pred [4.08633152 4.91366848 4.40224429 4.67129289 3.52953227 5.47046773]\n",
      "pred [4.55465409 4.44817054 4.51637126 4.48362874 4.48461386 4.51538614]\n",
      "pred [2.93116354 6.06883646 4.34982772 4.65017228 3.72004957 5.27995043]\n",
      "pred [2.9169982  6.0830018  4.55809039 4.44190961 3.99557885 5.00442115]\n",
      "pred [4.97296295 4.02703705 3.47708171 5.52291829 3.47060778 5.52939222]\n",
      "pred [4.87647046 4.12352954 4.62219968 4.37780032 4.45126033 4.58006724]\n",
      "pred [3.78428522 5.21571478 4.07812597 4.92187403 3.07749265 5.92250735]\n",
      "(296, 23) (296, 6)\n",
      "******* Feature select: RF  Feature type: OG-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.8632038407902857\n",
      "R2 Best score (validation) val. score :  0.5659434663660912\n",
      "R2 of the best estimator (testing dataset):  0.3686997353597108\n",
      "pred [5.07415341 3.92584659 4.45268358 4.54731642 4.34015434 4.65984566]\n",
      "pred [5.20402839 3.76936448 4.46408555 4.53591445 4.25030418 4.74969582]\n",
      "pred [3.96426676 5.03573324 4.236296   4.763704   3.15530161 5.84469839]\n",
      "pred [3.76726912 5.12281248 4.54340119 4.45659881 5.81541738 3.18458262]\n",
      "pred [4.12970295 4.87029705 3.9263049  5.0736951  2.98428243 6.01571757]\n",
      "pred [5.38387741 3.58951546 4.46408555 4.53591445 5.77507559 3.2365406 ]\n",
      "pred [4.67112047 4.32887953 4.48307397 4.51692603 4.46455926 4.53544074]\n",
      "pred [4.60655406 4.39344594 4.47559541 4.52440459 4.29815726 4.70184274]\n",
      "pred [3.92875533 5.07124467 4.67998327 4.32001673 4.29919575 4.70080425]\n",
      "pred [5.10530437 3.89469563 4.45842849 4.54157151 4.34015434 4.65984566]\n",
      "pred [5.10530437 3.89469563 4.45842849 4.54157151 4.25378605 4.74621395]\n",
      "pred [4.74572545 4.25427455 4.46093542 4.53906458 4.61450887 4.38549113]\n",
      "pred [3.54408801 5.45591199 4.57784223 4.42215777 5.15895498 3.84104502]\n",
      "pred [4.30870285 4.69129715 4.16132961 4.83867039 3.80568471 5.19431529]\n",
      "pred [4.60910233 4.56754396 4.68363591 4.31636409 4.19856255 4.80143745]\n",
      "pred [4.15133538 4.84866462 4.09090905 4.90909095 3.81645495 5.18354505]\n",
      "pred [3.36545242 5.63454758 4.5525796  4.4474204  4.35373226 4.64626774]\n",
      "pred [3.97588566 5.02411434 4.47505595 4.52494405 4.55794922 4.44205078]\n",
      "pred [4.30870285 4.69129715 4.0495656  4.9504344  3.80568471 5.19431529]\n",
      "pred [5.15255848 3.78968141 4.46408555 4.53591445 3.39235768 5.60764232]\n",
      "pred [4.21814287 4.78185713 4.54302243 4.45697757 4.36836587 4.63163413]\n",
      "pred [3.44753893 5.55246107 4.51804633 4.48195367 3.93512992 5.06487008]\n",
      "pred [3.97588566 5.02411434 4.46103744 4.53896256 4.54513958 4.45486042]\n",
      "pred [4.6887951  4.3112049  4.52899394 4.47100606 6.48384333 2.51615667]\n",
      "pred [3.0576724  5.9423276  4.48594953 4.51405047 4.4377926  4.5622074 ]\n",
      "pred [4.40106202 4.59893798 4.48041515 4.51958485 4.32214642 4.67785358]\n",
      "pred [4.31395532 4.68604468 4.30743305 4.69256695 4.09001899 4.90998101]\n",
      "pred [5.10530437 3.89469563 4.45842849 4.54157151 4.2805824  4.7194176 ]\n",
      "pred [3.40552094 5.36945633 4.35358241 4.64641759 4.17407622 4.82592378]\n",
      "pred [4.24179044 4.75820956 4.28207224 4.71792776 2.9378199  6.0621801 ]\n",
      "pred [3.67359691 5.32640309 3.40626035 5.59373965 2.9025527  6.0974473 ]\n",
      "pred [4.02186966 4.97813034 4.42255665 4.57744335 3.87099897 5.12900103]\n",
      "pred [4.60652617 4.39347383 4.32109351 4.67890649 3.29054437 5.70945563]\n",
      "pred [5.45324143 3.52015144 4.51088515 4.48911485 5.85305295 3.15856324]\n",
      "pred [4.32945711 4.67054289 4.4892734  4.5107266  3.93910802 5.06089198]\n",
      "pred [4.25997937 4.74002063 4.0495656  4.9504344  3.42088605 5.57911395]\n",
      "pred [3.9372285  5.0627715  4.409412   4.590588   4.16677594 4.83322406]\n",
      "pred [4.14652817 4.85347183 4.42255665 4.57744335 3.83546483 5.16453517]\n",
      "pred [4.44823798 4.55176202 4.42560081 4.57439919 4.04633461 4.95366539]\n",
      "pred [3.47050972 5.52949028 4.50969246 4.49030754 3.53881897 5.46118103]\n",
      "pred [4.81293078 4.07715082 4.53868924 4.46131076 5.67659413 3.32340587]\n",
      "pred [4.37216985 4.62783015 4.42387397 4.57612603 3.68401427 5.31598573]\n",
      "pred [4.55000386 4.34007774 4.53868924 4.46131076 3.12442478 5.87557522]\n",
      "pred [3.96352019 5.03647981 4.11114647 4.88885353 3.90498547 5.09501453]\n",
      "pred [3.43862497 5.56137503 4.71383552 4.28616448 3.88740028 5.11259972]\n",
      "pred [4.21814287 4.78185713 4.54302243 4.45697757 4.36836587 4.63163413]\n",
      "pred [4.28632542 4.89032086 4.47867366 4.52132634 4.29919575 4.70080425]\n",
      "pred [5.25324418 3.71468027 4.46408555 4.53591445 4.75544327 4.24455673]\n",
      "pred [4.61190351 4.38809649 4.41824175 4.58175825 4.43087638 4.56912362]\n",
      "pred [4.02899667 4.97100333 4.68721986 4.31278014 4.25563937 4.74436063]\n",
      "pred [4.45059311 4.72605318 4.48076067 4.51923933 4.29919575 4.70080425]\n",
      "pred [2.95920964 6.04079036 4.47203305 4.52796695 4.18920258 4.81079742]\n",
      "pred [5.05794693 3.94205307 4.45842849 4.54157151 4.34015434 4.65984566]\n",
      "pred [3.70509028 5.29490972 4.3826592  4.6173408  3.31355494 5.68644506]\n",
      "pred [3.43693953 5.56306047 3.90746262 5.09253738 3.97274271 5.02725729]\n",
      "pred [3.83347577 5.16652423 4.02480502 4.97519498 3.61279488 5.38720512]\n",
      "pred [4.05018698 4.94981302 4.42253602 4.57746398 4.08325123 4.91674877]\n",
      "pred [4.30870285 4.69129715 4.28769336 4.71230664 4.01689295 4.98310705]\n",
      "pred [3.12896148 5.87103852 4.46103744 4.53896256 4.22171045 4.77828955]\n",
      "pred [4.28750546 4.71249454 4.37851276 4.62148724 4.29069663 4.70930337]\n",
      "pred [4.06124    4.93876    4.45988884 4.54011116 4.14145832 4.85854168]\n",
      "pred [4.33758064 4.66241936 4.4967499  4.5032501  4.03056435 4.96943565]\n",
      "(296, 32) (296, 6)\n",
      "******* Feature select: RF  Feature type: ST-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.9069905064219085\n",
      "R2 Best score (validation) val. score :  0.5606546965409667\n",
      "R2 of the best estimator (testing dataset):  0.2910329813283354\n",
      "pred [4.97160242 4.02839758 4.35811728 4.64188272 4.38496554 4.61503446]\n",
      "pred [5.13592701 3.86407299 4.20520354 4.78507924 4.68809163 4.31190837]\n",
      "pred [3.78377386 5.21622614 3.57255553 5.42744447 3.07445518 5.92554482]\n",
      "pred [3.38717869 5.61282131 4.50918554 4.49081446 5.56254329 3.43745671]\n",
      "pred [3.81991028 5.18008972 3.49962636 5.59279257 2.99593965 6.00406035]\n",
      "pred [5.36482099 3.63517901 4.46867831 4.53132169 6.22251519 2.9051947 ]\n",
      "pred [3.95907535 5.04092465 4.24720019 4.82646722 4.29279389 4.70720611]\n",
      "pred [3.6303671  5.3696329  4.50610696 4.49389304 4.21893754 4.78106246]\n",
      "pred [3.65242251 5.34757749 4.5452269  4.46750696 4.30584428 4.71570533]\n",
      "pred [4.90054319 4.09945681 4.44369136 4.55630864 4.35892927 4.64107073]\n",
      "pred [4.68620886 4.31379114 4.4294614  4.5705386  4.33977319 4.66022681]\n",
      "pred [4.2426078  4.7573922  4.46653161 4.53346839 4.38031372 4.61968628]\n",
      "pred [3.06458504 5.93541496 4.5755783  4.4244217  4.31322501 4.68677499]\n",
      "pred [3.53701352 5.46298648 3.80997733 5.13137073 4.01932631 4.98067369]\n",
      "pred [3.36268056 5.63731944 4.25551806 4.74448194 4.09985768 4.85500523]\n",
      "pred [4.04601517 4.95398483 4.05670587 4.94329413 3.88644803 5.15967499]\n",
      "pred [2.6812472  6.32235171 4.35829135 4.64170865 4.10203365 4.89796635]\n",
      "pred [4.18406963 4.81593037 4.41139781 4.58860219 4.49262455 4.50737545]\n",
      "pred [3.46650002 5.53349998 3.76659659 5.17475147 4.01486912 4.98513088]\n",
      "pred [5.00574162 3.99425838 4.49290853 4.50709147 3.16633573 5.83366427]\n",
      "pred [3.59673189 5.40326811 3.5555086  5.47767465 3.96627925 5.03372075]\n",
      "pred [3.59466208 5.40533792 4.44388079 4.55611921 4.08342946 4.91657054]\n",
      "pred [3.82198244 5.17801756 4.43406384 4.56593616 4.57193843 4.42806157]\n",
      "pred [4.89750413 4.16193485 4.23338667 4.75689611 6.18418447 2.92089768]\n",
      "pred [3.85219643 5.13293486 4.35949996 4.64050004 4.44869024 4.55130976]\n",
      "pred [3.92468786 5.07531214 3.42696735 5.57303265 4.25744411 4.74255589]\n",
      "pred [3.89795871 5.10204129 4.4917882  4.5082118  3.81886514 5.18113486]\n",
      "pred [4.68620886 4.31379114 4.4351259  4.5648741  4.34423039 4.65576961]\n",
      "pred [3.31639112 5.68360888 3.88757432 5.16077848 4.04626175 4.95373825]\n",
      "pred [3.6372496  5.3627504  3.4090151  5.68001593 3.08647449 5.91352551]\n",
      "pred [4.36568667 4.60404674 3.1930236  5.7921321  3.01788474 5.98211526]\n",
      "pred [2.85681593 6.14318407 4.47695702 4.52304298 4.23784898 4.76215102]\n",
      "pred [4.51569144 4.51309365 3.4243558  5.5756442  3.37371622 5.62628378]\n",
      "pred [5.28487451 3.71512549 4.47779024 4.52220976 6.54941606 2.45058394]\n",
      "pred [3.91054677 5.08945323 4.08427077 4.91572923 3.76108603 5.23891397]\n",
      "pred [3.38697365 5.61302635 3.54496827 5.39637979 3.5954511  5.4045489 ]\n",
      "pred [3.8831669  5.1168331  4.36082099 4.63917901 4.42223486 4.57776514]\n",
      "pred [3.50678497 5.49321503 4.38619098 4.61380902 4.17422632 4.82577368]\n",
      "pred [4.37734277 4.62265723 4.56595104 4.43404896 4.20415297 4.79584703]\n",
      "pred [4.07701654 4.92298346 4.53910619 4.46089381 4.04770841 4.95229159]\n",
      "pred [4.89670675 4.10329325 4.44568887 4.58177405 5.50502586 3.62268402]\n",
      "pred [3.94922528 5.05077472 3.77357716 5.22642284 3.24447439 5.75552561]\n",
      "pred [4.50945095 4.49054905 4.46230342 4.53769658 3.0970254  5.85783751]\n",
      "pred [3.28524509 5.71475491 4.69588799 4.37666611 4.27121091 4.72878909]\n",
      "pred [3.7750304  5.2249696  3.62109768 5.37890232 3.79749128 5.21102693]\n",
      "pred [3.69659017 5.30340983 3.5555086  5.47767465 3.90974557 5.09025443]\n",
      "pred [4.01206227 4.97306902 4.61133459 4.40139927 4.38346209 4.68322462]\n",
      "pred [5.21658895 3.78341105 4.45481213 4.54518787 4.98051009 4.01948991]\n",
      "pred [3.98546698 5.01453302 4.3095258  4.6904742  4.5692483  4.4307517 ]\n",
      "pred [3.50804142 5.49195858 4.61945044 4.38054956 4.2017963  4.84432672]\n",
      "pred [3.941557   5.058443   4.45437531 4.55835855 4.45121254 4.61547417]\n",
      "pred [3.41643605 5.58356395 4.31523835 4.68476165 4.25173564 4.74826436]\n",
      "pred [4.99599568 4.00400432 4.48567467 4.51432533 4.38496554 4.61503446]\n",
      "pred [3.37143985 5.62856015 4.28276225 4.71723775 3.24854535 5.75145465]\n",
      "pred [3.22446438 5.77553562 3.68902108 5.25232698 3.91115723 5.08884277]\n",
      "pred [4.22522755 4.77477245 3.69327703 5.30672297 3.17217312 5.82782688]\n",
      "pred [4.35633999 4.64366001 4.23628417 4.76371583 4.2026356  4.7973644 ]\n",
      "pred [3.54383639 5.45616361 3.73440366 5.26559634 4.23797207 4.76202793]\n",
      "pred [3.76447192 5.23552808 4.37322548 4.62677452 4.49288371 4.50711629]\n",
      "pred [4.26928504 4.73071496 3.26868079 5.73131921 3.96569181 5.03430819]\n",
      "pred [3.20399299 5.79600701 4.21539658 4.78460342 4.20666976 4.79333024]\n",
      "pred [3.41815144 5.58184856 3.73415294 5.32718637 3.17244567 5.82755433]\n",
      "(296, 20) (296, 6)\n",
      "******* Feature select: LR20  Feature type: HG-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.9477701561920634\n",
      "R2 Best score (validation) val. score :  0.607124248440335\n",
      "R2 of the best estimator (testing dataset):  0.4734249789365966\n",
      "pred [4.41851748 4.58148252 4.55374083 4.44625917 4.06490436 4.93509564]\n",
      "pred [5.1982742  3.8017258  4.66796498 4.33203502 4.02153051 5.02406644]\n",
      "pred [4.29442185 4.69338185 4.01344523 5.02146485 3.45740959 5.54259041]\n",
      "pred [3.55276782 5.44723218 4.58888739 4.41111261 6.03022938 2.9461763 ]\n",
      "pred [4.47754935 4.52245065 3.23062978 5.76937022 2.97243772 6.02756228]\n",
      "pred [4.99156114 4.00843886 4.53441343 4.46558657 6.17644672 2.82355328]\n",
      "pred [4.39898962 4.60101038 4.42950645 4.58423472 4.41149035 4.58850965]\n",
      "pred [3.802769   5.197231   3.79997753 5.20002247 3.79793312 5.29226338]\n",
      "pred [4.47770064 4.52229936 4.48027494 4.51972506 4.39345826 4.60654174]\n",
      "pred [4.85181084 4.14818916 4.37584864 4.63771319 4.17876532 4.82123468]\n",
      "pred [5.03644622 3.96355378 4.54983415 4.45016585 4.01758693 4.98241307]\n",
      "pred [4.57151332 4.42848668 4.4070931  4.5929069  4.21162085 4.78837915]\n",
      "pred [3.31174314 5.68825686 4.59938516 4.40061484 5.40204563 3.57436005]\n",
      "pred [3.68040286 5.31959714 4.19101801 4.80898199 3.69131729 5.30868271]\n",
      "pred [4.61528272 4.38471728 4.42207253 4.57792747 4.45049166 4.54950834]\n",
      "pred [4.14115118 4.85884882 4.42534421 4.57465579 4.14369159 4.85630841]\n",
      "pred [3.57155815 5.42844185 4.57511872 4.42488128 4.33441148 4.66558852]\n",
      "pred [4.76571167 4.23428833 4.3534734  4.6465266  4.80578056 4.19421944]\n",
      "pred [3.54163489 5.45836511 4.21476356 4.78523644 3.58037762 5.41962238]\n",
      "pred [4.90809621 4.20905417 4.55851991 4.44148009 3.13177021 5.85284855]\n",
      "pred [3.59133008 5.40866992 3.89883777 5.09796962 3.94342925 5.05657075]\n",
      "pred [4.14897084 4.85277938 4.33670125 4.66329875 3.9887631  4.99670903]\n",
      "pred [4.39031783 4.60968217 4.42095293 4.57904707 4.34049767 4.65950233]\n",
      "pred [4.77016845 4.11268118 4.49127538 4.50872462 6.32400268 2.57554815]\n",
      "pred [3.02609727 5.97390273 4.48192819 4.51807181 4.16649069 4.83350931]\n",
      "pred [3.70960484 5.35734063 4.53662969 4.46337031 4.1295947  4.8704053 ]\n",
      "pred [4.14828014 4.85171986 4.47957438 4.52042562 3.98415405 5.01584595]\n",
      "pred [5.02661461 3.97338539 4.54983415 4.45016585 3.94010747 5.05989253]\n",
      "pred [2.92899218 6.07100782 4.39992311 4.60007689 3.93767634 5.06232366]\n",
      "pred [4.05669641 4.94330359 3.20326368 5.77317861 2.89744909 6.10255091]\n",
      "pred [3.08803858 5.91371164 3.52538306 5.47461694 3.00671252 5.97875962]\n",
      "pred [3.23817626 5.8034197  4.08535176 4.91464824 3.66313792 5.33686208]\n",
      "pred [4.39778011 4.56399218 4.30221683 4.73269324 2.96974052 6.03025948]\n",
      "pred [5.59898995 3.40101005 4.63296832 4.36703168 5.46129003 3.53870997]\n",
      "pred [4.37366813 4.62633187 4.51424024 4.48575976 4.02094202 4.97905798]\n",
      "pred [3.44614189 5.55385811 4.1180078  4.8819922  3.75196101 5.24803899]\n",
      "pred [2.57731109 6.42268891 4.34465244 4.65534756 3.74374812 5.25625188]\n",
      "pred [3.5744374  5.51417626 4.61137415 4.38862585 4.14550794 4.85449206]\n",
      "pred [3.96600085 4.92975502 4.43131701 4.55835664 3.94664373 5.12381082]\n",
      "pred [4.18631071 4.81543951 4.52281135 4.47718865 3.46245166 5.52302048]\n",
      "pred [5.11362634 3.88637366 4.54432893 4.45567107 5.25602472 3.74397528]\n",
      "pred [3.47525286 5.5350664  4.1769284  4.8230716  3.40921739 5.59078261]\n",
      "pred [4.75543773 4.24456227 4.63359453 4.36640547 3.78886831 5.22651293]\n",
      "pred [4.36306849 4.63868173 4.57930611 4.42069389 4.49478622 4.49068592]\n",
      "pred [4.34692947 4.65307053 4.69769625 4.30230375 3.89558564 5.10441436]\n",
      "pred [3.57972707 5.42027293 3.91052943 5.08947057 3.99825675 5.00174325]\n",
      "pred [4.78538295 4.21461705 4.56746301 4.43253699 4.51649101 4.48350899]\n",
      "pred [5.18083375 3.81916625 4.60346114 4.39653886 4.72724103 4.27275897]\n",
      "pred [4.10112966 4.89887034 4.38852232 4.61147768 4.20398463 4.77563225]\n",
      "pred [4.33187469 4.66812531 4.75538042 4.24461958 4.41949224 4.58050776]\n",
      "pred [4.76241264 4.23758736 4.41546056 4.57097761 4.49806964 4.50193036]\n",
      "pred [2.88735731 6.11264269 4.45840326 4.54159674 4.19151889 4.80848111]\n",
      "pred [4.80086843 4.19913157 4.52580939 4.47419061 4.24312025 4.75687975]\n",
      "pred [4.2046617  4.7953383  4.58415837 4.41584163 3.65885151 5.34114849]\n",
      "pred [2.71457739 6.28542261 3.90062018 5.09937982 4.08628773 4.91371227]\n",
      "pred [4.01570201 4.98429799 4.50834834 4.49165166 3.54209133 5.45790867]\n",
      "pred [4.20442183 4.79557817 4.55647627 4.44352373 4.17137669 4.82862331]\n",
      "pred [3.30202647 5.69797353 3.80702059 5.19297941 3.72730015 5.27269985]\n",
      "pred [2.48965984 6.51034016 4.33247206 4.66752794 4.12551832 4.87448168]\n",
      "pred [4.03840313 4.96159687 3.95788973 5.04211027 3.8811793  5.1188207 ]\n",
      "pred [4.48558083 4.51616939 4.67410327 4.32589673 4.46682157 4.51865056]\n",
      "pred [3.23851474 5.76148526 3.74830902 5.25169098 3.88386412 5.11613588]\n",
      "(296, 20) (296, 6)\n",
      "******* Feature select: LR20  Feature type: OG-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.8979330514208576\n",
      "R2 Best score (validation) val. score :  0.5902130158221013\n",
      "R2 of the best estimator (testing dataset):  0.36011061167033076\n",
      "pred [4.19252617 4.80747383 4.0354748  4.92624645 4.41675451 4.58324549]\n",
      "pred [4.89451683 4.10548317 4.58392022 4.41607978 4.40145837 4.59854163]\n",
      "pred [4.10151483 4.89848517 2.95832308 6.04167692 3.2982722  5.7017278 ]\n",
      "pred [4.04209601 4.95790399 4.50036716 4.49963284 5.32149312 3.67850688]\n",
      "pred [4.14842691 4.85157309 3.14330106 5.85669894 2.9392915  6.0607085 ]\n",
      "pred [5.06217509 3.93782491 4.23730185 4.76269815 6.70653169 2.29346831]\n",
      "pred [4.3756946  4.6243054  4.28287064 4.71712936 4.49280733 4.50719267]\n",
      "pred [3.79588851 5.20411149 4.60973441 4.39026559 4.33961969 4.66038031]\n",
      "pred [4.26045289 4.73954711 4.76773023 4.23226977 4.49712494 4.50287506]\n",
      "pred [4.03575966 4.96424034 4.22353103 4.77646897 4.22895364 4.77104636]\n",
      "pred [4.54022759 4.45977241 4.38721803 4.61278197 3.86815089 5.13184911]\n",
      "pred [3.70366861 5.29633139 4.2016766  4.7983234  4.53979146 4.46020854]\n",
      "pred [3.74660486 5.25339514 4.58423489 4.41576511 5.33619197 3.66380803]\n",
      "pred [3.57488842 5.42511158 3.48782764 5.51217236 3.57698828 5.42301172]\n",
      "pred [4.05495921 4.94504079 4.03195696 4.96804304 3.60981425 5.39018575]\n",
      "pred [4.37286516 4.66159163 3.8149259  5.1850741  3.92342937 5.07657063]\n",
      "pred [3.10151548 5.89848452 4.48997019 4.51002981 4.38362918 4.61637082]\n",
      "pred [4.24842808 4.75157192 4.21042931 4.78957069 4.6629669  4.3370331 ]\n",
      "pred [3.51247725 5.48752275 3.48782764 5.51217236 3.57698828 5.42301172]\n",
      "pred [5.14613085 3.88832593 4.49105713 4.50894287 3.75478963 5.44043661]\n",
      "pred [3.7340083  5.2659917  4.30539055 4.69460945 3.34698924 5.65301076]\n",
      "pred [4.44969226 4.55030774 4.54517338 4.45482662 4.36215673 4.63784327]\n",
      "pred [4.16975015 4.83024985 4.1666534  4.8333466  4.83178594 4.16821406]\n",
      "pred [4.38090225 4.61909775 4.15731886 4.84268114 6.16886281 2.83113719]\n",
      "pred [3.18736345 5.81263655 4.21766608 4.78233392 4.28866739 4.71133261]\n",
      "pred [3.58143722 5.41856278 4.05236402 4.94763598 4.39822236 4.60177764]\n",
      "pred [5.07514574 4.01376379 4.50309966 4.49690034 4.54249201 4.45750799]\n",
      "pred [4.64634822 4.35365178 4.48431031 4.51568969 3.86815089 5.13184911]\n",
      "pred [2.91932289 6.08067711 3.93886022 5.06113978 3.99163667 5.00836333]\n",
      "pred [4.1805614  4.8194386  2.98652046 6.01347954 2.84252054 6.15747946]\n",
      "pred [3.65584567 5.34415433 3.25409882 5.7154047  3.01929875 5.98070125]\n",
      "pred [4.12504532 4.87495468 4.36288835 4.63711165 4.34357579 4.65642421]\n",
      "pred [4.96398849 4.03601151 3.4855642  5.5144358  3.16753767 5.83246233]\n",
      "pred [5.59245066 3.40754934 4.55978158 4.44021842 6.58168837 2.41831163]\n",
      "pred [3.91206424 5.08793576 4.34327133 4.65672867 3.58338868 5.41661132]\n",
      "pred [3.51247725 5.48752275 3.40979093 5.59020907 3.4720937  5.5279063 ]\n",
      "pred [3.08027519 5.91972481 4.08400161 4.91599839 3.83432808 5.16567192]\n",
      "pred [3.86047552 5.13952448 4.56608206 4.43391794 4.33063521 4.66936479]\n",
      "pred [5.11351782 3.97539171 4.51748857 4.48251143 4.43589549 4.56410451]\n",
      "pred [3.75781529 5.24218471 4.33571318 4.66428682 3.59362917 5.40637083]\n",
      "pred [4.65251044 4.34748956 4.30983244 4.69016756 5.89780173 3.07428621]\n",
      "pred [3.54805015 5.45194985 4.04759038 4.95240962 3.4213942  5.5786058 ]\n",
      "pred [4.35115756 4.64884244 4.5536118  4.4463882  4.58101266 4.39107528]\n",
      "pred [3.77493941 5.22506059 4.46204158 4.53795842 3.99064782 5.00935218]\n",
      "pred [3.78040979 5.21959021 4.31612385 4.68387615 3.84868888 5.15131112]\n",
      "pred [3.7340083  5.2659917  4.30539055 4.69460945 3.34698924 5.65301076]\n",
      "pred [4.21216779 4.78783221 4.07328112 4.92671888 4.51283132 4.48716868]\n",
      "pred [4.89451683 4.10548317 4.27037915 4.72962085 4.19666681 4.80333319]\n",
      "pred [3.63904601 5.36095399 4.13475803 4.81404018 4.50299964 4.49700036]\n",
      "pred [3.8797296  5.1202704  4.49978321 4.449015   4.11610783 4.88389217]\n",
      "pred [4.29128619 4.70871381 4.22283013 4.77716987 4.56811741 4.43188259]\n",
      "pred [3.14365776 5.85634224 3.94219535 5.05780465 3.98838587 5.01161413]\n",
      "pred [4.82273657 4.17726343 4.28780032 4.71219968 4.40858226 4.59141774]\n",
      "pred [3.96492974 5.03507026 4.34400465 4.65599535 3.3770043  5.6229957 ]\n",
      "pred [2.95576475 6.04423525 3.99039709 5.00960291 4.07962913 4.92037087]\n",
      "pred [3.22883863 5.77116137 3.42873004 5.57126996 3.88357412 5.11642588]\n",
      "pred [5.06955594 4.01935359 4.51748857 4.48251143 4.40877708 4.59122292]\n",
      "pred [3.49527358 5.50472642 3.91002781 5.08997219 3.65752197 5.34247803]\n",
      "pred [3.28565562 5.71434438 4.16079752 4.83920248 4.24813613 4.75186387]\n",
      "pred [3.72016867 5.27983133 3.99089646 5.00910354 4.02415638 4.97584362]\n",
      "pred [3.85361048 5.14638952 4.36198742 4.63801258 3.90663007 5.09336993]\n",
      "pred [3.6148075  5.3851925  4.31142108 4.68857892 3.44095121 5.55904879]\n",
      "(296, 20) (296, 6)\n",
      "******* Feature select: LR20  Feature type: ST-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.8640326889544013\n",
      "R2 Best score (validation) val. score :  0.577731007827406\n",
      "R2 of the best estimator (testing dataset):  0.29998303211348326\n",
      "pred [4.74494692 4.25505308 4.38588962 4.61411038 4.48295571 4.51704429]\n",
      "pred [4.4686251  4.5313749  4.34604935 4.65395065 4.61985005 4.38014995]\n",
      "pred [4.30224891 4.69775109 3.31405522 5.68594478 3.11546975 5.88453025]\n",
      "pred [3.87514003 5.12485997 4.53131511 4.46868489 5.73240453 3.26759547]\n",
      "pred [4.64671012 4.35328988 2.85124657 6.14875343 3.15947901 5.84052099]\n",
      "pred [3.94414096 5.05585904 4.60255281 4.39744719 6.43015602 2.56984398]\n",
      "pred [4.60910431 4.39089569 4.48181391 4.51818609 4.51167976 4.48832024]\n",
      "pred [3.82080682 5.17919318 3.5697223  5.4302777  4.10425509 4.89574491]\n",
      "pred [4.49824845 4.50175155 4.49362734 4.50637266 4.50703298 4.49296702]\n",
      "pred [5.08831579 3.91168421 4.31385154 4.68614846 4.44871984 4.55128016]\n",
      "pred [5.12026089 3.87973911 4.36001588 4.63998412 4.2776916  4.7223084 ]\n",
      "pred [4.24826097 4.75173903 4.3846731  4.6153269  4.41719953 4.58280047]\n",
      "pred [3.64391483 5.35608517 4.5727188  4.4272812  5.52843108 3.47156892]\n",
      "pred [3.14426057 5.85573943 3.84381562 5.07711453 3.57207273 5.42792727]\n",
      "pred [3.94488184 5.05511816 4.18579116 4.81420884 4.48426279 4.51573721]\n",
      "pred [4.38541473 4.61458527 3.87449558 5.12550442 3.67999006 5.32000994]\n",
      "pred [3.51982404 5.48017596 4.48030615 4.51969385 4.26153017 4.73846983]\n",
      "pred [4.20183748 4.79816252 4.49568318 4.50431682 4.50155363 4.49844637]\n",
      "pred [3.00019841 5.99980159 3.84042013 5.08051002 3.57207273 5.42792727]\n",
      "pred [4.71070028 4.28929972 4.220564   4.779436   3.044375   5.955625  ]\n",
      "pred [4.16477616 4.83522384 3.5732529  5.4267471  3.26890169 5.73109831]\n",
      "pred [3.83562003 5.16437997 3.78457274 5.21542726 3.70332343 5.29667657]\n",
      "pred [4.2091086  4.7908914  4.42045248 4.57954752 4.52960704 4.47039296]\n",
      "pred [4.48436354 4.51563646 4.52609089 4.47390911 6.60866381 2.39133619]\n",
      "pred [2.895301   6.104699   4.46197812 4.53802188 4.0461134  4.9538866 ]\n",
      "pred [3.5240936  5.4759064  4.43952646 4.56047354 4.0962513  4.9037487 ]\n",
      "pred [3.83406438 5.16593562 4.48398653 4.51601347 4.10543185 4.89456815]\n",
      "pred [5.12026089 3.87973911 4.36001588 4.63998412 4.2776916  4.7223084 ]\n",
      "pred [3.86767811 5.13232189 4.25458656 4.74541344 3.73160418 5.26839582]\n",
      "pred [4.38519129 4.61480871 3.11230983 5.88769017 2.95826758 6.04173242]\n",
      "pred [3.97095441 5.02904559 2.87362067 6.12637933 2.93200998 6.02516899]\n",
      "pred [3.12212743 5.87787257 4.42365841 4.57634159 3.70947137 5.29052863]\n",
      "pred [5.11080675 3.88919325 2.6804442  6.3195558  3.13638233 5.86361767]\n",
      "pred [4.80483298 4.19516702 4.32208885 4.67791115 5.54971623 3.45028377]\n",
      "pred [4.32269468 4.67730532 4.13911846 4.86088154 3.90736192 5.09263808]\n",
      "pred [3.55721715 5.44278285 3.6644045  5.25652565 3.43810859 5.56189141]\n",
      "pred [2.80706231 6.19293769 4.20187975 4.79812025 3.74192782 5.25807218]\n",
      "pred [3.87218981 5.12781019 4.42365841 4.57634159 4.37574164 4.62425836]\n",
      "pred [4.01650648 4.98349352 4.52519704 4.47480296 4.23211506 4.76788494]\n",
      "pred [3.59553126 5.40446874 4.54741427 4.45258573 3.82067764 5.17932236]\n",
      "pred [4.99935926 4.00064074 4.50405437 4.49594563 5.28521831 3.71478169]\n",
      "pred [4.00841409 4.99158591 4.01628856 4.98371144 3.46382526 5.53617474]\n",
      "pred [4.44308857 4.55691143 4.4755106  4.5244894  3.0476378  5.9523622 ]\n",
      "pred [3.72658613 5.27341387 4.39028194 4.67189051 3.90515675 5.09484325]\n",
      "pred [3.44353569 5.57072119 3.77279472 5.22720528 3.31828259 5.63889638]\n",
      "pred [4.16477616 4.83522384 3.50208196 5.49791804 3.26890169 5.73109831]\n",
      "pred [4.42964194 4.57035806 4.48512336 4.51487664 4.46942786 4.53057214]\n",
      "pred [4.76720916 4.23279084 4.30523978 4.69476022 4.71549405 4.28450595]\n",
      "pred [3.8777104  5.1222896  4.4662937  4.5337063  4.44676691 4.55323309]\n",
      "pred [4.06046661 4.93953339 4.43019802 4.56980198 4.04764896 4.95235104]\n",
      "pred [4.9891382  4.0108618  4.57679627 4.42320373 4.50703298 4.49296702]\n",
      "pred [2.82156204 6.17843796 4.02286602 4.97713398 4.01989319 4.98010681]\n",
      "pred [4.74494692 4.25505308 4.38588962 4.61411038 4.48295571 4.51704429]\n",
      "pred [3.97573168 5.02426832 3.57935889 5.42064111 3.08376624 5.91623376]\n",
      "pred [4.07737796 4.8107032  3.90297414 5.09702586 3.1931245  5.8068755 ]\n",
      "pred [4.63248392 4.36751608 2.89928401 6.10071599 3.78895982 5.25386121]\n",
      "pred [4.71869862 4.28130138 4.40775137 4.59224863 4.15143022 4.84856978]\n",
      "pred [3.03421845 5.96578155 3.92917331 4.99175684 3.62200049 5.37799951]\n",
      "pred [2.85059107 6.14940893 4.4416919  4.5583081  3.92498149 5.07501851]\n",
      "pred [4.17296129 4.82703871 3.23999593 5.84423276 3.44025376 5.55974624]\n",
      "pred [3.99410533 5.00589467 4.44986659 4.55013341 4.49119675 4.50880325]\n",
      "pred [3.96040938 5.15150946 4.09833473 4.90166527 2.90021879 6.09978121]\n",
      "(296, 30) (296, 6)\n",
      "******* Feature select: LR30  Feature type: HG-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.8688619057218445\n",
      "R2 Best score (validation) val. score :  0.5805964713833259\n",
      "R2 of the best estimator (testing dataset):  0.43345595204238224\n",
      "pred [5.04696812 3.92703978 4.49942256 4.48313744 4.14381157 4.78912167]\n",
      "pred [5.39712676 3.54686673 4.5126696  4.47928322 4.17147521 4.78713475]\n",
      "pred [4.32508382 4.79467849 3.16401908 5.90785943 3.43326563 5.52596182]\n",
      "pred [3.1825997  5.77724765 4.5674854  4.44160672 5.90533386 3.02592724]\n",
      "pred [4.44367183 4.49826074 3.48862465 5.53205161 2.98494286 6.04933072]\n",
      "pred [5.02282543 3.91616033 4.50007786 4.48140831 5.69052072 3.12516094]\n",
      "pred [3.85103494 5.15475411 4.25004159 4.76501247 4.43262509 4.53472209]\n",
      "pred [3.31548961 5.70189347 4.36322195 4.62423254 3.98945855 4.94657222]\n",
      "pred [4.4116982  4.58932633 4.47546298 4.51128619 4.40235696 4.62293787]\n",
      "pred [4.9551599  4.03852624 4.5301199  4.46608871 4.31346881 4.72107805]\n",
      "pred [4.96239256 4.07128386 4.52383902 4.49721689 4.16975798 4.8007442 ]\n",
      "pred [4.26942373 4.68498228 4.38857707 4.62247466 4.39235671 4.61586895]\n",
      "pred [3.41728433 5.57203824 4.53637584 4.46236677 5.76708307 3.1317871 ]\n",
      "pred [3.48069974 5.51682138 3.80534966 5.23225606 3.79628691 5.29130814]\n",
      "pred [4.37754162 4.70698288 4.4134489  4.58793031 4.27093438 4.69804594]\n",
      "pred [4.48241294 4.43877401 4.40424501 4.5842045  4.09338501 4.92445989]\n",
      "pred [3.2806774  5.6108642  4.62689732 4.38645307 4.5129849  4.48904796]\n",
      "pred [4.66268634 4.41101261 4.41705241 4.57323677 4.71473695 4.2288192 ]\n",
      "pred [3.30964157 5.71434077 4.17769667 4.83221651 3.60213758 5.46634303]\n",
      "pred [5.27133719 3.73265757 4.48694028 4.50919148 3.28339005 5.60678245]\n",
      "pred [3.729188   5.3616148  3.74537151 5.30366055 3.42505431 5.5383836 ]\n",
      "pred [4.02110455 4.95190775 4.60994825 4.42665717 3.90204291 5.01421515]\n",
      "pred [4.46906857 4.67610607 4.42821067 4.59294762 4.43121656 4.54050302]\n",
      "pred [4.50237147 4.5291506  4.43231993 4.61584837 5.92165264 3.0970003 ]\n",
      "pred [3.48616185 5.51677075 4.47712359 4.53066282 4.07956142 4.92076516]\n",
      "pred [3.08861116 5.88227839 4.57319456 4.4230012  4.22221028 4.7763986 ]\n",
      "pred [4.40390522 4.60634421 4.5770502  4.42115569 4.24205313 4.7419377 ]\n",
      "pred [4.28883166 4.7443551  4.51432626 4.51112876 4.20650261 4.77514116]\n",
      "pred [2.76615129 6.21090512 4.32375058 4.66571944 3.89644317 5.20878143]\n",
      "pred [3.72606701 5.27303093 3.22593698 5.85227076 2.86358222 6.07909841]\n",
      "pred [3.75894892 5.2672492  3.18402067 5.9078684  3.65149399 5.33647104]\n",
      "pred [3.04239605 5.92589082 4.39388008 4.54601754 3.79791503 5.25558519]\n",
      "pred [3.88448468 5.08845178 3.64900264 5.38812115 2.84178697 6.19634347]\n",
      "pred [5.37878057 3.56880955 4.51582636 4.49783191 4.24975165 4.81981971]\n",
      "pred [4.00399448 5.07612211 4.54085808 4.46696061 4.06390561 4.90900618]\n",
      "pred [3.51965592 5.40400442 3.70367719 5.33484799 3.7489357  5.29130814]\n",
      "pred [3.25851358 5.77592397 4.34744557 4.66224169 3.78782388 5.21765704]\n",
      "pred [3.86644119 5.18508301 4.38213435 4.61793983 4.12609458 4.78933056]\n",
      "pred [4.43005088 4.53955462 4.52293438 4.49229374 4.26364001 4.78381336]\n",
      "pred [3.84558406 5.32819805 4.38202038 4.6393328  3.6325885  5.38109392]\n",
      "pred [4.94566346 4.00319249 4.53150926 4.50728985 5.40824529 3.65367776]\n",
      "pred [3.60841251 5.45422297 4.23465259 4.78862743 3.60643671 5.40591583]\n",
      "pred [4.88204141 4.03432585 4.68169099 4.34984878 3.74809435 5.37630491]\n",
      "pred [4.11130737 4.935977   4.69105628 4.35843843 4.14857009 4.86734856]\n",
      "pred [4.02874166 4.93958647 4.40667741 4.64457596 3.9038194  5.07013798]\n",
      "pred [3.66420325 5.40178283 3.6749563  5.36948377 3.43786367 5.55036817]\n",
      "pred [4.68803463 4.31850561 4.50756051 4.51027036 4.22107448 4.68828683]\n",
      "pred [5.39712676 3.54686673 4.5126696  4.47928322 4.16796882 4.742146  ]\n",
      "pred [4.24701163 4.80082851 4.39505507 4.63210247 4.5287084  4.48972872]\n",
      "pred [4.22033099 4.82126004 4.5846892  4.42383483 4.48794234 4.52939269]\n",
      "pred [4.65181437 4.37640527 4.49815687 4.52860434 4.44968064 4.46759196]\n",
      "pred [2.97170278 6.19268008 4.21966966 4.75989972 3.78782388 5.21819823]\n",
      "pred [4.96764428 3.91932615 4.49427897 4.47351444 4.21945786 4.73968983]\n",
      "pred [4.27533597 4.84727264 3.65039015 5.37069689 3.46589493 5.4840872 ]\n",
      "pred [2.98841563 5.962068   3.35084748 5.6397462  3.43916359 5.52533204]\n",
      "pred [3.82401015 5.28124672 4.18039933 4.82878206 4.19278592 4.79085222]\n",
      "pred [4.52946981 4.48234825 4.52359062 4.5040319  4.40274721 4.54305452]\n",
      "pred [3.23227608 5.80041038 4.00160593 4.99175236 3.78677915 5.24051461]\n",
      "pred [3.30096288 5.74297202 4.44467348 4.53906916 3.78782388 5.181383  ]\n",
      "pred [3.83870406 5.24708126 3.75258983 5.26330785 3.6404676  5.36484354]\n",
      "pred [4.26598589 4.77603961 4.61999866 4.40871739 4.52184943 4.45565009]\n",
      "pred [3.33253816 5.66366086 3.81573485 5.30260151 3.27709283 5.7658936 ]\n",
      "(296, 30) (296, 6)\n",
      "******* Feature select: LR30  Feature type: OG-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.8968447126297602\n",
      "R2 Best score (validation) val. score :  0.5737709590164574\n",
      "R2 of the best estimator (testing dataset):  0.43498096974480926\n",
      "pred [5.00001622 3.89283006 4.13007999 4.89858525 4.45027117 4.61136475]\n",
      "pred [5.23932275 3.62104908 4.46463543 4.49949966 5.00220376 3.83982976]\n",
      "pred [4.27518291 4.74507668 3.31438809 5.71466435 3.27868323 5.67705612]\n",
      "pred [3.94245181 5.01398466 4.5519978  4.47309791 5.84075894 3.12352709]\n",
      "pred [4.41324191 4.47687914 2.83942721 6.24311721 3.28146575 5.85282717]\n",
      "pred [4.88015517 4.12536298 4.42207141 4.58634724 5.8712156  3.11552458]\n",
      "pred [3.79050761 5.0024082  4.33531836 4.69506871 4.43659894 4.57873334]\n",
      "pred [4.11137425 4.94766203 4.38148619 4.53380392 4.3590709  4.65361007]\n",
      "pred [4.2483614  4.77492529 4.54616677 4.49919858 4.41671417 4.58911193]\n",
      "pred [5.13680464 3.83749642 4.217241   4.81113994 4.38348288 4.48697848]\n",
      "pred [5.13452158 3.89768748 4.24356051 4.77163679 4.29827331 4.6694341 ]\n",
      "pred [4.17452214 4.79634299 4.44408734 4.50370705 4.48308498 4.53710569]\n",
      "pred [3.90147315 5.07752758 4.5955095  4.43445273 5.71505968 3.32774057]\n",
      "pred [3.4804763  5.45938418 3.52272807 5.48375071 3.6544809  5.31784759]\n",
      "pred [4.68739987 4.31974456 3.96437612 5.12450462 4.32406808 4.6790356 ]\n",
      "pred [4.00030924 5.0131157  4.24584703 4.87016265 4.4542049  4.63210714]\n",
      "pred [3.41934816 5.68588569 4.64570171 4.33171292 4.10400448 4.90414414]\n",
      "pred [4.47404276 4.51363232 4.46095272 4.5259715  4.74237982 4.30534738]\n",
      "pred [3.46406591 5.45914409 3.49105947 5.47863157 3.46580694 5.4539522 ]\n",
      "pred [5.13445522 3.76210676 4.4835765  4.50034897 3.71275253 5.32128075]\n",
      "pred [3.29473573 5.61740264 4.45380384 4.73204093 3.47849972 5.61959751]\n",
      "pred [3.96418804 5.02002525 4.5331259  4.48204322 4.31673274 4.82359929]\n",
      "pred [4.16405575 4.87932695 4.40833229 4.57658811 4.68032823 4.28890849]\n",
      "pred [4.30776116 4.686535   4.40971468 4.60643556 5.24271856 3.77678651]\n",
      "pred [3.09238202 5.87558023 4.4123024  4.56941899 4.26706134 4.73468573]\n",
      "pred [3.86182391 4.92236054 4.56001043 4.36470448 4.58374915 4.39118323]\n",
      "pred [4.86204706 4.16409142 4.4541832  4.5237285  4.40595903 4.66318828]\n",
      "pred [5.0979413  3.85123098 4.24356051 4.77163679 4.3285209  4.59908481]\n",
      "pred [2.91541479 6.14984521 3.91742229 5.03845369 3.90856099 5.21241683]\n",
      "pred [4.2782491  4.73401164 2.7763479  6.34300239 3.06259469 5.98977525]\n",
      "pred [3.75069929 5.23108436 4.00652162 5.14276733 3.29631452 5.67514516]\n",
      "pred [3.79807855 5.2766563  4.49900168 4.52456476 3.93361257 4.98518102]\n",
      "pred [4.90077283 3.9749463  3.47380378 5.6934164  3.70615279 5.34934637]\n",
      "pred [5.38776815 3.48150214 4.50600168 4.48760813 5.47462255 3.40058477]\n",
      "pred [3.99653449 4.98115973 4.55267496 4.53724973 3.86614181 5.31349078]\n",
      "pred [3.6082646  5.31505005 3.36382154 5.60407914 3.34064908 5.5873976 ]\n",
      "pred [3.55520273 5.58395604 4.19297649 4.76341859 3.94405143 4.97566105]\n",
      "pred [3.95051436 5.13134293 4.46735438 4.5167546  3.84225693 5.12718286]\n",
      "pred [4.85235619 4.24562409 4.44629802 4.57376119 4.58664622 4.49300914]\n",
      "pred [3.95280074 4.97966069 4.34457725 4.72152883 3.76424336 5.18905321]\n",
      "pred [4.90462013 4.0192561  4.34418756 4.71132502 4.54983539 4.39296648]\n",
      "pred [3.49713854 5.26656739 3.85176026 5.0558264  3.44158924 5.56511174]\n",
      "pred [4.57506397 4.35501704 4.56815708 4.39530928 3.51442409 5.49010971]\n",
      "pred [4.20892537 4.74809999 4.38372428 4.78629726 4.16358277 4.86162632]\n",
      "pred [3.59754067 5.35391795 4.40468936 4.66056381 4.08845482 4.9353012 ]\n",
      "pred [3.42019248 5.55623119 3.89800036 5.06331193 3.47849972 5.61959751]\n",
      "pred [4.3584906  4.52065089 4.17377091 4.89699554 4.3119657  4.73702644]\n",
      "pred [5.27190716 3.62220624 4.37747595 4.68282135 4.9740628  3.89625777]\n",
      "pred [3.79171975 5.19135102 4.64640243 4.36372621 4.49330223 4.49910466]\n",
      "pred [4.20351018 4.76588091 4.40139485 4.74152604 4.3454464  4.6273997 ]\n",
      "pred [4.44930361 4.53787127 4.2671489  4.74006355 4.30460941 4.68278529]\n",
      "pred [3.37226173 5.65095303 4.2465908  4.74299158 3.83596696 5.12950611]\n",
      "pred [5.09334893 3.84411745 4.12619808 4.90766487 4.30610865 4.78126564]\n",
      "pred [4.47119863 4.55049852 3.84480424 5.12227    3.16964844 5.69631493]\n",
      "pred [3.20457864 5.88891066 3.70997697 5.23991946 3.95895157 5.12401203]\n",
      "pred [3.65450738 5.15542977 3.73455779 5.32950543 3.97385347 5.10017019]\n",
      "pred [4.53981757 4.42500423 4.42559007 4.53778761 4.31993555 4.72330623]\n",
      "pred [3.15035452 5.73191233 3.91938569 5.07814135 3.67375539 5.27706491]\n",
      "pred [2.89167119 6.11178257 4.41411252 4.58777726 4.06616534 4.95299904]\n",
      "pred [3.78430765 5.33948431 4.49768024 4.56580951 4.26026465 4.77718913]\n",
      "pred [4.00697598 4.93926949 4.42105147 4.73440888 4.31566341 4.7533934 ]\n",
      "pred [3.40119615 5.49426335 4.62075542 4.40933439 3.53897569 5.33808535]\n",
      "(296, 30) (296, 6)\n",
      "******* Feature select: LR30  Feature type: ST-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.9208337773152485\n",
      "R2 Best score (validation) val. score :  0.5809775076606316\n",
      "R2 of the best estimator (testing dataset):  0.19652284717213864\n",
      "pred [4.76792433 4.19580487 4.48657402 4.49758191 4.4124105  4.59061139]\n",
      "pred [4.51612061 4.48608574 4.3942711  4.52542594 4.7273296  4.28100365]\n",
      "pred [4.36846892 4.79067776 3.3754623  5.66079331 3.01403187 5.9969027 ]\n",
      "pred [3.8237721  5.17701657 4.56959837 4.44197193 5.68807921 3.26423347]\n",
      "pred [4.64572009 4.26770027 2.43275115 6.40553123 3.23025503 5.76275979]\n",
      "pred [4.28443163 4.76979058 4.54295432 4.44439851 6.7898991  2.31042457]\n",
      "pred [4.61746137 4.48889014 4.48884172 4.51240403 4.50212481 4.51797478]\n",
      "pred [4.14789643 5.08156255 3.52046095 5.55442758 4.28305114 4.72271358]\n",
      "pred [4.21846853 4.62563312 4.50548631 4.55707319 4.67642768 4.26204627]\n",
      "pred [5.23570236 3.67329898 4.36957317 4.60135884 4.41484295 4.58473128]\n",
      "pred [5.11035942 3.84611873 4.44758632 4.55539744 4.33426199 4.68025126]\n",
      "pred [4.08338624 4.8455369  4.3566485  4.67671555 4.71443042 4.31738127]\n",
      "pred [3.23964343 5.761083   4.55536372 4.4353381  5.46476027 3.33711567]\n",
      "pred [3.03073713 5.96543795 3.8654877  5.14674317 3.50214015 5.38523324]\n",
      "pred [4.18960154 4.76301034 4.23135629 4.73092041 4.36325756 4.59513034]\n",
      "pred [4.33450817 4.69906677 4.12703156 5.04317001 3.96943589 5.10345531]\n",
      "pred [2.96547399 6.05288689 4.45805019 4.50224034 4.13114292 4.89624456]\n",
      "pred [4.22680039 4.63999187 4.47203673 4.4924161  4.80703986 4.15358118]\n",
      "pred [2.99714481 5.99861179 3.9481866  5.03671155 3.41724807 5.46623594]\n",
      "pred [4.85737526 4.13828045 4.41892319 4.58192881 2.93712855 5.8440177 ]\n",
      "pred [4.74525487 4.22031908 3.20370524 5.87883893 3.31767475 5.58607696]\n",
      "pred [4.05271344 5.0032731  3.59999188 5.41746279 3.87315388 5.13687125]\n",
      "pred [4.1390826  4.79634491 4.39016034 4.61376755 4.42184051 4.59838415]\n",
      "pred [4.08794874 4.90187682 4.5736018  4.42094363 6.81453685 2.34046492]\n",
      "pred [2.87434299 6.22188569 4.43046807 4.55182518 3.99627223 5.01380447]\n",
      "pred [4.21911565 4.80805024 4.14013346 4.96803218 4.24728995 4.73482288]\n",
      "pred [4.093564   4.89754476 4.55256992 4.48134179 3.98142354 4.97118236]\n",
      "pred [5.19813505 3.70891108 4.44758632 4.55539744 4.42960361 4.62185577]\n",
      "pred [3.59896345 5.47026255 4.14825136 4.77472243 3.62129781 5.4290001 ]\n",
      "pred [4.5422202  4.55390146 2.80430515 6.16050758 2.99411591 6.0902971 ]\n",
      "pred [3.61169526 5.45309515 2.7846738  6.02164619 3.05572171 6.02256853]\n",
      "pred [3.54990779 5.67683357 4.31694559 4.76071905 3.86311936 5.11746006]\n",
      "pred [5.03996977 3.84941731 2.33174738 6.57668094 3.25986396 5.6581764 ]\n",
      "pred [5.13267108 3.82207519 4.44861448 4.51862412 5.86012917 3.31046606]\n",
      "pred [4.3844713  4.61193955 4.36775818 4.75461271 3.89927347 5.12884523]\n",
      "pred [3.59281833 5.39663619 3.79448336 5.2097845  3.49392395 5.45830781]\n",
      "pred [2.74300134 6.31076514 4.23628371 4.80959551 3.76493708 5.31499024]\n",
      "pred [3.76945548 5.31706207 4.34157661 4.69757963 4.18888622 4.81758826]\n",
      "pred [4.34683354 4.68030218 4.52731529 4.38301475 4.53596553 4.47245319]\n",
      "pred [3.73212134 5.19518953 4.57159173 4.40573433 3.64269903 5.33923886]\n",
      "pred [4.98469615 3.92364779 4.49761551 4.50090205 5.47020329 3.60145925]\n",
      "pred [4.1367798  4.83323803 3.56952725 5.24161817 3.30744522 5.62921262]\n",
      "pred [4.56351633 4.39786875 4.46155335 4.51817516 3.34747398 5.49362483]\n",
      "pred [4.05903988 4.97459892 4.44768388 4.56276443 4.0060773  4.95228766]\n",
      "pred [3.43086137 5.48262247 3.89001646 5.21217152 3.43796356 5.56253651]\n",
      "pred [4.74525487 4.22031908 3.13492983 5.87883893 3.35218862 5.58607696]\n",
      "pred [4.44358332 4.53615206 4.36831904 4.56404201 4.34728894 4.64484625]\n",
      "pred [5.19660272 3.81620122 4.36083079 4.58662238 4.68379134 4.3950944 ]\n",
      "pred [4.04445077 4.97639112 4.43001696 4.60437615 4.65688323 4.38707481]\n",
      "pred [4.25341395 4.78074681 4.51492774 4.44255748 4.19735508 4.78265326]\n",
      "pred [4.81274846 4.1400204  4.66367778 4.39642597 4.44379985 4.48719954]\n",
      "pred [2.82099649 6.23336008 4.07706853 4.88720239 3.86614081 5.10012502]\n",
      "pred [4.91557167 3.98271038 4.48597808 4.49758191 4.41174391 4.5781129 ]\n",
      "pred [4.11388016 4.86182566 3.08388985 5.77049336 3.0858629  5.94152962]\n",
      "pred [3.96001676 4.99526155 3.86388245 5.2039623  3.81894808 5.01979206]\n",
      "pred [5.09683045 3.82228699 2.67274258 6.43586852 3.58923762 5.39991823]\n",
      "pred [4.88187708 4.16459437 4.40245973 4.64362088 4.48993481 4.66365096]\n",
      "pred [2.87894583 6.21993532 3.9007126  5.0755664  3.63655445 5.28268629]\n",
      "pred [2.88513783 6.14827908 4.38116753 4.57921126 3.74135319 5.21738088]\n",
      "pred [4.80696939 4.36381637 3.60311042 5.39749586 3.67899862 5.27795024]\n",
      "pred [4.07160156 4.86061639 4.44582867 4.52193928 4.38400937 4.58568268]\n",
      "pred [4.14480107 4.77271396 4.40779989 4.74063284 2.86346023 6.1135443 ]\n",
      "(296, 40) (296, 6)\n",
      "******* Feature select: LR40  Feature type: HG-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.9327788617365348\n",
      "R2 Best score (validation) val. score :  0.6409989592949286\n",
      "R2 of the best estimator (testing dataset):  0.32076684077984463\n",
      "pred [4.81400831 4.18599169 4.54834416 4.45165584 4.26706886 4.73293114]\n",
      "pred [5.20628809 3.71730785 4.56971405 4.43028595 4.02257191 4.93341246]\n",
      "pred [4.05103253 4.94896747 4.22678435 4.77321565 3.33546003 5.66453997]\n",
      "pred [3.41398958 5.58601042 4.52277641 4.4610816  5.90055185 3.13317127]\n",
      "pred [4.65350192 4.34649808 3.13304226 5.86695774 2.95389291 6.04610709]\n",
      "pred [5.32652122 3.67347878 4.55202053 4.44797947 5.66169573 3.33830427]\n",
      "pred [4.66909348 4.33090652 4.36058556 4.65221434 4.53368765 4.46631235]\n",
      "pred [3.48860486 5.51139514 3.45400435 5.54599565 3.88821487 5.11178513]\n",
      "pred [4.36916119 4.63083881 4.62366008 4.37633992 4.40030207 4.59969793]\n",
      "pred [4.87543858 4.12456142 4.55175494 4.44824506 4.31678313 4.68321687]\n",
      "pred [4.93798756 4.06201244 4.49748299 4.50251701 4.22936903 4.77063097]\n",
      "pred [3.76042206 5.23957794 4.48804864 4.51195136 4.3942321  4.6057679 ]\n",
      "pred [3.3558692  5.6441308  4.57570238 4.40815563 5.53907797 3.47842604]\n",
      "pred [3.3441312  5.6558688  4.1632115  4.8367885  3.65659239 5.31761471]\n",
      "pred [3.92643109 5.07356891 4.47097605 4.52902395 4.32104575 4.67895425]\n",
      "pred [4.43348033 4.56651967 4.25897914 4.74102086 3.93095416 5.06904584]\n",
      "pred [3.65875832 5.34124168 4.53912396 4.46087604 4.63876883 4.36123117]\n",
      "pred [4.40706747 4.59293253 4.30225071 4.69774929 4.82538111 4.17461889]\n",
      "pred [3.24363127 5.75636873 4.00759811 4.99240189 3.63307509 5.341132  ]\n",
      "pred [5.13479169 3.94161237 4.46873288 4.53126712 3.00819221 6.01955537]\n",
      "pred [4.16686684 4.83313316 3.21084885 5.78915115 3.76832385 5.23167615]\n",
      "pred [4.20901165 4.79098835 3.50585817 5.49414183 4.33586908 4.66413092]\n",
      "pred [4.41348041 4.58651959 4.34517316 4.65482684 4.68394687 4.31605313]\n",
      "pred [4.52408723 4.47591277 4.35461075 4.64538925 6.14754563 2.87037244]\n",
      "pred [2.86744074 6.13255926 4.41878962 4.58121038 4.22626124 4.77373876]\n",
      "pred [3.86522584 5.13477416 4.5000891  4.4999109  4.46312545 4.53687455]\n",
      "pred [4.0445675  4.9554325  4.49841001 4.50158999 4.27288194 4.72711806]\n",
      "pred [4.96667262 4.03332738 4.49350652 4.50649348 4.27192152 4.72807848]\n",
      "pred [2.92117631 6.07882369 4.31225357 4.68774643 3.78417515 5.21582485]\n",
      "pred [4.4121212  4.5878788  3.17557955 5.82442045 2.98796171 6.01203829]\n",
      "pred [3.5702439  5.4297561  2.96410791 6.03589209 3.34231989 5.65768011]\n",
      "pred [3.52492096 5.47507904 4.2916916  4.7083084  3.68547223 5.31452777]\n",
      "pred [4.32832466 4.74730532 3.13560736 5.86439264 3.06100503 5.93899497]\n",
      "pred [5.37876783 3.62123217 4.48282036 4.51717964 5.5836784  3.4163216 ]\n",
      "pred [3.96378646 5.03621354 4.41719981 4.58280019 4.05958953 4.94041047]\n",
      "pred [3.64844787 5.35155213 3.64066125 5.35933875 3.69450929 5.2796978 ]\n",
      "pred [2.65114137 6.34885863 4.34801016 4.65198984 3.96477289 5.03522711]\n",
      "pred [3.40965837 5.59034163 4.46730341 4.53269659 3.96682432 5.03317568]\n",
      "pred [4.19809396 4.80190604 4.49692292 4.50307708 4.18849456 4.81150544]\n",
      "pred [3.78808325 5.21191675 4.44548441 4.55451559 3.56289653 5.43710347]\n",
      "pred [5.01647988 3.96909268 4.43713917 4.56286083 5.02144725 3.97855275]\n",
      "pred [3.76353324 5.23646676 3.56525879 5.43474121 3.85003688 5.14996312]\n",
      "pred [4.54223858 4.45776142 4.5448613  4.4551387  3.61308401 5.38691599]\n",
      "pred [4.11303777 4.88696223 4.59483325 4.40516675 4.41086253 4.58913747]\n",
      "pred [3.92301215 5.07698785 3.56652817 5.43347183 3.88896075 5.11103925]\n",
      "pred [4.16686684 4.83313316 3.09052771 5.90947229 3.8053504  5.21215257]\n",
      "pred [4.4925726  4.5074274  4.43176613 4.56823387 4.33760675 4.66239325]\n",
      "pred [5.28269215 3.71730785 4.56645428 4.43354572 4.67193321 4.32806679]\n",
      "pred [4.35694515 4.64305485 4.42181225 4.57818775 4.42578956 4.57421044]\n",
      "pred [4.296359   4.703641   4.60187471 4.39812529 4.41319024 4.58680976]\n",
      "pred [4.47536157 4.52463843 4.48053599 4.51946401 4.40826188 4.59173812]\n",
      "pred [2.64440193 6.35559807 4.45695497 4.54304503 4.09511695 4.90488305]\n",
      "pred [4.8201305  4.1798695  4.54295976 4.45704024 4.62398092 4.44947295]\n",
      "pred [4.1606804  4.8393196  3.22047102 5.77952898 3.54549019 5.45450981]\n",
      "pred [2.77529396 6.22470604 3.80765606 5.19234394 3.51012424 5.48987576]\n",
      "pred [3.63412344 5.36587656 3.23171424 5.76828576 3.61469732 5.38530268]\n",
      "pred [4.61766892 4.38233108 3.99824666 5.00175334 4.38722806 4.61277194]\n",
      "pred [2.78339644 6.21660356 4.03289767 4.96710233 3.80830248 5.16590462]\n",
      "pred [2.7360282  6.2639718  4.37015621 4.62984379 3.90937487 5.09062513]\n",
      "pred [3.80664584 5.19335416 3.6310056  5.3689944  4.15375104 4.84624896]\n",
      "pred [4.16716984 4.83283016 4.48925025 4.51074975 4.63519213 4.36480787]\n",
      "pred [3.42901582 5.57098418 4.254853   4.745147   3.54878793 5.45121207]\n",
      "(296, 40) (296, 6)\n",
      "******* Feature select: LR40  Feature type: OG-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.9007328383076327\n",
      "R2 Best score (validation) val. score :  0.583096599135259\n",
      "R2 of the best estimator (testing dataset):  0.40115937085797615\n",
      "pred [5.03111125 4.09381174 4.27869989 4.69810778 4.51998619 4.55385292]\n",
      "pred [5.0132448  3.95402432 4.46658142 4.53861322 5.58178371 3.4690715 ]\n",
      "pred [4.20480204 4.82016161 3.93835228 4.97582826 3.23843115 5.8460076 ]\n",
      "pred [4.07483585 4.86114824 4.60204186 4.39112612 5.867146   3.13810397]\n",
      "pred [4.60944644 4.28550624 3.59896876 5.47725501 3.25331428 5.74454357]\n",
      "pred [4.74921867 4.23683739 4.36293087 4.6287543  6.22030177 2.88671546]\n",
      "pred [4.53880126 4.2829935  4.29226186 4.71544131 4.45527892 4.52859971]\n",
      "pred [4.34590755 4.79232629 4.23823746 4.71797042 4.2276863  4.76608315]\n",
      "pred [3.75137213 4.82349616 4.45411174 4.49156985 4.60140128 4.40386958]\n",
      "pred [4.97512186 3.98559318 4.29259417 4.68868097 4.21019303 4.81858657]\n",
      "pred [5.28862763 3.68300183 4.18194122 4.85135403 3.9727632  5.0888646 ]\n",
      "pred [3.96468029 4.92560133 4.1689332  4.8389269  4.91105762 4.15394924]\n",
      "pred [3.65891832 5.28494829 4.62150964 4.3716438  5.73346646 3.24773876]\n",
      "pred [4.02075296 4.86710091 3.50031145 5.47034979 3.57273045 5.5227852 ]\n",
      "pred [4.51304232 4.35972753 3.99430363 4.98913782 3.54583501 5.6020463 ]\n",
      "pred [4.07622646 4.89063867 4.22128406 4.87624916 3.78269905 5.15345937]\n",
      "pred [3.33833924 5.49811198 4.48428024 4.54702378 4.08775585 4.89876105]\n",
      "pred [4.37187309 4.71719543 4.20253056 4.81936807 4.60134547 4.33528516]\n",
      "pred [3.99266775 4.89674874 3.52214634 5.47034979 3.55225971 5.55700849]\n",
      "pred [5.24936081 3.78705106 4.49039676 4.50506505 3.46171189 5.50903969]\n",
      "pred [4.17120372 5.13737641 4.44810859 4.57749023 3.83887443 5.18263349]\n",
      "pred [3.93534071 5.01348799 4.51085459 4.50168095 4.21219527 4.78225578]\n",
      "pred [4.26852064 4.57101498 4.15809719 4.85789677 4.56120818 4.39376893]\n",
      "pred [5.45181504 3.62164163 4.35221129 4.65198925 6.44261979 2.57646583]\n",
      "pred [2.92029208 6.06537552 4.17573566 4.83967199 4.45181314 4.51571168]\n",
      "pred [4.19133956 4.81228999 4.11537596 4.89837349 4.35803198 4.66037527]\n",
      "pred [5.12494489 4.08193904 4.45795148 4.54334044 4.34016007 4.66987603]\n",
      "pred [5.32795944 3.61906054 4.20802441 4.80040268 3.9727632  5.0888646 ]\n",
      "pred [2.71265058 6.42704355 3.74344642 5.24405078 4.14152987 4.76500168]\n",
      "pred [4.13017282 4.82674174 3.76839512 5.16255988 3.37539135 5.61390469]\n",
      "pred [3.8872991  4.81648484 2.76909697 6.10461728 3.43161888 5.61388802]\n",
      "pred [3.96719347 5.12908137 4.19251884 4.77434634 3.83479564 5.36814679]\n",
      "pred [4.79002234 4.36787113 4.17492259 4.80377347 3.40073729 5.57973899]\n",
      "pred [5.41333189 3.63171361 4.44589952 4.48530503 6.41275247 2.61300429]\n",
      "pred [4.3368471  4.68782183 4.38487203 4.60136816 3.70801358 5.333805  ]\n",
      "pred [4.00981915 4.85368994 3.49543428 5.44564274 3.1310358  5.99425015]\n",
      "pred [3.01603655 6.00607743 3.95303635 5.05871257 4.23970495 4.65785287]\n",
      "pred [4.20789715 4.99115293 4.10734038 4.85615384 3.7862193  5.30715699]\n",
      "pred [5.01967633 4.08240316 4.53175755 4.47950242 4.19431236 4.6651569 ]\n",
      "pred [3.89605492 5.16703503 4.40025681 4.6168822  3.23960649 5.73778756]\n",
      "pred [4.91017971 4.07685768 4.41691642 4.62662914 5.19070644 3.91568375]\n",
      "pred [3.53647471 5.43794486 4.35911512 4.65643478 3.32145896 5.63631785]\n",
      "pred [4.49986194 4.49508699 4.55747403 4.46939069 3.78065933 5.24324177]\n",
      "pred [3.48590827 5.3505342  4.42017354 4.52902993 3.90630008 5.12393085]\n",
      "pred [3.88718204 5.09033959 4.30269043 4.6270528  3.85344628 5.08435516]\n",
      "pred [4.17120372 5.09348468 4.41169751 4.61044802 3.83887443 5.18263349]\n",
      "pred [4.42001585 4.54753604 4.25439158 4.7049579  4.44637343 4.56217572]\n",
      "pred [5.0132448  3.95402432 4.27709665 4.68691744 4.8413167  4.12335419]\n",
      "pred [4.10218914 4.89738832 4.27983083 4.78454952 4.4839886  4.4979171 ]\n",
      "pred [3.83462703 5.19380739 4.58943988 4.42316297 4.06042913 4.85176741]\n",
      "pred [4.29503627 4.54899369 4.44862717 4.59745486 4.63348247 4.36934783]\n",
      "pred [2.76453201 6.32280932 3.92964815 5.07569289 3.89539565 5.12551659]\n",
      "pred [5.1894532  3.78701034 4.25603668 4.73116907 4.46859354 4.65002421]\n",
      "pred [4.47845801 4.66460122 4.23471733 4.77484867 3.01410066 6.05755705]\n",
      "pred [2.91410553 6.10162348 3.8189912  5.14131007 4.22485154 4.7678626 ]\n",
      "pred [3.93373651 4.95851166 4.12618084 4.88335208 3.67765128 5.33021721]\n",
      "pred [4.28950853 4.75609329 4.43671073 4.55747136 4.12866728 4.829297  ]\n",
      "pred [3.60324655 5.33174593 3.90079497 5.09025898 3.57932754 5.48809768]\n",
      "pred [2.92471516 6.07211088 4.15809719 4.85789677 4.14596815 4.84167366]\n",
      "pred [3.72417572 5.25097589 4.23667938 4.67926733 4.06697653 4.86287896]\n",
      "pred [3.8697177  5.0433218  4.52671798 4.51790619 4.04169598 4.96928922]\n",
      "pred [3.41624152 5.85779178 4.55887562 4.43422153 3.61083996 5.43391405]\n",
      "(296, 40) (296, 6)\n",
      "******* Feature select: LR40  Feature type: ST-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.8876316927449707\n",
      "R2 Best score (validation) val. score :  0.5744627890580616\n",
      "R2 of the best estimator (testing dataset):  0.24241535659430938\n",
      "pred [4.62547243 4.37452757 4.32329109 4.67670891 4.43587728 4.56412272]\n",
      "pred [4.47433072 4.52566928 4.2808583  4.7191417  4.36698174 4.63301826]\n",
      "pred [4.05727074 4.94272926 3.47676633 5.52323367 2.94827825 6.05172175]\n",
      "pred [3.74216427 5.25783573 4.56148178 4.43851822 5.63026654 3.36973346]\n",
      "pred [4.58995256 4.41004744 2.90154703 6.09845297 2.92538676 6.1477317 ]\n",
      "pred [4.26261187 4.73738813 4.55228173 4.44771827 6.56279684 2.39800657]\n",
      "pred [4.3444612  4.6555388  4.47109584 4.52890416 4.40757532 4.54241405]\n",
      "pred [4.00532086 4.99467914 3.75153484 5.24846516 4.09108272 4.90891728]\n",
      "pred [4.20864927 4.79135073 4.72602284 4.27397716 4.61227497 4.38772503]\n",
      "pred [5.12813621 3.87186379 4.30753447 4.69246553 4.4021248  4.5978752 ]\n",
      "pred [4.79851551 4.20148449 4.35310398 4.64689602 4.25547239 4.74452761]\n",
      "pred [4.12553996 4.87446004 4.41114424 4.58885576 4.65562831 4.34437169]\n",
      "pred [2.96368146 6.03631854 4.59646226 4.40353774 5.43800831 3.56199169]\n",
      "pred [3.21168093 5.78527204 3.95836801 5.0614744  3.60952625 5.39047375]\n",
      "pred [3.98754698 4.99982302 4.34995964 4.65004036 4.28829972 4.71170028]\n",
      "pred [4.55042099 4.44957901 4.08403282 4.91596718 3.89582066 5.10417934]\n",
      "pred [3.21673921 5.78630781 4.46538032 4.53461968 4.18001439 4.81998561]\n",
      "pred [4.31897966 4.68102034 4.48889904 4.51110096 4.78409389 4.21590611]\n",
      "pred [3.09591335 5.90103962 3.97080171 5.04904069 3.56259237 5.43740763]\n",
      "pred [4.53158929 4.47729117 4.18952402 4.81047598 3.10091889 5.89908111]\n",
      "pred [4.34578794 4.65725909 3.35928666 5.64071334 3.44007582 5.55992418]\n",
      "pred [3.94385482 5.04726472 3.7652984  5.2347016  3.92102541 5.07897459]\n",
      "pred [4.29455353 4.70544647 4.47386093 4.52613907 4.3536032  4.6463968 ]\n",
      "pred [4.28588241 4.71411759 4.60491704 4.39508296 6.38090732 2.61909268]\n",
      "pred [3.03262264 5.96737736 4.45617132 4.54382868 3.99064416 5.00935584]\n",
      "pred [4.07549377 4.92450623 3.99432589 5.00567411 3.99911311 5.00088689]\n",
      "pred [3.96117934 5.03882066 4.50440923 4.49559077 4.19910433 4.80089567]\n",
      "pred [5.01012385 3.98987615 4.35310398 4.64689602 4.37506617 4.62493383]\n",
      "pred [3.63340605 5.37547441 4.25646717 4.81039753 3.70375314 5.29624686]\n",
      "pred [4.57516137 4.41595816 3.21409367 5.78590633 2.92417226 6.07582774]\n",
      "pred [4.03366179 4.96633821 2.87445133 6.12554867 2.9155958  6.0844042 ]\n",
      "pred [3.26940631 5.73059369 4.45855247 4.54144753 3.6027965  5.3972035 ]\n",
      "pred [4.98366202 4.01633798 2.82987113 6.17012887 3.16091256 5.83908744]\n",
      "pred [4.76475101 4.24412945 4.28799565 4.71200435 5.63578238 3.32502103]\n",
      "pred [4.29145777 4.70854223 4.21975042 4.78024958 3.84714731 5.15285269]\n",
      "pred [3.63617442 5.36077855 3.79777037 5.22207203 3.36912122 5.63087878]\n",
      "pred [3.03092937 5.96907063 4.29740634 4.70259366 3.63365054 5.36634946]\n",
      "pred [3.75768807 5.24231193 4.49717397 4.50282603 4.34033398 4.65966602]\n",
      "pred [3.99020012 5.00979988 4.64835442 4.35164558 4.29352267 4.70647733]\n",
      "pred [3.5280196  5.4719804  4.57643242 4.42356758 3.54576091 5.43513182]\n",
      "pred [5.02214233 3.97785767 4.54608192 4.45391808 6.36279524 2.63720476]\n",
      "pred [3.98449804 5.01550196 3.62206187 5.37793813 3.49264539 5.50735461]\n",
      "pred [4.3628693  4.6371307  4.50477114 4.49522886 3.19242395 5.80757605]\n",
      "pred [3.93538435 5.06531816 4.52730627 4.47269373 3.84256431 5.15743569]\n",
      "pred [3.58369678 5.68649224 3.58069612 5.41930388 3.42337853 5.57662147]\n",
      "pred [4.38820379 4.61484324 3.12287126 5.87712874 3.44007582 5.55992418]\n",
      "pred [4.39253569 4.59533717 4.62992046 4.37007954 4.39311885 4.60688115]\n",
      "pred [4.94584784 4.05415216 4.37863886 4.62136114 4.64674159 4.35325841]\n",
      "pred [4.26342584 4.73657416 4.3475773  4.6524227  4.58067492 4.41932508]\n",
      "pred [4.15773622 4.84226378 4.72544367 4.27455633 4.01559413 4.98440587]\n",
      "pred [4.69626912 4.29160375 4.67282339 4.32717661 4.52096682 4.47903318]\n",
      "pred [3.24462393 5.75537607 4.14332195 4.85667805 3.82350411 5.17649589]\n",
      "pred [4.86330282 4.13669718 4.35834358 4.64165642 4.46255042 4.53744958]\n",
      "pred [4.14086166 4.85913834 3.25684268 5.74315732 3.19427558 5.80572442]\n",
      "pred [4.04435329 4.95259968 3.77244175 5.22755825 3.24757415 5.75242585]\n",
      "pred [4.92017625 4.07982375 2.87658625 6.12341375 3.69351716 5.30648284]\n",
      "pred [4.75763738 4.24236262 4.46160067 4.53839933 4.15504294 4.84495706]\n",
      "pred [3.09147248 5.9054805  3.89011826 5.10988174 3.5838713  5.4161287 ]\n",
      "pred [3.06996565 5.93003435 4.36766822 4.54172672 3.81048992 5.18951008]\n",
      "pred [4.47653088 4.52651615 3.73713612 5.26286388 3.66276716 5.33723284]\n",
      "pred [4.15005805 4.83781481 4.47872915 4.52127085 4.31047514 4.65180969]\n",
      "pred [4.02335919 4.97664081 3.5886092  5.4113908  3.01343786 5.98656214]\n",
      "(296, 61) (296, 6)\n",
      "******* Feature select: PCA99  Feature type: HG-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.9234339396725765\n",
      "R2 Best score (validation) val. score :  0.5737107708525461\n",
      "R2 of the best estimator (testing dataset):  0.2478843835486574\n",
      "pred [4.65435422 4.34564578 4.56714769 4.43285231 3.96914982 5.03085018]\n",
      "pred [4.92174068 4.07825932 4.32370893 4.67629107 4.15138983 4.84861017]\n",
      "pred [3.58726438 5.41273562 4.50557559 4.49442441 3.50022928 5.49977072]\n",
      "pred [3.75380948 5.24619052 4.40146864 4.59853136 5.00516603 3.99483397]\n",
      "pred [4.33802625 4.66197375 4.07203413 4.92796587 3.56812712 5.43187288]\n",
      "pred [4.89931336 4.10068664 4.46856336 4.53143664 5.07066879 3.92933121]\n",
      "pred [4.86075383 4.13924617 4.47496544 4.52503456 4.60277788 4.39722212]\n",
      "pred [3.7831829  5.2168171  4.48873933 4.51126067 3.91249994 5.08750006]\n",
      "pred [4.28514641 4.71485359 4.24775168 4.75224832 4.59077481 4.40922519]\n",
      "pred [4.78479    4.21521    4.30739608 4.69260392 4.10784322 4.89215678]\n",
      "pred [4.3886506  4.6113494  4.23918053 4.76081947 4.12309117 4.87690883]\n",
      "pred [4.24729828 4.75270172 4.59998229 4.40001771 4.56948155 4.43051845]\n",
      "pred [3.86321997 5.13678003 4.43526759 4.56473241 5.08063645 3.91936355]\n",
      "pred [3.41774465 5.58225535 4.41175567 4.58824433 4.16338587 4.83661413]\n",
      "pred [4.55923721 4.44076279 4.49540546 4.50459454 4.33627911 4.66372089]\n",
      "pred [4.53866492 4.46133508 4.33094674 4.66905326 4.42903837 4.57096163]\n",
      "pred [4.39832472 4.60167528 4.37005637 4.62994363 3.96338131 5.03661869]\n",
      "pred [4.26857771 4.73142229 4.4741645  4.5258355  4.39994372 4.60005628]\n",
      "pred [3.53623447 5.46376553 4.49800945 4.50199055 4.08278304 4.91721696]\n",
      "pred [4.83607492 4.16392508 4.54685487 4.45314513 3.91805283 5.08194717]\n",
      "pred [4.12944881 4.87055119 4.03167219 4.96832781 3.66615411 5.33384589]\n",
      "pred [4.22946035 4.77053965 4.5084701  4.4915299  4.48137837 4.51862163]\n",
      "pred [4.35549223 4.64450777 4.55370285 4.44629715 4.32835084 4.67164916]\n",
      "pred [4.47567362 4.52432638 4.47185153 4.52814847 5.68851456 3.31148544]\n",
      "pred [3.17520566 5.82479434 4.51969681 4.48030319 4.23810914 4.76189086]\n",
      "pred [4.16778276 4.83221724 4.52556991 4.47443009 4.36309723 4.63690277]\n",
      "pred [4.90126154 4.09873846 4.2498648  4.7501352  4.67263239 4.32736761]\n",
      "pred [4.37304317 4.62695683 4.26969954 4.73030046 4.11400744 4.88599256]\n",
      "pred [3.87784583 5.12215417 4.41158447 4.58841553 4.41116837 4.58883163]\n",
      "pred [4.29119984 4.70880016 3.67885846 5.32114154 3.29515571 5.70484429]\n",
      "pred [4.32895462 4.67104538 3.67385827 5.32614173 3.91007388 5.08992612]\n",
      "pred [3.82908494 5.17091506 4.31344662 4.68655338 4.04478928 4.95521072]\n",
      "pred [4.28422558 4.71577442 3.92830265 5.07169735 3.67036467 5.32963533]\n",
      "pred [4.83514892 4.16485108 4.72411638 4.27588362 4.86096417 4.13903583]\n",
      "pred [4.26358482 4.73641518 4.39295144 4.60704856 4.72961898 4.27038102]\n",
      "pred [3.47638841 5.52361159 4.43988988 4.56011012 3.82610372 5.17389628]\n",
      "pred [3.59145673 5.40854327 4.51093349 4.48906651 4.21843111 4.78156889]\n",
      "pred [3.88459116 5.11540884 4.38948493 4.61051507 4.10041836 4.89958164]\n",
      "pred [5.0066151  3.9933849  4.40083108 4.59916892 4.23251723 4.76748277]\n",
      "pred [3.7267776  5.2732224  4.55941254 4.44058746 3.75247205 5.24752795]\n",
      "pred [5.23645077 3.76354923 4.50426868 4.49573132 5.342683   3.657317  ]\n",
      "pred [3.64227323 5.35772677 4.24316408 4.75683592 3.60707717 5.39292283]\n",
      "pred [4.74185295 4.25814705 4.55623779 4.44376221 3.98121849 5.01878151]\n",
      "pred [4.03504126 4.96495874 4.53013366 4.46986634 4.51050668 4.48949332]\n",
      "pred [4.16228702 4.83771298 4.48822303 4.51177697 3.97011587 5.02988413]\n",
      "pred [4.1776206  4.8223794  4.08763656 4.91236344 3.64901682 5.35098318]\n",
      "pred [4.85253192 4.14746808 4.36350642 4.63649358 4.44268487 4.55731513]\n",
      "pred [5.30787383 3.69212617 4.27951524 4.72048476 4.81104285 4.18895715]\n",
      "pred [4.04604331 4.95395669 4.35538509 4.64461491 4.62741184 4.37258816]\n",
      "pred [4.105681   4.894319   4.27386054 4.72613946 4.24733644 4.75266356]\n",
      "pred [5.10304967 3.89695033 4.36436377 4.63563623 4.84249341 4.15750659]\n",
      "pred [3.23079057 5.76920943 4.42904013 4.57095987 4.14163008 4.85836992]\n",
      "pred [4.7549032  4.2450968  4.50818068 4.49181932 4.03489651 4.96510349]\n",
      "pred [3.80380656 5.19619344 4.35002775 4.64997225 4.16064906 4.83935094]\n",
      "pred [3.64044625 5.35955375 4.38509413 4.61490587 4.41171618 4.58828382]\n",
      "pred [4.14237203 4.85762797 4.35706019 4.64293981 4.06416254 4.93583746]\n",
      "pred [5.14024385 3.85975615 4.56418564 4.43581436 4.55019354 4.44980646]\n",
      "pred [3.50151633 5.49848367 4.41173697 4.58826303 4.11583079 4.88416921]\n",
      "pred [3.39623218 5.60376782 4.57664992 4.42335008 4.07535261 4.92464739]\n",
      "pred [3.83217828 5.16782172 4.20037299 4.79962701 3.94103179 5.05896821]\n",
      "pred [4.634199   4.365801   4.52442829 4.47557171 4.57687102 4.42312898]\n",
      "pred [3.68472858 5.31527142 4.33316516 4.66683484 3.793042   5.206958  ]\n",
      "(296, 39) (296, 6)\n",
      "******* Feature select: PCA99  Feature type: OG-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.9176248123894574\n",
      "R2 Best score (validation) val. score :  0.5132325388323683\n",
      "R2 of the best estimator (testing dataset):  0.17999810161797983\n",
      "pred [4.78969432 4.21030568 4.7094231  4.2905769  4.77524179 4.22475821]\n",
      "pred [4.92760883 4.07239117 4.55415866 4.44584134 4.37257017 4.62742983]\n",
      "pred [3.24972236 5.75027764 4.38431861 4.61568139 4.28237802 4.71762198]\n",
      "pred [4.75284635 4.24715365 4.53531878 4.46468122 5.75166013 3.24833987]\n",
      "pred [4.22627837 4.77372163 3.88856089 5.11143911 4.05678427 4.94321573]\n",
      "pred [5.13986712 3.86013288 4.47462523 4.52537477 5.08799347 3.98998988]\n",
      "pred [4.22467882 4.77532118 4.20012989 4.79987011 4.73616249 4.26383751]\n",
      "pred [3.47816776 5.52183224 4.8557465  4.1442535  4.45972482 4.54027518]\n",
      "pred [4.85005955 4.14994045 4.71589456 4.28410544 4.63980215 4.36019785]\n",
      "pred [5.00200207 3.99799793 4.64630158 4.35369842 4.43806669 4.56193331]\n",
      "pred [5.06055808 3.93944192 4.6675827  4.3324173  4.57055998 4.42944002]\n",
      "pred [4.64021458 4.35978542 4.62772307 4.37227693 3.80175936 5.19824064]\n",
      "pred [4.49833881 4.50166119 4.56657172 4.43342828 5.52621373 3.47378627]\n",
      "pred [4.00891856 4.99108144 4.13987149 4.86012851 4.40265743 4.59734257]\n",
      "pred [3.91896697 5.08103303 4.55686212 4.44313788 4.52152171 4.47847829]\n",
      "pred [4.54076487 4.45923513 4.4363682  4.5636318  4.2404784  4.7595216 ]\n",
      "pred [3.99862035 5.00137965 4.64356233 4.35643767 4.46595583 4.53404417]\n",
      "pred [4.15689915 4.84310085 4.56329098 4.43670902 4.78281593 4.21718407]\n",
      "pred [3.93885219 5.06114781 4.15465399 4.84534601 4.40265743 4.59734257]\n",
      "pred [5.13507541 3.86492459 4.63762195 4.36237805 3.77271099 5.22728901]\n",
      "pred [3.9764578  5.0235422  4.7171209  4.2828791  4.01555332 4.98444668]\n",
      "pred [4.19719659 4.80280341 4.72845197 4.27154803 4.63769825 4.36230175]\n",
      "pred [3.7901037  5.2098963  4.62167386 4.37832614 4.84761306 4.15238694]\n",
      "pred [5.07396367 3.92603633 4.55388625 4.44611375 6.05288791 2.94711209]\n",
      "pred [3.7507588  5.2492412  4.64532526 4.35467474 4.57524558 4.42475442]\n",
      "pred [4.71867367 4.28132633 4.08972161 4.91027839 4.92000492 4.07999508]\n",
      "pred [4.15028251 4.84971749 4.54887144 4.45112856 4.31634609 4.68365391]\n",
      "pred [5.06970258 3.93029742 4.67790902 4.32209098 4.57230275 4.42769725]\n",
      "pred [3.55392525 5.50122149 4.05038223 4.94961777 4.2463153  4.7536847 ]\n",
      "pred [4.04050865 4.95949135 3.78070493 5.21929507 4.17005295 4.82994705]\n",
      "pred [4.28238115 4.71761885 4.21942669 4.78057331 3.9014761  5.0985239 ]\n",
      "pred [4.29277823 4.70722177 4.43627277 4.56372723 4.59769649 4.40230351]\n",
      "pred [3.8286975  5.1713025  4.41647122 4.58352878 3.70922223 5.29077777]\n",
      "pred [5.08790889 3.91209111 4.66379363 4.33620637 5.61329949 3.38670051]\n",
      "pred [3.85859694 5.14140306 4.53337116 4.46662884 4.35432568 4.64567432]\n",
      "pred [4.03432228 5.02082446 3.92206152 5.07793848 4.38784456 4.61215544]\n",
      "pred [3.51390632 5.48609368 4.42665957 4.57334043 4.7255373  4.2744627 ]\n",
      "pred [4.27879936 4.72120064 4.35221597 4.64778403 4.39814902 4.60185098]\n",
      "pred [4.03264895 4.96735105 4.55723834 4.44276166 4.30463947 4.69536053]\n",
      "pred [3.68387139 5.31612861 4.60357638 4.39642362 4.44648865 4.55351135]\n",
      "pred [5.0425894  3.9574106  4.64540031 4.35459969 5.0418615  4.03612185]\n",
      "pred [3.69106189 5.30893811 4.55884452 4.44115548 4.06802014 4.93197986]\n",
      "pred [4.83091404 4.16908596 4.74838816 4.25161184 4.89178739 4.10821261]\n",
      "pred [3.96685221 5.03314779 4.57393196 4.42606804 4.49480108 4.50519892]\n",
      "pred [3.50575858 5.49424142 4.5704699  4.4295301  4.19079451 4.80920549]\n",
      "pred [3.9764578  5.0235422  4.7171209  4.2828791  4.01555332 4.98444668]\n",
      "pred [5.19223064 3.80776936 4.57267956 4.42732044 4.55923514 4.44076486]\n",
      "pred [4.94862555 4.05137445 4.64068144 4.35931856 4.36725098 4.63274902]\n",
      "pred [4.73389145 4.26610855 4.34611373 4.65388627 4.69561262 4.30438738]\n",
      "pred [3.98186627 5.01813373 4.67928098 4.32071902 4.74675395 4.25324605]\n",
      "pred [5.34817979 3.65182021 4.63425841 4.36574159 4.88367748 4.11632252]\n",
      "pred [3.78205422 5.21794578 4.63445879 4.36554121 4.56059372 4.43940628]\n",
      "pred [5.39512565 3.60487435 4.53932583 4.46067417 4.52642706 4.47357294]\n",
      "pred [3.87855794 5.12144206 4.51344289 4.48655711 4.08184742 4.91815258]\n",
      "pred [3.95918361 5.09596313 4.06636541 4.93363459 4.61512927 4.38487073]\n",
      "pred [4.19818863 4.80181137 4.49230459 4.50769541 4.15000123 4.84999877]\n",
      "pred [4.22698301 4.77301699 4.54733319 4.45266681 4.45699985 4.54300015]\n",
      "pred [4.52807361 4.47192639 4.42848743 4.57151257 4.40265743 4.59734257]\n",
      "pred [3.78768172 5.21231828 4.5847457  4.4152543  4.59037035 4.40962965]\n",
      "pred [4.00644552 4.99355448 4.70940343 4.29059657 4.70989173 4.29010827]\n",
      "pred [4.3439818  4.6560182  4.64324336 4.35675664 4.28818654 4.71181346]\n",
      "pred [3.60404288 5.39595712 4.57573289 4.42426711 4.46501621 4.53498379]\n",
      "(296, 32) (296, 6)\n",
      "******* Feature select: PCA99  Feature type: ST-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.8864027511224583\n",
      "R2 Best score (validation) val. score :  0.4556317116257424\n",
      "R2 of the best estimator (testing dataset):  0.33666609273970144\n",
      "pred [4.42017903 4.57982097 4.60461492 4.39538508 4.54056405 4.45943595]\n",
      "pred [5.06620811 3.93379189 4.32245286 4.67754714 3.85097212 5.14902788]\n",
      "pred [3.73850451 5.26149549 4.32891529 4.67108471 3.19531289 5.92963123]\n",
      "pred [3.70189437 5.29810563 4.54794761 4.45205239 4.83406885 4.16593115]\n",
      "pred [4.20298709 4.79701291 4.05557721 4.94442279 3.5424677  5.4575323 ]\n",
      "pred [5.20177544 3.79822456 4.31111342 4.68888658 4.70476547 4.29523453]\n",
      "pred [4.61571161 4.38428839 4.4848847  4.5151153  3.93403352 5.06596648]\n",
      "pred [3.5822816  5.4177184  4.04430691 4.95569309 4.11797738 4.88202262]\n",
      "pred [4.30046532 4.69953468 4.5103433  4.4896567  3.64581481 5.35418519]\n",
      "pred [4.03864085 4.96135915 4.3437437  4.6562563  4.34116908 4.65883092]\n",
      "pred [4.01327065 4.98672935 4.36584279 4.63415721 4.19687613 4.80312387]\n",
      "pred [4.29602405 4.70397595 4.21812166 4.78187834 3.96588646 5.03411354]\n",
      "pred [3.72706226 5.27293774 4.50617883 4.49382117 4.38439788 4.61560212]\n",
      "pred [3.77224084 5.22775916 4.13215134 4.86784866 3.47448224 5.52551776]\n",
      "pred [4.56776332 4.43223668 4.65657252 4.34342748 3.79603971 5.20396029]\n",
      "pred [4.33986296 4.66013704 4.402648   4.597352   3.67654208 5.32345792]\n",
      "pred [3.37900683 5.62099317 4.40018642 4.59981358 4.41758136 4.58241864]\n",
      "pred [4.23043473 4.76956527 4.64822051 4.35177949 4.41831159 4.58168841]\n",
      "pred [3.75094115 5.24905885 4.12069389 4.87930611 3.4908392  5.5091608 ]\n",
      "pred [4.58724088 4.41275912 4.42006353 4.57993647 3.92894585 5.07105415]\n",
      "pred [4.07069898 4.92930102 4.30666103 4.69333897 4.18758557 4.81241443]\n",
      "pred [4.38584136 4.61415864 4.23742572 4.76257428 3.84603159 5.15396841]\n",
      "pred [4.16197056 4.83802944 4.49839155 4.50160845 4.66174539 4.33825461]\n",
      "pred [3.83140701 5.16859299 4.35713718 4.64286282 4.47846464 4.52153536]\n",
      "pred [4.07605758 4.92394242 4.43419749 4.56580251 3.6096896  5.3903104 ]\n",
      "pred [3.7336512  5.2663488  4.02387256 4.97612744 4.25280923 4.74719077]\n",
      "pred [3.70909981 5.29090019 4.41426621 4.58573379 4.6841446  4.3158554 ]\n",
      "pred [4.01327065 4.98672935 4.39053069 4.60946931 4.18057044 4.81942956]\n",
      "pred [3.30978205 5.69021795 4.24874347 4.75125653 3.88169115 5.11830885]\n",
      "pred [3.84003435 5.15996565 3.66773732 5.33226268 3.22550616 5.77449384]\n",
      "pred [5.04612264 3.95387736 3.13482509 5.86517491 3.20754631 5.71634433]\n",
      "pred [4.12611806 4.87388194 4.31942253 4.68057747 3.806969   5.193031  ]\n",
      "pred [3.91627128 5.08372872 3.90006676 5.09993324 3.77964161 5.22035839]\n",
      "pred [5.09605741 3.90394259 4.54088605 4.45911395 4.99295548 4.16443443]\n",
      "pred [3.58380411 5.41619589 4.34961697 4.65038303 3.88237836 5.11762164]\n",
      "pred [3.70366467 5.29633533 4.10589707 4.89410293 3.50834766 5.49165234]\n",
      "pred [3.13161792 5.86838208 4.50132194 4.49867806 3.93908681 5.06091319]\n",
      "pred [3.89222039 5.10777961 4.52837251 4.47162749 3.79897604 5.20102396]\n",
      "pred [3.88651058 5.11348942 4.19329445 4.80670555 4.70876726 4.29123274]\n",
      "pred [4.31771127 4.68228873 4.51545512 4.48454488 3.57600002 5.42399998]\n",
      "pred [4.48464735 4.51535265 4.42761016 4.57238984 4.7503159  4.2496841 ]\n",
      "pred [3.95708233 5.04291767 4.49170102 4.50829898 3.88173314 5.11826686]\n",
      "pred [4.65042314 4.34957686 4.42647258 4.57352742 3.30562685 5.69437315]\n",
      "pred [4.3667893  4.6332107  4.69518248 4.30481752 3.93651575 5.06348425]\n",
      "pred [3.70353097 5.29646903 4.196705   4.803295   4.2351544  4.7648456 ]\n",
      "pred [4.09024782 4.90975218 4.34644649 4.65355351 4.21424434 4.78575566]\n",
      "pred [4.38299708 4.61700292 4.47161902 4.52838098 4.57791062 4.42208938]\n",
      "pred [5.03546211 3.96453789 4.30514952 4.69485048 3.85041804 5.14958196]\n",
      "pred [4.04129059 4.95870941 4.31315093 4.68684907 4.63267752 4.36732248]\n",
      "pred [4.274151   4.725849   4.69573571 4.30426429 4.1218302  4.8781698 ]\n",
      "pred [4.35243626 4.64756374 4.49644735 4.50355265 4.37893404 4.62106596]\n",
      "pred [3.05358218 5.94641782 4.48033203 4.51966797 3.74076444 5.25923556]\n",
      "pred [4.02877187 4.97122813 4.402073   4.597927   4.22266244 4.77733756]\n",
      "pred [4.13482373 4.86517627 4.30542104 4.69457896 3.67539645 5.32460355]\n",
      "pred [3.35828819 5.64171181 4.27094662 4.72905338 3.66372776 5.33627224]\n",
      "pred [3.97936851 5.02063149 4.23588332 4.76411668 3.93854383 5.06145617]\n",
      "pred [3.8010877  5.1989123  4.26204446 4.73795554 4.74163539 4.25836461]\n",
      "pred [3.77224084 5.22775916 4.20859068 4.79140932 3.60787548 5.39212452]\n",
      "pred [3.10729095 5.89270905 4.49101251 4.50898749 3.69690185 5.30309815]\n",
      "pred [4.17124038 4.82875962 4.50532878 4.49467122 4.17766156 4.82233844]\n",
      "pred [4.34888974 4.65111026 4.50847893 4.49152107 4.04664432 4.95335568]\n",
      "pred [4.0679783  4.9320217  4.32062177 4.67937823 4.06045902 4.93954098]\n",
      "(296, 183) (296, 6)\n",
      "******* Feature select: PCA9999  Feature type: HG-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.9858099162362174\n",
      "R2 Best score (validation) val. score :  0.6039130598302255\n",
      "R2 of the best estimator (testing dataset):  0.28413947812813306\n",
      "pred [4.12373895 4.85376479 4.44980259 4.53980192 3.979141   5.07713163]\n",
      "pred [5.12823773 3.73160344 4.28629497 4.65376514 4.24458168 4.81720053]\n",
      "pred [3.56476592 5.50409264 4.2213666  4.79870352 3.76434956 5.16670861]\n",
      "pred [3.91561843 5.06591092 4.2353635  4.81251791 4.69165279 4.23841501]\n",
      "pred [4.3058936  4.59228216 3.84415371 5.06819099 3.97199297 5.21181131]\n",
      "pred [5.01293465 4.09570747 4.44370013 4.65360943 5.15739734 3.94001935]\n",
      "pred [4.37971788 4.50266761 4.47927924 4.49376407 4.48566815 4.44841084]\n",
      "pred [4.47461481 4.56064643 4.35325104 4.59033002 3.9071796  5.02229217]\n",
      "pred [4.15365805 4.92979439 4.32972945 4.65293614 4.26425957 4.56596826]\n",
      "pred [4.35407183 4.60387678 4.32991786 4.58439719 4.18117004 4.83167579]\n",
      "pred [4.77471346 4.24819508 4.32741114 4.64065036 3.88678866 4.97765987]\n",
      "pred [3.72893241 5.06923551 4.35616977 4.43543527 4.50807469 4.51393405]\n",
      "pred [3.85432777 5.2158652  4.38235772 4.5820222  4.31191103 4.66419031]\n",
      "pred [3.62881408 5.00665947 4.31639008 4.64757591 3.99489033 5.02902853]\n",
      "pred [4.28126682 4.88049464 4.32717294 4.58125882 4.13206991 4.92711624]\n",
      "pred [3.87374361 5.12300967 4.51623374 4.51189583 4.36948647 4.7114759 ]\n",
      "pred [4.25980933 4.80971653 4.37504862 4.58813011 3.99631084 4.9746241 ]\n",
      "pred [4.16757437 4.7347431  4.41302979 4.54001752 4.29336626 4.68729333]\n",
      "pred [3.53187587 5.23518718 4.10574152 4.95100358 3.99787986 4.96693616]\n",
      "pred [4.94823411 4.04010848 4.42679192 4.58967858 4.26372101 4.66047431]\n",
      "pred [3.85083813 5.10874229 4.08028844 4.90083894 3.69641286 5.1884746 ]\n",
      "pred [4.24725214 4.8071272  4.28673378 4.74090281 3.97433096 5.10076565]\n",
      "pred [4.32418052 4.67527108 4.32718431 4.63759113 4.37495727 4.42433089]\n",
      "pred [4.71404641 4.2694853  4.15888204 4.80048007 5.52657635 3.47378183]\n",
      "pred [2.98477824 5.64381116 4.27776523 4.7247757  4.20267258 4.83190461]\n",
      "pred [4.20669367 4.59550396 4.27313624 4.78087695 4.42657494 4.62322744]\n",
      "pred [4.67105919 4.33885515 4.44162887 4.48226225 4.22991699 4.84313493]\n",
      "pred [4.75298713 4.25574499 4.34513086 4.72527011 4.13889691 4.90897124]\n",
      "pred [3.30669019 5.40016125 4.39789046 4.5717647  4.05857927 4.82643572]\n",
      "pred [4.28460604 4.56775758 4.14281564 4.94832917 3.39577893 5.77449657]\n",
      "pred [4.62828364 4.34950133 3.63707421 5.49616088 3.85281714 5.13093586]\n",
      "pred [4.26476327 4.45728818 4.45604969 4.54317721 4.35497747 4.73034933]\n",
      "pred [3.96096233 5.11578497 4.21922227 4.97150224 3.73050399 5.14937822]\n",
      "pred [4.97191738 4.07236221 4.40552472 4.6175152  5.45913272 3.28452289]\n",
      "pred [4.01621029 4.88174087 4.34201011 4.7573701  4.23707073 4.71549658]\n",
      "pred [3.60792603 5.11439824 4.27540255 4.7708821  3.83815755 5.14774577]\n",
      "pred [3.22248095 5.36379533 4.0996832  4.81227279 4.26617802 4.72824039]\n",
      "pred [4.10758121 4.59366706 4.40835938 4.50857407 4.02931407 4.7984782 ]\n",
      "pred [4.03475107 4.96212996 4.52808382 4.39067641 4.02175893 4.96088075]\n",
      "pred [3.84528145 4.97023767 4.35898723 4.63531027 3.71812974 5.32074143]\n",
      "pred [4.8062279  4.20105091 4.42582324 4.57719941 5.32388708 3.69872601]\n",
      "pred [3.46662106 5.53528157 4.15300753 4.88175702 3.65241584 5.3710031 ]\n",
      "pred [4.76933694 4.25714525 4.48066337 4.56089195 4.04880302 5.0058474 ]\n",
      "pred [4.3759649  4.48334958 4.27748781 4.82116768 4.53773852 4.46726551]\n",
      "pred [4.10828335 4.66453029 4.16375126 4.83294337 3.86490801 5.09666993]\n",
      "pred [3.99474068 4.96601199 4.13047929 4.81722406 3.77959784 5.17392861]\n",
      "pred [4.45424044 4.54088454 4.55112647 4.3669223  4.32347079 4.87338647]\n",
      "pred [5.08882054 3.86842063 4.25550009 4.70615714 5.06180417 3.97294462]\n",
      "pred [3.52881148 5.02446658 4.20504612 4.74295748 4.16498259 4.7564618 ]\n",
      "pred [4.4346677  4.47037634 4.30678359 4.61037606 4.08284218 4.90399893]\n",
      "pred [4.49005829 4.58496679 4.4136047  4.59187904 4.37749583 4.78181998]\n",
      "pred [2.94819055 5.85654978 4.39718315 4.64870812 4.2114912  4.94151024]\n",
      "pred [4.29620444 4.59213072 4.16951701 4.67837737 4.08688139 4.85969013]\n",
      "pred [4.27961682 4.76509696 4.41106706 4.65571123 4.12541362 4.74767528]\n",
      "pred [3.68981799 5.10481101 4.12278884 5.06346249 4.1576598  4.90405717]\n",
      "pred [4.41654301 4.53106506 4.403738   4.52240513 4.13847214 4.7953656 ]\n",
      "pred [4.61368293 4.53382627 4.51207351 4.45420811 4.23148874 4.65055083]\n",
      "pred [3.48036538 5.46697394 4.49444147 4.59112579 3.99435554 4.97542519]\n",
      "pred [3.12614053 5.75415557 4.26533779 4.71295572 4.19450934 4.88464673]\n",
      "pred [3.71968885 5.10687187 4.10648718 5.03108716 4.09094264 4.8899878 ]\n",
      "pred [4.13074595 5.0326894  4.33079066 4.72249671 4.29118612 4.78737096]\n",
      "pred [3.43146886 5.78136834 4.4414252  4.67711373 3.74082646 5.18622045]\n",
      "(296, 124) (296, 6)\n",
      "******* Feature select: PCA9999  Feature type: OG-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.9747497908464696\n",
      "R2 Best score (validation) val. score :  0.5141955543297889\n",
      "R2 of the best estimator (testing dataset):  0.03170344690839394\n",
      "pred [5.11609419 3.90014284 4.60669567 4.38253251 4.92472933 4.05290163]\n",
      "pred [5.48202044 3.53634731 4.46670526 4.64013434 4.7805431  4.16844414]\n",
      "pred [3.74765984 5.11266038 4.5129044  4.54795704 3.94902095 4.96104031]\n",
      "pred [4.62446904 4.37452141 4.65453813 4.42363728 6.09305445 2.78867028]\n",
      "pred [4.11970863 4.83594735 4.079826   4.87980592 3.63640036 5.35492436]\n",
      "pred [5.34331582 3.68429597 4.46948309 4.59297136 5.35383094 3.58866804]\n",
      "pred [5.21186657 3.9729209  4.47984065 4.55452289 4.5663511  4.32434429]\n",
      "pred [4.68402497 4.3885182  4.57804555 4.42033487 4.66320561 4.21268278]\n",
      "pred [4.93686507 4.04887032 4.67848143 4.39984861 4.70707694 4.29340715]\n",
      "pred [5.02129936 3.96380473 4.61520603 4.37770464 4.83980419 4.13610335]\n",
      "pred [5.24269543 3.77196531 4.71251182 4.25573949 4.71785395 4.20406979]\n",
      "pred [4.37755716 4.64980802 4.5671709  4.48479907 4.0673031  4.8431316 ]\n",
      "pred [4.32474129 4.64615577 4.7107311  4.3235778  5.69722523 3.18498142]\n",
      "pred [3.92360542 5.00715011 4.14284531 4.95247321 4.7258242  4.24937953]\n",
      "pred [3.58197923 5.39878285 4.66772863 4.31619514 4.65614911 4.47080961]\n",
      "pred [4.33248209 4.75616968 4.47529651 4.55418452 4.09456728 4.84891198]\n",
      "pred [4.50151546 4.44244853 4.65112615 4.47028006 4.49526465 4.39970281]\n",
      "pred [4.33925892 4.78475825 4.52864871 4.47957668 4.8756317  4.01295708]\n",
      "pred [3.84384614 5.07387424 4.15684738 4.81798938 4.71958226 4.26149525]\n",
      "pred [5.17719613 3.79257437 4.63206741 4.38337584 4.06532075 5.0013025 ]\n",
      "pred [3.5904179  5.34082964 4.74522189 4.31371751 4.05595236 4.87398929]\n",
      "pred [3.93722077 5.04474639 4.63324464 4.44884595 4.60897528 4.27205609]\n",
      "pred [4.29863186 4.82540396 4.75208072 4.39769281 4.94941334 3.99867807]\n",
      "pred [4.42618388 4.77956642 4.55010311 4.45942931 5.63993584 3.31630617]\n",
      "pred [3.42855949 5.6500839  4.55564995 4.50109105 4.71361792 4.22083298]\n",
      "pred [4.66759463 4.36742157 4.45037281 4.67491167 5.04981668 3.69040257]\n",
      "pred [4.27972224 4.62132339 4.32102285 4.64509964 4.28282533 4.63284088]\n",
      "pred [4.95776524 3.96602451 4.80430315 4.22754807 4.60914957 4.34317015]\n",
      "pred [3.61004627 5.29414744 3.9467184  5.05358574 4.47175172 4.4308805 ]\n",
      "pred [4.32307063 4.50498786 4.14619257 4.94781359 3.99716028 4.88301303]\n",
      "pred [4.35462362 4.49086526 4.13992498 4.95209803 3.74826151 5.10488279]\n",
      "pred [4.91624379 4.22284533 4.4201703  4.70069992 4.62090607 4.18148166]\n",
      "pred [3.31522003 5.83643922 4.603735   4.4371201  3.70648948 5.09115082]\n",
      "pred [5.36730264 3.69360651 4.74935116 4.40347027 5.23109204 3.73169119]\n",
      "pred [3.94970354 4.96017288 4.73095224 4.35665516 4.36145945 4.71586057]\n",
      "pred [4.03093688 4.83139958 3.9784558  5.04559352 4.66122165 4.39169956]\n",
      "pred [3.42648032 5.55148669 4.50029638 4.53360766 4.71098533 4.24330423]\n",
      "pred [4.92757881 4.2451969  4.57250561 4.43586957 4.45018909 4.33159034]\n",
      "pred [4.11390669 4.82710649 4.60777977 4.4755173  4.49711521 4.49199346]\n",
      "pred [3.99248011 5.06594634 4.58319127 4.53278649 4.6092725  4.37599421]\n",
      "pred [5.37473798 3.70145782 4.67629423 4.36744574 5.53921194 3.34003174]\n",
      "pred [3.56872742 5.40805599 4.56459362 4.40721365 4.03863435 4.74605453]\n",
      "pred [5.05732281 3.99266149 4.75803584 4.27949039 5.03488242 3.81729459]\n",
      "pred [3.52694788 5.46264204 4.59920096 4.42860837 4.59873295 4.28980031]\n",
      "pred [3.79062737 5.06940075 4.62048491 4.43495245 4.12152603 4.83192128]\n",
      "pred [3.65341391 5.30148724 4.79507665 4.23973323 4.10693066 4.88470911]\n",
      "pred [5.24756809 3.86321481 4.39590108 4.51479913 4.90700754 4.03551895]\n",
      "pred [5.41753914 3.50283849 4.56526397 4.45451978 4.75860131 4.20709009]\n",
      "pred [4.61299597 4.48028108 4.60247542 4.4170926  4.85924417 4.09690174]\n",
      "pred [4.0145624  4.93324359 4.65517213 4.44797867 5.06231889 3.9303364 ]\n",
      "pred [5.25667202 3.75255433 4.48444943 4.56102109 4.95019891 3.91695015]\n",
      "pred [3.7255351  5.16518682 4.60278928 4.37112427 4.75957145 4.16528352]\n",
      "pred [5.32447754 3.53204121 4.48140385 4.61483771 4.70859783 4.19650552]\n",
      "pred [4.19366564 4.80753655 4.54223653 4.47041514 4.14518348 4.80180575]\n",
      "pred [3.7367869  5.23593889 4.05587073 4.9656789  4.72259259 4.14065202]\n",
      "pred [4.17498157 4.93655966 4.6311915  4.42620418 4.5017302  4.37665217]\n",
      "pred [3.99206275 5.03077416 4.69568339 4.40561388 4.62928008 4.33534256]\n",
      "pred [4.38220538 4.57356451 4.46353696 4.5737873  4.60328217 4.3051307 ]\n",
      "pred [3.40571285 5.56381119 4.58145849 4.50416067 4.79763033 4.26064193]\n",
      "pred [3.84808704 5.10030398 4.70981375 4.28230653 4.88923526 4.10476185]\n",
      "pred [4.10865823 4.88545351 4.75698073 4.29792177 4.25525602 4.60255535]\n",
      "pred [3.18721415 5.76550715 4.6943293  4.29385602 4.31385412 4.47733011]\n",
      "(296, 86) (296, 6)\n",
      "******* Feature select: PCA9999  Feature type: ST-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.9929234410437715\n",
      "R2 Best score (validation) val. score :  0.5046395502558084\n",
      "R2 of the best estimator (testing dataset):  0.25889025958044515\n",
      "pred [4.50697631 4.49302369 4.59695781 4.40304219 4.22583157 4.77416843]\n",
      "pred [5.04362282 3.95637718 4.55130908 4.44869092 4.08774542 4.91225458]\n",
      "pred [3.57743243 5.42256757 3.88351863 5.11648137 3.48807692 5.51192308]\n",
      "pred [3.88678252 5.11321748 4.43771442 4.56228558 4.64356919 4.35643081]\n",
      "pred [4.23827472 4.76172528 4.14742927 4.85257073 3.52753969 5.47246031]\n",
      "pred [4.90398043 4.09601957 4.51749774 4.48250226 4.69693373 4.30306627]\n",
      "pred [4.67852918 4.32147082 4.69376237 4.30623763 4.151935   4.848065  ]\n",
      "pred [3.79916027 5.20083973 3.88670496 5.11329504 4.39601586 4.60398414]\n",
      "pred [4.76876997 4.23123003 4.80992476 4.19007524 3.89181139 5.10818861]\n",
      "pred [4.47850652 4.52149348 4.41482899 4.58517101 4.28326784 4.71673216]\n",
      "pred [4.78242112 4.21757888 4.47823411 4.52176589 4.06627075 4.93372925]\n",
      "pred [4.29134238 4.70865762 4.55976383 4.44023617 3.97736169 5.02263831]\n",
      "pred [3.90115638 5.09884362 4.58068856 4.41931144 4.09501735 4.90498265]\n",
      "pred [3.70853651 5.29146349 4.29576529 4.70423471 3.92209084 5.07790916]\n",
      "pred [4.89768245 4.10231755 4.49475175 4.50524825 3.97740883 5.02259117]\n",
      "pred [4.71305254 4.28694746 4.58207718 4.41792282 3.67552149 5.32447851]\n",
      "pred [3.13629516 5.86370484 4.51218916 4.48781084 4.0307084  4.9692916 ]\n",
      "pred [4.74432859 4.25567141 4.56449551 4.43550449 4.8032163  4.1967837 ]\n",
      "pred [3.77009388 5.22990612 4.41325235 4.58674765 3.9836961  5.0163039 ]\n",
      "pred [4.93900904 4.06099096 4.49004737 4.50995263 3.91769121 5.08230879]\n",
      "pred [4.01282117 4.98717883 4.4208946  4.5791054  3.95889278 5.04110722]\n",
      "pred [4.50901966 4.49098034 4.3782985  4.6217015  4.1814565  4.8185435 ]\n",
      "pred [4.93886336 4.06113664 4.54524135 4.45475865 4.64282782 4.35717218]\n",
      "pred [4.28580387 4.71419613 4.21812126 4.78187874 5.17272584 3.82727416]\n",
      "pred [4.19233158 4.80766842 4.40151479 4.59848521 3.85167939 5.14832061]\n",
      "pred [4.12150197 4.87849803 4.29447599 4.70552401 4.11990552 4.88009448]\n",
      "pred [4.15591425 4.84408575 4.491096   4.508904   4.84740365 4.15259635]\n",
      "pred [4.98493653 4.01506347 4.46975501 4.53024499 4.18736004 4.81263996]\n",
      "pred [3.24133445 5.75866555 4.34532146 4.65467854 4.34935413 4.65064587]\n",
      "pred [4.21297395 4.78702605 3.59063235 5.40936765 3.57224047 5.42775953]\n",
      "pred [3.31896311 5.68103689 3.64618828 5.35381172 3.83845157 5.16154843]\n",
      "pred [4.2505412  4.7494588  4.37572063 4.62427937 3.66690847 5.33309153]\n",
      "pred [4.25912665 4.74087335 3.32829172 5.67170828 3.85904855 5.14095145]\n",
      "pred [5.12586153 3.87413847 4.63597139 4.36402861 4.53626942 4.46373058]\n",
      "pred [3.55629778 5.44370222 4.48288998 4.51711002 4.25847178 4.74152822]\n",
      "pred [4.04044602 4.95955398 4.27854186 4.72145814 3.80133231 5.19866769]\n",
      "pred [3.02700275 5.97299725 4.52468176 4.47531824 4.03893975 4.96106025]\n",
      "pred [4.70671438 4.29328562 4.42519045 4.57480955 3.90996192 5.09003808]\n",
      "pred [4.25454311 4.74545689 4.28961274 4.71038726 4.78460716 4.21539284]\n",
      "pred [4.40601049 4.59398951 4.35677731 4.64322269 4.14330411 4.85669589]\n",
      "pred [4.15891169 4.84108831 4.53025415 4.46974585 4.78505385 4.21494615]\n",
      "pred [4.28464321 4.71535679 4.32492153 4.67507847 3.98656188 5.01343812]\n",
      "pred [4.57944062 4.42055938 4.59677826 4.40322174 2.94193811 6.05806189]\n",
      "pred [3.99473855 5.00526145 4.74196099 4.25803901 3.64121165 5.35878835]\n",
      "pred [4.18470933 4.81529067 4.36031645 4.63968355 4.32413615 4.67586385]\n",
      "pred [4.06119415 4.93880585 4.0471211  4.9528789  4.03845229 4.96154771]\n",
      "pred [5.01749885 3.98250115 4.575717   4.424283   4.86105311 4.13894689]\n",
      "pred [5.07055881 3.92944119 4.49417745 4.50582255 4.24975472 4.75024528]\n",
      "pred [4.70176246 4.29823754 4.48083312 4.51916688 4.37252713 4.62747287]\n",
      "pred [4.50560067 4.49439933 4.51987285 4.48012715 4.24801493 4.75198507]\n",
      "pred [4.81124138 4.18875862 4.52894957 4.47105043 4.52706365 4.47293635]\n",
      "pred [3.44427857 5.55572143 4.494168   4.505832   4.1536495  4.8463505 ]\n",
      "pred [4.39255957 4.60744043 4.55326139 4.44673861 4.00741567 4.99258433]\n",
      "pred [4.46078963 4.53921037 4.50627907 4.49372093 3.59334768 5.40665232]\n",
      "pred [3.74939113 5.25060887 4.33722721 4.66277279 3.93925454 5.06074546]\n",
      "pred [4.40875193 4.59124807 4.45440038 4.54559962 3.68497516 5.31502484]\n",
      "pred [4.53916666 4.46083334 4.44304244 4.55695756 5.05452136 3.94547864]\n",
      "pred [3.65856755 5.34143245 4.34793711 4.65206289 3.99086381 5.00913619]\n",
      "pred [3.45115641 5.54884359 4.57639338 4.42360662 4.0123267  4.9876733 ]\n",
      "pred [3.8726689  5.1273311  3.99886312 5.00113688 3.97323612 5.02676388]\n",
      "pred [4.51179522 4.48820478 4.6231364  4.3768636  4.42328267 4.57671733]\n",
      "pred [3.51400246 5.48599754 4.38604905 4.61395095 3.80447882 5.19552118]\n",
      "(296, 183) (296, 6)\n",
      "******* Feature select: FS_P  Feature type: HG-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.9351115613227666\n",
      "R2 Best score (validation) val. score :  0.6175146383999448\n",
      "R2 of the best estimator (testing dataset):  0.5769121447411513\n",
      "pred [4.39976665 4.63912239 4.4957909  4.45836941 4.24398023 4.67477812]\n",
      "pred [5.23228204 3.62432355 4.41148589 4.65101824 4.11902601 4.80238115]\n",
      "pred [3.80372136 5.09819844 3.45156368 5.61344436 3.32836237 5.73673807]\n",
      "pred [3.59673394 5.39145877 4.55051979 4.4263384  5.74790347 3.12816369]\n",
      "pred [4.75987601 4.36021183 3.27245701 5.81099324 3.30979057 5.76207127]\n",
      "pred [5.36890977 3.71449915 4.5127776  4.53109056 4.96821532 3.99200526]\n",
      "pred [4.59707813 4.31380893 4.26505051 4.72021106 4.66731636 4.32606104]\n",
      "pred [3.33483716 5.70098106 4.19658663 4.91548674 4.30419807 4.65931529]\n",
      "pred [4.60486589 4.51518148 4.25826507 4.65502913 4.55079158 4.42494038]\n",
      "pred [4.74830035 4.30684488 4.46012714 4.51680086 3.99955039 4.87440733]\n",
      "pred [4.6088131  4.40519299 4.43672644 4.54102573 4.13186939 4.7178362 ]\n",
      "pred [3.93607325 5.03002602 4.42600194 4.53063737 4.8725691  4.11060316]\n",
      "pred [3.3102819  5.74506154 4.5341067  4.38310677 5.55640901 3.38540325]\n",
      "pred [2.98023537 6.02182923 4.10536489 4.89189335 3.4405206  5.49783221]\n",
      "pred [4.05087065 4.94217088 4.52425026 4.43621149 4.42575142 4.59300854]\n",
      "pred [4.40430371 4.58433226 4.27952454 4.79534939 3.97962592 4.90417567]\n",
      "pred [3.9753702  4.98602963 4.43944111 4.57032617 4.54703985 4.37665909]\n",
      "pred [4.40633088 4.59304825 4.4239987  4.56249684 4.70294909 4.22664639]\n",
      "pred [2.93424275 5.92859503 4.09544337 4.93535573 3.41096663 5.52644327]\n",
      "pred [5.10917469 3.85364349 4.40137312 4.51065761 3.18037189 5.77194925]\n",
      "pred [3.62404881 5.45449553 4.09042794 4.84398458 3.73557673 5.25669474]\n",
      "pred [4.58702379 4.46974461 4.47646503 4.57238969 4.26954778 4.74002199]\n",
      "pred [4.03436914 4.91921613 4.33127879 4.64913947 4.38677938 4.60931421]\n",
      "pred [4.66455598 4.34311877 4.29482454 4.71353096 5.32933858 3.51109353]\n",
      "pred [2.47356628 6.49712031 4.50213746 4.48687691 3.90461352 5.12127146]\n",
      "pred [3.53257807 5.46866495 4.25675843 4.81011089 4.45781676 4.54450112]\n",
      "pred [4.32162967 4.77007764 4.52688711 4.46297692 4.05257851 4.96489487]\n",
      "pred [4.73983718 4.20463791 4.44686514 4.55794612 4.10518175 4.76179187]\n",
      "pred [2.91610432 5.98318368 4.08314073 4.88686635 4.17352563 4.9165343 ]\n",
      "pred [4.15583389 4.83430917 3.45155857 5.64183901 3.00719627 6.07999078]\n",
      "pred [4.39494014 4.53216967 2.86839397 6.17936198 3.72437168 5.31506213]\n",
      "pred [3.42983024 5.61281467 4.59001647 4.39904421 4.07738727 4.83724759]\n",
      "pred [4.02633192 4.9858088  3.82654693 5.13495537 3.44396169 5.54655623]\n",
      "pred [5.50907122 3.46067452 4.5147123  4.49559348 4.67555563 4.27709804]\n",
      "pred [3.97303747 4.93068986 4.37058185 4.64975032 3.88386753 5.23995586]\n",
      "pred [3.45034458 5.47167531 4.0850435  4.91847299 3.09393148 5.89038374]\n",
      "pred [2.48822533 6.44560011 4.09667485 4.90660888 3.90251151 5.06846043]\n",
      "pred [3.95121773 5.17248834 4.41687646 4.59287061 4.2033095  4.67405255]\n",
      "pred [4.06484623 4.97032722 4.55794486 4.44122823 4.10724915 4.84720604]\n",
      "pred [3.92043137 5.1760182  4.37716161 4.62859461 3.68154646 5.3253932 ]\n",
      "pred [5.02428256 3.97524868 4.36428118 4.66052872 4.58298764 4.37895648]\n",
      "pred [3.31981086 5.632812   4.27660933 4.64078662 3.64617882 5.41225963]\n",
      "pred [4.6028756  4.37968566 4.51910263 4.54416419 4.360399   4.58017725]\n",
      "pred [4.12175969 4.94789217 4.38322458 4.59957845 4.27142455 4.70268571]\n",
      "pred [3.74485975 5.38104208 4.43263725 4.54458294 3.9146846  5.13175069]\n",
      "pred [3.64364094 5.42888772 4.09042794 4.84808794 3.71741742 5.29234632]\n",
      "pred [4.8325703  4.14279504 4.28188283 4.69585252 4.46121307 4.5315934 ]\n",
      "pred [5.45737718 3.46399145 4.50165236 4.5117298  4.10127076 4.91321245]\n",
      "pred [4.36893556 4.63683309 4.28027112 4.68452801 4.56673636 4.40771974]\n",
      "pred [3.9497827  4.91032168 4.34408962 4.62004583 4.30949286 4.60937731]\n",
      "pred [4.58249793 4.48381619 4.36337193 4.61051543 4.52121731 4.46525343]\n",
      "pred [2.69540186 6.31508869 4.16254924 4.82048421 3.99919129 4.88436454]\n",
      "pred [4.7288743  4.35309217 4.41600987 4.58143541 4.42016498 4.49499428]\n",
      "pred [3.63864816 5.33209052 4.35331165 4.66252524 3.36435508 5.69506591]\n",
      "pred [2.90985325 5.93037106 3.81339725 5.1518869  3.86677856 5.18684379]\n",
      "pred [3.61610689 5.25758151 4.10351163 4.90834158 3.8689718  5.07990949]\n",
      "pred [4.51258442 4.4891272  4.55445794 4.4556034  4.22009788 4.74598936]\n",
      "pred [2.76601083 6.1164423  4.15287645 4.87102378 3.4543731  5.47908694]\n",
      "pred [2.60937646 6.40448545 4.26377471 4.68520743 3.95896367 4.98194384]\n",
      "pred [4.15129061 4.80431129 4.29869217 4.75398781 4.36955617 4.5685394 ]\n",
      "pred [4.43854985 4.62447383 4.52846562 4.42383929 4.45849823 4.54109159]\n",
      "pred [3.3065297  5.79948217 4.38925955 4.55384712 4.02917116 5.00382485]\n",
      "(296, 91) (296, 6)\n",
      "******* Feature select: FS_P  Feature type: OG-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.9267646195624867\n",
      "R2 Best score (validation) val. score :  0.570567303284232\n",
      "R2 of the best estimator (testing dataset):  0.3500262421156631\n",
      "pred [4.6921284  4.31785608 4.48006019 4.56630184 4.43730571 4.56082525]\n",
      "pred [5.29681906 3.67166164 4.49319888 4.51241893 4.8661565  3.95023994]\n",
      "pred [4.18052791 4.88052731 4.33938478 4.52712292 3.41197057 5.64300724]\n",
      "pred [3.56247265 5.39340315 4.53875182 4.49400291 5.38694905 3.55822974]\n",
      "pred [4.79582824 4.27592377 3.58418799 5.27315393 3.81964314 5.16466224]\n",
      "pred [5.31853743 3.66051244 4.49426033 4.49906284 5.94881283 3.20844223]\n",
      "pred [4.31371007 4.79377774 4.3745203  4.5510495  4.39626455 4.65326524]\n",
      "pred [4.22307198 4.70531819 4.26233361 4.68413571 4.65659765 4.45080557]\n",
      "pred [4.27169313 4.91072964 3.97674956 4.96742047 4.56793358 4.4833149 ]\n",
      "pred [4.49279822 4.44447713 4.43910717 4.57793888 4.33641085 4.59230884]\n",
      "pred [4.53955379 4.44302843 4.4259459  4.59221266 4.23335389 4.74697134]\n",
      "pred [4.83733509 4.25002085 4.35987114 4.55705677 4.56576767 4.42444874]\n",
      "pred [3.3638829  5.52136135 4.6434024  4.38164212 5.27449978 3.68176661]\n",
      "pred [4.12543021 4.72009506 3.91174139 5.10889719 3.98488236 5.13252086]\n",
      "pred [4.41741996 4.59365269 4.17714559 4.90429231 3.80048743 5.36304822]\n",
      "pred [4.53158761 4.69236047 3.80138426 5.10919626 3.7286515  5.19078991]\n",
      "pred [4.27165637 4.91750315 4.40898953 4.56431734 4.29788017 4.7600572 ]\n",
      "pred [4.48521254 4.51807648 4.38822286 4.57347576 4.5475466  4.30855316]\n",
      "pred [4.12543021 4.72009506 3.91174139 5.0904559  3.98488236 5.13252086]\n",
      "pred [5.39157048 3.64358207 4.50043029 4.52002519 3.34913579 5.61767631]\n",
      "pred [3.5488111  5.36861698 4.6837506  4.24094398 4.61684772 4.47776691]\n",
      "pred [3.95038858 5.06958321 4.51988523 4.48677844 4.30906052 4.6930806 ]\n",
      "pred [4.47162129 4.58299694 4.3789222  4.59992945 4.41692459 4.48128667]\n",
      "pred [4.71385923 4.32263805 4.41078682 4.55223958 6.03371841 2.75793511]\n",
      "pred [3.77814053 5.17748514 4.4356624  4.52644748 4.34278075 4.57576589]\n",
      "pred [4.70357525 4.37287331 4.28942217 4.66919004 4.65659765 4.40994623]\n",
      "pred [4.60562167 4.69357496 4.52648605 4.46609938 4.36900198 4.62337142]\n",
      "pred [4.65336552 4.3292167  4.47541944 4.54270865 4.23335389 4.74697134]\n",
      "pred [3.4609913  5.59482406 3.93806733 5.08515821 4.28894418 4.68919857]\n",
      "pred [4.44583647 4.73321105 3.48024325 5.32680663 3.81727594 5.16664291]\n",
      "pred [4.6075732  4.57336555 3.20607039 5.63662428 3.35848873 5.45739094]\n",
      "pred [4.07376702 5.03032328 4.2771042  4.61846143 4.25381569 4.86653328]\n",
      "pred [4.91207249 4.19702809 4.4071788  4.52742418 3.88542881 5.20872802]\n",
      "pred [5.47834955 3.47058775 4.50673435 4.48415484 5.85968576 3.40209421]\n",
      "pred [4.29588374 4.7424635  4.55275664 4.44359981 3.83254405 5.16566397]\n",
      "pred [4.27980989 4.78445139 3.8842841  5.0904559  3.54607193 5.50585152]\n",
      "pred [3.96837983 5.07602434 4.3678275  4.61984494 4.12087897 4.69264461]\n",
      "pred [4.08798987 5.01396619 4.30289987 4.61451743 4.28061849 4.86653328]\n",
      "pred [4.57905379 4.61340889 4.53694764 4.4618321  4.438648   4.5080215 ]\n",
      "pred [4.25103408 4.81574323 4.39925792 4.65080305 3.82765187 5.22450036]\n",
      "pred [4.98776506 3.97920262 4.44322959 4.50827022 4.62610982 4.05961709]\n",
      "pred [3.59934966 5.40845142 4.47891158 4.55699858 4.12142273 4.92626647]\n",
      "pred [4.70991415 4.29894782 4.5385916  4.47917951 2.87370543 6.14718516]\n",
      "pred [4.24945558 4.92471184 4.3052694  4.74507488 4.41214296 4.72920893]\n",
      "pred [3.74761082 5.33157102 4.45903639 4.56354034 4.2006677  5.02148747]\n",
      "pred [3.5488111  5.36861698 4.6837506  4.24094398 4.61684772 4.47776691]\n",
      "pred [4.49415534 4.73461387 4.4330067  4.50225986 4.50724212 4.54424986]\n",
      "pred [5.47251126 3.52721637 4.49319888 4.51241893 4.78938079 3.93540779]\n",
      "pred [4.92376752 4.12968387 4.36584133 4.68765356 4.48752964 4.5755782 ]\n",
      "pred [4.296024   4.72363701 4.52717708 4.48048364 4.38535881 4.63011244]\n",
      "pred [4.48515885 4.73325424 4.49572112 4.46803667 4.49141127 4.57672946]\n",
      "pred [3.57311239 5.25670846 4.36735586 4.61157461 3.98729204 5.13989783]\n",
      "pred [5.02588793 4.02191856 4.48858071 4.54799054 4.39702096 4.62456055]\n",
      "pred [4.56487042 4.42650941 4.39336371 4.58991057 3.26550231 5.76177568]\n",
      "pred [3.48030596 5.5093969  4.08936184 4.86366903 3.96695097 5.0193432 ]\n",
      "pred [4.10190946 4.84048786 4.36361906 4.70268741 4.09074763 4.84905739]\n",
      "pred [3.97293265 4.99183989 4.52002611 4.4815329  4.08208479 4.84893315]\n",
      "pred [4.19701526 4.62232282 3.94123119 5.04216132 3.91852906 5.11277083]\n",
      "pred [3.55061478 5.43076866 4.41487055 4.55222729 4.11849347 4.8493012 ]\n",
      "pred [4.03895821 5.03416407 4.47438529 4.51787734 4.66109916 4.4323441 ]\n",
      "pred [3.85725736 5.1090975  3.95542196 5.03730383 4.25251572 4.74680426]\n",
      "pred [3.26178907 5.68823651 4.60347816 4.38575984 4.5960302  4.5131543 ]\n",
      "(296, 56) (296, 6)\n",
      "******* Feature select: FS_P  Feature type: ST-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.932888880609517\n",
      "R2 Best score (validation) val. score :  0.6117389846136156\n",
      "R2 of the best estimator (testing dataset):  0.4262215202469363\n",
      "pred [5.27829036 3.72170964 4.51483332 4.48516668 4.15056142 4.84943858]\n",
      "pred [4.98502026 4.01497974 4.56054504 4.43945496 4.19007309 4.80992691]\n",
      "pred [3.46556993 5.53443007 4.28600741 4.71399259 3.42012634 5.57987366]\n",
      "pred [3.83157342 5.16842658 4.54793945 4.45206055 5.31633372 3.68366628]\n",
      "pred [4.13465662 4.86534338 4.15708143 4.84291857 3.24230818 5.75769182]\n",
      "pred [4.89727083 4.10272917 4.48776861 4.51223139 5.73675048 3.26324952]\n",
      "pred [4.64640446 4.35359554 4.26056222 4.73943778 4.19556956 4.80443044]\n",
      "pred [3.89449374 5.10550626 4.37180963 4.62819037 4.53300752 4.46699248]\n",
      "pred [4.53400324 4.46599676 4.3001179  4.6998821  4.59922929 4.35505507]\n",
      "pred [5.46713051 3.53286949 4.48589114 4.51410886 4.20995313 4.79004687]\n",
      "pred [5.37339365 3.62660635 4.44406524 4.55593476 4.04966975 4.95033025]\n",
      "pred [3.89351209 5.10648791 4.49777298 4.50222702 4.15332541 4.86822468]\n",
      "pred [3.87133771 5.12866229 4.55630864 4.44369136 5.43336636 3.56663364]\n",
      "pred [3.37394147 5.62605853 4.24123218 4.75876782 3.56690091 5.43309909]\n",
      "pred [4.14424036 4.85575964 4.5121282  4.4878718  4.27355758 4.72644242]\n",
      "pred [4.41175151 4.58824849 4.41886653 4.58113347 3.96064009 5.03935991]\n",
      "pred [3.41174713 5.58825287 4.42988584 4.57011416 4.32464183 4.65380808]\n",
      "pred [4.92480857 4.07519143 4.51382991 4.48617009 4.43830484 4.56169516]\n",
      "pred [3.17113044 5.82886956 4.25508585 4.74491415 3.54124131 5.45875869]\n",
      "pred [5.12202201 3.87797799 4.5681593  4.4318407  2.71782191 6.28217809]\n",
      "pred [4.21933732 4.78066268 4.68347079 4.31652921 3.71421632 5.28578368]\n",
      "pred [4.07526338 4.92473662 4.21795908 4.78204092 4.28374776 4.71625224]\n",
      "pred [4.44084974 4.55915026 4.53879219 4.46120781 4.17368921 4.82631079]\n",
      "pred [4.81552568 4.18447432 4.31457454 4.68542546 5.22573708 3.77426292]\n",
      "pred [3.23441756 5.76558244 4.36080023 4.63919977 4.08025798 4.91974202]\n",
      "pred [3.95109192 5.04890808 4.51589015 4.48410985 4.62491315 4.37508685]\n",
      "pred [4.11811181 4.88188819 4.5638969  4.4361031  4.07595011 4.92404989]\n",
      "pred [5.37339365 3.62660635 4.44406524 4.55593476 4.04966975 4.95033025]\n",
      "pred [3.41658089 5.58341911 4.11761561 4.88238439 4.0526738  4.9473262 ]\n",
      "pred [3.93614047 5.06385953 3.72125719 5.27874281 2.87677793 6.12322207]\n",
      "pred [3.86262542 5.13737458 3.11231571 5.88768429 3.50149669 5.49850331]\n",
      "pred [3.5339975  5.4660025  4.26754243 4.73245757 4.32232053 4.67767947]\n",
      "pred [3.88940223 5.11059777 4.14352523 4.85647477 3.26578643 5.73421357]\n",
      "pred [5.07431154 3.92568846 4.51667492 4.48332508 4.35276209 4.64723791]\n",
      "pred [4.37442543 4.62557457 4.48525117 4.51474883 4.3171433  4.6828567 ]\n",
      "pred [3.40237658 5.59762342 4.20305956 4.79694044 3.44287721 5.55712279]\n",
      "pred [2.98711483 6.01288517 4.43765537 4.56234463 4.03721605 4.96278395]\n",
      "pred [4.46599636 4.53400364 4.32416873 4.67583127 4.40153547 4.59846453]\n",
      "pred [4.02656569 4.97343431 4.57032277 4.42967723 4.14653358 4.85346642]\n",
      "pred [4.04922829 4.95077171 4.22328968 4.77671032 4.2178026  4.7821974 ]\n",
      "pred [5.40417749 3.59582251 4.41307949 4.58692051 4.5557099  4.4442901 ]\n",
      "pred [3.81832334 5.18167666 4.40742822 4.59257178 4.04736721 4.95263279]\n",
      "pred [4.82131896 4.17868104 4.49264557 4.50735443 3.66196417 5.33803583]\n",
      "pred [4.06760165 4.93239835 4.57819922 4.42180078 4.2753334  4.7246666 ]\n",
      "pred [3.67032105 5.32967895 4.34882715 4.65117285 4.27819088 4.72180912]\n",
      "pred [4.25561759 4.74438241 4.64509303 4.35490697 3.79709434 5.20290566]\n",
      "pred [4.80801895 4.19198105 4.29279596 4.70720404 4.0059439  4.94834046]\n",
      "pred [5.07179287 3.92820713 4.53610546 4.46389454 4.1634167  4.8365833 ]\n",
      "pred [4.42891602 4.57108398 4.23553413 4.76446587 4.34220056 4.65779944]\n",
      "pred [4.22663674 4.77336326 4.49891664 4.50108336 4.47306674 4.52693326]\n",
      "pred [4.99960192 4.00039808 4.29504806 4.70495194 4.26645016 4.6878342 ]\n",
      "pred [3.0339763  5.9660237  4.32551376 4.67448624 3.8547127  5.1452873 ]\n",
      "pred [5.22417303 3.77582697 4.5095304  4.4904696  4.12578411 4.87421589]\n",
      "pred [3.54699398 5.45300602 4.09397974 4.90602026 3.26100547 5.73899453]\n",
      "pred [3.30330953 5.69669047 4.07052176 4.92947824 3.64801986 5.35198014]\n",
      "pred [3.95321432 5.04678568 4.33180129 4.66819871 3.79019849 5.20980151]\n",
      "pred [5.04064578 3.95935422 4.40655715 4.59344285 3.91371459 5.08628541]\n",
      "pred [3.17145854 5.82854146 4.25086459 4.74913541 3.60947885 5.39052115]\n",
      "pred [3.23559801 5.76440199 4.55354844 4.44645156 3.81597353 5.18402647]\n",
      "pred [4.16074739 4.83925261 4.48518061 4.51481939 3.84061922 5.18093086]\n",
      "pred [4.31963751 4.68036249 4.37013962 4.62986038 4.3871817  4.6128183 ]\n",
      "pred [3.85726033 5.14273967 4.45090648 4.54909352 4.08414412 4.91585588]\n",
      "(296, 296) (296, 6)\n",
      "******* Feature select: FS_K  Feature type: HG-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.9405059378787763\n",
      "R2 Best score (validation) val. score :  0.6260123902893104\n",
      "R2 of the best estimator (testing dataset):  0.4074437980487477\n",
      "pred [4.52997928 4.47002072 4.52662522 4.47337478 4.29183688 4.70816312]\n",
      "pred [5.1216069  3.9051948  4.37822914 4.62177086 5.13451569 3.88940471]\n",
      "pred [3.85587946 5.14412054 3.92830608 5.07169392 3.52616525 5.47383475]\n",
      "pred [3.79908946 5.20091054 4.53626865 4.46373135 5.79290943 3.20709057]\n",
      "pred [4.20878536 4.83236358 3.43625223 5.56374777 3.47598289 5.52401711]\n",
      "pred [5.17633794 3.83154766 4.49142593 4.50857407 5.87846057 3.14545983]\n",
      "pred [4.59011856 4.40988144 4.45044667 4.54955333 4.46239809 4.53760191]\n",
      "pred [3.62718792 5.37281208 3.48012546 5.51987454 4.17641561 4.82358439]\n",
      "pred [4.62192374 4.37807626 4.587701   4.412299   4.51666917 4.48333083]\n",
      "pred [4.61810739 4.38189261 4.4457127  4.5542873  4.34664103 4.65335897]\n",
      "pred [4.65912782 4.34087218 4.42296417 4.57703583 4.1612447  4.8387553 ]\n",
      "pred [3.83063778 5.16936222 4.42251665 4.57748335 4.66607956 4.35784083]\n",
      "pred [3.52630432 5.47369568 4.60044735 4.39955265 5.45051621 3.57340418]\n",
      "pred [3.09566043 5.90433957 4.17825277 4.80437331 3.54016011 5.48376029]\n",
      "pred [4.40744232 4.59255768 4.63450066 4.36549934 4.48790932 4.51209068]\n",
      "pred [4.27722549 4.68778619 4.00748814 4.99251186 3.86754374 5.13245626]\n",
      "pred [3.68868363 5.31131637 4.50231575 4.49768425 4.6252502  4.3747498 ]\n",
      "pred [4.23004065 4.76995935 4.440461   4.559539   4.85817784 4.14182216]\n",
      "pred [3.25439515 5.74560485 4.16935644 4.81326964 3.54016011 5.48376029]\n",
      "pred [5.01855853 3.98144147 4.54850186 4.45149814 3.59836699 5.40163301]\n",
      "pred [3.28658551 5.71341449 3.95623327 5.04376673 4.02378423 4.97621577]\n",
      "pred [4.17877713 4.82122287 4.24112289 4.75887711 4.38076924 4.61923076]\n",
      "pred [3.96724019 5.03275981 4.36855273 4.65216549 4.52357089 4.47642911]\n",
      "pred [4.44470001 4.55529999 4.4912368  4.5087632  6.16157155 2.83842845]\n",
      "pred [2.99386701 6.00613299 4.4088183  4.56773191 4.04110375 4.98281664]\n",
      "pred [3.43055387 5.56944613 4.15413984 4.84586016 4.30469373 4.69530627]\n",
      "pred [4.63278032 4.36721968 4.48799451 4.51200549 4.28114604 4.71885396]\n",
      "pred [4.69658126 4.30341874 4.40167983 4.59832017 4.1421073  4.8578927 ]\n",
      "pred [3.15534764 5.84465236 4.30880327 4.69119673 4.01121119 4.98878881]\n",
      "pred [3.96931603 5.03068397 2.73157811 6.26842189 3.00853198 5.99146802]\n",
      "pred [3.8419256  5.12087975 2.74363155 6.25636845 3.77569647 5.22430353]\n",
      "pred [3.63264309 5.36735691 4.40829535 4.59170465 3.86965463 5.13034537]\n",
      "pred [3.88961701 5.15153193 3.30234079 5.69765921 3.45636867 5.54363133]\n",
      "pred [5.34806175 3.65193825 4.2410256  4.88360589 4.66483598 4.35908441]\n",
      "pred [4.02779055 4.97220945 4.39201919 4.60798081 4.05609218 4.94390782]\n",
      "pred [3.14291949 5.74882414 3.9861834  4.99644268 3.35716388 5.66675652]\n",
      "pred [2.90754064 6.09245936 4.3493261  4.70158119 3.80777237 5.21614803]\n",
      "pred [4.02624089 4.97375911 4.49223549 4.50776451 4.03407672 4.96592328]\n",
      "pred [4.33034736 4.66965264 4.47700431 4.52299569 4.57114248 4.41223291]\n",
      "pred [3.59082545 5.40917455 4.47938679 4.52061321 3.85552035 5.14447965]\n",
      "pred [4.74442341 4.25557659 4.49715967 4.50284033 5.46005228 3.56386811]\n",
      "pred [3.34516851 5.65483149 4.0709213  4.9290787  4.1488503  4.8511497 ]\n",
      "pred [4.57759843 4.42240157 4.55954563 4.44045437 3.8898609  5.1340595 ]\n",
      "pred [4.04056871 4.95943129 4.5216367  4.4783633  4.34336911 4.65663089]\n",
      "pred [3.69199546 5.30800454 4.32137115 4.67862885 3.92692966 5.07307034]\n",
      "pred [3.28658551 5.71341449 3.95623327 5.04376673 4.02378423 4.97621577]\n",
      "pred [4.97773722 4.06620853 4.42299137 4.57700863 4.48151474 4.51848526]\n",
      "pred [5.24680047 3.83514099 4.47487123 4.52512877 5.19857601 4.12664219]\n",
      "pred [4.60076065 4.39923935 4.41968436 4.58031564 4.2819977  4.74252754]\n",
      "pred [4.63873249 4.36126751 4.70305843 4.29694157 4.46472717 4.53527283]\n",
      "pred [4.88084855 4.11915145 4.44586244 4.55413756 4.51111776 4.48888224]\n",
      "pred [3.02575796 5.97424204 4.28744111 4.71255889 4.03107164 4.99284876]\n",
      "pred [4.56621061 4.43378939 4.5068979  4.4931021  4.51650237 4.48349763]\n",
      "pred [3.76876815 5.23123185 3.99923138 5.00076862 3.56470063 5.43529937]\n",
      "pred [3.18358745 5.81641255 4.1442259  4.8557741  3.52563024 5.47436976]\n",
      "pred [3.87970348 5.12029652 4.02409262 4.95853346 3.49452325 5.50547675]\n",
      "pred [4.00925911 4.95354624 4.50199288 4.49800712 4.53879703 4.44457836]\n",
      "pred [3.05951108 5.94048892 4.26652685 4.76700652 3.85440032 5.16952008]\n",
      "pred [2.80544186 6.19455814 4.39475632 4.60524368 4.0509496  4.9729708 ]\n",
      "pred [3.61464654 5.31258069 4.12031535 4.87968465 4.39072359 4.60927641]\n",
      "pred [4.14251478 4.85748522 4.53501637 4.46498363 4.52188208 4.47811792]\n",
      "pred [3.28061399 5.71938601 4.0965244  4.9034756  4.19690323 4.80309677]\n",
      "(296, 151) (296, 6)\n",
      "******* Feature select: FS_K  Feature type: OG-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.9060631619297626\n",
      "R2 Best score (validation) val. score :  0.5759312789444387\n",
      "R2 of the best estimator (testing dataset):  0.3547707136191989\n",
      "pred [5.08473656 3.98197244 4.46734486 4.53320126 4.45825855 4.56495614]\n",
      "pred [5.33220898 3.615176   4.47548534 4.53322832 5.0104604  3.75713223]\n",
      "pred [4.14016738 4.8987855  4.15867968 4.73966124 3.60338209 5.42171275]\n",
      "pred [3.43812222 5.46466264 4.4754818  4.50456632 5.88608431 2.90044992]\n",
      "pred [4.47719018 4.61831075 3.73301459 5.27989732 3.6413849  5.25544339]\n",
      "pred [5.11428307 3.839714   4.40083429 4.59742763 5.7346812  3.06331588]\n",
      "pred [4.7272453  4.32062831 4.4641435  4.51441476 4.41646077 4.64142993]\n",
      "pred [3.66507    5.3547699  4.21169226 4.77610566 4.65208893 4.4758746 ]\n",
      "pred [4.85868722 4.26750429 4.20514276 4.79751338 4.3363659  4.61960792]\n",
      "pred [5.00727198 3.91650229 4.45701147 4.52985425 4.36317418 4.60721867]\n",
      "pred [4.9761885  4.13707341 4.34389433 4.58364298 4.38883942 4.65262853]\n",
      "pred [4.80898132 4.26154829 4.41646813 4.58930468 4.5211863  4.59893438]\n",
      "pred [3.30077367 5.60584557 4.5723379  4.459485   5.76154026 3.1356122 ]\n",
      "pred [4.35205276 4.72181249 3.96521016 5.00090936 3.96729248 5.0619949 ]\n",
      "pred [4.66810412 4.33901006 4.51650875 4.44968278 4.41001624 4.51923743]\n",
      "pred [4.7427486  4.43046363 4.03211895 5.04366943 3.82325112 5.02923821]\n",
      "pred [4.35034628 4.52276123 4.46298437 4.56589414 4.57478595 4.48661482]\n",
      "pred [4.3741914  4.49296458 4.30078821 4.66072615 4.71270327 4.35515406]\n",
      "pred [4.35205276 4.72181249 3.96521016 5.00090936 3.96729248 5.0619949 ]\n",
      "pred [5.01588618 3.88261837 4.48039706 4.49923911 3.68206152 5.47270188]\n",
      "pred [4.02849302 5.09932995 4.47533417 4.51773745 4.29260308 4.69000966]\n",
      "pred [4.57458427 4.62267924 4.54945874 4.47955882 4.49380266 4.58705729]\n",
      "pred [4.27906777 4.47061143 4.294041   4.65785334 4.61804364 4.43740777]\n",
      "pred [4.50139194 4.40458192 4.35695123 4.60670795 5.776505   3.47786645]\n",
      "pred [4.05746693 4.99903298 4.32208923 4.67929385 4.31589901 4.68686101]\n",
      "pred [3.72745976 5.25238682 4.26842024 4.76210057 4.63228843 4.50346493]\n",
      "pred [4.4351642  4.61297763 4.51716527 4.46035985 4.09798102 4.97929398]\n",
      "pred [4.9761885  4.13707341 4.36930122 4.55830654 4.38883942 4.65262853]\n",
      "pred [4.06610219 5.07720678 4.05704391 4.92219029 4.29227815 4.7550323 ]\n",
      "pred [4.23265479 4.80693299 3.69387321 5.31275352 3.66270982 5.30640617]\n",
      "pred [4.51087588 4.57492254 3.38968872 5.79423525 3.67059256 5.30585756]\n",
      "pred [3.41843848 5.65251049 4.26243254 4.76357909 4.52748837 4.54225095]\n",
      "pred [4.52860239 4.53568459 4.18629884 4.73138392 3.7058243  5.296568  ]\n",
      "pred [5.36422729 3.61841306 4.48343741 4.51089082 5.93743787 3.06472217]\n",
      "pred [4.32339919 4.63472633 4.44023054 4.52020722 3.8858456  5.08815699]\n",
      "pred [4.39944197 4.69721001 3.94941505 5.05845515 3.47321809 5.59144762]\n",
      "pred [3.94367231 5.2236729  4.28632013 4.68598646 4.4155015  4.67910693]\n",
      "pred [4.16365505 5.09764913 4.21271374 4.78351727 4.38189825 4.70350276]\n",
      "pred [4.67414454 4.41018022 4.47154431 4.51258155 4.39902081 4.66872393]\n",
      "pred [4.38700794 4.71070284 4.4349107  4.55822134 4.04874932 5.01140497]\n",
      "pred [5.0223871  4.01148908 4.43565292 4.5289517  5.3585992  3.95413383]\n",
      "pred [3.78324298 5.30751921 4.38431087 4.62500002 4.20176892 4.8344712 ]\n",
      "pred [4.54814642 4.38327501 4.54253281 4.47636453 3.69934229 5.29675006]\n",
      "pred [4.32659009 4.74339668 4.54125171 4.47549202 4.46123896 4.58561396]\n",
      "pred [3.75651618 5.34958433 4.45522875 4.53202998 4.37412016 4.65074627]\n",
      "pred [4.02849302 5.09932995 4.47533417 4.51773745 4.29260308 4.69000966]\n",
      "pred [4.95128975 4.06125247 4.51930293 4.51504075 4.49924562 4.39055596]\n",
      "pred [5.33220898 3.615176   4.44980168 4.54472948 5.07363073 3.66737299]\n",
      "pred [5.00703069 4.02369221 4.35745835 4.66675461 4.4635552  4.55599546]\n",
      "pred [4.7217163  4.45986844 4.48858744 4.4884709  4.29023328 4.61146487]\n",
      "pred [5.05228613 4.01918762 4.56593787 4.49481583 4.57682177 4.37539924]\n",
      "pred [3.89977477 5.18442673 4.23569372 4.67250279 3.83928173 5.17238895]\n",
      "pred [5.05896036 3.96984954 4.46971612 4.53957659 4.45825855 4.56495614]\n",
      "pred [4.30048901 4.72751566 4.18370149 4.73385364 3.59060967 5.40585997]\n",
      "pred [3.98489256 5.15700633 4.03196949 5.01787704 3.99105752 4.99769849]\n",
      "pred [3.99856976 5.03746369 4.16836368 4.74591161 3.72776397 5.15667411]\n",
      "pred [4.1443842  4.84997301 4.49764847 4.50433352 4.42291552 4.62076423]\n",
      "pred [4.17182061 4.94500201 3.98955599 4.9620357  3.979843   5.03478114]\n",
      "pred [3.79006088 5.27341464 4.29942724 4.71669941 4.16060443 4.86255439]\n",
      "pred [4.27623365 4.8470116  4.52449185 4.53354256 4.25136373 4.74834951]\n",
      "pred [4.38231236 4.66101231 4.22814754 4.85371099 4.20343872 4.81586242]\n",
      "pred [3.65708249 5.442358   4.49972335 4.55182908 4.5331966  4.5579162 ]\n",
      "(296, 87) (296, 6)\n",
      "******* Feature select: FS_K  Feature type: ST-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.9083136791123003\n",
      "R2 Best score (validation) val. score :  0.6133004900409695\n",
      "R2 of the best estimator (testing dataset):  0.4506102000039051\n",
      "pred [4.85625473 4.14374527 4.48337467 4.51662533 4.28943899 4.71056101]\n",
      "pred [4.83787038 4.16212962 4.5737287  4.44235831 4.80453621 4.19546379]\n",
      "pred [3.53647434 5.46352566 4.14322445 4.85677555 2.96291941 6.03708059]\n",
      "pred [3.8244232  5.1755768  4.62054102 4.37945898 5.18713539 3.81286461]\n",
      "pred [4.38720264 4.67546174 3.85164635 5.14238237 2.80375017 6.19624983]\n",
      "pred [4.88737671 4.11262329 4.51988179 4.48011821 5.90045481 2.71269121]\n",
      "pred [4.71682043 4.28317957 4.32141834 4.67858166 4.37013707 4.55626102]\n",
      "pred [3.894544   5.105456   3.91382773 5.08617227 4.15722282 4.84277718]\n",
      "pred [4.83565339 4.16434661 4.50979474 4.51407037 4.52094889 4.47905111]\n",
      "pred [5.33275814 3.66724186 4.45763955 4.54236045 4.37799825 4.62200175]\n",
      "pred [5.07448703 3.92551297 4.51444384 4.48555616 4.23392402 4.76607598]\n",
      "pred [4.1766581  4.8233419  4.44595076 4.55404924 4.3868927  4.6131073 ]\n",
      "pred [3.28782423 5.71217577 4.60662677 4.39337323 4.78396088 4.21603912]\n",
      "pred [3.13527477 5.86472523 4.29612994 4.70387006 3.75675334 5.24324666]\n",
      "pred [4.09950281 4.90049719 4.3913582  4.6086418  4.36789729 4.74327161]\n",
      "pred [4.42151322 4.57848678 4.36662805 4.63337195 3.64884525 5.35115475]\n",
      "pred [3.14880835 5.85119165 4.4722248  4.5277752  4.35176237 4.64823763]\n",
      "pred [4.65025402 4.34974598 4.46947368 4.53052632 4.57401464 4.42598536]\n",
      "pred [3.13527477 5.86472523 4.31208168 4.68791832 3.75675334 5.24324666]\n",
      "pred [4.90279813 4.09720187 4.49008099 4.52600602 2.95558204 6.04441796]\n",
      "pred [3.97134037 5.02865963 4.28555865 4.71444135 3.46750468 5.53249532]\n",
      "pred [3.81212975 5.18787025 4.11909399 4.88090601 4.04920404 4.95079596]\n",
      "pred [4.47169142 4.52830858 4.48002341 4.51997659 4.39353349 4.60646651]\n",
      "pred [4.78266865 4.21733135 4.44889133 4.56719568 6.32303999 2.48655774]\n",
      "pred [3.11760313 5.88239687 4.48896731 4.51103269 4.07552679 4.92447321]\n",
      "pred [3.99286931 5.00713069 4.36631083 4.63368917 4.24850335 4.75149665]\n",
      "pred [3.89171611 5.10828389 4.46261918 4.53738082 3.89770302 5.10229698]\n",
      "pred [5.09525515 3.90474485 4.51444384 4.48555616 4.29082677 4.70917323]\n",
      "pred [3.29438776 5.70561224 4.09829146 4.90170854 4.01373176 4.98626824]\n",
      "pred [4.22300755 4.77699245 3.84268403 5.15731597 2.92261332 6.07738668]\n",
      "pred [3.43930285 5.56069715 2.86514129 6.13485871 3.08115215 6.12005497]\n",
      "pred [3.23638953 5.76361047 4.34551951 4.65448049 3.93853868 5.06146132]\n",
      "pred [4.29809833 4.76456605 3.40461858 5.58941014 3.22350987 5.77649013]\n",
      "pred [5.07538539 3.92461461 4.51153286 4.48846714 5.58951027 3.20928261]\n",
      "pred [4.18085763 4.81914237 4.33106425 4.66893575 4.17637787 4.82362213]\n",
      "pred [3.41918749 5.58081251 4.1691389  4.8308611  3.36599465 5.63400535]\n",
      "pred [2.96821356 6.03178644 4.46020382 4.53979618 3.89131337 5.10868663]\n",
      "pred [3.71102804 5.28897196 4.4247106  4.5752894  4.31345681 4.68654319]\n",
      "pred [3.89476329 5.10523671 4.57060764 4.42939236 4.54618105 4.45381895]\n",
      "pred [3.5394063  5.4605937  4.55310693 4.44689307 3.99237837 5.00762163]\n",
      "pred [4.98141943 4.01858057 4.4774562  4.53863081 5.26022338 3.52346615]\n",
      "pred [3.66577061 5.33422939 4.39731094 4.60268906 3.54095426 5.45904574]\n",
      "pred [4.48243635 4.51756365 4.62488423 4.37511577 3.2045226  5.7954774 ]\n",
      "pred [3.90251391 5.09748609 4.61795419 4.38204581 4.034133   4.965867  ]\n",
      "pred [3.2979307  5.62648692 4.11128772 4.88871228 3.86805797 5.13194203]\n",
      "pred [3.97134037 5.02865963 4.25482126 4.74517874 3.52649594 5.47350406]\n",
      "pred [4.79109213 4.29529992 4.5455509  4.4544491  4.31040158 4.80076732]\n",
      "pred [4.9415248  4.0584752  4.67155371 4.3445333  4.69179237 4.30820763]\n",
      "pred [4.34270416 4.65729584 4.41899232 4.58100768 4.48857101 4.51142899]\n",
      "pred [4.1719028  4.8280972  4.55291069 4.44708931 4.41248905 4.58751095]\n",
      "pred [5.07389626 4.01249579 4.57547621 4.42452379 4.45984888 4.65132002]\n",
      "pred [3.20880889 5.79119111 4.52217167 4.47782833 4.0693604  4.9306396 ]\n",
      "pred [4.93325781 4.06674219 4.48337467 4.51662533 4.29922801 4.70077199]\n",
      "pred [3.2335261  5.7664739  3.89042696 5.10957304 3.24199864 5.75800136]\n",
      "pred [3.20090252 5.79909748 4.01752496 4.98247504 3.43012198 5.56987802]\n",
      "pred [3.84470232 5.15529768 3.75378157 5.24621843 3.58069907 5.41930093]\n",
      "pred [4.538141   4.461859   4.38029498 4.61970502 4.40412824 4.59587176]\n",
      "pred [3.02991722 5.97008278 4.28374806 4.71625194 3.79188907 5.20811093]\n",
      "pred [3.29982311 5.70017689 4.46220438 4.53779562 3.95947512 5.04052488]\n",
      "pred [4.05718403 4.94281597 4.03782095 4.96217905 3.6343462  5.3656538 ]\n",
      "pred [4.16837159 4.83162841 4.56060405 4.43939595 4.27078034 4.77759474]\n",
      "pred [3.6646554  5.3353446  4.60240492 4.39759508 3.42964481 5.57035519]\n",
      "regression_type svr\n",
      "(296, 490) (296, 6)\n",
      "******* Feature select: all  Feature type: HG-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.9473573910525338\n",
      "R2 Best score (validation) val. score :  0.5042868327804478\n",
      "R2 of the best estimator (testing dataset):  0.39300599805011127\n",
      "pred [3.99152432 5.00840325 4.65169742 4.34906193 3.57950184 5.42098098]\n",
      "pred [5.09816192 3.90203812 4.68980703 4.31008439 3.17421785 5.82582332]\n",
      "pred [2.88726711 6.11286997 3.93353081 5.06653568 3.1137479  5.88641567]\n",
      "pred [3.09550634 5.9044527  4.68288149 4.31771617 6.04119115 2.95930509]\n",
      "pred [5.07214766 3.92788692 3.0340482  5.96596916 3.59866039 5.40092999]\n",
      "pred [5.03634243 3.96399776 4.74362693 4.25616545 5.48061852 3.51920706]\n",
      "pred [2.93772609 6.06273738 4.63025218 4.369617   3.76507506 5.23539661]\n",
      "pred [3.81870445 5.18152934 4.61745941 4.38361002 4.82379362 4.17645943]\n",
      "pred [4.43620182 4.56385171 5.5302004  3.47094966 4.11339492 4.88683553]\n",
      "pred [4.52301726 4.477033   4.18324984 4.81733143 3.67677389 5.32335689]\n",
      "pred [4.51374378 4.4862466  4.25357471 4.7466134  4.01158009 4.98844553]\n",
      "pred [3.92432723 5.07556209 4.86438007 4.13645105 3.87082145 5.13012065]\n",
      "pred [2.48226958 6.51791629 4.77668095 4.22420119 5.67747159 3.32322283]\n",
      "pred [2.20495872 6.794873   4.19747735 4.80204637 3.52580313 5.47410174]\n",
      "pred [4.58785426 4.41214063 5.15706802 3.84418282 4.12286068 4.87750206]\n",
      "pred [3.74254958 5.25834872 4.16477599 4.8347897  3.89375995 5.10605549]\n",
      "pred [4.21750382 4.78247686 4.59934797 4.40153947 5.14688818 3.85384446]\n",
      "pred [4.6664802  4.33338804 4.29541431 4.70490299 4.44383606 4.55654042]\n",
      "pred [2.15710331 6.84257521 4.30181902 4.69759887 3.69827789 5.30173825]\n",
      "pred [4.70335988 4.29684467 4.63871358 4.36117687 3.20968407 5.79064292]\n",
      "pred [3.19103029 5.80890355 4.73457467 4.265059   3.79631585 5.20355379]\n",
      "pred [5.25709557 3.74285455 4.67164328 4.32856565 4.89816868 4.10205915]\n",
      "pred [3.83122868 5.16852004 4.32893    4.67122365 4.53144108 4.46857542]\n",
      "pred [3.63768677 5.36195611 4.54012001 4.45953996 7.13371268 1.86550683]\n",
      "pred [1.76365493 7.23585765 4.72255577 4.27713688 3.7419198  5.25786748]\n",
      "pred [4.28414465 4.71606093 4.70277649 4.2978147  4.49288511 4.50768341]\n",
      "pred [3.69944428 5.30087821 4.41685578 4.58286516 3.76715036 5.23295861]\n",
      "pred [4.59278448 4.40731798 4.2488602  4.75112519 3.98611937 5.01387226]\n",
      "pred [2.13292653 6.86728527 4.26079892 4.73887878 3.95882543 5.04148883]\n",
      "pred [4.16598956 4.83390526 3.3180437  5.68227287 2.65516024 6.3446921 ]\n",
      "pred [4.33807854 4.66233203 3.3835141  5.61769425 3.01615394 5.98393855]\n",
      "pred [3.2527112  5.74754563 5.21387509 3.78594654 3.25733266 5.74291249]\n",
      "pred [4.61793924 4.38185111 3.59391645 5.40619513 3.37908038 5.62080508]\n",
      "pred [5.11588408 3.88426609 4.79809834 4.20150117 6.3177857  2.68209929]\n",
      "pred [3.76648481 5.23398723 5.22120108 3.77889082 3.33565779 5.6645157 ]\n",
      "pred [2.77353934 6.22658899 3.84508705 5.1546485  3.21373373 5.78626251]\n",
      "pred [1.80158333 7.19838345 4.14643869 4.85311937 3.77987084 5.22000487]\n",
      "pred [2.96145027 6.03887702 5.04580102 3.95466741 4.06064647 4.93964779]\n",
      "pred [4.22385297 4.77679756 4.54176575 4.45875126 3.53832437 5.4619998 ]\n",
      "pred [4.05265791 4.94761679 4.74665247 4.25366467 3.85727745 5.1426312 ]\n",
      "pred [4.52457946 4.47490757 4.54698082 4.45253301 5.41348862 3.58653949]\n",
      "pred [2.8982769  6.10135173 4.86637985 4.13384133 3.36796396 5.6319068 ]\n",
      "pred [3.45500466 5.54498238 4.73384148 4.26623044 3.65250669 5.34811603]\n",
      "pred [5.50768118 3.49223499 5.6775945  3.32368369 4.07087227 4.92920582]\n",
      "pred [4.44268518 4.55760762 4.9782418  4.0219691  3.66984181 5.33032261]\n",
      "pred [3.27273411 5.72718765 4.81667243 4.18291816 3.83315109 5.1666901 ]\n",
      "pred [4.80353666 4.19651398 4.66766756 4.33221298 4.16822309 4.83197141]\n",
      "pred [5.18184216 3.8183459  4.72559396 4.27427826 3.63810781 5.36189037]\n",
      "pred [3.3336565  5.66691451 3.942118   5.05895551 4.34072811 4.66022455]\n",
      "pred [4.53708671 4.46289642 5.05867841 3.94231386 4.29211797 4.70811118]\n",
      "pred [4.809395   4.19032404 4.97105148 4.02929738 4.8909232  4.10937902]\n",
      "pred [1.81932872 7.18047385 4.64078767 4.35904633 3.71652429 5.28330564]\n",
      "pred [4.94373724 4.05625761 4.52189405 4.47856377 4.03918833 4.96120841]\n",
      "pred [3.83655483 5.16399793 4.88633882 4.11367013 3.02629727 5.97332974]\n",
      "pred [2.33948122 6.66091653 3.88708091 5.11257136 3.69548855 5.3047085 ]\n",
      "pred [3.96448747 5.03574827 3.28741247 5.7122302  3.73460602 5.26524483]\n",
      "pred [3.94190726 5.05867769 4.45346353 4.54707775 3.96680577 5.03328738]\n",
      "pred [1.6524986  7.34718863 4.32754797 4.67203978 3.73818442 5.26168586]\n",
      "pred [1.9143738  7.08539011 4.34889087 4.65084306 3.7951419  5.20461682]\n",
      "pred [4.62802482 4.37160369 4.48065889 4.5201046  4.72431888 4.27662033]\n",
      "pred [4.70035141 4.29970529 5.33866125 3.6623183  4.36042664 4.6395969 ]\n",
      "pred [2.64065915 6.3588498  4.92957385 4.07048473 3.88485308 5.11498926]\n",
      "(296, 302) (296, 6)\n",
      "******* Feature select: all  Feature type: OG-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.9821227909517599\n",
      "R2 Best score (validation) val. score :  0.6386809037967256\n",
      "R2 of the best estimator (testing dataset):  0.4745974950810951\n",
      "pred [4.42254866 4.57746201 4.53868188 4.46151383 4.15003113 4.85009239]\n",
      "pred [5.49199161 3.50791366 4.60455389 4.39558469 3.53718432 5.46281467]\n",
      "pred [3.74330368 5.25680143 4.0612643  4.93877307 3.95043913 5.04969083]\n",
      "pred [3.63279267 5.36679613 4.55836985 4.44104009 5.92469592 3.07491975]\n",
      "pred [4.61571675 4.38422551 3.33710488 5.66285371 3.82589014 5.17450853]\n",
      "pred [5.23935233 3.76030175 4.45003361 4.55026344 6.06063169 2.93920957]\n",
      "pred [4.11635188 4.88369282 4.33877833 4.66127181 4.20256885 4.7974414 ]\n",
      "pred [4.06579585 4.93420083 4.34593511 4.65412635 4.19851061 4.80152381]\n",
      "pred [4.18555313 4.81450888 4.317432   4.68264833 4.18682936 4.81317105]\n",
      "pred [4.52349517 4.47636297 4.44624835 4.55367194 4.16123767 4.83872979]\n",
      "pred [4.87779187 4.12206518 4.33678772 4.66290797 4.30907088 4.69091659]\n",
      "pred [4.24491    4.75502627 4.37828879 4.62179104 4.2638764  4.73622681]\n",
      "pred [3.11242446 5.88759344 4.57126328 4.4284808  5.48404987 3.51558712]\n",
      "pred [3.20050306 5.79953044 4.49722084 4.50265623 4.17142788 4.82851727]\n",
      "pred [4.34664079 4.65345674 4.43148561 4.56854765 4.25055803 4.74955337]\n",
      "pred [4.61912526 4.38089491 4.1388946  4.86088213 4.1968416  4.8031918 ]\n",
      "pred [3.85091169 5.1491121  4.43694354 4.56313407 4.28016758 4.71984546]\n",
      "pred [4.43754023 4.56264711 4.3245754  4.67541564 4.38603827 4.61402204]\n",
      "pred [3.28006556 5.71989682 4.6388189  4.3609703  4.07913596 4.92037876]\n",
      "pred [4.70731418 4.29266096 4.59009707 4.41009583 3.65938867 5.34026164]\n",
      "pred [3.91104316 5.08903496 4.46770756 4.53242993 4.21174018 4.78819873]\n",
      "pred [4.23937437 4.76066189 4.41575148 4.58423253 4.35297025 4.64711279]\n",
      "pred [3.94249321 5.05772412 4.30458706 4.69519247 4.32363724 4.67638318]\n",
      "pred [4.05252633 4.94748216 4.34191137 4.65811148 4.37866454 4.62142286]\n",
      "pred [3.40511473 5.5950543  4.49049488 4.50973158 3.98501164 5.01458502]\n",
      "pred [4.2739117  4.72588324 4.33944484 4.66061126 4.46191847 4.53805953]\n",
      "pred [4.02384547 4.97652078 4.40799715 4.59186928 4.51412031 4.48560768]\n",
      "pred [4.93892026 4.06103006 4.43836177 4.56140447 4.23825307 4.76177015]\n",
      "pred [3.34350845 5.65655861 4.24069913 4.75920886 4.10659264 4.89366431]\n",
      "pred [4.2921656  4.70796872 4.1424799  4.85785774 2.9017832  6.09817349]\n",
      "pred [4.11807813 4.88194739 4.24997853 4.75018412 3.81427065 5.18578515]\n",
      "pred [4.05343339 4.94658191 4.35994699 4.64016015 4.1896574  4.81033799]\n",
      "pred [5.38288167 3.61687392 3.88959937 5.11062528 3.65261979 5.34757864]\n",
      "pred [5.09690983 3.90284798 4.44506085 4.55521907 5.79873184 3.20112465]\n",
      "pred [4.11056589 4.88938244 4.41611924 4.58387043 3.81468009 5.18529503]\n",
      "pred [3.48784576 5.51227875 4.21081437 4.78913643 3.46243547 5.53715934]\n",
      "pred [3.21179555 5.78814682 4.34578454 4.65434054 3.85519805 5.14431119]\n",
      "pred [4.02412529 4.97590867 4.36638799 4.63373207 4.18188021 4.81811265]\n",
      "pred [4.20902452 4.79108845 4.51726374 4.48312605 3.3558056  5.64402916]\n",
      "pred [3.63950706 5.36060186 4.73540461 4.26460544 3.84344898 5.157029  ]\n",
      "pred [4.94683978 4.05330162 4.31419819 4.68603993 4.65680278 4.34316565]\n",
      "pred [3.36799522 5.63190046 4.38248705 4.61786298 3.7615123  5.23804671]\n",
      "pred [4.60354791 4.39667706 4.45576573 4.54459332 2.601324   6.39920969]\n",
      "pred [4.15140845 4.84863427 4.41486867 4.58513659 4.19880729 4.80117876]\n",
      "pred [3.991517   5.00848494 4.40024562 4.59973079 3.75110303 5.24882226]\n",
      "pred [3.90544174 5.09463611 4.47141175 4.52871917 4.21142451 4.78853445]\n",
      "pred [4.34508701 4.65494751 4.36014055 4.63982908 4.21619824 4.78379228]\n",
      "pred [5.45501909 3.5448778  4.52355621 4.47669349 4.66536956 4.33465139]\n",
      "pred [4.12682809 4.87318695 4.33647251 4.66358679 4.18237597 4.81762266]\n",
      "pred [4.14039746 4.85960868 4.37363844 4.62634497 4.23431218 4.76566571]\n",
      "pred [4.4261922  4.57382572 4.37094964 4.62895168 4.24106691 4.75893617]\n",
      "pred [2.92196684 6.07809625 4.54304832 4.45700824 3.96594629 5.0338432 ]\n",
      "pred [4.25086911 4.74921323 4.58999603 4.41021867 4.01671039 4.98355737]\n",
      "pred [3.72496099 5.27510733 4.39354845 4.60648564 3.07561543 5.92455822]\n",
      "pred [3.21324979 5.78669271 4.04677167 4.95287312 3.90923484 5.09087822]\n",
      "pred [4.22616459 4.77389775 3.99460369 5.0054655  4.02796687 4.97218237]\n",
      "pred [4.66366828 4.33625266 4.47738712 4.52294916 4.66804392 4.3321347 ]\n",
      "pred [3.84243793 5.15747157 4.49270548 4.50741766 4.33117029 4.66870549]\n",
      "pred [2.94275462 6.05768219 4.47059336 4.52943829 3.78921308 5.21045845]\n",
      "pred [4.08200523 4.91812983 4.40103882 4.59894668 4.27685586 4.7231885 ]\n",
      "pred [4.12082194 4.87918539 4.36858681 4.63146233 4.17317235 4.82679412]\n",
      "pred [3.16856668 5.83153902 4.53752233 4.4622253  4.07235248 4.92793616]\n",
      "(296, 119) (296, 6)\n",
      "******* Feature select: all  Feature type: ST-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.9838002273400609\n",
      "R2 Best score (validation) val. score :  0.5337271031033743\n",
      "R2 of the best estimator (testing dataset):  0.3483661297031558\n",
      "pred [4.99057358 4.00945854 4.48027444 4.5194572  4.43458841 4.5652026 ]\n",
      "pred [4.90650074 4.09346977 4.56931388 4.43065059 3.3105876  5.68915692]\n",
      "pred [3.99738016 5.00256696 4.22144823 4.77862916 3.79871904 5.20123694]\n",
      "pred [3.09217086 5.90827004 4.3788574  4.62130038 5.41273803 3.58703334]\n",
      "pred [4.12973486 4.87022321 3.8935927  5.10641322 4.00193478 4.99790522]\n",
      "pred [5.02766783 3.97243002 4.42228849 4.57780855 4.93644979 4.06373995]\n",
      "pred [4.35017027 4.64977896 4.34244212 4.65760726 4.18811698 4.81163536]\n",
      "pred [3.9537431  5.04627261 4.37270889 4.62738561 4.12490845 4.87511232]\n",
      "pred [4.23568738 4.76425818 4.28862146 4.71148363 4.19702653 4.80299516]\n",
      "pred [4.62074429 4.37916844 4.33755577 4.6626539  4.22735166 4.77233943]\n",
      "pred [4.7358585  4.26399662 4.36689753 4.63334414 4.40549732 4.59405391]\n",
      "pred [3.84159389 5.15856706 4.49534393 4.50436323 3.90888788 5.09111735]\n",
      "pred [3.42353947 5.57629532 4.42836647 4.57188813 4.57035282 4.42964413]\n",
      "pred [3.67585286 5.32380331 4.28650974 4.71307984 4.32634663 4.67376473]\n",
      "pred [4.18150109 4.81844079 4.32234339 4.67772663 4.16291421 4.83719467]\n",
      "pred [4.23364004 4.76626628 4.20659925 4.79353207 4.15115833 4.84889397]\n",
      "pred [3.54415831 5.45580452 4.41144361 4.58862137 4.23095698 4.76876587]\n",
      "pred [4.63998817 4.35978595 4.6136236  4.38636046 4.80517558 4.1949139 ]\n",
      "pred [3.92731872 5.07234341 4.36263515 4.63706352 4.13366292 4.86622788]\n",
      "pred [3.37118211 5.62821653 4.44363027 4.556702   4.35333445 4.64647432]\n",
      "pred [3.7282572  5.27179352 4.3451361  4.65473893 4.00883868 4.99090875]\n",
      "pred [4.37227568 4.62791995 4.43145045 4.56836153 4.30268051 4.69742915]\n",
      "pred [3.82471218 5.17481131 4.62377997 4.37584237 4.5284088  4.47172366]\n",
      "pred [4.27692336 4.72310607 4.35966839 4.64030766 4.30328623 4.69683315]\n",
      "pred [3.06069569 5.93954993 4.61550815 4.38475764 3.83555574 5.16444806]\n",
      "pred [4.5220259  4.47843148 4.354579   4.64533201 4.55176155 4.44829453]\n",
      "pred [4.16890686 4.83101373 4.52779427 4.47219819 3.64476056 5.35492045]\n",
      "pred [4.635842   4.36391638 4.38715296 4.61277985 4.42700845 4.57254118]\n",
      "pred [3.07882834 5.92113489 4.15160838 4.84814381 4.04720786 4.9528753 ]\n",
      "pred [4.18559606 4.81438273 3.95969164 5.0402784  3.76755203 5.23253101]\n",
      "pred [4.07182318 4.928186   4.24941621 4.75062905 4.09109775 4.90894119]\n",
      "pred [3.65542938 5.34461519 4.33995495 4.66004474 3.83589053 5.16415656]\n",
      "pred [4.89165322 4.10871425 4.07437562 4.92579369 3.85170553 5.1484626 ]\n",
      "pred [4.43974059 4.56027547 4.30937961 4.69069228 4.50178682 4.49834921]\n",
      "pred [4.03495646 4.9651003  4.47684729 4.52315595 4.14430683 4.85559982]\n",
      "pred [3.71687777 5.28281692 4.31342337 4.68621027 3.9759794  5.02397158]\n",
      "pred [3.08521948 5.91482073 4.49352093 4.50649855 4.07063158 4.92957427]\n",
      "pred [3.60594576 5.39402767 4.34311261 4.65698017 3.86289682 5.1371202 ]\n",
      "pred [5.22713757 3.77329282 4.40148302 4.5984843  4.29244516 4.70692996]\n",
      "pred [3.05517081 5.94512121 4.95429219 4.04531254 3.55944071 5.44069146]\n",
      "pred [4.77582165 4.22423727 4.36239025 4.63753221 4.01509174 4.98483934]\n",
      "pred [3.1811867  5.81879537 4.45822862 4.54164344 3.96612831 5.03433966]\n",
      "pred [4.81772345 4.18206237 4.37428978 4.62573909 2.60445606 6.39548684]\n",
      "pred [4.10131959 4.89859951 4.35924721 4.64079556 4.1170333  4.88304138]\n",
      "pred [3.91923591 5.08080618 4.34512225 4.65504213 3.95236864 5.04753584]\n",
      "pred [3.72001311 5.28004482 4.33550846 4.66438258 4.0169816  4.98277557]\n",
      "pred [4.38660668 4.61343211 4.31032279 4.68977145 4.17534778 4.82467348]\n",
      "pred [4.97415215 4.02592432 4.5665714  4.43328832 3.96259676 5.03721353]\n",
      "pred [3.9857273  5.01429271 4.21451809 4.78554975 4.17095818 4.82920488]\n",
      "pred [4.10200831 4.89785076 4.38164861 4.6183968  4.14143162 4.85870844]\n",
      "pred [4.52401467 4.47606242 4.32579423 4.67425271 4.33559119 4.66444838]\n",
      "pred [3.23477188 5.76521692 4.67191283 4.3283451  4.06877335 4.93130313]\n",
      "pred [4.28990275 4.70994886 4.21246235 4.78681513 3.96459509 5.03531067]\n",
      "pred [3.6747904  5.32532844 4.56461804 4.43537165 3.30244628 5.69779045]\n",
      "pred [3.41057158 5.58935023 4.07658702 4.92317219 3.84557222 5.15490375]\n",
      "pred [3.97896499 5.02105976 4.40074725 4.59931888 4.01538782 4.98462938]\n",
      "pred [5.2663797  3.73380581 4.38844543 4.61133936 4.37477776 4.62465736]\n",
      "pred [3.86424503 5.13549266 4.28025316 4.71938708 4.19685445 4.80323376]\n",
      "pred [3.15873443 5.84127354 4.73242515 4.26784137 3.79190037 5.2080268 ]\n",
      "pred [4.38761298 4.61223937 4.21237743 4.78767039 3.97999123 5.02019955]\n",
      "pred [4.04163987 4.95826822 4.37787651 4.62209432 4.13926082 4.86090513]\n",
      "pred [3.09639629 5.90343348 4.58159758 4.41854751 4.18163929 4.81869101]\n",
      "(296, 124) (296, 6)\n",
      "******* Feature select: PCA999  Feature type: HG-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.9836541986883524\n",
      "R2 Best score (validation) val. score :  0.5483140566408311\n",
      "R2 of the best estimator (testing dataset):  0.22998378044553666\n",
      "pred [4.19612531 4.80399183 4.71978448 4.28025121 4.0702139  4.93004849]\n",
      "pred [4.7926361  4.20742757 4.63680313 4.36316349 3.80458438 5.19584118]\n",
      "pred [4.03736121 4.96280113 4.55802649 4.44205    4.3182853  4.68205973]\n",
      "pred [4.13064408 4.86909794 4.64104711 4.35878215 5.05288727 3.94726657]\n",
      "pred [4.70746024 4.292645   4.1360751  4.86403945 3.92366906 5.07671804]\n",
      "pred [4.49230374 4.50788086 4.66858718 4.33159903 5.29888243 3.7014056 ]\n",
      "pred [4.03906014 4.96104423 4.71568772 4.28441988 4.32822757 4.67208607]\n",
      "pred [4.06839497 4.93173474 4.57657662 4.42344101 4.40820027 4.59215253]\n",
      "pred [4.03139965 4.96868841 4.59461812 4.40528178 4.27471612 4.72563769]\n",
      "pred [4.668884   4.33103279 4.6474852  4.35256632 4.12683477 4.87335425]\n",
      "pred [4.69860519 4.30126211 4.71794091 4.28200383 4.07262092 4.92748736]\n",
      "pred [4.02832898 4.97177819 4.62816141 4.3718599  4.38400597 4.61629245]\n",
      "pred [3.93763438 5.0623052  4.63051249 4.36927124 4.90827933 4.09189167]\n",
      "pred [3.81024532 5.18968745 4.39626152 4.60376461 3.82616772 5.17397641]\n",
      "pred [4.05701146 4.94314087 4.63951702 4.3605442  4.29643528 4.70392084]\n",
      "pred [4.00678852 4.99335119 4.58235392 4.41765338 4.27380823 4.72653418]\n",
      "pred [4.09650771 4.90357473 4.60796922 4.3920063  4.27790957 4.72241864]\n",
      "pred [4.18035643 4.81969975 4.58686974 4.41314153 4.34513499 4.65517792]\n",
      "pred [3.66548728 5.33449641 4.60616161 4.39403591 3.95292678 5.04726762]\n",
      "pred [4.98961978 4.01004312 4.74996212 4.24986731 3.90047779 5.09959818]\n",
      "pred [4.03517905 4.96490991 4.5665165  4.4334167  4.06386318 4.93652314]\n",
      "pred [4.13110035 4.8689485  4.58494908 4.41509528 4.24762702 4.75266376]\n",
      "pred [4.14734727 4.85276838 4.57385245 4.42607669 4.29321691 4.70698844]\n",
      "pred [4.02308056 4.97699829 4.60564758 4.39433913 4.48349621 4.51685287]\n",
      "pred [3.77584308 5.22417565 4.77895294 4.22101204 4.07856024 4.92174548]\n",
      "pred [4.08776887 4.91228624 4.5762568  4.42376168 4.44709976 4.5533009 ]\n",
      "pred [4.26193383 4.73805733 4.64681818 4.35324683 4.30604165 4.69422705]\n",
      "pred [4.79977827 4.20008388 4.72733723 4.27254505 4.15177289 4.84845111]\n",
      "pred [3.54803158 5.45214371 4.50982845 4.48993282 4.1436535  4.85665307]\n",
      "pred [4.27813145 4.72191344 4.38135429 4.61869518 3.56849815 5.43157539]\n",
      "pred [3.99395155 5.0061196  4.61995049 4.3800744  4.1741795  4.82611947]\n",
      "pred [4.02290609 4.9772141  4.62710855 4.37297492 4.30837386 4.69194784]\n",
      "pred [4.53391357 4.46608702 4.28812029 4.71178833 4.00510254 4.99525382]\n",
      "pred [4.62607699 4.37405384 4.57510925 4.42494293 5.08900321 3.91112189]\n",
      "pred [4.03735239 4.96276544 4.65511859 4.34481824 4.10615515 4.8941455 ]\n",
      "pred [4.17911424 4.82073937 4.28521741 4.71489132 3.67222849 5.32814108]\n",
      "pred [3.83260806 5.1675356  4.44056299 4.55966484 4.17262624 4.82768393]\n",
      "pred [4.06372814 4.93640288 4.63222328 4.36780891 4.36508635 4.63527252]\n",
      "pred [4.18422032 4.81586997 4.63079738 4.3691833  4.30706734 4.69330144]\n",
      "pred [4.00437112 4.99559169 4.42192105 4.57801633 4.06398537 4.93637824]\n",
      "pred [4.25461439 4.74552834 4.64531456 4.35462658 4.53212589 4.46816463]\n",
      "pred [3.84410555 5.15581273 4.61459289 4.38538636 3.97241877 5.02795676]\n",
      "pred [4.47322573 4.52708702 4.63884503 4.36113071 3.95406621 5.04629887]\n",
      "pred [4.11264289 4.88749778 4.60132158 4.39867606 4.29897439 4.70137295]\n",
      "pred [4.10795964 4.89194123 4.44781668 4.552122   4.23214383 4.76817858]\n",
      "pred [4.08611914 4.91389812 4.58380574 4.4161735  4.04873551 4.951642  ]\n",
      "pred [4.20415533 4.79595909 4.63851274 4.36161491 4.33734074 4.66298824]\n",
      "pred [4.91825348 4.08177153 4.60537067 4.39457789 3.99035849 5.00999948]\n",
      "pred [4.11666409 4.88347563 4.60557104 4.39443158 4.3327435  4.66759488]\n",
      "pred [4.00541703 4.99469314 4.61117734 4.38890854 4.31648588 4.68385899]\n",
      "pred [4.16269922 4.83742574 4.73715007 4.26295431 4.42499263 4.57527971]\n",
      "pred [3.67510521 5.32471576 4.67547878 4.32456169 3.8922372  5.10795149]\n",
      "pred [4.30812096 4.691916   4.56537969 4.4346538  4.33275118 4.66753068]\n",
      "pred [3.96456079 5.03545836 4.5263898  4.47366759 3.90750174 5.09280785]\n",
      "pred [3.9401749  5.05996841 4.34799545 4.65192612 3.85567988 5.14454535]\n",
      "pred [3.96978662 5.03032258 4.58269237 4.41733904 4.3993291  4.60100616]\n",
      "pred [4.08341016 4.91673154 4.60503349 4.39488719 4.31528945 4.68505134]\n",
      "pred [3.62640786 5.3736831  4.52423445 4.47574807 3.99624728 5.00399215]\n",
      "pred [3.68503985 5.31492122 4.61353855 4.38666716 3.96886971 5.03130087]\n",
      "pred [4.06553556 4.93458721 4.61096547 4.38908239 4.25971638 4.74061735]\n",
      "pred [4.1381396  4.86199988 4.59392703 4.40601994 4.34997129 4.65036611]\n",
      "pred [3.54791849 5.45232428 4.74902434 4.25085629 4.17874319 4.82164444]\n",
      "(296, 81) (296, 6)\n",
      "******* Feature select: PCA999  Feature type: OG-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.9838916648012915\n",
      "R2 Best score (validation) val. score :  0.5682056465790719\n",
      "R2 of the best estimator (testing dataset):  -0.023214034410540135\n",
      "pred [4.18687322 4.81316348 4.37769331 4.62231688 4.34977991 4.65022179]\n",
      "pred [4.21294057 4.78710227 4.381892   4.61812838 4.33928787 4.66073927]\n",
      "pred [4.1536947  4.84634937 4.36104975 4.63896287 4.33329718 4.66673   ]\n",
      "pred [4.14130896 4.85875853 4.38092264 4.61909853 4.41189361 4.58813392]\n",
      "pred [4.1550738  4.8449537  4.34793518 4.65207977 4.31071791 4.68929838]\n",
      "pred [4.1792167  4.82083216 4.37854104 4.62146649 4.40147319 4.5985574 ]\n",
      "pred [4.15672453 4.84331856 4.36750728 4.63250593 4.33940525 4.66062147]\n",
      "pred [4.15615066 4.84389418 4.36657273 4.63343831 4.33746104 4.66256382]\n",
      "pred [4.15603846 4.8440044  4.36849502 4.63151806 4.33867411 4.66135241]\n",
      "pred [4.17734719 4.82268169 4.38104086 4.61898964 4.33667257 4.66333929]\n",
      "pred [4.20199065 4.79806587 4.38343533 4.61660435 4.34852532 4.65149936]\n",
      "pred [4.15469886 4.8453461  4.36836297 4.6316501  4.33845792 4.66156836]\n",
      "pred [4.11414969 4.88591711 4.38326232 4.61675104 4.40580701 4.59422109]\n",
      "pred [4.06390644 4.93612546 4.37453075 4.62547993 4.30095619 4.69909217]\n",
      "pred [4.15614779 4.84389539 4.36784255 4.63217019 4.33900042 4.66102712]\n",
      "pred [4.15735195 4.84269002 4.36824714 4.63176588 4.33753124 4.66249562]\n",
      "pred [4.15388317 4.84615664 4.37017327 4.62983934 4.33513499 4.66489192]\n",
      "pred [4.15408342 4.84595694 4.36881535 4.63120028 4.33888761 4.66113747]\n",
      "pred [4.05191702 4.94810764 4.38645518 4.61354754 4.29948338 4.70055035]\n",
      "pred [4.20088303 4.7991675  4.38325409 4.61679828 4.33597697 4.66405766]\n",
      "pred [4.1440965  4.85594791 4.37142126 4.62858988 4.32292687 4.67710508]\n",
      "pred [4.1546113  4.84543188 4.36789247 4.63212075 4.33886274 4.66116347]\n",
      "pred [4.14552792 4.8545135  4.37157376 4.62845169 4.33479714 4.66522859]\n",
      "pred [4.15644097 4.8436027  4.36808923 4.63192615 4.34464453 4.65538101]\n",
      "pred [4.12450535 4.87553404 4.37064902 4.62936567 4.32852433 4.67149954]\n",
      "pred [4.16198534 4.83805956 4.36780793 4.63220512 4.34804976 4.65198703]\n",
      "pred [4.15596614 4.8440764  4.36766698 4.63234665 4.33871041 4.66131627]\n",
      "pred [4.21481381 4.78524793 4.38729502 4.61274297 4.35987962 4.64014039]\n",
      "pred [4.13953924 4.86050045 4.36839173 4.63162052 4.33656576 4.66346263]\n",
      "pred [4.15765902 4.84237152 4.3731553  4.62684023 4.29282865 4.70721043]\n",
      "pred [4.15595242 4.84409077 4.3657529  4.63426211 4.33486863 4.66515938]\n",
      "pred [4.15535031 4.84469255 4.36789384 4.6321195  4.33881414 4.66121254]\n",
      "pred [4.16017288 4.83987006 4.3615061  4.63850885 4.33452689 4.66550294]\n",
      "pred [4.17221293 4.82783677 4.36970806 4.63030668 4.36513548 4.63489395]\n",
      "pred [4.15530008 4.84474562 4.36763582 4.6323767  4.33066575 4.66936092]\n",
      "pred [4.10648778 4.89356779 4.35710507 4.64290481 4.28169459 4.71834781]\n",
      "pred [4.14339715 4.85664748 4.36865693 4.6313584  4.33809457 4.66193525]\n",
      "pred [4.15394557 4.84609775 4.36869096 4.63132242 4.33539892 4.66462815]\n",
      "pred [4.16568413 4.83435365 4.37400362 4.62600697 4.3271994  4.67283104]\n",
      "pred [4.13299362 4.86704651 4.36975561 4.6302625  4.32445554 4.67557081]\n",
      "pred [4.15959118 4.84045092 4.36850596 4.63151173 4.35394399 4.64608337]\n",
      "pred [4.08976544 4.91023965 4.37976578 4.62026429 4.30987225 4.69016883]\n",
      "pred [4.17867889 4.82135332 4.37281921 4.62720462 4.28349374 4.7165218 ]\n",
      "pred [4.15626705 4.84377597 4.36742283 4.63259051 4.33944908 4.66057752]\n",
      "pred [4.15207403 4.8479666  4.36695491 4.63306069 4.3357088  4.66432088]\n",
      "pred [4.14160695 4.85842903 4.37077859 4.62923158 4.32366164 4.67636935]\n",
      "pred [4.15323602 4.84680031 4.36944403 4.63057693 4.33383542 4.6661911 ]\n",
      "pred [4.2062006  4.7938475  4.38216424 4.61786094 4.36106659 4.63895908]\n",
      "pred [4.15665209 4.84339106 4.36751011 4.63250305 4.339512   4.66051466]\n",
      "pred [4.15634484 4.8436981  4.36830567 4.63170728 4.3399596  4.66006654]\n",
      "pred [4.15386669 4.84617753 4.36924871 4.63076522 4.34053496 4.65949258]\n",
      "pred [4.12118303 4.87885154 4.37255524 4.62746555 4.33287143 4.6671465 ]\n",
      "pred [4.16704236 4.83299628 4.37143156 4.62858834 4.3433591  4.65665037]\n",
      "pred [4.14107261 4.85896047 4.37187968 4.62813924 4.31046543 4.68955449]\n",
      "pred [4.10058894 4.89944603 4.35382099 4.64618191 4.30763965 4.69237021]\n",
      "pred [4.15651993 4.8435233  4.36745295 4.63256023 4.33941742 4.66060926]\n",
      "pred [4.15764346 4.84240074 4.367699   4.63231525 4.33943573 4.66059096]\n",
      "pred [4.08064884 4.91941772 4.37855208 4.6214704  4.32145262 4.67859651]\n",
      "pred [4.11558454 4.88445982 4.37394964 4.62607658 4.32385688 4.67617419]\n",
      "pred [4.15520156 4.84484516 4.3621436  4.63786807 4.32917166 4.67084819]\n",
      "pred [4.15666128 4.84338172 4.36801391 4.63199963 4.33873547 4.66129123]\n",
      "pred [4.10026579 4.89979467 4.37718788 4.62282495 4.33326017 4.66676134]\n",
      "(296, 60) (296, 6)\n",
      "******* Feature select: PCA999  Feature type: ST-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.9844594765179281\n",
      "R2 Best score (validation) val. score :  0.5192871136137609\n",
      "R2 of the best estimator (testing dataset):  0.19627216585886084\n",
      "pred [4.46117178 4.53896951 4.38798129 4.61201896 4.35648706 4.64359244]\n",
      "pred [4.47217103 4.52799671 4.52142448 4.47850181 4.18577619 4.81420309]\n",
      "pred [4.12762273 4.87248048 4.29256719 4.70748104 4.10331849 4.89671859]\n",
      "pred [3.85385953 5.14634028 4.39926669 4.60060151 4.79565467 4.20446811]\n",
      "pred [4.13759948 4.8624524  4.12223299 4.87764777 4.06728663 4.93279998]\n",
      "pred [4.44836046 4.55156978 4.38763787 4.61237673 4.80977419 4.1902595 ]\n",
      "pred [4.18096255 4.81910099 4.32110799 4.67890696 4.27553104 4.72451623]\n",
      "pred [4.16672476 4.83332741 4.31422168 4.68580889 4.27880253 4.72125079]\n",
      "pred [4.18245065 4.81759657 4.32005952 4.67998604 4.29096093 4.70909024]\n",
      "pred [4.35995008 4.64012248 4.34320463 4.65636949 4.2739174  4.72613076]\n",
      "pred [4.47531764 4.52477385 4.40664944 4.59295815 4.40972428 4.59031302]\n",
      "pred [4.16055761 4.83953914 4.35953193 4.64039142 4.26458996 4.73539424]\n",
      "pred [3.89850186 5.10162999 4.40277193 4.59718078 4.68060763 4.31947668]\n",
      "pred [3.42405397 5.57623964 4.33458094 4.66524699 4.08086471 4.91916099]\n",
      "pred [4.2170894  4.78295318 4.3424603  4.65756531 4.26440826 4.73564474]\n",
      "pred [4.24815485 4.75193807 4.3051798  4.69479576 4.27140252 4.72863728]\n",
      "pred [3.96372779 5.03633441 4.35049381 4.64945068 4.23689019 4.76313903]\n",
      "pred [4.22292391 4.77722232 4.52041408 4.47967513 4.45743025 4.54253776]\n",
      "pred [3.66124537 5.3387991  4.42738865 4.57235223 4.23806866 4.76208021]\n",
      "pred [4.3242089  4.67592208 4.44172191 4.55805023 4.2036658  4.79625303]\n",
      "pred [3.97981287 5.02022668 4.36362201 4.63627305 4.20135555 4.7986404 ]\n",
      "pred [4.04405917 4.95601611 4.42827571 4.57167157 4.41047467 4.58963388]\n",
      "pred [3.94873102 5.05152459 4.50459109 4.49534877 4.47007424 4.52987647]\n",
      "pred [4.20034722 4.7997033  4.30777147 4.69226163 4.29474773 4.70530106]\n",
      "pred [3.98938403 5.01066326 4.34909507 4.65086799 4.28171248 4.71837318]\n",
      "pred [4.16243525 4.83774279 4.38366973 4.61635321 4.45902727 4.54108377]\n",
      "pred [4.23307675 4.76698944 4.46368971 4.5362047  4.2927163  4.70716175]\n",
      "pred [4.37886694 4.62123067 4.41180296 4.58770711 4.36590528 4.63408376]\n",
      "pred [3.70238251 5.29766663 4.36529656 4.63473931 4.25066265 4.74945302]\n",
      "pred [4.25529442 4.74478505 4.17011153 4.82983618 4.02357968 4.97653348]\n",
      "pred [4.19252419 4.80752536 4.29102333 4.70901465 4.27648909 4.7235629 ]\n",
      "pred [4.06977493 4.93027473 4.32144164 4.6785895  4.20002922 4.80003248]\n",
      "pred [4.55859694 4.44137362 4.14367591 4.85629226 4.10641945 4.89374478]\n",
      "pred [4.39069359 4.60927031 4.33236494 4.66766535 4.52941099 4.47063725]\n",
      "pred [4.15803351 4.84201364 4.35263327 4.64737016 4.17347544 4.82653535]\n",
      "pred [4.02243188 4.97754876 4.27429849 4.72581475 4.03921179 4.96081167]\n",
      "pred [3.56705919 5.4329921  4.43851459 4.56146554 4.19801862 4.80191785]\n",
      "pred [4.0671972  4.93277741 4.34350299 4.65654452 4.19032683 4.80969067]\n",
      "pred [3.91849662 5.0815646  4.41862238 4.58128252 4.25259966 4.74740161]\n",
      "pred [3.64650701 5.3535649  4.51362036 4.48623188 4.17008371 4.83000973]\n",
      "pred [4.30418141 4.69585297 4.28879445 4.71121335 4.30498028 4.6950543 ]\n",
      "pred [3.75285048 5.24698696 4.31747482 4.68266866 4.07557535 4.92447924]\n",
      "pred [4.07440662 4.92571757 4.35487251 4.64504855 4.12858613 4.87148724]\n",
      "pred [4.16568709 4.83437927 4.32980469 4.67023089 4.26427956 4.73577482]\n",
      "pred [3.96810617 5.03196301 4.3444622  4.65549028 4.21585113 4.78410126]\n",
      "pred [4.03112012 4.96890496 4.3405489  4.65947416 4.23911253 4.7609636 ]\n",
      "pred [4.24867616 4.75135941 4.32021624 4.67977669 4.30965123 4.69039836]\n",
      "pred [4.45386094 4.54625643 4.47087035 4.5290796  4.49545284 4.50458262]\n",
      "pred [4.19358514 4.80646508 4.30020745 4.69982945 4.29182629 4.70822397]\n",
      "pred [4.19934334 4.80069697 4.32252848 4.67751193 4.27813454 4.72191463]\n",
      "pred [4.22512778 4.77487914 4.33065916 4.6694527  4.27273732 4.72734939]\n",
      "pred [3.69471344 5.30548411 4.49657142 4.50336832 4.18873128 4.81123496]\n",
      "pred [4.13167881 4.86838141 4.31094503 4.68864142 4.18826613 4.81162576]\n",
      "pred [4.21015775 4.78990193 4.32524243 4.67479222 4.00322137 4.99679644]\n",
      "pred [3.79706331 5.20304362 4.31768716 4.68230088 4.17897892 4.82109987]\n",
      "pred [4.17559246 4.82446813 4.30320902 4.69682993 4.26245328 4.73759191]\n",
      "pred [4.05500128 4.94506799 4.41582991 4.58409723 4.47024131 4.52970281]\n",
      "pred [3.45128195 5.54893652 4.40356893 4.59629559 4.13659758 4.86351479]\n",
      "pred [3.66268919 5.3373532  4.52141329 4.47871991 4.11067161 4.88931034]\n",
      "pred [4.12795769 4.87212173 4.31123258 4.6887835  4.20162574 4.79841874]\n",
      "pred [4.19322591 4.80680787 4.3728523  4.6271547  4.28341362 4.71669518]\n",
      "pred [3.64795512 5.35234129 4.40495841 4.59538507 4.20073623 4.79920273]\n",
      "(296, 10) (296, 6)\n",
      "******* Feature select: LR10  Feature type: HG-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.19959972134170223\n",
      "R2 Best score (validation) val. score :  0.07279943700523912\n",
      "R2 of the best estimator (testing dataset):  0.11271855571380442\n",
      "pred [3.59679821 5.40191554 4.44818239 4.55154679 4.16341263 4.83724661]\n",
      "pred [4.78178876 4.21660585 4.46976213 4.53047806 4.45762983 4.54189465]\n",
      "pred [4.03635093 4.96021011 3.93287412 5.06751192 2.87415444 6.12543485]\n",
      "pred [4.33254122 4.66895693 4.52438248 4.4759009  4.62968691 4.36921656]\n",
      "pred [4.18258014 4.81531984 3.81986763 5.1812785  2.79180732 6.20830827]\n",
      "pred [4.80707881 4.19186052 4.45371709 4.54661311 4.44900666 4.55053935]\n",
      "pred [3.47660723 5.52426019 4.57024807 4.42948392 4.46597678 4.53354545]\n",
      "pred [3.89817162 5.10239392 4.28609913 4.71519218 3.52200852 5.47668369]\n",
      "pred [4.14461357 4.85734693 4.44045798 4.55913271 4.43490552 4.56465741]\n",
      "pred [4.21322225 4.78026243 4.24006533 4.75962512 3.9546213  5.04562597]\n",
      "pred [4.18967163 4.80371848 4.24125206 4.75844849 3.95767165 5.04252677]\n",
      "pred [3.47705635 5.5284715  4.40340239 4.59679298 4.35352366 4.64558985]\n",
      "pred [4.2969007  4.70501489 4.53223851 4.46799213 4.66383787 4.33492086]\n",
      "pred [4.30271996 4.69455338 4.17889399 4.82109882 3.99935758 5.00065252]\n",
      "pred [4.87779828 4.1268023  4.21708051 4.78334778 4.27268519 4.72644526]\n",
      "pred [5.26325183 3.73347269 4.45688228 4.54313086 4.16665723 4.83497779]\n",
      "pred [3.98758557 5.01472527 4.25759295 4.74240732 3.87658948 5.12352648]\n",
      "pred [3.09343104 5.91025327 4.62719447 4.37243546 4.59173023 4.4072718 ]\n",
      "pred [4.31065147 4.68631391 4.17590099 4.82411854 3.98809541 5.01192301]\n",
      "pred [4.79417192 4.20257549 4.49435039 4.50580481 4.42496461 4.57477724]\n",
      "pred [3.81747755 5.18169239 3.90673576 5.09430338 2.95774414 6.04186596]\n",
      "pred [3.96541294 5.03478571 4.19977516 4.80030211 3.6950138  5.30524282]\n",
      "pred [2.86491268 6.14023816 4.53020321 4.46959383 4.53731387 4.46153063]\n",
      "pred [4.40134396 4.59838397 4.50405031 4.49621193 4.52885782 4.47039434]\n",
      "pred [3.34736543 5.65367966 4.46462386 4.53531127 4.3919263  4.60720916]\n",
      "pred [3.15554361 5.8470771  4.2685081  4.73259212 3.60495008 5.3929611 ]\n",
      "pred [4.59133557 4.41212601 4.56448385 4.43583591 4.5914577  4.40870388]\n",
      "pred [4.14536963 4.8480967  4.2477984  4.75192988 3.96672989 5.03343841]\n",
      "pred [3.99157752 5.0058358  4.05671107 4.94332605 3.69005525 5.31081205]\n",
      "pred [4.37993057 4.61858762 3.88495264 5.11628637 2.86868961 6.13145984]\n",
      "pred [4.36005966 4.64226943 4.18057513 4.81955278 3.76428602 5.23626812]\n",
      "pred [3.43314459 5.56936847 4.38678141 4.61393273 3.90383602 5.09448622]\n",
      "pred [3.82640617 5.17195555 3.998268   5.0019586  3.10267446 5.89642523]\n",
      "pred [4.85988655 4.13793391 4.45525177 4.54502119 4.41346263 4.58622635]\n",
      "pred [4.6654621  4.33204899 4.46176045 4.53751897 4.30497958 4.69496203]\n",
      "pred [4.28927335 4.70766366 4.17873511 4.8213008  3.99211239 5.00787874]\n",
      "pred [2.92880848 6.07005623 4.49850109 4.50140596 4.36754915 4.63151652]\n",
      "pred [3.63309317 5.36582192 4.13966862 4.86125356 3.27715595 5.72137531]\n",
      "pred [4.66680533 4.33887253 4.50192767 4.49859936 4.62273077 4.37714256]\n",
      "pred [3.98832902 5.01107844 4.1806953  4.81923875 3.53181376 5.46837903]\n",
      "pred [4.6810386  4.31870351 4.47229418 4.52798247 4.50869461 4.49061017]\n",
      "pred [3.68407701 5.31525186 4.02048288 4.97979657 3.14901351 5.84999879]\n",
      "pred [4.61986219 4.38037818 4.48188229 4.51834775 4.54424179 4.45492001]\n",
      "pred [5.0521103  3.9472432  4.6274094  4.37285827 4.34204669 4.65871659]\n",
      "pred [4.19514291 4.80417249 4.16723553 4.83284979 3.57736254 5.42291167]\n",
      "pred [3.96324432 5.0352596  3.93266041 5.06842608 2.95832052 6.04138492]\n",
      "pred [4.36177431 4.63774735 4.50631107 4.49342824 4.4438936  4.55593403]\n",
      "pred [4.77454074 4.22516298 4.4532421  4.54706054 4.48355124 4.5158283 ]\n",
      "pred [3.30363913 5.69831021 4.63600722 4.36376403 4.5536517  4.44572919]\n",
      "pred [4.48888945 4.51138276 4.59364248 4.40640146 4.37880574 4.62141507]\n",
      "pred [4.24844656 4.75142307 4.466264   4.53329251 4.40154006 4.59824173]\n",
      "pred [2.9739962  6.02969251 4.51910205 4.48093779 4.42079027 4.57871519]\n",
      "pred [4.00546964 4.98912247 4.27270209 4.72697955 4.0351506  4.96481685]\n",
      "pred [4.08316597 4.91401859 4.01400203 4.98623503 3.21789355 5.78200928]\n",
      "pred [2.97009103 6.0301349  3.88245282 5.11758364 3.6649819  5.33498267]\n",
      "pred [3.31094219 5.69132775 4.34302077 4.65673058 3.95892301 5.04040632]\n",
      "pred [4.7087278  4.29662273 4.49988976 4.50058669 4.61143926 4.38846728]\n",
      "pred [4.24379582 4.75364841 4.18934992 4.81067323 4.01752304 4.98242776]\n",
      "pred [2.55546503 6.448986   4.46112081 4.53895348 4.46016676 4.53851711]\n",
      "pred [4.19986667 4.79574508 3.95634801 5.04472709 2.87808474 6.1220501 ]\n",
      "pred [4.55838807 4.44359098 4.46631818 4.53381161 4.28188198 4.71859757]\n",
      "pred [3.59013435 5.40803883 4.05197145 4.94821621 3.1749497  5.82386759]\n",
      "(296, 10) (296, 6)\n",
      "******* Feature select: LR10  Feature type: OG-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.9683879178262975\n",
      "R2 Best score (validation) val. score :  0.4738989135694182\n",
      "R2 of the best estimator (testing dataset):  0.24233923048141845\n",
      "pred [4.70070677 4.29957118 4.63585051 4.36458251 4.32770665 4.67182078]\n",
      "pred [5.4808856  3.51908996 4.32147199 4.67852175 3.96176009 5.03982121]\n",
      "pred [5.02619108 3.97427516 3.62975823 5.37029108 3.67900684 5.32090044]\n",
      "pred [3.36232633 5.63795656 4.62005926 4.38009475 6.28276604 2.71772441]\n",
      "pred [4.91830571 4.0816668  1.60033026 7.39945001 4.73962118 4.26072747]\n",
      "pred [5.28030067 3.71960864 4.43172418 4.56820624 6.28444556 2.7155929 ]\n",
      "pred [4.61594945 4.38428976 4.82742408 4.17272282 4.5136208  4.48598463]\n",
      "pred [3.34034407 5.65975833 4.78253746 4.21809286 4.86178064 4.14011345]\n",
      "pred [4.42922041 4.57069592 4.39028692 4.60957916 4.33680591 4.66310702]\n",
      "pred [4.33002436 4.66987711 4.44249405 4.55530691 4.44452159 4.55562172]\n",
      "pred [4.28877521 4.71109935 4.61942974 4.37893855 4.52014519 4.48003329]\n",
      "pred [4.13628363 4.86386634 4.55123818 4.44872115 4.42519498 4.57500614]\n",
      "pred [2.90299293 6.09684389 4.52773911 4.47261753 5.61690124 3.38055412]\n",
      "pred [4.73315556 4.26672091 3.8439368  5.15612179 3.949385   5.05051543]\n",
      "pred [4.45123792 4.54881815 4.56064549 4.43929057 4.54085802 4.45929353]\n",
      "pred [4.02273527 4.97709293 4.91610667 4.08378387 4.41807911 4.58215028]\n",
      "pred [4.90733441 4.09253033 4.51511737 4.48513461 4.45399375 4.54661041]\n",
      "pred [4.69137645 4.30868627 4.44075241 4.5592199  4.6666798  4.33354182]\n",
      "pred [4.87283157 4.12713258 3.71010908 5.29007299 3.72893346 5.27092043]\n",
      "pred [5.30807758 3.69181106 4.49428571 4.50572669 3.00324686 5.99744331]\n",
      "pred [3.9558615  5.04400302 4.05371644 4.94588648 4.60984852 4.39090027]\n",
      "pred [4.18921873 4.81068212 4.57038405 4.42946889 4.21176933 4.78859532]\n",
      "pred [4.25928089 4.74052921 4.36654608 4.6335511  4.62046482 4.37977754]\n",
      "pred [4.21837944 4.78186195 4.37806983 4.6220782  7.19434225 1.80576013]\n",
      "pred [3.79761555 5.202223   4.48130021 4.51867583 4.3538181  4.64616441]\n",
      "pred [3.69907289 5.30103164 4.69648331 4.30380591 5.04588195 3.95514984]\n",
      "pred [3.01764337 5.98231426 4.5753042  4.42457343 3.38683939 5.61321901]\n",
      "pred [4.47592699 4.52402667 4.56677611 4.43129849 4.54253574 4.45764614]\n",
      "pred [3.38424787 5.61559181 4.44210829 4.5577722  4.3560818  4.64388354]\n",
      "pred [4.27191405 4.72805802 3.17441972 5.82537463 3.80227588 5.19788764]\n",
      "pred [3.73787779 5.26213647 4.4927069  4.50732543 3.8422289  5.15752325]\n",
      "pred [2.72097556 6.2787162  5.17041902 3.83000962 3.99125419 5.01007037]\n",
      "pred [5.67747732 3.32250065 3.86605444 5.13437597 3.7782427  5.22215083]\n",
      "pred [5.53739192 3.46270705 4.2578079  4.74194498 5.29179642 3.70894155]\n",
      "pred [4.35695513 4.64299958 4.70257062 4.2976476  4.02453532 4.97573275]\n",
      "pred [5.15877869 3.84114818 3.68042329 5.31981715 3.36726524 5.63274044]\n",
      "pred [3.97575837 5.02422085 4.48291348 4.51712599 4.41257128 4.58747219]\n",
      "pred [2.47851372 6.52147829 5.11390612 3.88693134 4.26828178 4.7334899 ]\n",
      "pred [5.16741012 3.83197137 4.55383972 4.44606666 4.0188305  4.98102758]\n",
      "pred [4.63698821 4.36345538 4.43221472 4.56815613 3.72820445 5.2717841 ]\n",
      "pred [5.1356441  3.86431509 4.36637865 4.63364945 4.47487998 4.52458631]\n",
      "pred [3.91986454 5.0802153  4.55922112 4.44097095 3.67958474 5.32038741]\n",
      "pred [4.51762081 4.48246061 4.58515768 4.41498596 2.95498949 6.0429464 ]\n",
      "pred [4.1153744  4.88472258 4.64191651 4.35787634 4.5580913  4.44226267]\n",
      "pred [3.71867452 5.28147156 3.9367864  5.06312954 4.32950109 4.67066118]\n",
      "pred [3.95744637 5.0424196  4.04967179 4.94990782 4.60934323 4.39140323]\n",
      "pred [4.61360103 4.38654639 4.63115487 4.36873416 4.48975036 4.51006989]\n",
      "pred [5.66424721 3.33564526 4.61380526 4.38609063 6.52590298 2.47319687]\n",
      "pred [2.86626644 6.13385338 4.21246455 4.78791129 4.44608394 4.55341536]\n",
      "pred [3.82781375 5.17226238 4.83588127 4.16388122 4.56415666 4.43630534]\n",
      "pred [4.58760926 4.41253886 4.65845204 4.34149557 4.56296434 4.43676832]\n",
      "pred [3.3495919  5.65022975 4.33987109 4.66026786 4.06250496 4.93736957]\n",
      "pred [4.23396503 4.76606665 4.66463735 4.3332211  4.28155475 4.71857456]\n",
      "pred [4.21180771 4.78883777 3.83785808 5.16211703 3.07913498 5.92084903]\n",
      "pred [3.45213903 5.54786801 4.41755999 4.5823226  4.37653165 4.6234963 ]\n",
      "pred [4.55738587 4.44292097 3.49255051 5.50774504 3.05875541 5.94054998]\n",
      "pred [3.70319304 5.29611683 4.53813407 4.46175681 4.22719006 4.77251478]\n",
      "pred [4.82904733 4.1712257  3.80761067 5.1925294  4.04388447 4.95593357]\n",
      "pred [3.71169527 5.28808957 4.41405163 4.5860455  4.24693978 4.75309111]\n",
      "pred [5.26854671 3.73178476 4.48476803 4.51516501 4.52994804 4.47044853]\n",
      "pred [4.29270189 4.70739902 4.52642451 4.47346283 4.51966346 4.48054162]\n",
      "pred [3.48579647 5.51446336 4.78738061 4.21329793 3.37731236 5.62376766]\n",
      "(296, 10) (296, 6)\n",
      "******* Feature select: LR10  Feature type: ST-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.9577210276087307\n",
      "R2 Best score (validation) val. score :  0.44090432631358356\n",
      "R2 of the best estimator (testing dataset):  0.055704736559095636\n",
      "pred [4.89152036 4.10891232 4.46772064 4.53229966 4.69519071 4.30419211]\n",
      "pred [5.60735443 3.39284293 4.32362095 4.67680151 4.54163893 4.45819162]\n",
      "pred [4.36220804 4.63790444 2.60838074 6.39152141 4.18380155 4.81653417]\n",
      "pred [3.46554981 5.534237   4.50062045 4.49951353 5.9122347  3.08849479]\n",
      "pred [4.00062728 4.99953199 3.84309544 5.15706571 3.40822223 5.59259143]\n",
      "pred [5.57092396 3.42861905 4.5276318  4.47326147 5.83948667 3.16121532]\n",
      "pred [4.91233341 4.08751633 4.55938597 4.44070449 4.22685605 4.7727554 ]\n",
      "pred [4.90202457 4.09812145 4.71010443 4.28985825 3.82550146 5.17512472]\n",
      "pred [4.77877232 4.22093072 4.50894332 4.4907702  4.44318012 4.55653882]\n",
      "pred [4.87195124 4.12847415 4.38589683 4.61418463 4.79899255 4.20036398]\n",
      "pred [4.68494199 4.31552079 4.67823509 4.32191634 4.75872324 4.24081627]\n",
      "pred [3.90016799 5.10045532 4.43511779 4.5647952  3.99064436 5.00965774]\n",
      "pred [2.60088231 6.39902248 4.49732167 4.50440273 5.10091575 3.89958623]\n",
      "pred [3.86645722 5.13314476 3.37379946 5.62610367 4.04176565 4.95831841]\n",
      "pred [4.30302085 4.69702567 4.37121129 4.62859457 4.25502919 4.74508735]\n",
      "pred [4.37447716 4.62565504 4.24332612 4.75681862 4.16763048 4.83216452]\n",
      "pred [3.38895857 5.61102159 4.39475272 4.60525864 3.68391646 5.31580074]\n",
      "pred [5.05024259 3.94956803 4.36863391 4.63178976 5.27231658 3.72814855]\n",
      "pred [3.75350265 5.24623492 2.56073873 6.43913607 3.63973237 5.36027874]\n",
      "pred [5.13793555 3.8622869  4.53901682 4.46179595 2.96752719 6.03325061]\n",
      "pred [3.66897914 5.33106048 4.14823405 4.85176819 3.89154774 5.10804272]\n",
      "pred [3.84147947 5.15868429 4.41008888 4.58967973 3.89270592 5.10718571]\n",
      "pred [2.81086894 6.18899753 4.50855191 4.49158789 4.45082137 4.54930307]\n",
      "pred [4.51453733 4.48583832 4.58881253 4.41161204 6.50731484 2.49135746]\n",
      "pred [3.21152701 5.78829977 4.47497198 4.52505056 4.38164754 4.61842083]\n",
      "pred [3.93730114 5.06273795 4.38461094 4.61525843 5.19082207 3.80935515]\n",
      "pred [3.66598766 5.33439588 4.62068931 4.37904162 3.47997906 5.52023557]\n",
      "pred [4.49354374 4.50690425 4.74650788 4.25365484 4.66271661 4.33699209]\n",
      "pred [2.45658098 6.5433874  4.02872921 4.97122894 3.96859825 5.03206317]\n",
      "pred [4.04488297 4.95526589 4.35409927 4.64605451 3.63564228 5.3647505 ]\n",
      "pred [4.2730351  4.72705341 4.34656495 4.65358985 3.89620131 5.10387163]\n",
      "pred [5.80777655 3.19226282 3.97249579 5.02776349 4.08883551 4.91180638]\n",
      "pred [5.84645802 3.15366003 3.5881803  5.41225465 3.20341808 5.79648422]\n",
      "pred [5.77467712 3.22497549 4.64809515 4.35264034 4.47005496 4.53028302]\n",
      "pred [4.17152036 4.82885033 4.55568786 4.44459256 3.32639015 5.67405701]\n",
      "pred [4.01300795 4.98655327 3.29325684 5.7067839  3.82580961 5.17427402]\n",
      "pred [2.63712055 6.36247809 4.28924072 4.71083629 4.00308625 4.99676608]\n",
      "pred [4.35503094 4.64476111 4.18254238 4.8175296  4.77671804 4.22302516]\n",
      "pred [5.7782325  3.22157051 4.48236973 4.51788655 4.34157001 4.65813959]\n",
      "pred [3.03403123 5.96568903 4.42551291 4.57480138 3.98473709 5.01487742]\n",
      "pred [5.59572844 3.40455133 4.22223129 4.77846652 5.59372902 3.40645214]\n",
      "pred [3.47713449 5.52302771 4.08243265 4.9178883  3.0965428  5.90363956]\n",
      "pred [5.29355655 3.70667737 4.19204662 4.80836457 4.42792976 4.57221922]\n",
      "pred [4.41347501 4.5865969  4.30224077 4.69791231 4.27047935 4.72922915]\n",
      "pred [3.67772914 5.32244278 4.37986832 4.61977273 3.5582181  5.44172443]\n",
      "pred [3.54348747 5.45654743 4.09534397 4.90468134 3.9267006  5.07290042]\n",
      "pred [4.76228264 4.23740544 4.34635645 4.65347105 4.19177266 4.8079801 ]\n",
      "pred [5.67306418 3.32692221 4.35867018 4.64231212 7.05428622 1.94537037]\n",
      "pred [3.75853995 5.24160971 4.53339873 4.46654141 4.61487724 4.38525643]\n",
      "pred [4.00713938 4.99307095 4.30722716 4.69279189 4.40241506 4.59727505]\n",
      "pred [4.90129229 4.09830824 4.38836647 4.61140374 4.34528618 4.65444672]\n",
      "pred [3.81998366 5.17993354 4.52648505 4.4733461  4.54171355 4.4582459 ]\n",
      "pred [4.97778199 4.02260019 4.20529314 4.79466843 4.66201217 4.33728015]\n",
      "pred [4.15299446 4.84667015 4.68285576 4.31706698 3.00233385 5.99731319]\n",
      "pred [3.44958188 5.55008323 3.98725463 5.01225589 3.70136293 5.29883034]\n",
      "pred [4.33592031 4.66390226 3.4596122  5.54046211 3.6673012  5.3335629 ]\n",
      "pred [5.84321594 3.15683816 4.33308781 4.6675286  4.7672338  4.23272843]\n",
      "pred [3.96595684 5.03361984 3.28295085 5.71704594 3.87249639 5.12758536]\n",
      "pred [3.58164685 5.41820499 4.57249416 4.42750616 4.14152992 4.85866969]\n",
      "pred [4.12255153 4.87747937 4.09566004 4.90435091 4.52694982 4.47246894]\n",
      "pred [4.46742026 4.53240476 4.40580418 4.59422275 4.11251704 4.88738243]\n",
      "pred [3.0061612  5.99407644 4.22112219 4.77913171 3.75061465 5.24924661]\n",
      "(296, 189) (296, 6)\n",
      "******* Feature select: FS_S  Feature type: HG-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.9839144254901019\n",
      "R2 Best score (validation) val. score :  0.637571690386759\n",
      "R2 of the best estimator (testing dataset):  0.3383278667944725\n",
      "pred [4.24261732 4.75741923 4.36677959 4.63325878 4.20437844 4.79566603]\n",
      "pred [4.82060932 4.17941521 4.42362469 4.5763716  3.51215366 5.487943  ]\n",
      "pred [3.98015765 5.01988716 4.27445954 4.72558911 4.10754431 4.89254622]\n",
      "pred [3.99391403 5.00625648 4.38170215 4.61828379 4.65747436 4.34251208]\n",
      "pred [4.40920707 4.59077044 3.66450667 5.33526253 4.02949291 4.97045164]\n",
      "pred [4.77757043 4.22233856 4.38857313 4.61137332 5.00854849 3.99150628]\n",
      "pred [4.08204453 4.91801204 4.31193877 4.68809215 4.16304344 4.83702643]\n",
      "pred [4.0590929  4.94095696 4.30700199 4.69302793 4.15761774 4.84245238]\n",
      "pred [4.09269704 4.90735132 4.31413126 4.68590624 4.16638716 4.83368689]\n",
      "pred [4.27799067 4.72215811 4.27786878 4.72212261 4.14971866 4.85010543]\n",
      "pred [4.55325114 4.44669323 4.30390107 4.69603905 4.19642715 4.80334933]\n",
      "pred [4.08894628 4.91109762 4.30745205 4.69257452 4.16370992 4.836361  ]\n",
      "pred [3.87517551 5.12487526 4.36545286 4.6345565  4.52035678 4.47972882]\n",
      "pred [2.91656398 6.08289812 4.44510437 4.55470082 3.96512105 5.0346888 ]\n",
      "pred [4.13370544 4.86635925 4.3326285  4.66740754 4.17542165 4.82464718]\n",
      "pred [4.03790028 4.96223806 4.30171454 4.69820859 4.16651068 4.83348135]\n",
      "pred [4.07486091 4.92518846 4.30751764 4.69251161 4.15814364 4.84192471]\n",
      "pred [4.32159519 4.67841338 4.32092268 4.6790742  4.32746349 4.6726429 ]\n",
      "pred [3.07943621 5.92046657 4.74718765 4.25259342 4.10770698 4.89222246]\n",
      "pred [4.30811207 4.6908413  4.68461407 4.31432427 3.68766235 5.3120986 ]\n",
      "pred [3.81583522 5.18413618 4.43838005 4.5615375  4.11298264 4.88703816]\n",
      "pred [4.10511866 4.89491524 4.31691754 4.68309559 4.20350859 4.7965343 ]\n",
      "pred [4.18525608 4.81496397 4.34046094 4.6594703  4.40995366 4.59020779]\n",
      "pred [4.08293378 4.91709816 4.31478441 4.68523654 4.38200038 4.61810965]\n",
      "pred [3.36905481 5.63076218 4.39140635 4.60874993 4.05108591 4.94879515]\n",
      "pred [4.11537753 4.88469552 4.30559505 4.69443457 4.22311961 4.77697008]\n",
      "pred [4.08145989 4.91865778 4.32262854 4.67737471 4.18781644 4.81225071]\n",
      "pred [4.55632476 4.44355859 4.30592371 4.69392216 4.20850467 4.79129355]\n",
      "pred [3.11844702 5.88169882 4.21722389 4.7826129  4.14155133 4.85856542]\n",
      "pred [4.26282948 4.73704952 3.62430521 5.37572646 3.55502154 5.44506332]\n",
      "pred [4.07497333 4.9250384  4.27636871 4.7236304  4.05259267 4.94751057]\n",
      "pred [4.0693265  4.93072292 4.30643695 4.69359381 4.15149372 4.84857484]\n",
      "pred [4.7181425  4.28198007 4.05996303 4.93990774 3.8407211  5.15932708]\n",
      "pred [4.89775575 4.10178759 4.44065823 4.55904376 5.12156434 3.87837336]\n",
      "pred [4.10518459 4.89489258 4.33561161 4.66441778 4.03185248 4.96827736]\n",
      "pred [3.31967428 5.67997395 4.17974401 4.82034902 3.81170953 5.18813367]\n",
      "pred [3.3920172  5.60765883 4.37720751 4.62286776 3.99780368 5.0021529 ]\n",
      "pred [4.06379044 4.9362597  4.30767207 4.69235933 4.15038241 4.84968686]\n",
      "pred [3.82931518 5.17092787 4.35749307 4.64245108 3.96724014 5.03278931]\n",
      "pred [4.03625178 4.96389588 4.44662828 4.55352419 4.11686097 4.88328418]\n",
      "pred [4.61919409 4.38072477 4.18668294 4.81334279 4.12825467 4.87169212]\n",
      "pred [3.53915351 5.46087181 4.27971755 4.7200628  4.00408705 4.99597354]\n",
      "pred [4.01505167 4.98514018 4.40227907 4.59785703 3.66108808 5.33876474]\n",
      "pred [4.07902523 4.92102375 4.31258353 4.68744555 4.1561145  4.84395311]\n",
      "pred [4.11458182 4.88552805 4.33459626 4.66548946 4.03587234 4.96433008]\n",
      "pred [3.81736588 5.18259494 4.44578102 4.55414255 4.10823416 4.89178765]\n",
      "pred [4.1328293  4.86722584 4.31973653 4.6803126  4.17252927 4.8275578 ]\n",
      "pred [4.92584132 4.074248   4.40603637 4.59397471 4.07317282 4.92689587]\n",
      "pred [4.07666816 4.92338161 4.30526117 4.6947688  4.15602262 4.84404499]\n",
      "pred [4.08495451 4.91508889 4.32998826 4.6700498  4.1617185  4.83835736]\n",
      "pred [4.11194151 4.88811052 4.31645464 4.68358779 4.16863657 4.83144565]\n",
      "pred [3.26986819 5.7297084  4.46589362 4.53417211 4.16061728 4.83936664]\n",
      "pred [4.11796775 4.88208664 4.3445112  4.65549334 4.1460718  4.85400863]\n",
      "pred [3.84284384 5.15737435 4.39714091 4.60292509 3.51632327 5.48383893]\n",
      "pred [3.4606076  5.53931914 4.06987301 4.93012018 3.89406245 5.1062376 ]\n",
      "pred [3.94631691 5.05370757 4.29837724 4.70161592 4.01011097 4.99000203]\n",
      "pred [4.27969598 4.72039872 4.41975422 4.58023414 4.33310196 4.66679814]\n",
      "pred [3.21652574 5.78338048 4.47230756 4.52767146 4.24046196 4.75934547]\n",
      "pred [3.35833741 5.64129295 4.44106972 4.55908672 3.98414258 5.01591217]\n",
      "pred [4.07623648 4.92381817 4.31423493 4.68580199 4.17265097 4.82742167]\n",
      "pred [4.09683945 4.90320923 4.31850893 4.68152573 4.16335474 4.83671588]\n",
      "pred [3.55338249 5.44690523 4.43695314 4.56295777 4.13440963 4.86565996]\n",
      "(296, 99) (296, 6)\n",
      "******* Feature select: FS_S  Feature type: OG-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.9836187773909707\n",
      "R2 Best score (validation) val. score :  0.547006590539522\n",
      "R2 of the best estimator (testing dataset):  0.23217365709788265\n",
      "pred [4.13833679 4.86168326 4.30040152 4.6996277  4.16390014 4.83611387]\n",
      "pred [4.96437321 4.03563783 4.54128273 4.45879871 4.01332224 4.98660963]\n",
      "pred [4.05011773 4.94987303 4.27163414 4.72839457 4.13894158 4.86104836]\n",
      "pred [3.85362906 5.14629799 4.40889345 4.59102472 5.02116261 3.97869468]\n",
      "pred [4.1943111  4.80567803 4.0148756  4.98513012 4.09939718 4.90059013]\n",
      "pred [4.84394078 4.15622757 4.40179416 4.59813345 5.09920401 3.90102899]\n",
      "pred [4.05049819 4.94949266 4.27177911 4.72824964 4.1390751  4.86091497]\n",
      "pred [4.05049633 4.94949452 4.27177922 4.72824954 4.13907451 4.86091555]\n",
      "pred [4.05050439 4.94948646 4.27177665 4.72825211 4.13907526 4.86091481]\n",
      "pred [4.2393311  4.76052383 4.30181923 4.69808262 4.18291207 4.81709532]\n",
      "pred [4.62165112 4.3784302  4.32354966 4.67632649 4.26007347 4.73995693]\n",
      "pred [4.06362876 4.93636197 4.27490094 4.72512922 4.14771375 4.85228519]\n",
      "pred [3.83667828 5.16329589 4.33132661 4.66864957 4.48663668 4.5133168 ]\n",
      "pred [3.44893755 5.55099275 4.30217904 4.69779334 3.99024424 5.00973044]\n",
      "pred [4.05202273 4.94796835 4.27254244 4.72748603 4.13958986 4.86039938]\n",
      "pred [4.08227701 4.91772133 4.26683359 4.73319653 4.14064136 4.8593463 ]\n",
      "pred [4.04335638 4.95663311 4.27301018 4.72702076 4.14012349 4.85986533]\n",
      "pred [4.06097136 4.93903107 4.27012106 4.7298989  4.17268349 4.82734646]\n",
      "pred [3.51903776 5.48092067 4.38246981 4.61745173 4.02318582 4.9765744 ]\n",
      "pred [4.12722243 4.87285183 4.31155589 4.68854009 4.08759894 4.91240813]\n",
      "pred [4.04292111 4.95707253 4.27655207 4.72347461 4.13923241 4.8607556 ]\n",
      "pred [4.05291874 4.94707111 4.27273831 4.72728952 4.14110803 4.85888353]\n",
      "pred [3.99621527 5.00384539 4.29477745 4.70520331 4.24917004 4.75084974]\n",
      "pred [4.04501096 4.95498698 4.27203824 4.72799059 4.18811844 4.81188745]\n",
      "pred [3.78364184 5.21631569 4.3142463  4.68574148 4.08258357 4.91740855]\n",
      "pred [4.06240403 4.93758818 4.27228196 4.72773299 4.15998818 4.83999964]\n",
      "pred [4.01923595 4.98062152 4.31425126 4.68573811 4.1767673  4.82322412]\n",
      "pred [4.63260116 4.36748611 4.39531535 4.604437   4.23720541 4.76273867]\n",
      "pred [3.71018843 5.28981899 4.23881101 4.76119787 4.12585914 4.87422846]\n",
      "pred [4.20231001 4.79776947 4.01050871 4.98948909 3.45073707 5.54935887]\n",
      "pred [4.0503078  4.94968169 4.26921126 4.73081791 4.13593203 4.86405803]\n",
      "pred [4.05049926 4.94949159 4.27177911 4.72824965 4.13907446 4.86091561]\n",
      "pred [4.23701923 4.76293874 4.21485503 4.78513669 4.06336527 4.93664086]\n",
      "pred [4.52855413 4.4715923  4.35366033 4.64632307 4.61975489 4.38034332]\n",
      "pred [4.0504399  4.94955004 4.27222584 4.72780277 4.13742913 4.8625608 ]\n",
      "pred [3.74542838 5.25436806 4.11841107 4.88173913 3.59234721 5.40797856]\n",
      "pred [3.84143688 5.15855833 4.29232711 4.70768602 4.09219561 4.90780763]\n",
      "pred [4.05049873 4.94949211 4.27177922 4.72824954 4.13907383 4.86091624]\n",
      "pred [4.07918256 4.92084609 4.30703261 4.69303665 3.91722963 5.08286805]\n",
      "pred [3.97882256 5.02114931 4.27531135 4.72471478 4.10601507 4.89398164]\n",
      "pred [4.5741965  4.42588002 4.28845024 4.71157998 4.41052573 4.58944963]\n",
      "pred [3.78857396 5.21158729 4.260784   4.73923703 4.00773726 4.99231912]\n",
      "pred [4.36798665 4.63217953 4.3918398  4.60795395 3.22588149 5.77405281]\n",
      "pred [4.05050621 4.94948465 4.27179656 4.72823221 4.1390752  4.86091486]\n",
      "pred [4.0489754  4.9510169  4.271804   4.72822735 4.11257673 4.88740681]\n",
      "pred [4.04274934 4.95724429 4.27674576 4.72328094 4.13923887 4.86074915]\n",
      "pred [4.05411008 4.94588108 4.27212274 4.7279052  4.14066661 4.85932529]\n",
      "pred [5.03200195 3.96797731 4.49352024 4.5063058  4.64061853 4.35931261]\n",
      "pred [4.05049933 4.94949152 4.27177908 4.72824967 4.13907446 4.86091561]\n",
      "pred [4.05050005 4.94949074 4.27188654 4.72814233 4.13917114 4.86081851]\n",
      "pred [4.05629465 4.94369661 4.27308225 4.72694595 4.1417515  4.85824015]\n",
      "pred [3.52866582 5.47143968 4.33950296 4.660456   4.05112909 4.94883869]\n",
      "pred [4.05738417 4.94260298 4.28124536 4.71877036 4.13823551 4.86175061]\n",
      "pred [4.03237681 4.96759607 4.27190599 4.72812247 3.89995309 5.10004917]\n",
      "pred [3.60499866 5.39500645 4.13710482 4.86299143 3.94855431 5.05130012]\n",
      "pred [4.0573994  4.94259199 4.26010472 4.73992292 4.13661442 4.86337067]\n",
      "pred [4.32803367 4.67190116 4.32315182 4.67710739 4.39511015 4.60503372]\n",
      "pred [3.76712738 5.23289954 4.32480097 4.67515169 4.14981818 4.85020356]\n",
      "pred [3.53363261 5.46634009 4.35858023 4.64139828 3.99962982 5.00030427]\n",
      "pred [4.05125111 4.9487399  4.2729547  4.72707516 4.14091705 4.85907356]\n",
      "pred [4.05052424 4.94946669 4.27186717 4.72816148 4.13910141 4.86088875]\n",
      "pred [3.79757394 5.20249719 4.33966541 4.66031736 4.13739984 4.86259063]\n",
      "(296, 58) (296, 6)\n",
      "******* Feature select: FS_S  Feature type: ST-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.9841521530842264\n",
      "R2 Best score (validation) val. score :  0.5699682646321114\n",
      "R2 of the best estimator (testing dataset):  0.25163030485151355\n",
      "pred [4.69715316 4.30311043 4.39607903 4.60405857 4.37043374 4.62913069]\n",
      "pred [4.98487514 4.01531947 4.62493813 4.37530012 3.97997307 5.0201346 ]\n",
      "pred [4.10336944 4.89667323 4.33500756 4.66509109 4.10181039 4.89815951]\n",
      "pred [3.45242305 5.54755012 4.44057764 4.5596247  5.1998178  3.80017615]\n",
      "pred [4.40595961 4.5939693  3.76669854 5.2334817  4.13318423 4.86673151]\n",
      "pred [4.90371088 4.09632908 4.42309195 4.57712109 4.9569048  4.04306709]\n",
      "pred [4.21863265 4.78139388 4.34525493 4.65482743 4.18701962 4.81301718]\n",
      "pred [4.02144468 4.97860739 4.35869722 4.64125865 4.17044216 4.82958546]\n",
      "pred [4.21806225 4.78194514 4.33274036 4.66735828 4.19064956 4.80932618]\n",
      "pred [3.94120935 5.05867896 4.16671252 4.83315773 3.95512454 5.04498385]\n",
      "pred [4.09242494 4.90755804 4.18230819 4.81754623 4.25920912 4.74076738]\n",
      "pred [4.03519997 4.96486917 4.46257961 4.53759584 4.00358173 4.99632096]\n",
      "pred [3.73063705 5.26914251 4.44539098 4.55467845 4.45388935 4.54615436]\n",
      "pred [3.58665744 5.41367762 4.42952874 4.57079039 4.53457743 4.46549756]\n",
      "pred [4.20506424 4.79499742 4.35035138 4.64970258 4.20624608 4.79370963]\n",
      "pred [4.2977712  4.70222861 4.28528655 4.71475456 4.18384093 4.81613423]\n",
      "pred [3.91029417 5.08975078 4.38123363 4.61877007 4.23978579 4.76023089]\n",
      "pred [4.64127716 4.35896387 4.39422412 4.6058502  4.72197983 4.27769743]\n",
      "pred [3.67636662 5.32371758 4.54085023 4.45966728 4.55667833 4.4432668 ]\n",
      "pred [4.04657509 4.95322575 4.43495448 4.5651855  4.13187801 4.86814739]\n",
      "pred [3.9687476  5.03121972 4.32481513 4.6753501  4.00535718 4.99463248]\n",
      "pred [4.12239315 4.87746809 4.41197098 4.58807037 4.35263501 4.64733443]\n",
      "pred [3.94230811 5.05782351 4.46532922 4.53483735 4.57895542 4.42103132]\n",
      "pred [4.22459161 4.77541773 4.34433812 4.65573036 4.21108968 4.78887805]\n",
      "pred [3.13782447 5.86260981 4.47398706 4.5261673  3.92331956 5.07663309]\n",
      "pred [4.43692076 4.56309106 4.36397161 4.63614384 4.42911518 4.57080232]\n",
      "pred [3.50117193 5.49879898 4.46801282 4.53173311 3.25074871 5.74925526]\n",
      "pred [4.01883421 4.98125507 4.18541903 4.81441271 4.39493943 4.60493175]\n",
      "pred [3.23256389 5.76757043 4.15909319 4.84091687 4.02972738 4.97013802]\n",
      "pred [4.12292748 4.8770755  4.22672443 4.77344119 3.75408102 5.24594066]\n",
      "pred [4.16802587 4.83199277 4.35429649 4.64584005 4.1005295  4.89948839]\n",
      "pred [4.10532797 4.89468555 4.35218692 4.64788169 4.11563606 4.88433377]\n",
      "pred [4.94340772 4.05655676 4.0966726  4.90349712 3.90599375 5.09374485]\n",
      "pred [4.32988637 4.67012046 4.35046889 4.64963687 4.35086209 4.64911788]\n",
      "pred [4.15008557 4.84986971 4.3717373  4.62832561 4.15414558 4.84585119]\n",
      "pred [3.65229376 5.34781976 4.4879507  4.51206747 4.43057012 4.56934189]\n",
      "pred [3.20652448 5.79343377 4.38295322 4.61691923 4.07848929 4.92151452]\n",
      "pred [4.04914178 4.95085737 4.36915495 4.63090441 4.10909635 4.89084835]\n",
      "pred [4.79994848 4.19998809 4.4403189  4.55961657 4.38454322 4.61602691]\n",
      "pred [3.46610447 5.53361471 4.86589465 4.13433782 3.55123602 5.44881488]\n",
      "pred [4.62117907 4.37893401 4.3567902  4.64328144 4.46133391 4.5387616 ]\n",
      "pred [3.41887823 5.58139438 4.45763004 4.54258054 3.89319715 5.10672713]\n",
      "pred [4.8186096  4.1813247  4.39284227 4.60712982 2.87500014 6.12503658]\n",
      "pred [4.18049015 4.81952585 4.36999436 4.63010207 4.17369235 4.82629714]\n",
      "pred [3.85338532 5.14676162 4.35777676 4.642306   3.91669154 5.08335217]\n",
      "pred [3.96861307 5.03135549 4.32507591 4.67507944 4.0025758  4.99741485]\n",
      "pred [4.35740107 4.64263137 4.36185992 4.63815193 4.2173924  4.78263542]\n",
      "pred [5.04748107 3.95275759 4.56761319 4.43266027 4.4771511  4.52295734]\n",
      "pred [4.16818201 4.83188198 4.32151402 4.67859323 4.18480512 4.8151767 ]\n",
      "pred [4.17505752 4.82498192 4.38992333 4.61019287 4.18108008 4.81889058]\n",
      "pred [4.44016598 4.55986005 4.37475637 4.62530919 4.28047653 4.71955344]\n",
      "pred [3.26513977 5.73492431 4.53345171 4.46675512 4.02141546 4.97865949]\n",
      "pred [3.68025074 5.31962307 4.11889632 4.88094296 3.77474099 5.2253991 ]\n",
      "pred [4.07814716 4.92185075 4.3997108  4.60024479 3.52720742 5.47282096]\n",
      "pred [3.64244773 5.35749265 4.12206395 4.87813747 3.87801354 5.12174109]\n",
      "pred [4.07301257 4.92697273 4.37566847 4.62441138 4.10595947 4.8940666 ]\n",
      "pred [4.94009848 4.05970087 4.39205166 4.60770899 4.55978005 4.44054825]\n",
      "pred [3.6536537  5.34655483 4.44231948 4.55770203 4.42187036 4.57818722]\n",
      "pred [3.11204812 5.88788973 4.58498063 4.41515561 3.85413009 5.14589175]\n",
      "pred [4.18902412 4.81097719 4.16572114 4.83427887 4.17383717 4.82615712]\n",
      "pred [4.17978878 4.8202126  4.38909608 4.61094427 4.17811014 4.82187231]\n",
      "pred [3.42999288 5.57018097 4.54192105 4.45844532 4.21190917 4.78794714]\n",
      "(296, 15) (296, 6)\n",
      "******* Feature select: RF  Feature type: HG-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.9486538983939661\n",
      "R2 Best score (validation) val. score :  0.4325181038388318\n",
      "R2 of the best estimator (testing dataset):  0.15001891367171757\n",
      "pred [5.0051017  3.99514334 4.78165564 4.21936434 4.13780749 4.86203754]\n",
      "pred [5.29230619 3.70756747 4.48176434 4.51824799 2.81269451 6.1879928 ]\n",
      "pred [4.15938063 4.8407051  3.98804735 5.01203291 4.10128235 4.8987277 ]\n",
      "pred [4.38429026 4.6156575  4.52494405 4.4750773  6.46362351 2.53658548]\n",
      "pred [4.95060944 4.04941919 2.94637992 6.05358476 4.02121025 4.97879283]\n",
      "pred [5.76591712 3.23411209 4.43866853 4.56109399 6.39034268 2.60965092]\n",
      "pred [4.56115048 4.43877261 4.31094533 4.68891529 4.65459674 4.34537379]\n",
      "pred [3.69282473 5.30725402 4.31650282 4.68349073 3.72481324 5.27501168]\n",
      "pred [5.56334919 3.43698239 4.63211523 4.36776429 4.76684209 4.23349522]\n",
      "pred [4.67938693 4.32014149 4.478339   4.52160416 4.13559169 4.86384824]\n",
      "pred [5.17141567 3.82802821 4.42606052 4.57395181 4.3581393  4.64103996]\n",
      "pred [3.86747832 5.13272817 4.16539154 4.83470828 3.79733148 5.20277409]\n",
      "pred [4.13881611 4.86110638 4.51822025 4.48172575 6.28977819 2.71048005]\n",
      "pred [2.7899398  6.209853   4.0893585  4.91066644 3.38783888 5.61231808]\n",
      "pred [4.44947474 4.5503009  4.39704365 4.60274889 4.35489507 4.64453754]\n",
      "pred [4.0373201  4.96229961 3.61591904 5.38411438 3.75783069 5.24191251]\n",
      "pred [4.11415751 4.88630712 4.6471505  4.35286163 4.61354045 4.38692797]\n",
      "pred [4.39701677 4.60318369 4.03667853 4.96317325 4.35106025 4.64904251]\n",
      "pred [2.82792877 6.17187243 4.04807712 4.95190817 3.32411943 5.6760165 ]\n",
      "pred [5.30332406 3.69653534 4.50367731 4.49614609 3.72218    5.27839644]\n",
      "pred [4.72181099 4.27829469 3.20923484 5.79080519 4.46165445 4.53818704]\n",
      "pred [4.51924637 4.48110249 4.330398   4.67003632 4.85714561 4.1427975 ]\n",
      "pred [4.13389974 4.86612064 4.25280818 4.74698799 4.67582588 4.32388164]\n",
      "pred [3.33999379 5.66016577 4.35517559 4.6452362  5.19755321 3.80210178]\n",
      "pred [2.39601426 6.60341078 4.47636797 4.52330292 3.51342103 5.48628156]\n",
      "pred [3.64990688 5.35020146 4.23757624 4.76267769 4.26309044 4.73681871]\n",
      "pred [4.58331102 4.41673611 4.56727368 4.4328722  4.61899478 4.38084093]\n",
      "pred [5.20516983 3.79461432 4.53191985 4.46804462 4.40603425 4.59339877]\n",
      "pred [3.35052069 5.6497282  4.35611705 4.64379538 4.3305453  4.66957953]\n",
      "pred [4.41946525 4.58041831 3.72738063 5.27262636 3.63089724 5.36886086]\n",
      "pred [2.54445101 6.45571655 4.4716063  4.52862888 4.06233319 4.93802423]\n",
      "pred [4.13846955 4.86173953 4.00496141 4.9951752  4.00070885 4.99937086]\n",
      "pred [4.24791176 4.75217396 4.18015115 4.81984656 3.50855759 5.49157473]\n",
      "pred [4.90945917 4.09086176 4.50101367 4.49895826 5.1832027  3.817269  ]\n",
      "pred [3.71507047 5.28476363 4.41678902 4.58303018 3.21421297 5.78556454]\n",
      "pred [3.23013944 5.76964798 3.82727773 5.17276435 3.19246403 5.80764873]\n",
      "pred [3.99097274 5.00916126 4.23787694 4.76203877 4.30953392 4.69101099]\n",
      "pred [3.88515139 5.11497159 4.11722778 4.88286581 3.61104453 5.38902093]\n",
      "pred [3.44253037 5.55776745 4.87857355 4.12182431 4.07652084 4.92349706]\n",
      "pred [3.56301762 5.43703692 4.41791105 4.58188454 3.95104434 5.04862934]\n",
      "pred [5.40081654 3.59963085 4.62566632 4.37471544 5.88984224 3.11032305]\n",
      "pred [4.06054098 4.93947232 4.14914289 4.85086147 3.57466372 5.42547149]\n",
      "pred [4.73174403 4.26826895 4.68283303 4.31765838 4.72660282 4.27352514]\n",
      "pred [3.5093797  5.49055056 4.14893663 4.85128034 4.16167985 4.83786438]\n",
      "pred [4.55847308 4.44150075 4.262155   4.73818663 3.97330559 5.02670706]\n",
      "pred [4.72181098 4.27829469 3.20923485 5.79080518 4.46165445 4.53818704]\n",
      "pred [4.61155434 4.38856098 4.64512796 4.35499711 4.1721279  4.82799085]\n",
      "pred [6.07141006 2.92871006 4.53368513 4.46603869 6.31519247 2.68475991]\n",
      "pred [3.17388576 5.82634809 3.68820886 5.31137976 4.24945741 4.75027996]\n",
      "pred [3.79460282 5.20528484 4.43492823 4.56514081 4.20569285 4.79384991]\n",
      "pred [5.03598799 3.96388103 4.5725271  4.42750655 4.72220022 4.27795407]\n",
      "pred [2.65902757 6.34088331 4.632837   4.36738284 3.94691583 5.05345523]\n",
      "pred [4.07465283 4.92466959 4.40898524 4.59094412 3.87361522 5.12590447]\n",
      "pred [3.93486052 5.06550861 4.38688373 4.61319177 3.24219173 5.75802444]\n",
      "pred [3.12147885 5.87798746 3.99657939 5.00363984 3.75066818 5.24956008]\n",
      "pred [5.40411401 3.5962244  4.1520894  4.84791706 4.56234868 4.43718035]\n",
      "pred [4.16659422 4.83351192 4.54472462 4.45586248 4.30396166 4.69574769]\n",
      "pred [2.4818533  6.51792092 4.29125505 4.70883736 3.62844721 5.37176318]\n",
      "pred [2.57647773 6.42323316 4.58050585 4.41961405 3.77988068 5.22066664]\n",
      "pred [4.53521032 4.46491562 3.97175229 5.02841651 5.13831657 3.86173048]\n",
      "pred [4.44805971 4.55141706 4.45107811 4.54891681 4.39711449 4.60304489]\n",
      "pred [4.01111239 4.98884079 4.17372079 4.82624881 3.39104051 5.60900412]\n",
      "(296, 23) (296, 6)\n",
      "******* Feature select: RF  Feature type: OG-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.9619947558438057\n",
      "R2 Best score (validation) val. score :  0.49717128838214963\n",
      "R2 of the best estimator (testing dataset):  0.48639245179288526\n",
      "pred [4.90638998 4.0934121  4.47027347 4.5294402  4.21565759 4.784411  ]\n",
      "pred [5.41891964 3.58113081 4.51756195 4.48289896 3.30424671 5.69597044]\n",
      "pred [4.65723775 4.34294507 3.39357241 5.60664372 3.91163158 5.0886058 ]\n",
      "pred [3.65892638 5.34080239 4.49669839 4.5031026  5.59914118 3.40093685]\n",
      "pred [4.82099258 4.17903729 3.00962899 5.99066282 4.34402051 4.6557306 ]\n",
      "pred [4.76556942 4.23467049 4.36713438 4.63240575 5.18152566 3.81834315]\n",
      "pred [4.74237296 4.25732952 4.39469542 4.60509784 4.39237156 4.60765468]\n",
      "pred [4.14686661 4.85321735 4.38170314 4.61826462 4.20273583 4.79723877]\n",
      "pred [4.52083255 4.47914847 4.56206113 4.43776989 4.17559026 4.8242313 ]\n",
      "pred [4.86057867 4.13860114 4.3360015  4.66486156 3.99416631 5.005926  ]\n",
      "pred [5.0405702  3.95917751 4.54855116 4.45192885 4.12804685 4.87198686]\n",
      "pred [3.47689393 5.52292334 4.46087035 4.53834938 3.59158675 5.40835899]\n",
      "pred [3.13981608 5.85982334 4.53303184 4.46726913 5.65723618 3.34301793]\n",
      "pred [2.9070852  6.09317924 4.17966155 4.81976513 3.31449252 5.68584625]\n",
      "pred [4.35178085 4.64802934 4.36353439 4.63647464 4.44013032 4.55987482]\n",
      "pred [4.2765139  4.72353557 4.53121308 4.46883448 4.27311885 4.72682543]\n",
      "pred [2.92096056 6.07885848 4.58335355 4.41689256 4.53736994 4.46308774]\n",
      "pred [4.34484101 4.65517252 4.2784923  4.72131889 4.40022506 4.60007545]\n",
      "pred [2.93601319 6.06422748 4.23922063 4.76056337 3.28719122 5.71305349]\n",
      "pred [4.88089488 4.1188272  4.57336523 4.42658132 3.35776994 5.6426403 ]\n",
      "pred [4.12787091 4.87209242 3.94256853 5.0574132  4.44757204 4.5523772 ]\n",
      "pred [4.12249302 4.87757268 4.40496374 4.59512362 4.16015197 4.83988827]\n",
      "pred [3.87654971 5.12333936 4.32991941 4.66961245 4.28436489 4.71586692]\n",
      "pred [4.30144394 4.6986528  4.31477863 4.68523287 4.30809104 4.69180172]\n",
      "pred [3.52537269 5.47461914 4.48364159 4.51636619 3.79455383 5.20530166]\n",
      "pred [4.32977958 4.67040639 4.35831717 4.64171363 4.62624721 4.37350579]\n",
      "pred [3.71733859 5.28331686 4.57967795 4.41999306 3.45447143 5.54601249]\n",
      "pred [5.18880964 3.81077888 4.4240665  4.57658721 4.21325699 4.78682991]\n",
      "pred [2.87776353 6.12281955 4.37146193 4.62830934 4.10075638 4.89909586]\n",
      "pred [4.47633736 4.52328669 2.71648857 6.28320454 3.79340588 5.20643459]\n",
      "pred [4.05971233 4.94038951 4.24646298 4.75356442 3.1602534  5.83939809]\n",
      "pred [3.58003718 5.42008166 4.43441503 4.56548064 4.35871247 4.64125272]\n",
      "pred [5.01522857 3.98500139 3.9805855  5.01909263 3.82968732 5.17049903]\n",
      "pred [4.73687006 4.26336207 4.35349716 4.64590737 5.20400282 3.79601828]\n",
      "pred [4.35999106 4.63985677 4.57602382 4.42419462 4.64194211 4.35854521]\n",
      "pred [3.5383954  5.46215906 4.02523611 4.9750402  2.95305186 6.04709418]\n",
      "pred [3.00969602 5.99056998 4.18038373 4.81914496 4.11488273 4.88519111]\n",
      "pred [3.83345265 5.16674122 4.36481126 4.63503602 4.05652722 4.94348609]\n",
      "pred [4.40266478 4.59691219 4.45023299 4.54965549 3.66657315 5.33349195]\n",
      "pred [3.82751106 5.17249592 4.33393935 4.66605803 3.5092073  5.49056976]\n",
      "pred [5.24704416 3.75314126 4.31342665 4.68659821 5.44085176 3.55915151]\n",
      "pred [3.26607244 5.73395756 4.21117681 4.78891026 4.24084756 4.75897626]\n",
      "pred [4.38577328 4.61396172 4.49199035 4.50772862 3.12793335 5.8722819 ]\n",
      "pred [4.23410312 4.76595786 4.33324346 4.66675046 4.20935782 4.79060597]\n",
      "pred [3.86501794 5.13515638 4.3818882  4.61794743 3.77832431 5.22133917]\n",
      "pred [4.12755467 4.87240846 3.94189774 5.05808412 4.44818269 4.55176659]\n",
      "pred [4.52627543 4.47356983 4.22912856 4.7707248  4.35336631 4.64656776]\n",
      "pred [5.41838025 3.5818335  4.45857357 4.54179307 4.65116372 4.34899514]\n",
      "pred [3.6932485  5.3067691  3.91370946 5.08638491 4.31627061 4.68381809]\n",
      "pred [4.17312521 4.8270037  4.40944975 4.59055865 4.22611632 4.77387124]\n",
      "pred [4.70578583 4.29403244 4.19884031 4.80095559 4.29655928 4.70336748]\n",
      "pred [2.55153189 6.44803035 4.41563592 4.58452805 3.77078625 5.22920116]\n",
      "pred [4.98053756 4.01866223 3.95730991 5.04391343 3.82329309 5.1767745 ]\n",
      "pred [3.88644795 5.11325317 4.558436   4.44165609 3.06526736 5.93427018]\n",
      "pred [2.88028439 6.12000477 4.01459395 4.98507115 3.69441478 5.30532381]\n",
      "pred [3.91192669 5.08810129 4.48780778 4.51222996 4.03285043 4.9670288 ]\n",
      "pred [4.14112922 4.85892046 4.51148461 4.48857207 4.52447284 4.47518979]\n",
      "pred [2.99969147 6.00043654 4.43589205 4.56376661 3.64181662 5.35856501]\n",
      "pred [2.79432196 6.2054241  4.40973984 4.5896582  3.77506734 5.2253295 ]\n",
      "pred [4.40354886 4.59639764 4.27548611 4.72461762 4.46856888 4.5311585 ]\n",
      "pred [4.22640386 4.77367632 4.39463963 4.60538326 4.22113529 4.7788419 ]\n",
      "pred [2.97386068 6.02639219 4.59188947 4.40820087 4.10492455 4.89513046]\n",
      "(296, 32) (296, 6)\n",
      "******* Feature select: RF  Feature type: ST-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.970065091866472\n",
      "R2 Best score (validation) val. score :  0.5155079714233832\n",
      "R2 of the best estimator (testing dataset):  0.22508173109257948\n",
      "pred [4.70519051 4.29445265 4.35547092 4.64459018 4.50205781 4.49768564]\n",
      "pred [5.12367573 3.87640541 4.57293442 4.42739877 4.171671   4.82852122]\n",
      "pred [4.24755623 4.75231812 3.52633998 5.47359194 3.96996472 5.03020248]\n",
      "pred [3.34639906 5.65392643 4.43431811 4.56583044 5.2926493  3.70745863]\n",
      "pred [4.07063463 4.92943102 4.23872885 4.76131511 3.84562332 5.15434783]\n",
      "pred [4.42793598 4.57215001 4.30230979 4.69771911 4.63887052 4.36119449]\n",
      "pred [4.14179795 4.85820789 4.30029058 4.69974941 4.2110736  4.78895705]\n",
      "pred [4.43359839 4.56630123 4.22458663 4.77528766 4.5063313  4.49350401]\n",
      "pred [4.15108924 4.84894135 4.28590791 4.71411056 4.20633574 4.79368913]\n",
      "pred [4.65534702 4.34463962 4.41917516 4.58072225 4.32339546 4.67664599]\n",
      "pred [4.82467837 4.17535633 4.45084043 4.54900983 4.36983905 4.63020569]\n",
      "pred [3.93275188 5.06739853 4.35858704 4.64153776 3.93340261 5.06638709]\n",
      "pred [3.8350823  5.16504405 4.39119228 4.60876469 4.39777767 4.60212721]\n",
      "pred [4.00087193 4.99913696 4.19504303 4.80496869 4.16778339 4.83219284]\n",
      "pred [4.13383023 4.86608932 4.28511156 4.71489964 4.22556876 4.7744796 ]\n",
      "pred [4.13185623 4.86816642 4.2789059  4.72114215 4.20727    4.79275957]\n",
      "pred [3.91899154 5.08096975 4.37384194 4.62629733 4.07214007 4.92783992]\n",
      "pred [4.47416092 4.52588995 4.3766917  4.62318637 4.6837277  4.31608506]\n",
      "pred [3.99549546 5.00451544 4.15053897 4.84950164 4.1260551  4.87390834]\n",
      "pred [4.25646978 4.74350263 4.34886157 4.6512391  4.00479965 4.99509497]\n",
      "pred [4.169907   4.83008265 4.19198224 4.80808872 4.14282205 4.85721768]\n",
      "pred [3.89477584 5.10524915 4.34915369 4.65075445 4.3494673  4.65062768]\n",
      "pred [3.81829628 5.18192752 4.47762951 4.52240095 4.6549263  4.34495432]\n",
      "pred [4.13346446 4.86656483 4.28243187 4.71759622 4.20678702 4.79323761]\n",
      "pred [3.90488942 5.09515436 4.33243303 4.66757782 4.14752102 4.85240224]\n",
      "pred [4.5556147  4.44418467 4.32673724 4.67336968 4.63550439 4.36429712]\n",
      "pred [3.57741636 5.42279674 4.39166598 4.60828136 3.86326438 5.13682429]\n",
      "pred [4.78515009 4.21492037 4.4716235  4.52828952 4.33532635 4.66467059]\n",
      "pred [3.76879333 5.231266   4.09322927 4.90691626 3.91768576 5.0823414 ]\n",
      "pred [4.11622004 4.88388037 4.25985604 4.74020561 4.09755994 4.90249754]\n",
      "pred [4.1324385  4.86759056 4.28242404 4.71760404 4.2042753  4.79574924]\n",
      "pred [3.49624139 5.50375446 4.26456729 4.73549878 4.17136562 4.82855624]\n",
      "pred [5.72117566 3.27916722 3.76907441 5.23096932 3.45179883 5.54799611]\n",
      "pred [4.16591929 4.83411583 4.28418413 4.71584404 4.25662997 4.74340078]\n",
      "pred [4.15675055 4.84331613 4.43422668 4.565742   3.8032573  5.19644653]\n",
      "pred [4.06187817 4.938135   4.13564472 4.86441415 4.08876743 4.9112325 ]\n",
      "pred [3.38827267 5.61174082 4.3751669  4.62477493 4.05970594 4.94050418]\n",
      "pred [3.65958169 5.34044579 4.42801582 4.5720091  4.00587486 4.99425168]\n",
      "pred [4.67774854 4.32237497 4.37344501 4.62648232 4.79011362 4.20986052]\n",
      "pred [4.68777273 4.31235062 4.37666102 4.62355641 4.33960533 4.66029389]\n",
      "pred [4.56283726 4.43715343 4.28286794 4.71716062 4.64569864 4.35426669]\n",
      "pred [4.00776673 4.99235064 3.80868725 5.19085946 3.37816875 5.6217722 ]\n",
      "pred [4.52423449 4.47565141 4.44778859 4.55220515 2.96569996 6.0345429 ]\n",
      "pred [4.13758462 4.86243295 4.29767139 4.70235237 4.21511837 4.78490476]\n",
      "pred [4.06638645 4.93372502 4.33563332 4.66431611 4.26903782 4.73101374]\n",
      "pred [4.17675426 4.82324067 4.18326109 4.81679653 4.15175678 4.84827327]\n",
      "pred [4.14797165 4.85205863 4.28834974 4.71167289 4.21213976 4.78788792]\n",
      "pred [4.99671195 4.00337637 4.48758225 4.51266018 4.42828739 4.57189848]\n",
      "pred [4.2405617  4.75951519 4.37995252 4.62003284 4.35987695 4.64026293]\n",
      "pred [4.13278143 4.86725222 4.30621021 4.69383713 4.24027645 4.75975032]\n",
      "pred [4.17573876 4.8242892  4.28427707 4.7157208  4.20613343 4.79388329]\n",
      "pred [3.57085545 5.42904195 4.34578202 4.65425775 4.10083641 4.89917497]\n",
      "pred [4.35684988 4.64314521 4.44378937 4.55628138 4.18593459 4.81401743]\n",
      "pred [4.13825535 4.86176789 4.23245597 4.76770767 3.7015707  5.29848978]\n",
      "pred [4.04264517 4.95742103 4.21804777 4.78197286 4.09498585 4.90498774]\n",
      "pred [4.51922487 4.48068953 3.88889023 5.11096334 3.70860374 5.29133084]\n",
      "pred [4.44053975 4.55959406 4.35136532 4.64853208 4.38414816 4.61539556]\n",
      "pred [3.96524693 5.03476245 4.17201776 4.82800519 4.15772647 4.84222281]\n",
      "pred [3.42298724 5.57689053 4.38786506 4.61215435 3.96811636 5.03168745]\n",
      "pred [4.24076963 4.7593809  4.31979025 4.68032813 4.34875962 4.65147083]\n",
      "pred [4.09287722 4.90714263 4.28927858 4.71074213 4.20337724 4.79659256]\n",
      "pred [3.66840685 5.33138986 4.66787342 4.33223648 3.49993204 5.50003949]\n",
      "(296, 20) (296, 6)\n",
      "******* Feature select: LR20  Feature type: HG-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.9428816602017198\n",
      "R2 Best score (validation) val. score :  0.47425641458826007\n",
      "R2 of the best estimator (testing dataset):  0.3139483163279864\n",
      "pred [4.90985327 4.08956797 4.4066707  4.59320894 4.57332415 4.42711194]\n",
      "pred [5.39329402 3.60670988 4.46115981 4.53841704 4.88915684 4.11059816]\n",
      "pred [4.01512697 4.98487038 4.28181355 4.71822357 4.09839868 4.90165242]\n",
      "pred [3.25456789 5.74552669 4.5729812  4.42726761 6.13711468 2.86225285]\n",
      "pred [4.24314745 4.75694733 3.7397077  5.26021221 3.7001982  5.29991021]\n",
      "pred [5.32345543 3.67680005 4.6248965  4.37517817 5.41582923 3.58368469]\n",
      "pred [3.60194764 5.39770343 4.20133567 4.79872053 4.17297235 4.82702918]\n",
      "pred [4.0176508  4.98234693 4.28247405 4.71756138 4.10583144 4.89421755]\n",
      "pred [4.20115206 4.79882998 4.2999574  4.70005499 4.20412475 4.79592566]\n",
      "pred [4.87302992 4.12653153 4.41220749 4.58731174 4.29561229 4.70406519]\n",
      "pred [5.0095171  3.98970235 4.42291497 4.57665221 4.38707557 4.61263839]\n",
      "pred [4.05378766 4.94625236 4.34016761 4.65999615 4.07685334 4.92310443]\n",
      "pred [2.80765639 6.19205622 4.4627532  4.53735326 5.54708005 3.45267896]\n",
      "pred [2.60514555 6.39502275 4.1375005  4.86231632 3.65256279 5.34877824]\n",
      "pred [4.1342647  4.86577259 4.33290762 4.66713872 4.13991366 4.86019252]\n",
      "pred [3.94738917 5.05264241 4.29363476 4.70624888 4.12882043 4.8712113 ]\n",
      "pred [3.48082279 5.5193176  4.30381719 4.69634923 4.03714314 4.96308804]\n",
      "pred [4.42339031 4.57643978 4.21391013 4.78637517 4.59479771 4.4050698 ]\n",
      "pred [2.74514431 6.25497242 4.13028155 4.8697016  3.5985864  5.40307847]\n",
      "pred [5.17075542 3.82896288 4.53159195 4.46870288 3.67318088 5.32663273]\n",
      "pred [4.0026185  4.99736945 4.30044964 4.69956694 4.11387952 4.88619349]\n",
      "pred [4.08185341 4.91809677 4.3275757  4.67243121 4.15901257 4.8410409 ]\n",
      "pred [4.16259733 4.83713298 4.5595565  4.44053695 4.91300624 4.08686747]\n",
      "pred [4.46909172 4.53124288 4.44413029 4.55581152 6.32480977 2.67532713]\n",
      "pred [2.93189224 6.06819011 4.42270657 4.57722135 3.97242478 5.02757918]\n",
      "pred [4.11174358 4.88826512 4.28341426 4.7165746  4.26115275 4.73886984]\n",
      "pred [4.64354078 4.35628408 4.61223893 4.38805837 4.85221604 4.14780905]\n",
      "pred [4.86218969 4.13714126 4.47582998 4.52369558 4.27942592 4.72021615]\n",
      "pred [2.9795149  6.02070285 4.18859534 4.81126556 4.08317414 4.91695065]\n",
      "pred [4.12133176 4.87866288 3.94307374 5.0568901  3.69318586 5.30686797]\n",
      "pred [3.74834666 5.25173647 4.2595075  4.74075592 3.97534848 5.02488523]\n",
      "pred [4.01802259 4.98197543 4.28256875 4.71746512 4.11122984 4.88881725]\n",
      "pred [4.18304416 4.81678132 4.13605024 4.86400403 3.79095718 5.20912345]\n",
      "pred [5.68680772 3.3131924  4.56287822 4.43735681 5.01257761 3.98694944]\n",
      "pred [4.14790256 4.85186275 4.37869112 4.62116719 3.98873164 5.01125812]\n",
      "pred [3.12741476 5.87270581 4.04655754 4.95351698 3.4220898  5.57882212]\n",
      "pred [3.29244071 5.70785325 4.24648529 4.75360747 3.919828   5.08013214]\n",
      "pred [4.00661562 4.99338385 4.28581667 4.7142168  4.09323645 4.90680247]\n",
      "pred [4.70322077 4.29688511 4.45412545 4.54573327 4.14174577 4.85852455]\n",
      "pred [3.69759335 5.30238917 4.34564169 4.65431564 3.93242289 5.06748006]\n",
      "pred [4.85737532 4.14298142 4.44043357 4.5592396  5.56976686 3.42986285]\n",
      "pred [3.7391191  5.26073136 4.27275647 4.72725985 4.02904237 4.97110572]\n",
      "pred [4.48906773 4.51131487 4.49533845 4.50445472 4.47858435 4.52101792]\n",
      "pred [4.0282815  4.97173554 4.31132419 4.68873278 4.11048119 4.88955648]\n",
      "pred [4.08246007 4.91755943 4.29194453 4.70801139 3.91814083 5.08186669]\n",
      "pred [3.99894952 5.00103541 4.31334236 4.68666559 4.12294639 4.87713998]\n",
      "pred [4.51200495 4.48821738 4.37540466 4.62475108 4.30997294 4.69023444]\n",
      "pred [5.30810989 3.69210742 4.49966698 4.50014398 5.81166905 3.18807342]\n",
      "pred [4.26687817 4.73301694 4.3342673  4.66578309 4.15907194 4.84099173]\n",
      "pred [4.03183623 4.96820234 4.33987094 4.66023927 4.14273482 4.85726778]\n",
      "pred [4.61652796 4.38363695 4.39326274 4.60678573 4.61257263 4.38769767]\n",
      "pred [2.61800123 6.38183857 4.56003325 4.44010086 3.86181527 5.13813511]\n",
      "pred [4.6126129  4.38777432 4.54214076 4.45726718 4.09956924 4.90000603]\n",
      "pred [3.89875086 5.10121688 4.27469546 4.72526526 3.55037985 5.44963675]\n",
      "pred [3.29446097 5.7052438  4.04138714 4.95835655 3.79971372 5.20023258]\n",
      "pred [4.08555109 4.91440554 4.30217787 4.69784116 4.08511136 4.91492586]\n",
      "pred [4.78697803 4.21311819 4.48981343 4.51010919 4.32098119 4.67927487]\n",
      "pred [2.28713948 6.71296977 4.38439993 4.61547443 4.06473401 4.93741975]\n",
      "pred [3.19588673 5.80415805 4.40506166 4.59461405 3.8319153  5.16802116]\n",
      "pred [4.11019761 4.88980241 4.36009261 4.63987722 4.17027482 4.82983126]\n",
      "pred [4.0240702  4.97593078 4.28073961 4.71928816 4.10915015 4.89089722]\n",
      "pred [3.73726749 5.26272572 4.35178006 4.64819301 4.09004827 4.91003147]\n",
      "(296, 20) (296, 6)\n",
      "******* Feature select: LR20  Feature type: OG-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.9452057903758245\n",
      "R2 Best score (validation) val. score :  0.4687445174277999\n",
      "R2 of the best estimator (testing dataset):  0.1188712031732004\n",
      "pred [4.73069333 4.26912648 4.22023226 4.78084812 4.6121391  4.38802261]\n",
      "pred [5.42520631 3.57468256 4.4643538  4.53568252 5.48551663 3.51529934]\n",
      "pred [3.94816736 5.05179619 3.032462   5.96678221 3.86357003 5.13607886]\n",
      "pred [3.30685094 5.69319427 4.61660043 4.38292424 6.1796349  2.82076453]\n",
      "pred [4.07139898 4.92729356 3.58385674 5.41528874 4.24995859 4.75000385]\n",
      "pred [5.37003388 3.62979884 4.6945707  4.30531282 5.4923577  3.50776613]\n",
      "pred [3.94907704 5.05076065 4.46202282 4.53741426 4.28594843 4.7138893 ]\n",
      "pred [3.93549383 5.06498222 4.43468516 4.5655854  4.19750996 4.80257677]\n",
      "pred [4.48985029 4.51012274 4.41170522 4.58810102 4.29114279 4.70878597]\n",
      "pred [3.37753472 5.6225531  4.12153435 4.87847095 3.94782602 5.05151502]\n",
      "pred [3.36473122 5.63548086 4.11808249 4.88175219 3.76603562 5.23382771]\n",
      "pred [4.48215668 4.51781873 4.4108953  4.58900793 4.22520126 4.77480173]\n",
      "pred [2.81869155 6.18204006 4.55982352 4.44014332 5.52624347 3.47433118]\n",
      "pred [5.13401145 3.8657485  2.70008335 6.30026753 3.91762386 5.08221633]\n",
      "pred [4.53341658 4.46668261 4.46585974 4.53395326 4.28015986 4.71974641]\n",
      "pred [4.1715946  4.82800411 4.73476704 4.26573276 4.31858527 4.68143957]\n",
      "pred [3.30281226 5.69702565 4.64572122 4.35458104 4.61129131 4.38867331]\n",
      "pred [4.96851648 4.03167431 4.29534205 4.70515024 4.76855795 4.23168916]\n",
      "pred [5.39281019 3.60700078 2.77061238 6.22968837 3.97383855 5.02599492]\n",
      "pred [5.33770908 3.66208092 4.63679967 4.36441327 3.28885005 5.71179999]\n",
      "pred [2.73734881 6.26256596 4.91119253 4.08844581 4.44733543 4.55267095]\n",
      "pred [3.9347378  5.06543748 4.66677048 4.33319772 4.52947562 4.4708104 ]\n",
      "pred [4.24634528 4.75353458 4.33727171 4.66287661 4.64382476 4.35642408]\n",
      "pred [4.29879685 4.70067477 4.45526993 4.54411635 5.54277736 3.45697047]\n",
      "pred [3.44488503 5.55511158 4.35472051 4.64510797 4.08546975 4.91477598]\n",
      "pred [4.52272015 4.47741874 4.40933677 4.59100654 4.73502511 4.26482461]\n",
      "pred [4.28852279 4.71197231 4.61655424 4.38338232 3.70100389 5.29875506]\n",
      "pred [3.77566697 5.22459247 4.03698654 4.96256297 3.92367789 5.07616532]\n",
      "pred [3.07631884 5.92362605 4.17504692 4.82472815 4.05056566 4.94954467]\n",
      "pred [4.02459448 4.97532953 4.09804073 4.90141622 2.5834086  6.41631063]\n",
      "pred [4.40232366 4.5975199  3.85072919 5.14949399 2.73175425 6.26782129]\n",
      "pred [4.07124678 4.92877753 4.53390003 4.46639492 4.30626362 4.69381629]\n",
      "pred [5.45461438 3.54525922 3.94095527 5.05909978 3.6412882  5.35872022]\n",
      "pred [5.84129172 3.15847068 4.66754868 4.33262557 5.12543589 3.87448343]\n",
      "pred [4.06206136 4.93778168 4.49493318 4.50520529 3.47095321 5.52883811]\n",
      "pred [5.61628646 3.3834987  2.86050646 6.13962498 3.58166604 5.41828209]\n",
      "pred [3.50926511 5.4908556  4.34402706 4.65600799 4.14294252 4.85706436]\n",
      "pred [3.70277528 5.29757693 4.58440506 4.41607142 4.16007184 4.84015196]\n",
      "pred [3.83103408 5.16899741 4.4611127  4.53880566 4.62957525 4.37086472]\n",
      "pred [3.25472138 5.74545374 4.48760655 4.51273411 3.68050291 5.31990401]\n",
      "pred [4.57656944 4.4233763  4.15420042 4.84513705 6.28571143 2.71470895]\n",
      "pred [3.22205265 5.7776058  4.46218394 4.53728622 4.00159026 4.99795041]\n",
      "pred [4.70112634 4.29877694 4.40174181 4.59827485 4.16876871 4.83175701]\n",
      "pred [3.76926439 5.23068827 4.53697828 4.4625327  4.26980208 4.730132  ]\n",
      "pred [3.67996709 5.31983757 4.41227688 4.58779432 3.80420956 5.19625501]\n",
      "pred [2.73663801 6.26328342 4.90581641 4.09382793 4.45078093 4.54922144]\n",
      "pred [4.64737268 4.35283219 4.44048967 4.55915925 4.27983504 4.72025279]\n",
      "pred [5.33531434 3.66470424 4.46733155 4.53266    6.54580887 2.45514501]\n",
      "pred [3.33567139 5.66430143 4.22558156 4.77444419 4.15327772 4.84660385]\n",
      "pred [4.07479194 4.92470487 4.63969971 4.35992766 4.33241302 4.66719985]\n",
      "pred [4.81241899 4.18753728 4.51142386 4.48824252 4.42915005 4.57092114]\n",
      "pred [3.10576246 5.89432414 4.27056248 4.72931493 3.90109431 5.09899456]\n",
      "pred [4.06709804 4.93272197 4.09773269 4.90199616 4.0815103  4.91789369]\n",
      "pred [3.33005324 5.66996002 4.6775577  4.32275356 3.00997063 5.99011029]\n",
      "pred [3.21443328 5.78549692 4.15993601 4.83973867 3.99845945 5.00170726]\n",
      "pred [4.35986033 4.64007344 3.87140902 5.1285484  4.07578405 4.92413205]\n",
      "pred [3.27923069 5.72073133 4.47241572 4.52757687 4.42395085 4.57596559]\n",
      "pred [5.28270243 3.71720745 2.9267449  6.07359577 4.41819476 4.58152793]\n",
      "pred [3.4008141  5.59926754 4.24992499 4.75002062 3.92613863 5.07393889]\n",
      "pred [4.42636806 4.57348647 4.62251715 4.37748485 4.36730315 4.63319687]\n",
      "pred [3.81090586 5.18929356 4.21018201 4.78964109 4.15222828 4.84800553]\n",
      "pred [3.19738351 5.8024168  4.46899047 4.53129528 4.20498929 4.7949438 ]\n",
      "(296, 20) (296, 6)\n",
      "******* Feature select: LR20  Feature type: ST-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.9771983058219381\n",
      "R2 Best score (validation) val. score :  0.5413187172346012\n",
      "R2 of the best estimator (testing dataset):  0.35510821076185106\n",
      "pred [4.77526821 4.22439393 4.45078244 4.54928995 4.42235265 4.57756967]\n",
      "pred [5.50468871 3.49541406 4.62609869 4.37388134 3.72604359 5.27387439]\n",
      "pred [4.22823811 4.77201963 3.00992242 5.99053561 3.93410301 5.06560792]\n",
      "pred [3.46416414 5.53612823 4.56643971 4.43383007 6.23936307 2.7606245 ]\n",
      "pred [4.05097903 4.94904892 4.28066883 4.71940937 3.88233189 5.11762638]\n",
      "pred [5.02994071 3.96997138 4.42585905 4.57432671 5.25368116 3.74603973]\n",
      "pred [4.19850116 4.80150435 4.3511659  4.64889848 4.1800919  4.81989414]\n",
      "pred [3.96529076 5.03472682 4.35191411 4.64801455 4.06710635 4.93313003]\n",
      "pred [4.37946618 4.62065599 4.39791033 4.60208219 4.3453468  4.65460525]\n",
      "pred [4.73967127 4.26076998 4.16394542 4.83652356 4.44725042 4.55208696]\n",
      "pred [4.71182499 4.28838584 4.35239101 4.6475448  4.5552265  4.4445059 ]\n",
      "pred [3.82413096 5.17603123 4.39426532 4.60581629 3.98465851 5.01517747]\n",
      "pred [3.15351455 5.84644827 4.55475704 4.44491659 5.27578328 3.7243028 ]\n",
      "pred [4.00774121 4.99228162 4.10365762 4.89641478 3.8745587  5.12541114]\n",
      "pred [4.29075782 4.70923396 4.3754748  4.62443198 4.236519   4.76373558]\n",
      "pred [4.14431821 4.85568538 4.31009049 4.68997116 4.15743844 4.84257885]\n",
      "pred [3.6615692  5.33840321 4.38252776 4.61745535 4.18263689 4.81736434]\n",
      "pred [4.57888643 4.42115917 4.36719788 4.63277738 4.68599917 4.31394087]\n",
      "pred [3.72600852 5.27416561 3.16051805 5.83908433 3.71898507 5.28096024]\n",
      "pred [5.07704761 3.9229958  4.60021686 4.40009525 3.3643274  5.63638403]\n",
      "pred [4.09350205 4.90649602 4.24579597 4.75418606 4.0108585  4.98923103]\n",
      "pred [3.78431817 5.21561601 4.33670528 4.66321827 4.02567878 4.97424905]\n",
      "pred [3.53498149 5.46525688 4.41972804 4.58028017 4.34182837 4.65820497]\n",
      "pred [4.24064548 4.75932941 4.3258453  4.67418786 4.36004937 4.63992965]\n",
      "pred [2.99507226 6.00528759 4.44935453 4.55067219 4.06898871 4.93125529]\n",
      "pred [4.15321527 4.8470092  4.39651773 4.60349557 4.64652605 4.35361333]\n",
      "pred [3.5508462  5.44888522 4.43983284 4.56006417 3.96741228 5.03317631]\n",
      "pred [4.74494762 4.25502014 4.38887717 4.61128625 4.66401426 4.33613425]\n",
      "pred [3.11725538 5.88275224 4.17134254 4.82861944 4.05328372 4.94672398]\n",
      "pred [4.13394741 4.86606584 4.30087027 4.69905135 3.88445959 5.11554665]\n",
      "pred [4.12037396 4.87963628 4.31099985 4.68905224 4.12328907 4.87673004]\n",
      "pred [3.6148664  5.3852011  4.33147595 4.66866415 4.16691971 4.83297793]\n",
      "pred [5.50730938 3.49288429 3.83027736 5.16960928 3.54517222 5.45484755]\n",
      "pred [4.95404576 4.04589697 4.40151379 4.59870674 5.05465379 3.94510139]\n",
      "pred [4.17408827 4.8258586  4.38163319 4.61831662 3.94192519 5.05820791]\n",
      "pred [4.053982   4.94610923 3.40329364 5.59663785 3.66812602 5.33180559]\n",
      "pred [3.47918686 5.52086848 4.37181375 4.62811974 4.14224575 4.85778712]\n",
      "pred [3.76992329 5.23011855 4.35054391 4.64955447 3.95378867 5.04617727]\n",
      "pred [4.8064967  4.19383758 4.46585802 4.53410946 4.20493477 4.79458324]\n",
      "pred [4.26821149 4.73155126 4.23788582 4.76182481 4.05956063 4.94008193]\n",
      "pred [5.52260049 3.47719956 4.29772878 4.70168819 5.94683186 3.05286586]\n",
      "pred [3.82077537 5.17909094 4.09274805 4.90721988 3.15332135 5.84696122]\n",
      "pred [4.86873538 4.13144443 4.42435393 4.57567769 2.69488797 6.30553873]\n",
      "pred [4.12393414 4.87607104 4.31389988 4.68615452 4.16233571 4.83767594]\n",
      "pred [3.67424434 5.32580602 4.27545085 4.7244452  3.65647317 5.34335644]\n",
      "pred [4.0905094  4.90949986 4.25761505 4.74237641 4.00225538 4.99784162]\n",
      "pred [4.28620756 4.71382775 4.35945503 4.64058918 4.22067481 4.77933207]\n",
      "pred [5.45073984 3.54922284 4.57624764 4.42367818 5.41074435 3.58944523]\n",
      "pred [4.08497632 4.91511305 4.36911198 4.6309273  4.34229999 4.65757652]\n",
      "pred [4.11297212 4.88695835 4.3444719  4.65558229 4.20657384 4.79339731]\n",
      "pred [4.29573589 4.70436332 4.35866481 4.64136004 4.2714278  4.72855486]\n",
      "pred [3.55351803 5.44648511 4.371692   4.62834207 4.04010414 4.95994216]\n",
      "pred [4.62865555 4.37169248 4.05083243 4.9499375  4.29571317 4.70406797]\n",
      "pred [4.00338868 4.99664849 4.26220923 4.73752411 3.38228263 5.61751906]\n",
      "pred [3.51845738 5.48138234 4.05019735 4.94957498 3.81253559 5.18778331]\n",
      "pred [3.95209376 5.04798316 4.38258177 4.61747096 4.03933367 4.96065823]\n",
      "pred [4.58576604 4.41434604 4.3943727  4.60558252 4.65565634 4.34437882]\n",
      "pred [4.01258255 4.98745308 4.09696093 4.9030876  3.89271732 5.10725236]\n",
      "pred [3.2988595  5.70124412 4.42565438 4.57432813 3.96971385 5.03039917]\n",
      "pred [4.37652395 4.62367712 4.31187806 4.68804297 4.36984874 4.62994636]\n",
      "pred [4.24263715 4.75726178 4.38940405 4.61060912 4.14251277 4.85751108]\n",
      "pred [3.06703046 5.93292432 4.53135046 4.46860553 3.89685654 5.10331058]\n",
      "(296, 30) (296, 6)\n",
      "******* Feature select: LR30  Feature type: HG-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.9809746071784659\n",
      "R2 Best score (validation) val. score :  0.484778868896545\n",
      "R2 of the best estimator (testing dataset):  0.2673947781397299\n",
      "pred [4.76960703 4.23048502 4.48356574 4.51644124 4.38438297 4.61550691]\n",
      "pred [5.5945181  3.4055974  4.46527439 4.53435755 4.3855822  4.61450542]\n",
      "pred [3.97686133 5.02319085 4.28485375 4.7151853  4.10319989 4.89684659]\n",
      "pred [3.31066449 5.68908623 4.55245406 4.44757698 5.97928015 3.02067708]\n",
      "pred [4.1609929  4.83886435 3.80937743 5.19058299 3.72350885 5.27642919]\n",
      "pred [5.47717677 3.52289846 4.48681572 4.51302404 6.25059677 2.74950117]\n",
      "pred [3.52158353 5.47827925 4.25363785 4.74628764 4.25654726 4.74324443]\n",
      "pred [3.98377579 5.0162744  4.2976398  4.70239953 4.11944546 4.88059794]\n",
      "pred [4.0358812  4.9641737  4.3159811  4.68407765 4.16220368 4.83785694]\n",
      "pred [4.9794702  4.02035267 4.31783855 4.68188336 4.40616254 4.59355624]\n",
      "pred [4.92186435 4.07829263 4.51995327 4.47960688 4.26896731 4.73061362]\n",
      "pred [4.07329007 4.92668375 4.33208001 4.66799487 4.11709887 4.88291196]\n",
      "pred [3.04653039 5.95355738 4.44202232 4.55798157 4.97614719 4.02411611]\n",
      "pred [3.00159252 5.99902775 3.9993004  5.00020794 3.47080447 5.52873991]\n",
      "pred [4.13317644 4.86695519 4.36323164 4.63669029 4.16324328 4.83671907]\n",
      "pred [3.98183787 5.01824534 4.29015197 4.70990718 4.14429617 4.8556668 ]\n",
      "pred [3.52767059 5.47216088 4.44276558 4.55740772 4.2509749  4.74921991]\n",
      "pred [4.46750547 4.53271499 4.29369809 4.70642707 4.53188318 4.46808638]\n",
      "pred [2.63202542 6.36774945 4.46698311 4.53403453 3.8500598  5.15027177]\n",
      "pred [5.10503052 3.89553093 4.62657585 4.37303526 3.0006788  5.99961618]\n",
      "pred [3.99002476 5.01003257 4.29856085 4.70145857 4.12219076 4.8778577 ]\n",
      "pred [4.09251389 4.90753939 4.32880539 4.67130273 4.16882384 4.83123951]\n",
      "pred [4.09213085 4.90804814 4.36284088 4.63739784 4.5795333  4.42055108]\n",
      "pred [4.40760387 4.59212434 4.45639948 4.54378697 5.94860048 3.05126219]\n",
      "pred [3.32157779 5.67827662 4.35759278 4.64227843 4.08428593 4.91580947]\n",
      "pred [4.07539271 4.92457753 4.29763906 4.70240027 4.25902359 4.74097059]\n",
      "pred [4.61127551 4.38842177 4.61056622 4.38954025 4.81808836 4.1822248 ]\n",
      "pred [4.97904014 4.02109591 4.58903832 4.41071173 4.42339072 4.57621043]\n",
      "pred [3.14707574 5.85316136 4.26590502 4.73410331 4.09362947 4.90645258]\n",
      "pred [4.05554997 4.94447898 3.97440162 5.02555538 3.7460959  5.25381659]\n",
      "pred [3.84398188 5.1560964  4.22257029 4.77747621 3.9297188  5.07030132]\n",
      "pred [3.98987522 5.01016854 4.29770106 4.70233827 4.13042868 4.86961004]\n",
      "pred [4.28461392 4.7153903  4.14685292 4.85306141 3.8120161  5.18794361]\n",
      "pred [5.52120363 3.47899631 4.69841061 4.30124113 3.20103149 5.79911197]\n",
      "pred [4.07252019 4.92732123 4.39547025 4.60451731 3.79854624 5.20162961]\n",
      "pred [3.4350571  5.56497943 3.96461223 5.03609    3.53867831 5.46133046]\n",
      "pred [3.87072456 5.12930927 4.31222809 4.68780495 4.08201838 4.91802188]\n",
      "pred [3.97657754 5.02347477 4.29798283 4.70205589 4.11038448 4.8896627 ]\n",
      "pred [4.47454397 4.52535792 4.44594164 4.5543073  4.29234118 4.70792017]\n",
      "pred [3.51327275 5.48677772 4.37358044 4.62631319 3.88814503 5.11197655]\n",
      "pred [4.81749821 4.18232491 4.31222754 4.68761982 4.96964437 4.03044914]\n",
      "pred [3.72651322 5.27355919 4.26900325 4.73101846 4.0135415  4.98645731]\n",
      "pred [4.89201566 4.10753237 4.39507984 4.60476743 3.33904581 5.66128622]\n",
      "pred [3.9834414  5.016615   4.310082   4.68996758 4.11020448 4.88984263]\n",
      "pred [4.06945029 4.93052305 4.29841285 4.70167119 3.92305698 5.07700868]\n",
      "pred [3.99124259 5.00881399 4.29828884 4.7017295  4.1213942  4.87865397]\n",
      "pred [4.36286184 4.63745449 4.45215936 4.54766279 4.20580916 4.79428963]\n",
      "pred [5.58132498 3.41873665 4.44529634 4.55453623 6.86214193 2.13798067]\n",
      "pred [4.11366143 4.88638046 4.30565203 4.69441178 4.14307845 4.85701857]\n",
      "pred [3.97984414 5.02021727 4.30398099 4.69606315 4.11569373 4.88435878]\n",
      "pred [4.25010695 4.74988971 4.42694198 4.57322919 4.46667577 4.53343031]\n",
      "pred [2.90121237 6.09875565 4.41304253 4.58667871 3.86601572 5.13377807]\n",
      "pred [4.01654637 4.98260586 4.09203972 4.90836019 4.51968546 4.48015808]\n",
      "pred [3.79971223 5.20035791 4.24372183 4.75628981 3.58683353 5.41329055]\n",
      "pred [3.599532   5.40049204 4.1621997  4.837511   3.94522756 5.05490263]\n",
      "pred [3.94531935 5.05473799 4.31471956 4.68532032 4.08788453 4.91216543]\n",
      "pred [4.65398511 4.34593375 4.48181714 4.51836591 4.41829546 4.58188317]\n",
      "pred [2.68939963 6.31130476 4.24526221 4.75443921 3.81394574 5.18584462]\n",
      "pred [3.56697019 5.43294904 4.36636869 4.63341167 3.97562256 5.02429223]\n",
      "pred [4.07217104 4.92788312 4.31158026 4.6883923  4.16942981 4.83061538]\n",
      "pred [4.00048779 4.99952443 4.31065047 4.68943173 4.12181852 4.87818693]\n",
      "pred [3.65958322 5.34045856 4.35165496 4.64837226 4.07929443 4.92070293]\n",
      "(296, 30) (296, 6)\n",
      "******* Feature select: LR30  Feature type: OG-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.9726351565022605\n",
      "R2 Best score (validation) val. score :  0.488357033604247\n",
      "R2 of the best estimator (testing dataset):  0.025684817486722245\n",
      "pred [4.67847039 4.32154826 4.42600605 4.57405491 4.37880867 4.62097197]\n",
      "pred [5.4518955  3.54859528 4.46722526 4.53258673 4.83554037 4.16442582]\n",
      "pred [4.00977866 4.99024859 4.24087596 4.7590818  4.1124654  4.88757211]\n",
      "pred [3.35994997 5.64018759 4.55771758 4.44259654 6.02239941 2.97719212]\n",
      "pred [4.6389214  4.36127006 3.19722005 5.80247874 3.90747242 5.09246666]\n",
      "pred [5.41035027 3.58983964 4.68245081 4.31697087 5.62594385 3.37395506]\n",
      "pred [3.96014288 5.03987686 4.23600191 4.7640239  4.15211383 4.84792945]\n",
      "pred [4.11480046 4.8851141  3.97886703 5.02111359 4.11517274 4.88501972]\n",
      "pred [4.1779623  4.82204611 4.30719937 4.69277705 4.1599007  4.84015019]\n",
      "pred [3.29454183 5.70541582 4.1068376  4.89245381 4.06757553 4.93206737]\n",
      "pred [3.24278619 5.75717057 4.21677633 4.78207446 3.91986664 5.07972797]\n",
      "pred [4.10843038 4.89150921 4.34737343 4.65247981 4.11480929 4.88519283]\n",
      "pred [2.99247899 6.00800808 4.40897258 4.59107161 5.03881722 3.96162177]\n",
      "pred [5.21093348 3.78978737 2.58806774 6.40984576 4.36545099 4.63392528]\n",
      "pred [4.17942638 4.82062768 4.32380644 4.67617493 4.17371017 4.82629585]\n",
      "pred [4.09993037 4.9000045  4.41048251 4.58926451 4.20243098 4.79776496]\n",
      "pred [3.4978612  5.50210802 4.44841002 4.55168882 4.31023962 4.68952179]\n",
      "pred [4.96773604 4.03235758 4.31087612 4.68914996 4.75511983 4.24444438]\n",
      "pred [5.45625311 3.54437963 2.3567557  6.64112315 4.1722928  4.82732008]\n",
      "pred [5.29071851 3.71018849 4.50559848 4.49425834 2.97020967 6.03004324]\n",
      "pred [3.76589257 5.23403279 4.4586226  4.54127431 4.11050525 4.88956116]\n",
      "pred [4.13343185 4.86661957 4.31986239 4.68015269 4.23763474 4.76237984]\n",
      "pred [4.22819577 4.77183253 4.40284094 4.59693606 4.68809238 4.31162666]\n",
      "pred [4.36778995 4.63226191 4.38415422 4.61566463 5.7413907  3.25881507]\n",
      "pred [3.63801377 5.36209456 4.3233352  4.67667133 4.04416364 4.95582398]\n",
      "pred [4.10903192 4.89074681 4.42943228 4.57062017 4.54121816 4.45915905]\n",
      "pred [3.99621709 5.00347056 4.58151883 4.41777346 3.61144993 5.3880216 ]\n",
      "pred [3.40387872 5.59604609 4.17625702 4.82288558 3.9934204  5.0062035 ]\n",
      "pred [3.28555657 5.71440808 4.28496747 4.71488656 4.19338505 4.80609269]\n",
      "pred [4.24785524 4.75260731 3.86500568 5.13474843 2.95214712 6.04771452]\n",
      "pred [3.94649315 5.05369012 4.10745881 4.89248868 3.68396987 5.31616804]\n",
      "pred [3.8613266  5.13860885 4.21180167 4.78826501 3.96709496 5.03295793]\n",
      "pred [5.50224572 3.49762376 3.80851271 5.19128147 3.18775672 5.81229838]\n",
      "pred [5.68252564 3.3178985  4.58777818 4.41145499 5.06489833 3.93498001]\n",
      "pred [4.04357323 4.95653293 4.39975261 4.60002807 3.65965093 5.3402434 ]\n",
      "pred [5.53783282 3.46250976 2.48264506 6.51573143 3.74735031 5.2525895 ]\n",
      "pred [3.84324779 5.15680428 4.2835249  4.71642235 4.11408892 4.88597625]\n",
      "pred [3.77978786 5.22014511 4.26196763 4.73807202 3.83826829 5.16186574]\n",
      "pred [3.63930083 5.36062115 4.43835812 4.56123964 4.62204439 4.37840378]\n",
      "pred [3.48543684 5.51435601 4.33166633 4.66840062 4.00553128 4.99459603]\n",
      "pred [4.83120717 4.16884738 4.05377663 4.94607077 5.63129104 3.36888921]\n",
      "pred [3.53670329 5.46305536 4.1815799  4.81827917 3.6950367  5.30483142]\n",
      "pred [4.79672913 4.2033471  4.31844439 4.68212447 3.30244475 5.69737587]\n",
      "pred [4.07913089 4.92093415 4.31276906 4.68718    4.15038384 4.84968242]\n",
      "pred [3.82408949 5.17579728 4.31361018 4.68628581 3.92392893 5.07631007]\n",
      "pred [3.7630768  5.23686508 4.46430591 4.53561213 4.11428559 4.88577177]\n",
      "pred [4.26090308 4.73909608 4.31277411 4.68719231 4.1742189  4.82587024]\n",
      "pred [5.39478409 3.60568476 4.47301064 4.52659719 6.27480279 2.72515532]\n",
      "pred [4.37376032 4.62623223 4.50292599 4.49706895 4.22626952 4.77372278]\n",
      "pred [4.06098722 4.93922845 4.33767413 4.66227062 4.18748383 4.81257876]\n",
      "pred [4.37156123 4.62856099 4.37065465 4.62934854 4.26054986 4.73961756]\n",
      "pred [3.04601098 5.95396013 4.40846658 4.59157096 3.95305754 5.04731145]\n",
      "pred [3.96566    5.03486914 4.17740235 4.82270605 4.16819214 4.83164377]\n",
      "pred [3.95666127 5.04328591 4.31354037 4.68665256 3.23322294 5.76686648]\n",
      "pred [3.44764476 5.55237417 4.19457716 4.80540757 4.07904037 4.92050042]\n",
      "pred [4.12421401 4.87579411 4.15518551 4.84479785 4.02741962 4.97261329]\n",
      "pred [3.12232798 5.87811083 4.44758184 4.55229955 4.25988474 4.73975725]\n",
      "pred [5.43399229 3.56672836 2.44213001 6.55586905 4.55357049 4.44585431]\n",
      "pred [3.4004162  5.59981265 4.34470583 4.65504988 3.9039054  5.09611548]\n",
      "pred [4.25109934 4.74889301 4.36571277 4.63425248 4.26629379 4.73365034]\n",
      "pred [4.13033966 4.86967972 4.30329958 4.69670065 4.14942315 4.85062246]\n",
      "pred [3.15969812 5.84017808 4.41114902 4.58885595 3.72743651 5.27254513]\n",
      "(296, 30) (296, 6)\n",
      "******* Feature select: LR30  Feature type: ST-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.9834324716280127\n",
      "R2 Best score (validation) val. score :  0.5312928882286159\n",
      "R2 of the best estimator (testing dataset):  0.31991880056241745\n",
      "pred [4.7411142  4.25866525 4.40315826 4.59691403 4.47680979 4.5229479 ]\n",
      "pred [5.24634115 3.75331302 4.58833332 4.41170366 4.51529824 4.48439715]\n",
      "pred [4.20152358 4.79868622 2.91830897 6.08191172 3.80360568 5.19628687]\n",
      "pred [3.52410848 5.47595167 4.49842531 4.50160771 5.91916308 3.08087471]\n",
      "pred [3.98198987 5.0182551  4.20336775 4.79668075 3.71827653 5.28178646]\n",
      "pred [5.19835169 3.80183959 4.41460458 4.58568394 5.33050359 3.66964303]\n",
      "pred [4.20614719 4.79382716 4.36516829 4.6348691  4.20371551 4.79632713]\n",
      "pred [4.00775517 4.99218579 4.30841939 4.69180703 4.0037411  4.99632307]\n",
      "pred [4.16652768 4.83343955 4.35023176 4.64984265 4.24908041 4.75096257]\n",
      "pred [3.69123565 5.30862115 4.19913179 4.80069287 4.24399198 4.75640547]\n",
      "pred [3.91046435 5.08930407 4.30379283 4.69594591 4.34933525 4.6508711 ]\n",
      "pred [3.96780406 5.03196986 4.3645012  4.63568673 4.05999249 4.93999689]\n",
      "pred [3.14119999 5.8586039  4.45987872 4.54011786 5.05081216 3.94874651]\n",
      "pred [3.87201365 5.12798914 3.91042924 5.08926979 3.84761855 5.15244018]\n",
      "pred [4.25437987 4.74560223 4.36804144 4.63186149 4.25051685 4.74943052]\n",
      "pred [4.1083412  4.89163595 4.33345663 4.66663799 4.18455856 4.81550802]\n",
      "pred [3.53462482 5.46539387 4.42820927 4.5717941  4.25353979 4.746809  ]\n",
      "pred [4.597138   4.40272228 4.40857995 4.59210622 4.73436104 4.26574375]\n",
      "pred [3.67696406 5.32303477 3.07578382 5.92346463 3.64464231 5.35504599]\n",
      "pred [4.78303091 4.21647427 4.27588672 4.7243026  3.94562436 5.05381822]\n",
      "pred [4.06781753 4.93229554 4.17663461 4.8232941  4.05293785 4.94713192]\n",
      "pred [3.83757409 5.1624868  4.36954766 4.63047638 4.26618473 4.73399696]\n",
      "pred [3.7793414  5.22057075 4.46631457 4.53413859 4.57767314 4.42231978]\n",
      "pred [4.17017775 4.82986687 4.3404996  4.65955057 4.49744089 4.50262276]\n",
      "pred [3.24476566 5.75519922 4.39649383 4.60354674 4.02890599 4.97110692]\n",
      "pred [4.38013346 4.61961853 4.35824943 4.64185195 4.66514179 4.33522319]\n",
      "pred [3.66479759 5.33555097 4.43355236 4.5665849  3.84849378 5.15136789]\n",
      "pred [3.92554862 5.0743786  4.32807355 4.67158245 4.43478176 4.56519107]\n",
      "pred [3.21649605 5.78364758 4.17589144 4.82417793 4.06541493 4.93452024]\n",
      "pred [4.11881882 4.88115459 4.27534633 4.7248271  3.66642716 5.33366633]\n",
      "pred [4.06152331 4.93846228 4.31260259 4.68745368 4.04780902 4.95227348]\n",
      "pred [3.68226528 5.31769708 4.39922019 4.60079059 4.14196918 4.8580852 ]\n",
      "pred [5.62320715 3.37652037 3.75647543 5.24363208 3.48092736 5.51917728]\n",
      "pred [4.91003963 4.09003812 4.37213132 4.62816526 4.83811951 4.16203515]\n",
      "pred [4.128311   4.87163003 4.45750592 4.54253021 3.8151747  5.18490998]\n",
      "pred [4.11380168 4.88618599 3.30624054 5.69275942 3.43830531 5.56129921]\n",
      "pred [3.68010561 5.31997847 4.35820827 4.64177317 4.12245366 4.87743649]\n",
      "pred [3.81155015 5.18834799 4.38771442 4.61231439 4.08256414 4.91759627]\n",
      "pred [4.51120751 4.48862635 4.45025031 4.54975253 4.54062663 4.45925404]\n",
      "pred [4.47273609 4.52709506 4.38094264 4.61901049 4.03309062 4.96706944]\n",
      "pred [5.18368194 3.81630434 4.27985991 4.71995032 5.7162627  3.28329404]\n",
      "pred [3.83199771 5.16801137 4.10852675 4.89182458 3.09456483 5.90581443]\n",
      "pred [4.99725772 4.00314221 4.41544169 4.58461204 2.5997856  6.39986207]\n",
      "pred [4.08078382 4.91920436 4.32559016 4.67446358 4.17816623 4.82190725]\n",
      "pred [3.6390341  5.36101036 4.28589444 4.71415696 3.66885958 5.33126785]\n",
      "pred [4.06789568 4.93222656 4.18440473 4.81552317 4.04893011 4.9511345 ]\n",
      "pred [4.25822223 4.74179831 4.36376427 4.63633166 4.20182019 4.79822812]\n",
      "pred [5.28308301 3.71666376 4.55218858 4.44771359 5.57285848 3.42684924]\n",
      "pred [4.0518234  4.94820251 4.37325662 4.62665195 4.42610999 4.57383498]\n",
      "pred [4.08357254 4.91642924 4.36695358 4.63308954 4.25403458 4.7460686 ]\n",
      "pred [4.21371709 4.7862678  4.36093521 4.63916077 4.26989789 4.73013049]\n",
      "pred [3.34596614 5.6540434  4.39946918 4.60056186 4.01469442 4.98530046]\n",
      "pred [3.64916563 5.35091125 4.17977874 4.82008509 4.15248243 4.84772258]\n",
      "pred [3.96056316 5.03959323 4.20833903 4.79164791 3.32324233 5.67682471]\n",
      "pred [3.5879376  5.41199815 4.13337527 4.8663147  3.91366958 5.0865445 ]\n",
      "pred [3.87407721 5.12592709 4.43772836 4.56231001 4.0380417  4.96199589]\n",
      "pred [4.59140748 4.4085478  4.40595383 4.59422686 4.71446886 4.285419  ]\n",
      "pred [3.87197445 5.12799071 3.95550277 5.04421352 3.81969145 5.18032636]\n",
      "pred [3.25119726 5.74896005 4.43505278 4.5649876  3.94178959 5.05828557]\n",
      "pred [4.37049122 4.62948976 4.35028251 4.64980326 4.41643677 4.58342599]\n",
      "pred [4.07191546 4.92805206 4.33738985 4.66271169 4.16791201 4.83217804]\n",
      "pred [3.15558086 5.84426488 4.50383735 4.49644143 3.78401226 5.21617274]\n",
      "(296, 40) (296, 6)\n",
      "******* Feature select: LR40  Feature type: HG-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.9827458987532859\n",
      "R2 Best score (validation) val. score :  0.49483766742218327\n",
      "R2 of the best estimator (testing dataset):  0.3632648589749183\n",
      "pred [4.68458571 4.31546292 4.46746577 4.53252685 4.35113681 4.64915543]\n",
      "pred [5.15358556 3.84611939 4.42987359 4.57023011 4.31029769 4.68955296]\n",
      "pred [3.99899705 5.00104922 4.30603767 4.69398306 4.11227992 4.88776343]\n",
      "pred [3.62351275 5.37648945 4.4844149  4.51509217 5.68567352 3.31432928]\n",
      "pred [4.25817393 4.74190203 3.71354733 5.28629522 3.58377363 5.41608029]\n",
      "pred [5.33480338 3.66545689 4.52120721 4.47836742 5.56103578 3.43900369]\n",
      "pred [3.86504188 5.13502912 4.27759452 4.72239852 4.13484613 4.86520071]\n",
      "pred [4.00260835 4.99743834 4.30610585 4.69391491 4.11738412 4.8826591 ]\n",
      "pred [4.08203045 4.91800509 4.32667813 4.67334624 4.18539791 4.81463572]\n",
      "pred [4.84162604 4.15831808 4.36799611 4.6322622  4.47131971 4.52878686]\n",
      "pred [5.09646121 3.90372058 4.46776388 4.53268777 4.6478271  4.35234313]\n",
      "pred [4.04740412 4.95265707 4.32997473 4.67006031 4.12832914 4.87172219]\n",
      "pred [3.39926167 5.60088613 4.40171668 4.59799094 4.87502551 4.12513312]\n",
      "pred [2.86491528 6.13546605 4.1520159  4.84764536 3.74988413 5.25035784]\n",
      "pred [4.18024922 4.8198213  4.38211725 4.61787848 4.17793312 4.82220087]\n",
      "pred [4.02178424 4.97828555 4.30684494 4.69314623 4.13359264 4.8664161 ]\n",
      "pred [3.58186854 5.41802625 4.42245801 4.57734025 4.24644509 4.75370822]\n",
      "pred [4.54472355 4.45525098 4.29340822 4.70663821 4.53233382 4.46762363]\n",
      "pred [2.42495544 6.57461753 4.68936153 4.31073333 3.86738219 5.13284469]\n",
      "pred [4.5700711  4.42924395 4.5160621  4.48461746 3.08956973 5.90959063]\n",
      "pred [4.00158461 4.99845626 4.3155653  4.68445838 4.12382786 4.87623538]\n",
      "pred [4.16350876 4.83654269 4.35472828 4.64528871 4.24570715 4.75440946]\n",
      "pred [4.1947296  4.80512852 4.34135256 4.65869593 4.5638252  4.43613777]\n",
      "pred [4.39595299 4.60373252 4.42246278 4.57776911 5.54822121 3.45164751]\n",
      "pred [3.31636904 5.68368116 4.36810881 4.6318366  4.07439189 4.9257267 ]\n",
      "pred [4.11730982 4.88277927 4.30610515 4.69391561 4.30099247 4.69902081]\n",
      "pred [4.27164925 4.72842195 4.4361625  4.56378664 4.49426826 4.50540937]\n",
      "pred [5.05225598 3.94776467 4.51560867 4.48490726 4.74751408 4.25272671]\n",
      "pred [3.17118381 5.82886115 4.23269922 4.76731162 4.11878951 4.88135345]\n",
      "pred [4.12314748 4.87680103 4.01310118 4.98671663 3.54601302 5.4539234 ]\n",
      "pred [3.99742216 5.00261411 4.19116615 4.80882249 3.93993714 5.06016304]\n",
      "pred [4.00314711 4.99690025 4.3061417  4.69387909 4.11948895 4.88055386]\n",
      "pred [4.40395616 4.59596944 4.07716295 4.92278593 3.75759226 5.24247787]\n",
      "pred [5.32515992 3.67504717 4.41168968 4.58807128 4.46127129 4.53890966]\n",
      "pred [4.08952653 4.910678   4.41259894 4.58753047 3.81350843 5.18671259]\n",
      "pred [3.24821438 5.75148942 4.32186839 4.67821548 3.53426713 5.46593908]\n",
      "pred [3.52109224 5.4788828  4.35405153 4.64591078 3.99236327 5.00783099]\n",
      "pred [3.99647348 5.00357319 4.30646245 4.69355846 4.10988739 4.89015847]\n",
      "pred [4.25825152 4.74174955 4.38736636 4.61272614 4.12464526 4.87547803]\n",
      "pred [3.67012786 5.32981249 4.286139   4.71389839 3.92209708 5.07786378]\n",
      "pred [4.65197827 4.3480445  4.15620128 4.84426194 4.63495996 4.36460272]\n",
      "pred [3.59979207 5.40019034 4.27826797 4.72178601 3.99635678 5.00376221]\n",
      "pred [4.53590822 4.46402535 4.28202635 4.71851205 3.19651163 5.80294918]\n",
      "pred [4.00551215 4.9945354  4.31678277 4.68324218 4.1161786  4.8838648 ]\n",
      "pred [4.06443385 4.9357303  4.31259715 4.68749365 3.99494285 5.00520039]\n",
      "pred [3.99848565 5.00155483 4.31811764 4.68190832 4.1226706  4.87740055]\n",
      "pred [4.2869201  4.7129928  4.42606252 4.57396305 4.24098221 4.75901363]\n",
      "pred [5.16917919 3.8306904  4.43593634 4.56401438 5.47741151 3.5224896 ]\n",
      "pred [4.03686906 4.96317796 4.29902917 4.70100847 4.12636949 4.87364773]\n",
      "pred [4.00796975 4.99207597 4.32807264 4.67195088 4.13195742 4.86807917]\n",
      "pred [4.29340037 4.70665728 4.42964229 4.57036169 4.46412777 4.53589179]\n",
      "pred [2.8344931  6.1656909  4.4521154  4.54812359 3.86261333 5.13769585]\n",
      "pred [4.09092929 4.90897674 4.45604079 4.54411103 4.11499851 4.88496407]\n",
      "pred [3.8113827  5.18862285 4.27000922 4.73004825 3.48698842 5.51303373]\n",
      "pred [3.35713997 5.64295203 4.07754407 4.92226895 3.84603354 5.1542838 ]\n",
      "pred [3.93367704 5.06636282 4.34135021 4.65871295 4.05248175 4.9475357 ]\n",
      "pred [4.41024502 4.59003717 4.47083768 4.52922233 4.40591821 4.59403783]\n",
      "pred [2.340854   6.65913599 4.60590974 4.39402405 4.1678875  4.83234134]\n",
      "pred [3.27476653 5.72522397 4.42097098 4.57896467 3.91200888 5.08828054]\n",
      "pred [4.07134778 4.9287095  4.32624859 4.6737671  4.16216162 4.83793223]\n",
      "pred [4.0335088  4.96650152 4.31486274 4.68516639 4.1271382  4.87289026]\n",
      "pred [3.6019759  5.39808349 4.38867277 4.61146452 4.08473651 4.91539385]\n",
      "(296, 40) (296, 6)\n",
      "******* Feature select: LR40  Feature type: OG-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.8737495599216413\n",
      "R2 Best score (validation) val. score :  0.5143147724473812\n",
      "R2 of the best estimator (testing dataset):  0.46445536179410823\n",
      "pred [4.7215667  4.27814301 4.40146274 4.59849535 4.28470162 4.71536581]\n",
      "pred [5.29354159 3.70585477 4.48568409 4.51412406 5.15927168 3.84043138]\n",
      "pred [3.71241382 5.28781384 3.49356742 5.50652353 3.71487447 5.28508737]\n",
      "pred [3.29212791 5.7076674  4.5641299  4.43598557 6.10463854 2.89554612]\n",
      "pred [4.37372753 4.6263748  3.69081428 5.30926304 3.72527928 5.27451026]\n",
      "pred [5.27427531 3.72514764 4.66705102 4.3328991  5.67959693 3.3200377 ]\n",
      "pred [3.4714007  5.52888598 4.10146222 4.89827257 4.12245763 4.87729625]\n",
      "pred [3.96934098 5.03066305 4.33914032 4.66082861 4.58973782 4.41015381]\n",
      "pred [4.88660426 4.11361524 4.43228186 4.56786401 4.24329864 4.75690144]\n",
      "pred [4.46213734 4.53797526 4.41360429 4.58625642 3.97955485 5.0203982 ]\n",
      "pred [4.70176231 4.29834961 4.40454605 4.59541527 3.92408341 5.0758919 ]\n",
      "pred [4.32324143 4.67685221 4.51089555 4.48922231 4.07117852 4.92838784]\n",
      "pred [2.73341099 6.26668299 4.54117777 4.45908594 5.53354707 3.46670416]\n",
      "pred [3.76426484 5.23527353 3.70165344 5.297925   3.68764771 5.31260211]\n",
      "pred [4.74292352 4.25719752 4.49362027 4.5063123  4.29823341 4.70137344]\n",
      "pred [4.52377769 4.47592713 4.49501594 4.50527947 4.19030083 4.80890628]\n",
      "pred [3.47569833 5.52395651 4.5488279  4.4509623  4.68475387 4.31541119]\n",
      "pred [4.67397013 4.32627445 4.37153891 4.62854031 4.77043285 4.22955288]\n",
      "pred [3.78041064 5.21907707 3.696527   5.30294404 3.7580039  5.24229494]\n",
      "pred [5.20460222 3.79451204 4.55375147 4.44589566 3.86618169 5.13351758]\n",
      "pred [3.28055445 5.71938058 4.73118887 4.2693063  4.10557858 4.89459117]\n",
      "pred [4.32360037 4.67676263 4.68767306 4.31203397 4.78824443 4.2118481 ]\n",
      "pred [3.79219848 5.20790168 4.41748714 4.58260533 4.43889301 4.56098019]\n",
      "pred [4.2211577  4.77808783 4.41100295 4.58908378 6.16425851 2.83605678]\n",
      "pred [2.84203579 6.15818142 4.40184913 4.5980063  3.94119044 5.05829156]\n",
      "pred [4.59714466 4.40278036 4.36625899 4.63369849 4.74990355 4.24996032]\n",
      "pred [4.35866459 4.64152347 4.54042055 4.45959097 4.11811627 4.88179061]\n",
      "pred [4.83531368 4.16487245 4.5058424  4.49412091 4.06729452 4.9326776 ]\n",
      "pred [3.06247274 5.93802371 4.22646144 4.77350376 4.16753875 4.83226043]\n",
      "pred [4.16925451 4.83031205 3.39119698 5.60897242 2.98449912 6.01554849]\n",
      "pred [3.93922784 5.06102274 3.6841794  5.31577772 2.84409986 6.15614011]\n",
      "pred [3.31303517 5.68706494 4.4138542  4.58644117 4.139236   4.86072204]\n",
      "pred [4.18411864 4.81555077 3.82787754 5.17195349 3.53973363 5.46079788]\n",
      "pred [5.52582771 3.4736447  4.65013099 4.34962038 5.37766275 3.62184924]\n",
      "pred [4.01100794 4.98930658 4.6176021  4.38236182 3.32797162 5.67179929]\n",
      "pred [3.86947574 5.13005321 3.54309212 5.45667901 3.31472537 5.68539028]\n",
      "pred [2.99431681 6.00554317 4.07019728 4.92960534 3.73271914 5.26721366]\n",
      "pred [3.36546663 5.63452779 4.38179172 4.61845536 4.12341964 4.87657383]\n",
      "pred [4.49612485 4.50415043 4.52949671 4.47066667 3.84733853 5.15264389]\n",
      "pred [3.23868718 5.76141354 4.60251908 4.39758084 4.08107161 4.91874352]\n",
      "pred [4.8097697  4.18989152 4.42249447 4.57762742 5.46317202 3.5368804 ]\n",
      "pred [3.12816193 5.87168725 4.36898044 4.63071463 3.71346321 5.2864712 ]\n",
      "pred [4.54575192 4.45489255 4.46392614 4.53606296 4.88193204 4.11850317]\n",
      "pred [4.15467865 4.84561406 4.68027928 4.31967406 4.19830518 4.80154348]\n",
      "pred [3.76310218 5.23695924 4.44157839 4.55839177 4.20544406 4.79510761]\n",
      "pred [3.29290344 5.70703489 4.71554028 4.28494566 4.11435409 4.88581159]\n",
      "pred [4.48472893 4.51546634 4.29318889 4.70689046 4.1627931  4.83715653]\n",
      "pred [5.3601032  3.63932992 4.49602862 4.50374055 5.33243909 3.66722317]\n",
      "pred [4.25041001 4.74961454 4.56564679 4.43437213 4.35286159 4.64705704]\n",
      "pred [4.00837133 4.99181109 4.65674125 4.34348305 4.23943652 4.76022521]\n",
      "pred [4.90618053 4.09419939 4.50444725 4.49569728 4.48968959 4.51025849]\n",
      "pred [2.58308508 6.41700522 4.41664873 4.5833483  3.81491162 5.18463149]\n",
      "pred [4.40269751 4.59750105 4.51658129 4.48332561 4.21572039 4.78424602]\n",
      "pred [3.75121123 5.24878071 4.55258756 4.44738235 3.2977994  5.70189811]\n",
      "pred [3.06026704 5.94019007 4.07255132 4.92750834 3.9067402  5.09274691]\n",
      "pred [4.42068746 4.57940161 3.57798598 5.42205824 3.63083004 5.36925362]\n",
      "pred [4.23898374 4.76098855 4.46889031 4.53095765 4.45120807 4.5486233 ]\n",
      "pred [3.75386217 5.24560874 3.7392666  5.26000191 4.08236981 4.91808064]\n",
      "pred [2.63234893 6.36754053 4.21360486 4.78631512 3.68475615 5.31481425]\n",
      "pred [4.32328009 4.67653733 4.32918789 4.67114183 4.62160067 4.37876779]\n",
      "pred [4.30875299 4.69144508 4.45520604 4.54488525 3.99042545 5.00936883]\n",
      "pred [3.03945595 5.96039076 4.56582146 4.4338993  4.2316858  4.76837616]\n",
      "(296, 40) (296, 6)\n",
      "******* Feature select: LR40  Feature type: ST-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.9794912404204085\n",
      "R2 Best score (validation) val. score :  0.5302115960789948\n",
      "R2 of the best estimator (testing dataset):  0.29647171571085656\n",
      "pred [4.67622418 4.32333611 4.39553319 4.60453727 4.43927995 4.5609606 ]\n",
      "pred [5.26341781 3.73699851 4.63330366 4.3666542  4.57432943 4.42555942]\n",
      "pred [4.11976046 4.88046426 3.06762359 5.93178344 3.85810635 5.1417386 ]\n",
      "pred [3.42696553 5.57280964 4.50947466 4.49085656 5.7131815  3.28694798]\n",
      "pred [3.9601397  5.0401544  4.17483821 4.82519529 3.88554537 5.11477138]\n",
      "pred [5.24866856 3.75133148 4.4411579  4.55881542 5.44413213 3.55559502]\n",
      "pred [4.20946142 4.79061149 4.33928413 4.66079448 4.19985461 4.80020695]\n",
      "pred [4.03216436 4.9678033  4.30786805 4.69217227 4.13274796 4.8672534 ]\n",
      "pred [4.08804792 4.91192973 4.30663234 4.69339391 4.17887091 4.82112335]\n",
      "pred [4.087628   4.91234141 4.2527997  4.74746226 4.21374359 4.78628591]\n",
      "pred [4.26431938 4.73557399 4.3433691  4.656889   4.32443107 4.67567406]\n",
      "pred [3.98579356 5.01427888 4.33872321 4.66112506 4.07764728 4.92240485]\n",
      "pred [3.36438113 5.63555718 4.36826598 4.63182557 4.77496139 4.22526555]\n",
      "pred [3.91568715 5.08427944 4.22809199 4.77164467 4.00712435 4.99281251]\n",
      "pred [4.14102148 4.85899113 4.3317611  4.66823872 4.18426627 4.81570877]\n",
      "pred [4.07341291 4.92656672 4.30462348 4.69540964 4.16280159 4.83718321]\n",
      "pred [3.57148747 5.42828934 4.40864777 4.59134161 4.17473327 4.8252394 ]\n",
      "pred [4.53373445 4.46645578 4.44047215 4.55938389 4.77172328 4.22840455]\n",
      "pred [3.79734211 5.20278436 4.308824   4.69063629 3.97727523 5.02277337]\n",
      "pred [4.47089547 4.52892676 4.48039327 4.5196511  4.28922279 4.71106878]\n",
      "pred [4.0016902  4.99837127 4.29182882 4.70827513 3.93860872 5.06155733]\n",
      "pred [3.81780001 5.18222057 4.3493801  4.65060636 4.17959626 4.82040741]\n",
      "pred [3.80844392 5.1915571  4.49815943 4.50186569 4.65163511 4.34832194]\n",
      "pred [4.16179936 4.8383406  4.34339653 4.65659298 4.68054665 4.3193014 ]\n",
      "pred [3.23732119 5.76264097 4.40261704 4.59747638 3.97113364 5.02883386]\n",
      "pred [4.33832478 4.66153075 4.31642869 4.68358358 4.4572353  4.54295046]\n",
      "pred [3.62396123 5.37620599 4.44471209 4.55527248 3.78418642 5.21597154]\n",
      "pred [4.23844085 4.76139444 4.38611684 4.61391381 4.38228716 4.61782365]\n",
      "pred [3.36815079 5.63163381 4.2126539  4.78743502 4.10576611 4.89403167]\n",
      "pred [4.08106341 4.9189298  4.27987323 4.72005493 3.91496211 5.08494917]\n",
      "pred [4.05174664 4.94824385 4.29867358 4.70134945 4.07779322 4.92221526]\n",
      "pred [3.96963579 5.03035473 4.30950368 4.69051607 4.14838776 4.85159227]\n",
      "pred [4.90370946 4.09635304 4.01044711 4.98970868 3.76776566 5.23239051]\n",
      "pred [4.64943223 4.35065295 4.3791069  4.6208907  4.61602933 4.38385076]\n",
      "pred [4.11700873 4.88291544 4.40260465 4.59739886 4.01503508 4.98517722]\n",
      "pred [4.01209072 4.98798506 4.2639088  4.73538213 3.90017261 5.09989521]\n",
      "pred [3.57694368 5.42303263 4.35445019 4.64564501 4.07614742 4.9239352 ]\n",
      "pred [3.9928929  5.00710256 4.31417921 4.6858453  4.14218541 4.85779675]\n",
      "pred [4.42702766 4.57385218 4.41980798 4.58016962 4.43759116 4.56244612]\n",
      "pred [3.52612483 5.47384586 4.47194265 4.52769686 3.76550189 5.23446338]\n",
      "pred [5.20517765 3.79462074 4.29379184 4.70588118 5.5778063  3.42185045]\n",
      "pred [3.9931321  5.00675647 4.17091752 4.82911638 3.46275986 5.53737486]\n",
      "pred [4.83620662 4.16394976 4.42504407 4.57498217 2.8039227  6.1965121 ]\n",
      "pred [4.06549772 4.93448725 4.30666777 4.69335249 4.16531122 4.83466905]\n",
      "pred [3.71959428 5.28045972 4.31536451 4.68463629 3.85122875 5.14884544]\n",
      "pred [3.98539403 5.01467688 4.27734721 4.72276608 3.95462913 5.04560589]\n",
      "pred [4.20772894 4.7921738  4.34102921 4.65899034 4.17992046 4.82007559]\n",
      "pred [5.2832165  3.71710887 4.5266047  4.4731527  5.55020576 3.44977761]\n",
      "pred [4.04212236 4.95810371 4.38602815 4.61399569 4.40400567 4.59602738]\n",
      "pred [4.07022204 4.92975161 4.32625055 4.67374162 4.18850447 4.8114576 ]\n",
      "pred [4.16644465 4.83353162 4.3307733  4.66926223 4.2335225  4.76648794]\n",
      "pred [3.2531134  5.7468196  4.40487775 4.59529107 3.9839895  5.01599844]\n",
      "pred [3.97193244 5.02804192 4.20299586 4.796947   4.12542674 4.87450212]\n",
      "pred [4.04715835 4.95289042 4.23428592 4.76576455 3.40870577 5.59120728]\n",
      "pred [3.60124493 5.39879249 4.14546583 4.85454375 3.94000283 5.05982869]\n",
      "pred [4.0149215  4.98509204 4.32199685 4.67798609 4.09609461 4.90385509]\n",
      "pred [4.85660239 4.14409041 4.39817045 4.60190554 4.54078532 4.45944265]\n",
      "pred [3.87699851 5.12300195 4.22248259 4.77720262 3.96473574 5.03521653]\n",
      "pred [3.36732922 5.63266832 4.39845832 4.60168021 3.94121482 5.05884414]\n",
      "pred [4.29388581 4.70597351 4.29672205 4.70343191 4.35283694 4.64710209]\n",
      "pred [4.05142257 4.9485384  4.30749697 4.69250127 4.15684121 4.84309992]\n",
      "pred [3.46680228 5.53278601 4.43767885 4.56217296 3.93622985 5.06416711]\n",
      "(296, 61) (296, 6)\n",
      "******* Feature select: PCA99  Feature type: HG-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.9823351781021921\n",
      "R2 Best score (validation) val. score :  0.601410012816668\n",
      "R2 of the best estimator (testing dataset):  0.0019409485415934347\n",
      "pred [4.17232629 4.82773439 4.38398147 4.61610825 4.24264197 4.75734609]\n",
      "pred [4.1833691  4.81668597 4.38437054 4.61569873 4.2217054  4.77830492]\n",
      "pred [4.15307292 4.84698561 4.37505649 4.62502922 4.23967144 4.76032155]\n",
      "pred [4.15475636 4.84530053 4.38960248 4.6104582  4.30381643 4.696181  ]\n",
      "pred [4.19726362 4.80280572 4.33885577 4.6612219  4.23653867 4.76343628]\n",
      "pred [4.16979701 4.83027848 4.38179514 4.61829558 4.27301674 4.72697677]\n",
      "pred [4.14655072 4.85351755 4.37996792 4.62011604 4.24225165 4.75773578]\n",
      "pred [4.15656451 4.84349929 4.38042123 4.61966337 4.24318189 4.75681124]\n",
      "pred [4.15928835 4.84077545 4.38398687 4.6160922  4.2443873  4.75560884]\n",
      "pred [4.1890273  4.81103048 4.38205411 4.61802806 4.22665281 4.77334072]\n",
      "pred [4.2020344  4.79803261 4.39600991 4.6040521  4.21244033 4.78753742]\n",
      "pred [4.15602869 4.84403522 4.38137967 4.61870438 4.24239114 4.75760019]\n",
      "pred [4.13144806 4.86861825 4.3906096  4.60945132 4.28407139 4.71592693]\n",
      "pred [4.10291469 4.89713599 4.37879785 4.62127939 4.21120218 4.78878379]\n",
      "pred [4.15782604 4.84223765 4.38053408 4.61955058 4.24338171 4.75661169]\n",
      "pred [4.15715397 4.84291005 4.38069467 4.61939019 4.24295555 4.75703743]\n",
      "pred [4.15743389 4.84263067 4.38079104 4.61929356 4.24313627 4.75685729]\n",
      "pred [4.15382176 4.84623453 4.38507004 4.61501353 4.24833407 4.7516552 ]\n",
      "pred [4.10165415 4.89840054 4.38609527 4.61399078 4.20775856 4.7922121 ]\n",
      "pred [4.20573367 4.79432271 4.38395425 4.61611076 4.20206396 4.79793357]\n",
      "pred [4.14532348 4.85473804 4.38596436 4.61412391 4.23853208 4.76145284]\n",
      "pred [4.16460259 4.83545876 4.3871308  4.61295239 4.2421804  4.75780637]\n",
      "pred [4.15691314 4.84312121 4.3927397  4.60734344 4.27704277 4.72293592]\n",
      "pred [4.15737853 4.84268593 4.38071971 4.61936537 4.24509226 4.75489988]\n",
      "pred [4.11699373 4.88305898 4.37993006 4.62014935 4.22116534 4.7788252 ]\n",
      "pred [4.16325303 4.83680345 4.38080479 4.61927999 4.25699266 4.74299991]\n",
      "pred [4.15783507 4.84222881 4.38085027 4.61923448 4.24308151 4.75691142]\n",
      "pred [4.20760581 4.7924588  4.39664243 4.60342045 4.21383318 4.78614976]\n",
      "pred [4.11486287 4.8852033  4.37735373 4.62272617 4.22689925 4.77310077]\n",
      "pred [4.17442029 4.82563974 4.35274124 4.64731382 4.20125385 4.79873503]\n",
      "pred [4.15765888 4.84240535 4.38056654 4.61951806 4.24295123 4.75704172]\n",
      "pred [4.155711   4.84435281 4.38110714 4.61897584 4.23925733 4.76073802]\n",
      "pred [4.21682167 4.78324711 4.37004346 4.63003596 4.22080304 4.77916693]\n",
      "pred [4.1784029  4.82166869 4.38222756 4.61784934 4.26579571 4.73420042]\n",
      "pred [4.15461343 4.84544756 4.38443145 4.61565266 4.23249263 4.76749666]\n",
      "pred [4.12042444 4.87963614 4.35734618 4.64271573 4.19228831 4.80769741]\n",
      "pred [4.10593104 4.89412486 4.38371592 4.61637988 4.23190332 4.76808253]\n",
      "pred [4.15666867 4.84339543 4.38037304 4.61971149 4.24286247 4.7571307 ]\n",
      "pred [4.17166895 4.82838967 4.38310869 4.61697328 4.24581327 4.75417498]\n",
      "pred [4.07551446 4.92452675 4.40975759 4.5902972  4.19188059 4.80809827]\n",
      "pred [4.16720858 4.83285934 4.37780129 4.62227316 4.23182501 4.76816775]\n",
      "pred [4.12556005 4.87449817 4.38161184 4.61846458 4.22205624 4.77792987]\n",
      "pred [4.18101328 4.81907143 4.38717427 4.61290844 4.20408283 4.79591237]\n",
      "pred [4.15764617 4.84241789 4.38045028 4.61963467 4.24327272 4.75672029]\n",
      "pred [4.12657186 4.87347285 4.38640941 4.61367057 4.2146083  4.78538099]\n",
      "pred [4.14654999 4.8535111  4.3861461  4.61394071 4.2372302  4.76275442]\n",
      "pred [4.16546679 4.83459714 4.38478417 4.6152979  4.23937756 4.76061019]\n",
      "pred [4.18576571 4.81429394 4.38345443 4.61662003 4.24011835 4.75988629]\n",
      "pred [4.15667466 4.84338943 4.38047517 4.61960904 4.24318545 4.75680763]\n",
      "pred [4.15802313 4.84204056 4.38082131 4.61926305 4.24269576 4.75729749]\n",
      "pred [4.16506556 4.83500084 4.38572744 4.61435073 4.24911443 4.75087983]\n",
      "pred [4.11117555 4.88887476 4.38554083 4.61454971 4.22586561 4.77412862]\n",
      "pred [4.15944863 4.84061538 4.38370687 4.61638137 4.23957032 4.76042036]\n",
      "pred [4.14708031 4.85298143 4.38453898 4.61552142 4.19533996 4.80466309]\n",
      "pred [4.12824395 4.87181667 4.36848683 4.63159145 4.21875353 4.78122996]\n",
      "pred [4.15666482 4.84339867 4.37903953 4.62104541 4.24086396 4.75912859]\n",
      "pred [4.1623438  4.83771662 4.38704195 4.61304323 4.24753965 4.75244598]\n",
      "pred [4.11523868 4.88481464 4.37502761 4.62505542 4.23447145 4.76552263]\n",
      "pred [4.08806205 4.91198793 4.38646968 4.61362743 4.21745725 4.78251608]\n",
      "pred [4.15824257 4.84181966 4.38113001 4.61895459 4.24320146 4.7567903 ]\n",
      "pred [4.16230327 4.83776477 4.38321612 4.61686705 4.24249782 4.7574931 ]\n",
      "pred [4.1254281  4.87464642 4.38609266 4.61399465 4.24221067 4.75778175]\n",
      "(296, 39) (296, 6)\n",
      "******* Feature select: PCA99  Feature type: OG-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.9793527808342494\n",
      "R2 Best score (validation) val. score :  0.5619196811391407\n",
      "R2 of the best estimator (testing dataset):  -0.020747239632254704\n",
      "pred [4.11416577 4.88584163 4.29702778 4.70301753 4.15888758 4.84111522]\n",
      "pred [4.11416135 4.88584604 4.29702851 4.7030168  4.158881   4.84112178]\n",
      "pred [4.11415328 4.88585412 4.29702667 4.70301864 4.15887721 4.84112557]\n",
      "pred [4.11415168 4.88585572 4.29703006 4.70301524 4.15889883 4.84110395]\n",
      "pred [4.11415872 4.88584867 4.29701819 4.70302712 4.15887731 4.84112548]\n",
      "pred [4.11415469 4.88585271 4.29702699 4.70301832 4.15887867 4.84112411]\n",
      "pred [4.11415334 4.88585405 4.29702682 4.70301849 4.15887714 4.84112565]\n",
      "pred [4.11415328 4.88585411 4.29702681 4.7030185  4.15887714 4.84112565]\n",
      "pred [4.11415338 4.88585402 4.29702682 4.70301849 4.15887713 4.84112565]\n",
      "pred [4.11415908 4.88584832 4.29702885 4.70301646 4.15888039 4.84112241]\n",
      "pred [4.11416773 4.88583966 4.29702681 4.70301849 4.15889142 4.84111137]\n",
      "pred [4.1141597  4.88584769 4.29702822 4.7030171  4.15888159 4.84112119]\n",
      "pred [4.1141451  4.88586229 4.29702941 4.7030159  4.15889001 4.84111277]\n",
      "pred [4.11411046 4.88589694 4.29702507 4.70302024 4.15885173 4.84115106]\n",
      "pred [4.11415338 4.88585402 4.29702682 4.7030185  4.15887713 4.84112565]\n",
      "pred [4.11415333 4.88585407 4.29702685 4.70301846 4.15887715 4.84112564]\n",
      "pred [4.1141456  4.8858618  4.2970286  4.70301671 4.15887856 4.84112423]\n",
      "pred [4.11415342 4.88585397 4.29702683 4.70301848 4.15887718 4.84112561]\n",
      "pred [4.11412764 4.88587975 4.29703012 4.70301519 4.15886491 4.84113787]\n",
      "pred [4.11417082 4.88583658 4.29703017 4.70301514 4.15887833 4.84112446]\n",
      "pred [4.11415328 4.88585412 4.2970269  4.70301842 4.15887718 4.84112561]\n",
      "pred [4.11415348 4.88585391 4.29702686 4.70301845 4.15887728 4.8411255 ]\n",
      "pred [4.11415456 4.88585284 4.29702747 4.70301784 4.1588793  4.84112348]\n",
      "pred [4.11415338 4.88585402 4.29702682 4.7030185  4.15887715 4.84112564]\n",
      "pred [4.1141514  4.88585599 4.29702704 4.70301828 4.15887641 4.84112637]\n",
      "pred [4.11415346 4.88585394 4.29702682 4.7030185  4.15887731 4.84112547]\n",
      "pred [4.11415337 4.88585402 4.29702682 4.7030185  4.15887713 4.84112566]\n",
      "pred [4.11417546 4.88583193 4.29702917 4.70301612 4.1588972  4.84110559]\n",
      "pred [4.11415367 4.88585372 4.29702691 4.70301841 4.15887748 4.84112531]\n",
      "pred [4.11415821 4.88584918 4.29700682 4.70303849 4.15886153 4.84114126]\n",
      "pred [4.11415337 4.88585403 4.29702681 4.7030185  4.15887707 4.84112571]\n",
      "pred [4.11415337 4.88585403 4.29702682 4.7030185  4.15887713 4.84112566]\n",
      "pred [4.11415383 4.88585357 4.29702666 4.70301866 4.1588769  4.84112589]\n",
      "pred [4.11415391 4.88585348 4.2970269  4.70301842 4.15887769 4.8411251 ]\n",
      "pred [4.11415334 4.88585406 4.29702685 4.70301846 4.15887675 4.84112604]\n",
      "pred [4.11414996 4.88585744 4.29701828 4.70302704 4.15885839 4.84114441]\n",
      "pred [4.11415271 4.88585468 4.29702683 4.70301848 4.15887681 4.84112598]\n",
      "pred [4.11415335 4.88585404 4.29702682 4.70301849 4.15887711 4.84112567]\n",
      "pred [4.11415313 4.88585427 4.29702787 4.70301745 4.15887542 4.84112736]\n",
      "pred [4.11415279 4.8858546  4.29702726 4.70301805 4.15887649 4.8411263 ]\n",
      "pred [4.11415354 4.88585386 4.29702682 4.7030185  4.15887739 4.8411254 ]\n",
      "pred [4.11412159 4.88588582 4.2970274  4.70301791 4.15886185 4.84114094]\n",
      "pred [4.11415775 4.88584964 4.29702694 4.70301837 4.15886655 4.84113624]\n",
      "pred [4.11415337 4.88585403 4.29702682 4.70301849 4.15887713 4.84112566]\n",
      "pred [4.11415342 4.88585398 4.29702691 4.7030184  4.1588774  4.84112538]\n",
      "pred [4.11415327 4.88585412 4.2970269  4.70301841 4.15887718 4.8411256 ]\n",
      "pred [4.11415675 4.88585065 4.29702856 4.70301675 4.15887939 4.8411234 ]\n",
      "pred [4.1141611  4.88584629 4.29702825 4.70301707 4.15888361 4.84111918]\n",
      "pred [4.11415337 4.88585402 4.29702682 4.7030185  4.15887713 4.84112566]\n",
      "pred [4.11415335 4.88585404 4.29702686 4.70301846 4.15887716 4.84112562]\n",
      "pred [4.11415401 4.88585339 4.29702725 4.70301806 4.15887805 4.84112473]\n",
      "pred [4.11414792 4.88585947 4.29702732 4.703018   4.15887624 4.84112655]\n",
      "pred [4.1141573  4.88585012 4.29704035 4.70300496 4.15886942 4.84113338]\n",
      "pred [4.11415305 4.88585435 4.29702699 4.70301833 4.15887483 4.84112796]\n",
      "pred [4.1141203  4.88588709 4.29701498 4.70303034 4.15886091 4.84114187]\n",
      "pred [4.11415373 4.88585367 4.29702614 4.70301917 4.15887697 4.84112582]\n",
      "pred [4.11415614 4.88585125 4.2970271  4.70301821 4.15887794 4.84112485]\n",
      "pred [4.11411307 4.88589431 4.29703474 4.70301058 4.15886855 4.84113422]\n",
      "pred [4.11414986 4.88585753 4.29702729 4.70301802 4.15887646 4.84112633]\n",
      "pred [4.11415341 4.88585399 4.29702692 4.70301839 4.15887731 4.84112548]\n",
      "pred [4.11415347 4.88585392 4.29702694 4.70301837 4.15887713 4.84112566]\n",
      "pred [4.11413424 4.88587315 4.29703187 4.70301344 4.15887664 4.84112615]\n",
      "(296, 32) (296, 6)\n",
      "******* Feature select: PCA99  Feature type: ST-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.9654444492458939\n",
      "R2 Best score (validation) val. score :  0.5335784355997737\n",
      "R2 of the best estimator (testing dataset):  0.09082012651450301\n",
      "pred [4.22494204 4.77504149 4.34684481 4.65315584 4.17811186 4.82198022]\n",
      "pred [4.28851755 4.71153286 4.39805214 4.60188496 4.03544964 4.96469612]\n",
      "pred [4.14127938 4.85871826 4.31857434 4.6814398  4.10799332 4.89216837]\n",
      "pred [4.04564188 4.95435743 4.37162769 4.628362   4.35398602 4.64611088]\n",
      "pred [4.20448718 4.79562965 4.12729654 4.8726721  4.06335772 4.93683583]\n",
      "pred [4.34521925 4.65474968 4.35005254 4.64993567 4.37226934 4.62784315]\n",
      "pred [4.15406472 4.84593614 4.32839984 4.67161456 4.18057168 4.81956037]\n",
      "pred [4.11275316 4.88722097 4.3580385  4.6419506  4.15782225 4.84226274]\n",
      "pred [4.14686488 4.85313783 4.32795301 4.67205425 4.17113455 4.82898923]\n",
      "pred [3.96664326 5.03341862 4.34317607 4.65718651 4.12875681 4.87135928]\n",
      "pred [3.98492799 5.01512956 4.34616076 4.65416237 4.15044023 4.84966406]\n",
      "pred [4.14692705 4.85311167 4.33831459 4.66165837 4.14849427 4.85163057]\n",
      "pred [4.04168225 4.95831043 4.34476438 4.6552527  4.28727826 4.71284233]\n",
      "pred [3.65211335 5.34791486 4.40925047 4.59119623 4.19237381 4.80777165]\n",
      "pred [4.15416682 4.84585845 4.33550834 4.66451318 4.18688143 4.81321452]\n",
      "pred [4.17986127 4.82013254 4.31381872 4.68618964 4.16953424 4.83058199]\n",
      "pred [4.00605416 4.99395854 4.3364099  4.66361007 4.18409595 4.81610502]\n",
      "pred [4.17289486 4.82714815 4.34534076 4.65467812 4.19570529 4.80431839]\n",
      "pred [3.65536268 5.34468348 4.45072012 4.54974061 4.2313941  4.76881962]\n",
      "pred [4.26949659 4.73046036 4.34352045 4.65642181 4.08268126 4.91747418]\n",
      "pred [3.97405223 5.02593501 4.41432002 4.58564809 4.13654132 4.86356056]\n",
      "pred [4.08239754 4.91765287 4.37854763 4.62147034 4.20010759 4.80001218]\n",
      "pred [3.94163216 5.05840116 4.38340162 4.61662335 4.17594293 4.82408538]\n",
      "pred [4.14518477 4.85481605 4.3194202  4.68059059 4.17147615 4.82864981]\n",
      "pred [3.85454783 5.14554319 4.39675135 4.60338261 4.11165246 4.88849237]\n",
      "pred [4.19065172 4.80938576 4.34434313 4.65576126 4.27077885 4.72932039]\n",
      "pred [4.12045927 4.87954125 4.37489205 4.62510183 4.12269205 4.87739385]\n",
      "pred [3.98751678 5.01255319 4.34663905 4.65360521 4.14553289 4.85455587]\n",
      "pred [4.00702295 4.99295685 4.3155373  4.68448314 4.15724989 4.8428668 ]\n",
      "pred [4.15514925 4.84485711 4.27974852 4.72023755 4.04519462 4.95496718]\n",
      "pred [4.14479776 4.85520256 4.31903102 4.68097982 4.17055436 4.82957157]\n",
      "pred [4.1114287  4.88857717 4.33310456 4.66691061 4.16260013 4.8375289 ]\n",
      "pred [4.41877254 4.58119909 4.24831705 4.75169596 4.04936446 4.95085308]\n",
      "pred [4.19571269 4.80427986 4.32473372 4.67527423 4.21816092 4.78196257]\n",
      "pred [4.14373492 4.85626603 4.32769441 4.67232041 4.15487733 4.84525556]\n",
      "pred [3.66640387 5.33364644 4.43789749 4.56282744 4.16345331 4.83670496]\n",
      "pred [3.97376515 5.02630885 4.35700995 4.64302731 4.14353918 4.85660484]\n",
      "pred [4.1039398  4.89607181 4.33841949 4.66157479 4.15475159 4.84536958]\n",
      "pred [4.07514903 4.92481029 4.3449489  4.65504613 4.17606097 4.82409502]\n",
      "pred [4.12691159 4.87306888 4.47283666 4.52709833 4.15257103 4.84760068]\n",
      "pred [4.20343222 4.79658302 4.32902057 4.6709841  4.14953878 4.85059792]\n",
      "pred [3.78365316 5.21636491 4.43573385 4.56438241 4.11947253 4.88059385]\n",
      "pred [4.25606244 4.74397315 4.3334575  4.66650247 3.96181519 5.03827938]\n",
      "pred [4.14590803 4.85409211 4.32453203 4.67548316 4.17060448 4.82952127]\n",
      "pred [4.12155956 4.87843326 4.33025485 4.66977633 4.0599095  4.94027897]\n",
      "pred [3.96250534 5.03748757 4.41425754 4.58572509 4.13247802 4.86761972]\n",
      "pred [4.2108175  4.78918015 4.36239765 4.63759147 4.20107189 4.79901013]\n",
      "pred [4.35829809 4.64174177 4.39832345 4.60158859 4.18131573 4.81882191]\n",
      "pred [4.14213466 4.85787146 4.32220825 4.67780373 4.16992748 4.83020025]\n",
      "pred [4.14515618 4.85484421 4.32927782 4.67074122 4.17044931 4.82967687]\n",
      "pred [4.19671248 4.80330041 4.35377731 4.64621986 4.20393575 4.79615944]\n",
      "pred [3.91197934 5.08809145 4.38889839 4.61118495 4.10851756 4.8915923 ]\n",
      "pred [4.05151488 4.94854065 4.31808722 4.68223327 4.09699907 4.9031069 ]\n",
      "pred [4.13380321 4.86613604 4.40314719 4.59681682 3.97725189 5.02289764]\n",
      "pred [4.0451557  4.95490548 4.29935577 4.70074    4.13712098 4.86309139]\n",
      "pred [4.14135858 4.8586451  4.31862879 4.6813833  4.16727843 4.83284796]\n",
      "pred [4.1025436  4.89742447 4.34325549 4.65677845 4.19434318 4.80580237]\n",
      "pred [3.69922898 5.30080328 4.41259963 4.58770501 4.22355568 4.77659432]\n",
      "pred [3.91828002 5.08181004 4.41545679 4.58466706 4.11939937 4.8807016 ]\n",
      "pred [4.13889652 4.86110153 4.32385144 4.67614932 4.14944749 4.85068763]\n",
      "pred [4.16520531 4.83474711 4.35649499 4.64345105 4.16493715 4.835207  ]\n",
      "pred [3.89926299 5.10066443 4.41879862 4.58130096 4.1572063  4.84297929]\n",
      "(296, 183) (296, 6)\n",
      "******* Feature select: PCA9999  Feature type: HG-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.9164722990021895\n",
      "R2 Best score (validation) val. score :  0.2837067252055416\n",
      "R2 of the best estimator (testing dataset):  0.07469518632701698\n",
      "pred [4.14645631 4.85386487 4.69078719 4.30914792 3.97669185 5.02485366]\n",
      "pred [6.36037648 2.63978016 4.65069322 4.34788578 3.39213321 5.60757487]\n",
      "pred [4.88261284 4.1173837  3.63270337 5.36538435 4.04343871 4.95759876]\n",
      "pred [4.67130883 4.32815093 4.88984801 4.10952526 5.83943968 3.15938847]\n",
      "pred [5.42393624 3.57679166 3.25284337 5.74605398 2.96342724 6.03546543]\n",
      "pred [5.18317263 3.81643872 4.80793191 4.19145517 5.35023043 3.64946904]\n",
      "pred [4.607172   4.39239153 5.29227977 3.70678017 4.22690676 4.77291271]\n",
      "pred [4.83365347 4.16699311 3.91320751 5.08635768 3.90533886 5.09560517]\n",
      "pred [4.19626156 4.80511519 4.86818549 4.13184582 4.84632711 4.15374653]\n",
      "pred [5.11987393 3.88013427 4.73010186 4.26919538 4.24074951 4.75930406]\n",
      "pred [4.99184113 4.00889284 5.11019713 3.88910312 3.9489747  5.05048122]\n",
      "pred [3.53271373 5.46866821 4.39278082 4.60683775 4.40966376 4.58996676]\n",
      "pred [3.78710821 5.21331221 5.16385309 3.83597317 5.85540965 3.1431754 ]\n",
      "pred [3.65788307 5.34228394 4.52911368 4.47014042 3.11933162 5.88108208]\n",
      "pred [5.15004125 3.85112386 4.10491458 4.89577868 4.25223017 4.74749419]\n",
      "pred [3.04071979 5.96012974 5.2094022  3.78972485 2.79362106 6.20489677]\n",
      "pred [4.42073559 4.57997892 4.59981827 4.40086678 3.86196393 5.13902172]\n",
      "pred [4.00433214 4.99666526 4.65681291 4.34300289 3.89882782 5.10017913]\n",
      "pred [2.98485476 6.015492   4.56003297 4.43957897 3.31650833 5.68330243]\n",
      "pred [6.1950631  2.8057562  4.95267989 4.04654773 3.28370467 5.71567307]\n",
      "pred [4.26846246 4.7331445  4.5157622  4.48320983 3.2528307  5.74812608]\n",
      "pred [4.23455488 4.7672741  4.36350133 4.63565129 4.15793015 4.84260529]\n",
      "pred [5.46186578 3.53871168 4.27166605 4.72734075 3.89711949 5.10273197]\n",
      "pred [4.72315984 4.27707442 4.59371184 4.40545218 3.64893464 5.35053766]\n",
      "pred [2.71113378 6.28751628 5.26982715 3.72983072 3.26970438 5.72875598]\n",
      "pred [3.83020016 5.17045943 4.44785485 4.55208087 4.41314169 4.58774636]\n",
      "pred [5.25558185 3.74468021 4.58447698 4.41522427 4.04774256 4.95238803]\n",
      "pred [5.13313528 3.86739708 4.81289011 4.18610351 4.05932797 4.93999244]\n",
      "pred [3.18497026 5.81551957 4.43522405 4.56434457 3.73086423 5.26818728]\n",
      "pred [4.21667386 4.78445304 3.86599781 5.13355304 2.29362196 6.70623776]\n",
      "pred [4.31738431 4.68274929 4.02484787 4.97426416 3.19583718 5.80365244]\n",
      "pred [4.49408021 4.50632639 4.34919716 4.6504316  3.6651253  5.33501609]\n",
      "pred [5.39960407 3.60077212 3.32315622 5.67640563 3.37264968 5.62793723]\n",
      "pred [4.73858226 4.25905839 4.95771114 4.04247389 7.00183009 1.99789635]\n",
      "pred [4.37249697 4.62727354 4.77925126 4.22027034 3.28589336 5.7145101 ]\n",
      "pred [4.70829006 4.29167445 3.83054753 5.16887126 2.60953153 6.39063003]\n",
      "pred [3.06353032 5.93809446 3.81393955 5.1858269  3.71695843 5.28311573]\n",
      "pred [4.94896394 4.05098145 4.47852859 4.52063437 4.07723392 4.92267387]\n",
      "pred [4.96369051 4.03605088 5.27568391 3.72597854 3.5235805  5.47717519]\n",
      "pred [4.03849906 4.96262846 3.5859103  5.41380277 2.9762345  6.02381998]\n",
      "pred [4.48953518 4.51244389 4.86999033 4.1299401  5.33288035 3.66794985]\n",
      "pred [3.26099039 5.73948593 4.77596351 4.22346505 3.00596837 5.9941812 ]\n",
      "pred [5.22283738 3.77653251 4.65372718 4.34610041 4.55455928 4.44614868]\n",
      "pred [4.83486055 4.16485381 4.7558314  4.24387378 3.777988   5.22149719]\n",
      "pred [4.87025375 4.13156556 4.12919621 4.87085683 4.12286922 4.87736067]\n",
      "pred [4.36743858 4.63412771 4.51755624 4.48135829 3.31774577 5.6832104 ]\n",
      "pred [4.1510755  4.84913457 4.86439921 4.13504479 4.34006574 4.65995145]\n",
      "pred [6.02154662 2.97874092 4.67471825 4.32405404 3.84152233 5.15826845]\n",
      "pred [4.52801721 4.47281629 5.11659312 3.88278518 4.499778   4.50048058]\n",
      "pred [4.39596242 4.60497632 4.16576373 4.83375419 4.12544094 4.87601015]\n",
      "pred [5.08383961 3.91472567 4.86385051 4.1344634  5.4692438  3.5294367 ]\n",
      "pred [3.10812059 5.89162087 5.28289653 3.71629105 3.45305886 5.5462925 ]\n",
      "pred [4.37388167 4.62712627 5.42908744 3.57101251 4.09968438 4.90051522]\n",
      "pred [4.43482305 4.56512243 5.26328393 3.73650622 2.79832496 6.20148582]\n",
      "pred [3.63004841 5.36959491 3.66074568 5.33836206 3.0609562  5.93808236]\n",
      "pred [4.00334518 4.99680183 4.49621235 4.50353974 3.71865207 5.28112898]\n",
      "pred [4.64560281 4.35414974 4.89465823 4.10532455 4.90669739 4.09244047]\n",
      "pred [2.98281253 6.01711373 4.75468714 4.24483703 3.64339114 5.3570169 ]\n",
      "pred [3.31925793 5.68100714 4.15436199 4.84511974 3.37872744 5.62117069]\n",
      "pred [4.03439334 4.96641497 4.46943138 4.53021664 3.2088595  5.79145567]\n",
      "pred [4.45805685 4.54273037 5.13990887 3.86017088 4.44383823 4.55469163]\n",
      "pred [3.55916242 5.44086502 5.06463697 3.93470957 3.64864737 5.35141437]\n",
      "(296, 124) (296, 6)\n",
      "******* Feature select: PCA9999  Feature type: OG-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.983655320608409\n",
      "R2 Best score (validation) val. score :  0.39206213380068494\n",
      "R2 of the best estimator (testing dataset):  -0.006452287286472865\n",
      "pred [4.02960575 4.97038575 4.29597959 4.70402487 4.19586473 4.80417754]\n",
      "pred [4.04211989 4.95786723 4.29897845 4.70103576 4.18779362 4.81223593]\n",
      "pred [4.01386254 4.98612366 4.29312227 4.70688582 4.1883996  4.81163233]\n",
      "pred [4.01203852 4.98794974 4.30098234 4.69902842 4.23726135 4.76277665]\n",
      "pred [4.0160101  4.98397624 4.28994682 4.71006032 4.1864082  4.81362397]\n",
      "pred [4.02240847 4.9775755  4.29390873 4.70609919 4.20038754 4.79964489]\n",
      "pred [4.01386236 4.9861239  4.29332785 4.70668021 4.18848313 4.81154882]\n",
      "pred [4.01389709 4.98608915 4.29328907 4.70671899 4.18848808 4.81154385]\n",
      "pred [4.01385746 4.9861288  4.29335126 4.70665682 4.18845548 4.81157649]\n",
      "pred [4.03314537 4.96683971 4.29548595 4.70453171 4.19526119 4.8047706 ]\n",
      "pred [4.04217338 4.9578106  4.29956902 4.70044516 4.19621537 4.80381132]\n",
      "pred [4.01383535 4.9861509  4.29330004 4.70670802 4.18852913 4.8115028 ]\n",
      "pred [4.0031449  4.99684321 4.2987531  4.70125675 4.2220209  4.77801616]\n",
      "pred [3.98469404 5.01529254 4.2869488  4.71306074 4.17445276 4.82557621]\n",
      "pred [4.013863   4.98612323 4.29335143 4.70665665 4.18849794 4.81153402]\n",
      "pred [4.01387636 4.98610986 4.29332452 4.70668351 4.18840331 4.81162864]\n",
      "pred [4.01399872 4.98598747 4.29340087 4.70660727 4.18848196 4.81154999]\n",
      "pred [4.01384749 4.98613877 4.29333452 4.70667355 4.18848877 4.81154318]\n",
      "pred [3.9910608  5.00893709 4.29536093 4.70465287 4.18009786 4.81993347]\n",
      "pred [4.04455409 4.95543261 4.30239682 4.69761595 4.18297371 4.81706401]\n",
      "pred [4.01533819 4.98464691 4.29279415 4.7072131  4.18646582 4.81356605]\n",
      "pred [4.01380814 4.98617811 4.29330392 4.7067042  4.1884484  4.81158352]\n",
      "pred [4.0129386  4.98704866 4.29389152 4.7061168  4.18774531 4.81228729]\n",
      "pred [4.01411461 4.98587145 4.29345217 4.70655606 4.18961476 4.81041713]\n",
      "pred [4.01219555 4.98779092 4.29326969 4.70673824 4.18808416 4.81194728]\n",
      "pred [4.01890759 4.98107605 4.29354655 4.70645729 4.19619047 4.80383879]\n",
      "pred [4.01414682 4.98583951 4.29334689 4.70666129 4.18833615 4.81169581]\n",
      "pred [4.05010981 4.94986567 4.30248569 4.69751153 4.19757983 4.80244715]\n",
      "pred [4.01270924 4.98727714 4.2932868  4.70672171 4.18837417 4.81165785]\n",
      "pred [4.01878319 4.98120511 4.28226947 4.71774948 4.15894289 4.84108757]\n",
      "pred [4.01386829 4.98611797 4.29329257 4.70671547 4.18848427 4.81154768]\n",
      "pred [4.01385639 4.98612986 4.29331887 4.70668919 4.18847737 4.81155458]\n",
      "pred [4.01407557 4.98591073 4.29315116 4.70685686 4.18841124 4.81162073]\n",
      "pred [4.02035203 4.9796346  4.29415986 4.70584797 4.19562187 4.80441055]\n",
      "pred [4.0139231  4.98606325 4.29326671 4.70674122 4.18806577 4.81196605]\n",
      "pred [4.01495192 4.98503927 4.28390785 4.71610422 4.16800488 4.83202299]\n",
      "pred [4.01308606 4.98690014 4.29336903 4.7066392  4.18848043 4.81155149]\n",
      "pred [4.01390318 4.98608299 4.29324944 4.70675865 4.18832444 4.81170749]\n",
      "pred [4.01707258 4.98291334 4.29354491 4.70646429 4.18729511 4.81273766]\n",
      "pred [4.01233979 4.98764599 4.29311982 4.70688762 4.1870227  4.81300877]\n",
      "pred [4.01488081 4.98510604 4.29346862 4.70653993 4.19037323 4.80965872]\n",
      "pred [3.9889074  5.01107008 4.29183341 4.7081753  4.17537241 4.82464829]\n",
      "pred [4.04119416 4.9587986  4.29893429 4.7010683  4.16709451 4.83294276]\n",
      "pred [4.01386982 4.98611645 4.29330674 4.7067013  4.18847573 4.81155622]\n",
      "pred [4.01386726 4.98611889 4.29329302 4.70671505 4.18827845 4.8117535 ]\n",
      "pred [4.01509532 4.98488993 4.29257205 4.70743603 4.18696293 4.81306871]\n",
      "pred [4.01439573 4.98559055 4.29299764 4.70701033 4.18884823 4.81118357]\n",
      "pred [4.03766678 4.96232104 4.29592155 4.70409339 4.19615118 4.80387958]\n",
      "pred [4.01385451 4.98613175 4.2933289  4.70667915 4.18848971 4.81154224]\n",
      "pred [4.01390482 4.98608145 4.29331735 4.70669068 4.18851216 4.81151978]\n",
      "pred [4.01384136 4.98614491 4.29310379 4.70690421 4.18847017 4.81156169]\n",
      "pred [4.01194451 4.98804195 4.29337708 4.70663105 4.18828499 4.81174772]\n",
      "pred [4.01418663 4.98579962 4.29345746 4.70655057 4.18845114 4.8115809 ]\n",
      "pred [4.01386104 4.98612526 4.2931119  4.70689599 4.18782304 4.8122089 ]\n",
      "pred [4.00013555 4.99985438 4.28947301 4.71054023 4.18363725 4.81639062]\n",
      "pred [4.01385762 4.98612864 4.29332055 4.70668752 4.18848383 4.81154812]\n",
      "pred [4.01416234 4.98582398 4.29333469 4.70667351 4.18856835 4.8114637 ]\n",
      "pred [3.99266876 5.0073203  4.29243455 4.70757853 4.18483554 4.81519097]\n",
      "pred [4.01193947 4.98804758 4.2930372  4.7069723  4.18769335 4.81233926]\n",
      "pred [4.01431869 4.98566777 4.29258885 4.70741853 4.18800138 4.81203011]\n",
      "pred [4.01387906 4.9861072  4.29330383 4.70670426 4.18844745 4.8115845 ]\n",
      "pred [3.98549664 5.01447729 4.30105025 4.69894751 4.18799327 4.81203888]\n",
      "(296, 86) (296, 6)\n",
      "******* Feature select: PCA9999  Feature type: ST-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.9636205959994767\n",
      "R2 Best score (validation) val. score :  0.4768131212044825\n",
      "R2 of the best estimator (testing dataset):  0.3468196963852224\n",
      "pred [5.08479295 3.9155179  4.72567877 4.27430578 4.55619702 4.4441902 ]\n",
      "pred [4.74828721 4.25201554 4.84774399 4.15230758 4.79058063 4.20940898]\n",
      "pred [3.63353552 5.36672019 4.12106506 4.87917434 3.84811508 5.15245878]\n",
      "pred [3.44325148 5.55714679 4.78927847 4.21094664 5.66672601 3.33359947]\n",
      "pred [3.95535378 5.04546889 3.63436784 5.3654148  4.06108724 4.93954088]\n",
      "pred [4.92873597 4.07150401 4.69161638 4.30837571 5.62460569 3.37545999]\n",
      "pred [4.44789102 4.55265885 4.5971537  4.40311355 4.4753759  4.52507455]\n",
      "pred [3.90012358 5.10019452 4.53908104 4.46094672 4.20043522 4.79987619]\n",
      "pred [4.63502898 4.36527283 4.76447441 4.2357681  4.45376214 4.54653912]\n",
      "pred [4.87760616 4.12248311 4.67512254 4.32484279 4.29350176 4.70699751]\n",
      "pred [4.93255212 4.06739796 4.68450901 4.31544346 4.31998243 4.68033884]\n",
      "pred [3.96881965 5.03164595 4.70728205 4.29240021 4.0093135  4.99096134]\n",
      "pred [3.25514038 5.74501629 4.83506541 4.16496764 5.22216718 3.77825153]\n",
      "pred [2.80153871 6.19822513 4.34853681 4.6514813  3.56266171 5.43788594]\n",
      "pred [4.31023978 4.69005924 4.58147801 4.41895985 4.28235498 4.71806079]\n",
      "pred [4.28243542 4.71804303 4.3704138  4.62964896 3.91352948 5.08672319]\n",
      "pred [3.11678671 5.88361155 4.72587725 4.27422978 3.94678277 5.05392672]\n",
      "pred [4.40654581 4.59396105 4.64421583 4.3558362  4.83101376 4.16957376]\n",
      "pred [3.11807897 5.88178292 4.5415325  4.45830258 3.7806834  5.21984159]\n",
      "pred [4.85651965 4.14381843 4.77238059 4.2280292  4.06130287 4.93903763]\n",
      "pred [3.49707633 5.50292217 4.66025333 4.34000293 4.12386756 4.87653666]\n",
      "pred [4.06426992 4.93603584 4.74425569 4.25576622 4.2149019  4.78559481]\n",
      "pred [4.28149952 4.71884833 4.65461189 4.3451822  4.60541205 4.39515017]\n",
      "pred [4.60473751 4.39576604 4.22203055 4.7780933  4.5529812  4.44734663]\n",
      "pred [2.93849349 6.06176574 4.80796193 4.19233873 4.16623366 4.83439282]\n",
      "pred [4.29162362 4.70865325 4.52956127 4.47079444 4.82691805 4.1732765 ]\n",
      "pred [3.9380818  5.0620615  4.7635418  4.23629661 4.46199546 4.53833325]\n",
      "pred [4.94323257 4.05669129 4.74267126 4.25735133 4.30203841 4.69824283]\n",
      "pred [2.91684469 6.08323496 4.59894116 4.40133024 4.08856016 4.91157062]\n",
      "pred [4.21644564 4.78368752 4.15508106 4.84499007 3.66493754 5.33561768]\n",
      "pred [3.71128166 5.28876328 4.31681682 4.68357059 4.30131341 4.69875948]\n",
      "pred [3.73923635 5.2609582  4.13574303 4.86471229 4.02420286 4.97623686]\n",
      "pred [5.24842873 3.75169708 3.71043159 5.289423   3.94127077 5.05928803]\n",
      "pred [4.82780893 4.17263568 4.62319424 4.37718534 5.82079398 3.17949181]\n",
      "pred [4.01792571 4.98244023 4.43046479 4.56934159 3.62527514 5.37481985]\n",
      "pred [3.87562079 5.12449874 4.08314212 4.91682142 3.3708172  5.62975008]\n",
      "pred [2.61573831 6.38447979 4.79010739 4.20978031 4.14938695 4.85098382]\n",
      "pred [4.15630557 4.84412064 4.20502744 4.79526583 4.24551019 4.75505485]\n",
      "pred [3.62628935 5.37396651 4.48412123 4.51607489 4.21457847 4.78577487]\n",
      "pred [4.22899032 4.77150334 4.20200316 4.7984356  4.3786578  4.62169657]\n",
      "pred [4.55137817 4.44898889 4.47012096 4.53000249 4.27794465 4.72268021]\n",
      "pred [3.25244466 5.74771752 4.4360013  4.56430307 3.65731728 5.34299001]\n",
      "pred [4.19127227 4.8087756  4.56560965 4.43447085 3.99627706 5.00431191]\n",
      "pred [4.4876078  4.51261327 4.68125094 4.31887493 4.04851704 4.95194438]\n",
      "pred [4.65632289 4.34391766 4.35440155 4.64556651 4.37639064 4.62399964]\n",
      "pred [3.46981252 5.53007553 4.63961192 4.36080721 4.30236459 4.69794454]\n",
      "pred [4.55775694 4.44277258 4.32156438 4.67866294 4.3663289  4.63378564]\n",
      "pred [4.87728357 4.12294487 4.78890656 4.21129019 5.1867603  3.81335314]\n",
      "pred [4.78754342 4.21291851 4.01333583 4.98675785 4.15498348 4.84553157]\n",
      "pred [4.73025258 4.26992496 4.5412875  4.45898676 4.2753891  4.72503338]\n",
      "pred [4.14031489 4.85995001 4.71237787 4.28789929 4.15601321 4.84416132]\n",
      "pred [3.15477628 5.84517634 4.42995831 4.57010197 4.233532   4.76699079]\n",
      "pred [4.63688276 4.36314138 4.63877445 4.36144911 4.24892248 4.75167254]\n",
      "pred [4.57884521 4.4213836  4.14862633 4.8513787  3.50150544 5.49900721]\n",
      "pred [3.54232616 5.45786943 4.22735013 4.77273608 4.1771992  4.82331896]\n",
      "pred [4.3352806  4.66509488 3.79953125 5.20040544 3.97777884 5.0226773 ]\n",
      "pred [3.83199951 5.16822    4.62524131 4.37503935 4.67010919 4.33011316]\n",
      "pred [2.56505124 6.43469095 4.50568044 4.49436621 3.83894981 5.16156092]\n",
      "pred [3.14571645 5.85465274 4.56805165 4.43214946 4.13369439 4.86680828]\n",
      "pred [3.90611305 5.09411578 4.24603715 4.75400068 4.09756897 4.90279711]\n",
      "pred [4.65771569 4.34268003 4.5637526  4.4363232  4.55315644 4.44725124]\n",
      "pred [2.91470054 6.08555808 4.6611553  4.33869612 4.02126952 4.97946014]\n",
      "(296, 183) (296, 6)\n",
      "******* Feature select: FS_P  Feature type: HG-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.9791242476613652\n",
      "R2 Best score (validation) val. score :  0.5813197341340655\n",
      "R2 of the best estimator (testing dataset):  0.45672834495344844\n",
      "pred [4.55094232 4.44925106 4.63502862 4.36489944 4.14301078 4.85710277]\n",
      "pred [5.18404773 3.81634927 5.00045318 3.99987436 2.61629303 6.3838179 ]\n",
      "pred [3.52097003 5.47895883 3.95560288 5.04458835 3.88256084 5.117778  ]\n",
      "pred [3.80419813 5.19628582 4.66188571 4.33780172 5.6185275  3.38171118]\n",
      "pred [5.20172542 3.7981818  2.76383309 6.23601547 3.98601644 5.01439493]\n",
      "pred [5.32144203 3.67895816 4.72851701 4.27201686 5.3635347  3.63650765]\n",
      "pred [3.93585769 5.06450543 4.49461886 4.50520445 4.31143243 4.68877958]\n",
      "pred [3.83982551 5.16000912 4.40838309 4.59160144 4.32468194 4.67529529]\n",
      "pred [4.6704186  4.32938116 4.82276638 4.17720648 4.44939055 4.55068165]\n",
      "pred [4.75551301 4.24446843 4.13439803 4.86579033 4.18086414 4.81922194]\n",
      "pred [4.94398578 4.0559144  4.30782887 4.69221838 4.29214886 4.7078414 ]\n",
      "pred [4.94769549 4.05231838 4.53633704 4.46343905 4.47325926 4.52665084]\n",
      "pred [3.45305856 5.54715502 4.68349568 4.31595674 5.02516087 3.97520044]\n",
      "pred [2.42574737 6.57463702 4.57847795 4.42116584 4.08306879 4.91768727]\n",
      "pred [4.73576881 4.26416679 4.7137963  4.28607667 4.29437433 4.70556334]\n",
      "pred [4.27077909 4.72965975 3.97447598 5.02556251 4.35933225 4.6403979 ]\n",
      "pred [4.88501447 4.11517061 4.35424041 4.64589401 4.75755748 4.24253803]\n",
      "pred [5.05697119 3.94281792 4.43245982 4.56730433 4.64552444 4.3546657 ]\n",
      "pred [2.40721148 6.59259691 5.19317506 3.80612634 4.22170131 4.77896212]\n",
      "pred [4.60722969 4.3930577  4.93695672 4.06276779 3.72369318 5.27634621]\n",
      "pred [3.69341143 5.30669399 4.56502284 4.43507997 3.99710164 5.00308863]\n",
      "pred [5.25168257 3.74841897 4.43994573 4.56015172 4.90943326 4.09082069]\n",
      "pred [4.47108788 4.52869075 4.41720534 4.58289561 4.58363235 4.41662593]\n",
      "pred [4.09902375 4.90140986 4.40834351 4.59162559 6.21522373 2.78548459]\n",
      "pred [2.78457701 6.21546897 4.37625945 4.62398375 4.03467181 4.96583135]\n",
      "pred [4.76902958 4.2310976  4.30843742 4.69163661 4.69152046 4.30858254]\n",
      "pred [3.82353536 5.17672807 4.43472081 4.56526517 4.02298754 4.97734724]\n",
      "pred [4.92179878 4.07812623 4.34246686 4.65754413 4.37950728 4.62054763]\n",
      "pred [2.78300078 6.21704785 4.46913737 4.53093539 4.28428087 4.71588112]\n",
      "pred [4.4264911  4.57384187 3.35897127 5.64075367 3.03167289 5.96826606]\n",
      "pred [4.94229186 4.05810416 3.99993277 5.00013686 3.48671956 5.51312507]\n",
      "pred [3.82494997 5.17523619 4.66823212 4.33177186 4.02117235 4.97893399]\n",
      "pred [5.48560341 3.51427015 3.75295296 5.2470145  3.37311824 5.62739594]\n",
      "pred [5.25733807 3.74298058 4.88235749 4.11818997 5.76756386 3.23215978]\n",
      "pred [4.32385927 4.67646714 4.73824433 4.26184453 3.68115088 5.3185841 ]\n",
      "pred [2.8671731  6.13309025 4.02656928 4.97321444 3.67664053 5.32353239]\n",
      "pred [2.46844911 6.53180311 4.32677221 4.6734419  3.9054598  5.09471341]\n",
      "pred [3.70056537 5.2995212  4.59203766 4.40795192 4.2388529  4.76124578]\n",
      "pred [3.80113377 5.19902969 4.56001991 4.44019235 3.69023026 5.3096644 ]\n",
      "pred [4.12013887 4.87996301 4.80503972 4.19489783 3.87045476 5.12986419]\n",
      "pred [5.08560192 3.91508539 4.41019163 4.5898078  4.31781197 4.68268029]\n",
      "pred [3.36321991 5.63650515 4.48578465 4.51395016 3.61487846 5.38543148]\n",
      "pred [3.87997504 5.11998793 4.80858321 4.19111763 3.16409728 5.83617199]\n",
      "pred [4.78168073 4.2185786  4.77440847 4.22596043 4.31061702 4.6892659 ]\n",
      "pred [4.69130494 4.30845861 4.60296156 4.39696272 3.44172201 5.55846486]\n",
      "pred [3.73530972 5.26482064 4.70590778 4.29424066 3.89277663 5.10741762]\n",
      "pred [5.02015931 3.97980768 4.49972354 4.50036116 4.39931115 4.60070192]\n",
      "pred [5.35306134 3.64732657 4.97066809 4.02974694 3.07397401 5.92616086]\n",
      "pred [4.19331397 4.80680301 4.25860722 4.74131536 4.31702687 4.68311627]\n",
      "pred [4.55749347 4.44255493 4.7220287  4.27809928 4.41779521 4.58209599]\n",
      "pred [5.0184811  3.98145201 4.65265819 4.34748971 4.65526236 4.34476233]\n",
      "pred [2.6659231  6.33433765 4.6573317  4.34263808 4.29933957 4.70089579]\n",
      "pred [4.66501763 4.33546654 4.62793803 4.37192178 4.44167572 4.55874614]\n",
      "pred [3.81124586 5.18901924 4.83786277 4.16200064 3.12866153 5.87196329]\n",
      "pred [3.11830698 5.88197592 4.07485949 4.92501436 3.82267085 5.17769566]\n",
      "pred [3.68409705 5.31594355 3.96218559 5.0379754  3.48639643 5.51335207]\n",
      "pred [3.90206169 5.09817568 4.48825282 4.51202175 4.09194559 4.90818209]\n",
      "pred [2.05980134 6.94046827 4.45563484 4.54428769 4.53173868 4.46869263]\n",
      "pred [2.6095038  6.39072029 4.50377065 4.49643536 3.9293552  5.07087713]\n",
      "pred [4.90996082 4.09031402 4.29594851 4.70404404 4.6659099  4.33396117]\n",
      "pred [4.99289283 4.00694195 4.81628586 4.18369572 4.31443133 4.68555048]\n",
      "pred [3.13140072 5.86841729 4.52461689 4.47518168 4.12720047 4.87302809]\n",
      "(296, 91) (296, 6)\n",
      "******* Feature select: FS_P  Feature type: OG-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.9841794680034744\n",
      "R2 Best score (validation) val. score :  0.5566684388004774\n",
      "R2 of the best estimator (testing dataset):  0.27927756054489544\n",
      "pred [4.14935737 4.85064638 4.30291826 4.69708958 4.17378871 4.82617827]\n",
      "pred [5.07503057 3.92500165 4.54489653 4.45540323 3.90923075 5.09093225]\n",
      "pred [4.03995297 4.96005824 4.27615664 4.7238451  4.14201453 4.8579682 ]\n",
      "pred [3.80972002 5.19040197 4.44045836 4.55956733 5.1909363  3.80900165]\n",
      "pred [4.24270144 4.7573526  3.92408656 5.07593686 4.09070762 4.90924712]\n",
      "pred [4.91848495 4.08157085 4.42645765 4.57374779 5.2436446  3.75606442]\n",
      "pred [4.05682267 4.94318928 4.27698875 4.72301275 4.143084   4.85689803]\n",
      "pred [4.05682267 4.94318929 4.27698902 4.72301248 4.14308095 4.85690108]\n",
      "pred [4.05685302 4.94315895 4.276976   4.72302551 4.143087   4.85689503]\n",
      "pred [4.24983074 4.75007203 4.3149041  4.68510002 4.19433791 4.80566019]\n",
      "pred [4.64110906 4.35901161 4.30907108 4.69088792 4.28149421 4.71864299]\n",
      "pred [4.06628581 4.93373261 4.27938988 4.72061481 4.14919526 4.85078395]\n",
      "pred [3.75023466 5.24977556 4.360439   4.63954156 4.62101671 4.37895858]\n",
      "pred [3.31612418 5.68424776 4.24371997 4.75618368 3.90578542 5.09426206]\n",
      "pred [4.06051074 4.93950146 4.27881573 4.72118796 4.14434763 4.85563734]\n",
      "pred [4.11485306 4.88515784 4.26655495 4.73343513 4.14551667 4.85446622]\n",
      "pred [4.05018185 4.94982979 4.27839374 4.72160488 4.1443122  4.8556696 ]\n",
      "pred [4.06841663 4.93159128 4.27274224 4.72724672 4.16581046 4.83414834]\n",
      "pred [3.36718625 5.63251896 4.34822594 4.65157556 3.93841707 5.06130155]\n",
      "pred [4.17757719 4.82243502 4.33285497 4.66732584 4.06016328 4.93980658]\n",
      "pred [4.04254752 4.95745885 4.2857592  4.71424248 4.14308938 4.85687648]\n",
      "pred [4.06166897 4.9383408  4.27882922 4.7211745  4.14712213 4.85285834]\n",
      "pred [4.00533408 4.99465649 4.29087443 4.7090735  4.27464152 4.72522971]\n",
      "pred [4.04837511 4.95165897 4.27770099 4.72230075 4.22526722 4.77469264]\n",
      "pred [3.75341479 5.24659252 4.32280927 4.67717775 4.07102907 4.92891953]\n",
      "pred [4.07415474 4.92586075 4.27750604 4.72250546 4.17384018 4.826121  ]\n",
      "pred [4.03406129 4.96599904 4.30584254 4.694067   4.17109258 4.82889477]\n",
      "pred [4.70422378 4.29584537 4.39872163 4.60136182 4.2546037  4.74548   ]\n",
      "pred [3.84447943 5.15553001 4.25590348 4.74406525 4.13418476 4.8657981 ]\n",
      "pred [4.23655193 4.76349115 3.96580128 5.03429257 3.29972694 5.70025054]\n",
      "pred [4.05644455 4.94356927 4.27316795 4.72683347 4.13726966 4.86270978]\n",
      "pred [4.05682465 4.94318731 4.27698933 4.72301217 4.14308088 4.85690115]\n",
      "pred [4.36781211 4.63214478 4.18032956 4.819747   4.01588222 4.98403584]\n",
      "pred [4.73029689 4.26967918 4.3835346  4.61664549 4.79529191 4.20451441]\n",
      "pred [4.05729311 4.94272061 4.28078116 4.71921857 4.13801588 4.8619645 ]\n",
      "pred [3.71635222 5.28383969 4.05085783 4.94896964 3.53023814 5.46965702]\n",
      "pred [3.87299029 5.12707289 4.29114112 4.70888101 4.1103627  4.88959276]\n",
      "pred [4.05681336 4.9431986  4.27699248 4.72300902 4.14307744 4.85690459]\n",
      "pred [4.08625373 4.91388466 4.33561792 4.66437013 3.90128231 5.09883112]\n",
      "pred [3.91479167 5.08521311 4.35889434 4.64113057 4.06561569 4.93440042]\n",
      "pred [4.7088836  4.29090262 4.2933714  4.70666342 4.46004388 4.53994267]\n",
      "pred [3.71943076 5.28055892 4.28103719 4.71897545 3.97789167 5.02228069]\n",
      "pred [4.41752726 4.58232493 4.40922253 4.59083447 3.07332349 5.92695304]\n",
      "pred [4.05684844 4.94316353 4.27703504 4.72296646 4.14308343 4.8568986 ]\n",
      "pred [4.05468641 4.94532845 4.27703779 4.72296372 4.12013682 4.87985148]\n",
      "pred [4.04223576 4.95777025 4.28609768 4.71390392 4.14310996 4.85685602]\n",
      "pred [4.06473732 4.9352767  4.27774302 4.72225964 4.14677073 4.85321231]\n",
      "pred [5.13879446 3.86116731 4.49738852 4.50272265 4.63613331 4.36399069]\n",
      "pred [4.05683004 4.94318192 4.27698869 4.72301281 4.14308061 4.85690142]\n",
      "pred [4.05682476 4.94318845 4.27732343 4.72267761 4.14338297 4.85659927]\n",
      "pred [4.06965802 4.93035777 4.27990488 4.72009763 4.14970863 4.85027713]\n",
      "pred [3.43012698 5.56989758 4.35915523 4.64077752 4.03059212 4.96954141]\n",
      "pred [4.06423008 4.93576863 4.29514223 4.704883   4.1395226  4.86046511]\n",
      "pred [4.02538543 4.97467846 4.28898902 4.71102508 3.81759079 5.18240236]\n",
      "pred [3.5630191  5.43713629 4.12709819 4.87293652 3.93616626 5.06373416]\n",
      "pred [4.05732244 4.94268978 4.27431418 4.7256882  4.14134115 4.85863971]\n",
      "pred [4.32970458 4.67035356 4.39321996 4.60677221 4.43505725 4.56510274]\n",
      "pred [3.58129963 5.41904515 4.33352787 4.66641573 4.14056629 4.85945082]\n",
      "pred [3.56434991 5.43570642 4.36036336 4.63958808 4.02020355 4.97977416]\n",
      "pred [4.05757746 4.94243437 4.27962288 4.72037779 4.14681609 4.85316682]\n",
      "pred [4.05690441 4.94310739 4.27725298 4.72274867 4.1431362  4.85684665]\n",
      "pred [3.72355203 5.27647155 4.36505732 4.63496511 4.13849495 4.86148668]\n",
      "(296, 56) (296, 6)\n",
      "******* Feature select: FS_P  Feature type: ST-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.9840547335397339\n",
      "R2 Best score (validation) val. score :  0.5640230819807763\n",
      "R2 of the best estimator (testing dataset):  0.2772621738313725\n",
      "pred [4.67735315 4.32315193 4.41095631 4.58914681 4.38067397 4.61937917]\n",
      "pred [4.82616766 4.17411602 4.63015416 4.36953443 3.79206446 5.20809978]\n",
      "pred [4.07058107 4.9294352  4.30276155 4.6972835  4.11210463 4.88797583]\n",
      "pred [3.5193636  5.48075001 4.41327752 4.58677305 5.16857817 3.83182385]\n",
      "pred [4.27228231 4.72777167 3.94002441 5.05994635 4.16545735 4.83450409]\n",
      "pred [5.05001283 3.95016415 4.44221888 4.55764344 5.02571295 3.97482365]\n",
      "pred [4.1463017  4.85370857 4.31061572 4.68938685 4.1670426  4.83301093]\n",
      "pred [4.0207203  4.9793847  4.34144069 4.65859293 4.12106221 4.87900004]\n",
      "pred [4.14161401 4.85840112 4.29990722 4.70014015 4.1694125  4.83063878]\n",
      "pred [4.15852544 4.84091304 4.2608536  4.73855237 4.11508989 4.884924  ]\n",
      "pred [4.29869707 4.70081952 4.27275297 4.7268286  4.30462383 4.69539463]\n",
      "pred [3.96694999 5.03285197 4.40684377 4.59303979 3.98896054 5.01080896]\n",
      "pred [3.67003638 5.329883   4.4050705  4.59503898 4.56855905 4.43143205]\n",
      "pred [3.68968992 5.31017402 4.36848034 4.63125876 4.41452352 4.58536715]\n",
      "pred [4.13709591 4.86292632 4.31246032 4.68757531 4.18491607 4.81514685]\n",
      "pred [4.21287836 4.78713218 4.26841372 4.7316525  4.16376182 4.83626027]\n",
      "pred [3.9037892  5.09629502 4.33877325 4.66128959 4.19642523 4.80377998]\n",
      "pred [4.65178447 4.34826949 4.3804365  4.61970808 4.70038393 4.29943107]\n",
      "pred [3.777919   5.22216054 4.44790792 4.55177951 4.43735779 4.5627463 ]\n",
      "pred [3.68056703 5.31912888 4.4976506  4.50144894 4.39191854 4.60826299]\n",
      "pred [3.98713953 5.01283478 4.2778419  4.72219238 4.11090352 4.88910469]\n",
      "pred [4.10063945 4.89945191 4.36378568 4.63647351 4.3277616  4.67226593]\n",
      "pred [3.97680514 5.02300147 4.45275409 4.54722106 4.58195453 4.41776852]\n",
      "pred [4.18199517 4.81809298 4.32633053 4.67376354 4.29628949 4.70368641]\n",
      "pred [3.17774666 5.82252231 4.44200652 4.55800617 3.91391034 5.08589412]\n",
      "pred [4.3365022  4.66370404 4.34074027 4.65929257 4.40089689 4.5992501 ]\n",
      "pred [3.97318983 5.02689521 4.46355093 4.53638027 3.55926632 5.44066025]\n",
      "pred [4.22731387 4.77228533 4.28599629 4.71343484 4.35449904 4.64553797]\n",
      "pred [3.23194317 5.76805758 4.17570266 4.82420335 4.05499446 4.94518151]\n",
      "pred [4.13724063 4.86275257 4.16264611 4.83740544 3.93129741 5.06872793]\n",
      "pred [4.1096745  4.89035343 4.30049442 4.69954807 4.15207159 4.84797015]\n",
      "pred [3.98422442 5.01578375 4.34004578 4.66002002 4.06143616 4.93865307]\n",
      "pred [4.74432009 4.25573794 4.11665577 4.88326908 3.87618204 5.12379022]\n",
      "pred [4.44815561 4.55190296 4.35315474 4.64680243 4.5052548  4.49503611]\n",
      "pred [4.09663207 4.90343361 4.33412599 4.66586165 4.147008   4.85305684]\n",
      "pred [3.71475394 5.28522972 4.41054025 4.58911225 4.35149037 4.64870384]\n",
      "pred [3.18338988 5.81652635 4.37395908 4.62605855 4.02546778 4.97454111]\n",
      "pred [3.90514208 5.09484902 4.36864568 4.63144906 4.05806685 4.94206623]\n",
      "pred [4.67391933 4.32625399 4.42308064 4.57690589 4.26560035 4.73458968]\n",
      "pred [3.68378918 5.3160176  4.63975554 4.36049015 3.73911743 5.26068807]\n",
      "pred [4.74160748 4.2585653  4.35352837 4.64653324 4.21747802 4.78235627]\n",
      "pred [3.53683235 5.46339103 4.39618405 4.60385393 3.97562178 5.02437315]\n",
      "pred [4.79269506 4.20746689 4.36078826 4.63931681 2.85865616 6.14152071]\n",
      "pred [4.11655245 4.88349123 4.3270288  4.67299809 4.15793255 4.84211204]\n",
      "pred [3.92650867 5.07350935 4.32323417 4.67680598 3.96521802 5.03486229]\n",
      "pred [3.98480793 5.01516635 4.28065771 4.71937729 4.11052772 4.88947836]\n",
      "pred [4.24799171 4.7519963  4.3306632  4.66943342 4.19380023 4.80628238]\n",
      "pred [4.96970879 4.03061571 4.58091202 4.41916621 4.2812831  4.71894141]\n",
      "pred [4.11016356 4.88986201 4.29626386 4.70380216 4.16736411 4.83267929]\n",
      "pred [4.11653842 4.88351831 4.34220699 4.65781957 4.16402335 4.83603551]\n",
      "pred [4.31861832 4.68143844 4.33892429 4.66120475 4.23988918 4.76019873]\n",
      "pred [3.28818807 5.71189621 4.47764822 4.5224106  4.02286408 4.97719456]\n",
      "pred [3.91905479 5.0804222  4.22424259 4.77479415 3.98380655 5.01619813]\n",
      "pred [4.05642788 4.94353394 4.34421405 4.65577376 3.67423319 5.32567547]\n",
      "pred [3.63281881 5.36697611 4.12039124 4.87955986 3.89457577 5.1051996 ]\n",
      "pred [4.04469021 4.95535072 4.32752235 4.67255132 4.11346549 4.88656482]\n",
      "pred [4.80594833 4.1942056  4.38009382 4.61995441 4.43151377 4.56851194]\n",
      "pred [3.77707359 5.22288937 4.37147452 4.62831331 4.31141033 4.68852212]\n",
      "pred [3.1182557  5.88180958 4.53004683 4.46995263 3.85760968 5.14238149]\n",
      "pred [4.20087837 4.79910416 4.2817887  4.71825362 4.12499772 4.87509492]\n",
      "pred [4.13985377 4.86011244 4.35298162 4.64707145 4.16192516 4.83811038]\n",
      "pred [3.4806386  5.51952266 4.48587152 4.51409296 4.15246393 4.84737406]\n",
      "(296, 296) (296, 6)\n",
      "******* Feature select: FS_K  Feature type: HG-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.9831510086419285\n",
      "R2 Best score (validation) val. score :  0.6425461355356434\n",
      "R2 of the best estimator (testing dataset):  0.4717862127727533\n",
      "pred [4.55546277 4.4448933  4.54681898 4.45325005 4.33424832 4.665863  ]\n",
      "pred [5.39935679 3.6011876  4.55979347 4.44056722 3.0297253  5.9702474 ]\n",
      "pred [3.650019   5.35003242 4.09435283 4.9054811  3.82551985 5.17444177]\n",
      "pred [3.81963147 5.18044211 4.43649055 4.56334704 5.29494335 3.70515952]\n",
      "pred [4.81389632 4.18627383 3.24793503 5.75256536 3.93033961 5.0691744 ]\n",
      "pred [5.23698505 3.76296957 4.42689951 4.57265257 5.56581207 3.43403687]\n",
      "pred [4.18096668 4.81923873 4.42664167 4.57339141 4.28058618 4.71941298]\n",
      "pred [4.08689467 4.91314709 4.37780371 4.62220053 4.24716993 4.75288478]\n",
      "pred [4.27399424 4.72606626 4.40289458 4.59707149 4.27354569 4.72652539]\n",
      "pred [4.46073412 4.53958108 4.27775752 4.72227937 4.17804166 4.82182123]\n",
      "pred [4.78370083 4.21634364 4.32014602 4.67980316 4.27520242 4.72464889]\n",
      "pred [4.32004747 4.67999734 4.37215532 4.6278648  4.28079608 4.71928614]\n",
      "pred [3.60951406 5.39024581 4.4500035  4.54997276 4.93553775 4.06472047]\n",
      "pred [2.71304909 6.28709209 4.57045754 4.42965245 3.95986358 5.04012797]\n",
      "pred [4.34745653 4.65268768 4.42499789 4.57493151 4.2706627  4.7293524 ]\n",
      "pred [4.14464474 4.85524873 4.25496078 4.74489854 4.27448857 4.72553808]\n",
      "pred [4.22348437 4.77660189 4.3864353  4.61355713 4.29941623 4.70065718]\n",
      "pred [4.63084009 4.36946664 4.41663674 4.5834598  4.55611748 4.44381541]\n",
      "pred [2.8567385  6.14322179 4.87135297 4.12874275 4.12276471 4.87756879]\n",
      "pred [4.40939348 4.59240792 4.76507867 4.23567708 3.42977468 5.57005163]\n",
      "pred [3.54119758 5.45887456 4.63120375 4.369152   4.07649647 4.92319281]\n",
      "pred [4.38701287 4.6130779  4.38914927 4.61083317 4.45648944 4.54363459]\n",
      "pred [4.27408717 4.72599846 4.41937992 4.58091142 4.58597767 4.41436727]\n",
      "pred [4.20802191 4.79210715 4.39240215 4.60751312 4.83785679 4.16217738]\n",
      "pred [3.0221343  5.97780868 4.48252604 4.51768266 4.05843319 4.94191576]\n",
      "pred [4.35879792 4.64102297 4.35921203 4.64077591 4.43725669 4.56270693]\n",
      "pred [4.14456483 4.85571665 4.39791276 4.60214313 4.41547722 4.58424989]\n",
      "pred [4.81003022 4.19005516 4.30972545 4.69025505 4.29578974 4.70411785]\n",
      "pred [2.93541036 6.06480519 4.23669981 4.76336682 4.20427027 4.79567838]\n",
      "pred [4.35848242 4.6413037  3.37558623 5.62481003 3.32753965 5.67234195]\n",
      "pred [4.23223548 4.7678405  4.31501886 4.68487436 3.70273607 5.29751356]\n",
      "pred [4.07158789 4.92843594 4.3949464  4.60502331 4.2237185  4.77634764]\n",
      "pred [5.26495502 3.73497076 3.93940867 5.06090723 3.56230534 5.43767858]\n",
      "pred [5.15111317 3.84897041 4.47293377 4.52651174 5.58641106 3.41336839]\n",
      "pred [4.24002086 4.75984636 4.45307398 4.54674615 3.94389924 5.05609001]\n",
      "pred [3.13731192 5.86271874 4.16801161 4.83194995 3.66831616 5.33148718]\n",
      "pred [2.97563486 6.02423928 4.39259365 4.60759212 4.01228971 4.98790535]\n",
      "pred [4.00758656 4.9924361  4.40615459 4.59380117 4.25111798 4.74895326]\n",
      "pred [3.65265184 5.34715089 4.47615539 4.52415758 3.77949674 5.2204804 ]\n",
      "pred [4.05833685 4.94174437 4.790074   4.20956139 3.96579361 5.03432472]\n",
      "pred [5.00805688 3.9922513  4.21863113 4.78169887 4.29150489 4.70863839]\n",
      "pred [3.22015679 5.7794784  4.47886666 4.52110337 3.78361028 5.21631312]\n",
      "pred [4.0301912  4.97059263 4.48281409 4.51765599 3.25535907 5.74476081]\n",
      "pred [4.23698862 4.76309636 4.43304502 4.56696809 4.24498335 4.75503317]\n",
      "pred [4.22007202 4.78015763 4.47522356 4.52466226 3.82008215 5.17991994]\n",
      "pred [3.53593264 5.46412641 4.67608153 4.32426974 4.04244837 4.9572858 ]\n",
      "pred [4.42324777 4.57677117 4.41204479 4.58785103 4.2863436  4.71382617]\n",
      "pred [5.48529352 3.51506958 4.51797574 4.48217788 3.88559834 5.11443685]\n",
      "pred [4.21294224 4.78714036 4.34399705 4.6560091  4.24635127 4.75370392]\n",
      "pred [4.21939751 4.78071137 4.44930581 4.55079248 4.27289159 4.72710389]\n",
      "pred [4.42653472 4.57348915 4.43435031 4.56554076 4.33486544 4.66527301]\n",
      "pred [2.86117037 6.13906824 4.68302002 4.31700799 4.23619121 4.7641833 ]\n",
      "pred [4.36998487 4.6304317  4.51688228 4.48326225 4.25292193 4.74728171]\n",
      "pred [3.53980688 5.46017601 4.63571863 4.36423899 3.15464532 5.84533152]\n",
      "pred [3.30804494 5.691711   4.05879479 4.94141043 3.82965233 5.17050463]\n",
      "pred [3.72228027 5.27754671 4.14592185 4.85392278 3.64747161 5.35248388]\n",
      "pred [4.16311059 4.83677857 4.50037038 4.50000296 4.30030685 4.69953761]\n",
      "pred [2.69385691 6.30642432 4.59524258 4.40488732 4.33144057 4.66840722]\n",
      "pred [2.96678489 6.03321499 4.55456999 4.44544138 3.95291183 5.0473423 ]\n",
      "pred [4.23347322 4.76657023 4.39353674 4.60647516 4.31760877 4.68243392]\n",
      "pred [4.35490642 4.64520105 4.47354864 4.52646611 4.26377082 4.73625399]\n",
      "pred [3.12932809 5.87039654 4.55429381 4.44603832 4.13241485 4.86781882]\n",
      "(296, 151) (296, 6)\n",
      "******* Feature select: FS_K  Feature type: OG-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.9828329014903289\n",
      "R2 Best score (validation) val. score :  0.6184270547055782\n",
      "R2 of the best estimator (testing dataset):  0.3867272074922474\n",
      "pred [4.32584811 4.67408651 4.38295769 4.61714213 4.20312564 4.79676316]\n",
      "pred [5.31424606 3.6857705  4.55334666 4.44649177 3.95246173 5.04762037]\n",
      "pred [4.0185168  4.98149992 4.24087109 4.75914769 4.12137538 4.87863002]\n",
      "pred [3.69734206 5.30252993 4.50344867 4.49686222 5.50793999 3.49223904]\n",
      "pred [4.50192884 4.4981215  3.51906375 5.48133875 3.97246181 5.02788197]\n",
      "pred [5.04801836 3.95181125 4.40872837 4.59139406 5.63977843 3.36008132]\n",
      "pred [4.09052725 4.90948294 4.29585041 4.70418305 4.15843489 4.84160268]\n",
      "pred [4.08276981 4.91724288 4.29638768 4.70364537 4.15818214 4.84185457]\n",
      "pred [4.09403954 4.90596837 4.29464763 4.70538699 4.15926496 4.8407722 ]\n",
      "pred [4.43120882 4.56886625 4.34517188 4.6547082  4.22962054 4.77044655]\n",
      "pred [4.83390489 4.16608    4.34092161 4.65900526 4.3329387  4.66710488]\n",
      "pred [4.14228174 4.85776152 4.3076339  4.6924378  4.19295625 4.80708977]\n",
      "pred [3.46803414 5.5319378  4.44214688 4.55799743 4.91112456 4.08912872]\n",
      "pred [3.13616249 5.86384092 4.45228562 4.54762126 4.05547587 4.94436327]\n",
      "pred [4.15249493 4.84751908 4.32681677 4.67322092 4.17863422 4.82134892]\n",
      "pred [4.35188261 4.64805334 4.25869429 4.74135366 4.18016818 4.81981657]\n",
      "pred [3.9957041  5.00430804 4.31815431 4.68189003 4.17890247 4.82116354]\n",
      "pred [4.1538116  4.84622053 4.25912524 4.74088921 4.25782716 4.742196  ]\n",
      "pred [3.21140968 5.78842257 4.56188924 4.43771254 4.01490071 4.98484148]\n",
      "pred [4.33183535 4.66823834 4.4179569  4.58214394 3.97187475 5.02817427]\n",
      "pred [4.01380772 4.9862033  4.34378428 4.65626168 4.15255193 4.84749921]\n",
      "pred [4.13878305 4.86121937 4.31558319 4.68443311 4.20807804 4.79199196]\n",
      "pred [3.93098857 5.06909852 4.306094   4.69394674 4.33169195 4.66830435]\n",
      "pred [4.07565749 4.92435763 4.29687102 4.70316326 4.2290346  4.77097802]\n",
      "pred [3.45068832 5.54930869 4.41137259 4.58835227 3.99889498 5.00121778]\n",
      "pred [4.16601479 4.83399397 4.29573062 4.70430262 4.30261295 4.69731777]\n",
      "pred [4.0201273  4.98006759 4.35423261 4.64587562 4.21332352 4.78671452]\n",
      "pred [4.89055666 4.10936742 4.44478593 4.55498322 4.28066151 4.71933181]\n",
      "pred [3.4605266  5.53919488 4.22955342 4.77045711 4.12828563 4.87160557]\n",
      "pred [4.27931969 4.72098106 3.98565169 5.0143598  3.10013919 5.89957661]\n",
      "pred [4.08978705 4.91025407 4.24134093 4.75869311 4.05421415 4.94580625]\n",
      "pred [4.08894681 4.91106324 4.29607624 4.70395691 4.15805446 4.84198257]\n",
      "pred [4.86812928 4.13181465 4.04476628 4.95530722 3.83582418 5.16421283]\n",
      "pred [4.77804548 4.22173524 4.3934483  4.60665597 5.16098881 3.83918756]\n",
      "pred [4.08575587 4.91420046 4.32131054 4.678691   4.06361613 4.93640227]\n",
      "pred [3.616954   5.38272393 4.15865533 4.8410869  3.4226708  5.57724991]\n",
      "pred [3.43421604 5.56570806 4.33297934 4.66695926 4.01775994 4.98238755]\n",
      "pred [4.08621299 4.91379728 4.29693006 4.70310286 4.15733118 4.8427064 ]\n",
      "pred [4.16337472 4.83654812 4.42103066 4.57899898 3.50960154 5.49013569]\n",
      "pred [3.78366788 5.21633905 4.38358836 4.61621617 4.00792233 4.99219673]\n",
      "pred [4.69924966 4.30085558 4.30694632 4.69309874 4.64784698 4.35203932]\n",
      "pred [3.5331419  5.46663264 4.26210252 4.73793015 3.8285619  5.17149893]\n",
      "pred [4.57181876 4.42840383 4.42136248 4.57877842 2.84366161 6.15628228]\n",
      "pred [4.09131845 4.90869016 4.29869499 4.70134099 4.15868451 4.84135243]\n",
      "pred [4.05555138 4.94447479 4.30039963 4.69962904 3.96960559 5.0304756 ]\n",
      "pred [4.01345821 4.98655275 4.34406125 4.65598448 4.15263014 4.84742089]\n",
      "pred [4.17357318 4.82641528 4.30452458 4.69551164 4.1845361  4.81549372]\n",
      "pred [5.35889731 3.64108678 4.49819679 4.50169598 4.89885185 4.10117929]\n",
      "pred [4.0901092  4.90990075 4.2956983  4.70433494 4.15792621 4.84211056]\n",
      "pred [4.08912919 4.91089187 4.30416994 4.69587555 4.1647582  4.83527925]\n",
      "pred [4.21168592 4.78830383 4.31783797 4.68219547 4.21000755 4.7900254 ]\n",
      "pred [3.21208271 5.78795196 4.42431482 4.57538951 4.0057544  4.99439596]\n",
      "pred [4.15144517 4.84858472 4.37490931 4.62502898 4.14166439 4.85836531]\n",
      "pred [3.94869055 5.05119037 4.30598759 4.69389136 3.4143249  5.58578846]\n",
      "pred [3.37522755 5.62469267 4.07986254 4.91961473 3.86899464 5.13101424]\n",
      "pred [4.17314332 4.82680733 4.1142118  4.88579107 4.09804732 4.90197641]\n",
      "pred [4.47071544 4.52941945 4.43140203 4.56868666 4.52315858 4.4770953 ]\n",
      "pred [3.48622299 5.51416218 4.4795291  4.52023571 4.25715966 4.7426782 ]\n",
      "pred [3.15792972 5.84189312 4.44048692 4.55922039 3.89475178 5.10522289]\n",
      "pred [4.0879985  4.91202605 4.31954714 4.68050177 4.19056797 4.80947718]\n",
      "pred [4.09563954 4.90435261 4.30385693 4.69617337 4.15789525 4.84213848]\n",
      "pred [3.44252234 5.55744162 4.45490946 4.54508697 4.11277703 4.88726042]\n",
      "(296, 87) (296, 6)\n",
      "******* Feature select: FS_K  Feature type: ST-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.9841702657046115\n",
      "R2 Best score (validation) val. score :  0.55664110781279\n",
      "R2 of the best estimator (testing dataset):  0.3418926480773666\n",
      "pred [4.79941517 4.2007712  4.43648245 4.56300162 4.42051847 4.57999537]\n",
      "pred [5.03441547 3.96577992 4.58310637 4.41654356 3.6947829  5.30544888]\n",
      "pred [3.99477741 5.0054108  4.32945982 4.67058712 4.00852339 4.99155059]\n",
      "pred [3.347674   5.65240603 4.43450467 4.5657084  5.23673754 3.76365202]\n",
      "pred [4.3819657  4.61836939 3.73819553 5.26193462 4.17603467 4.82406404]\n",
      "pred [4.99861743 4.00132552 4.42792505 4.57217214 4.96867429 4.03163529]\n",
      "pred [4.30832773 4.69166239 4.36057542 4.63941266 4.20718332 4.79290775]\n",
      "pred [4.04518003 4.95483572 4.3889721  4.6110364  4.15742702 4.84254555]\n",
      "pred [4.25502173 4.74501427 4.32284639 4.67715922 4.22316072 4.77694405]\n",
      "pred [4.37249494 4.627463   4.30080424 4.69953278 4.19859612 4.80162349]\n",
      "pred [4.51172179 4.48823056 4.33665992 4.66353754 4.36475504 4.63510534]\n",
      "pred [3.94945353 5.05037355 4.44575187 4.55421494 3.9432516  5.05645936]\n",
      "pred [3.75840344 5.24152686 4.41838255 4.58200251 4.40728508 4.59271355]\n",
      "pred [3.5493792  5.45052738 4.31479653 4.6846714  4.21137197 4.78883402]\n",
      "pred [4.21737218 4.78265787 4.34664371 4.6533429  4.21411213 4.7860125 ]\n",
      "pred [4.27513851 4.72485898 4.28234745 4.7176476  4.19713132 4.80285619]\n",
      "pred [3.77150529 5.22855646 4.40817961 4.59183062 4.28194273 4.71799987]\n",
      "pred [4.59520887 4.40439488 4.43028782 4.57011709 4.75088123 4.24927852]\n",
      "pred [3.70573952 5.29400289 4.36325663 4.63617312 4.01401758 4.98625646]\n",
      "pred [3.93912243 5.06077978 4.43307398 4.56629546 4.11952842 4.88068831]\n",
      "pred [3.93040267 5.06972495 4.26817505 4.73196352 4.09909379 4.90081722]\n",
      "pred [4.04495561 4.95521787 4.46736723 4.53278406 4.39799632 4.60194934]\n",
      "pred [3.83687043 5.16288318 4.54208811 4.4583139  4.62151824 4.37866792]\n",
      "pred [4.26795175 4.73210698 4.35433929 4.64572255 4.26659286 4.73350889]\n",
      "pred [3.09720321 5.90299264 4.54094518 4.45914116 3.88697438 5.11293138]\n",
      "pred [4.55283164 4.44727768 4.37939284 4.62061587 4.54862879 4.45129684]\n",
      "pred [3.90654426 5.09348807 4.50118227 4.49876371 3.71304573 5.28682722]\n",
      "pred [4.43539002 4.56436257 4.35477809 4.64521178 4.4085571  4.59115065]\n",
      "pred [3.15527482 5.84502884 4.14891437 4.85096149 4.04436463 4.95566902]\n",
      "pred [4.16225306 4.83787004 4.06298287 4.93701278 3.87292617 5.12705771]\n",
      "pred [4.16891456 4.83112679 4.32391601 4.67613956 4.13489428 4.8651615 ]\n",
      "pred [4.0364704  4.96360716 4.34594538 4.65406896 4.01620065 4.98387685]\n",
      "pred [5.09607978 3.90389548 4.0660568  4.93363598 3.87513746 5.12476138]\n",
      "pred [4.43707658 4.56292149 4.34867272 4.6513836  4.45057727 4.54957568]\n",
      "pred [4.10434234 4.89561951 4.42891882 4.57109718 4.16197591 4.83813014]\n",
      "pred [3.65486684 5.34486114 4.3140527  4.68538752 3.87290016 5.12724512]\n",
      "pred [3.12960883 5.8704313  4.43407652 4.56599963 4.10105607 4.89876947]\n",
      "pred [3.947655   5.05240628 4.38862475 4.61137962 4.009842   4.99023223]\n",
      "pred [4.85024223 4.15008742 4.42476753 4.57565471 4.31596261 4.68375241]\n",
      "pred [3.11783873 5.88242966 5.06505851 3.93495901 3.5450857  5.45505577]\n",
      "pred [4.70894755 4.29107978 4.36809105 4.63189612 4.3702319  4.62985695]\n",
      "pred [3.36345404 5.63645423 4.47265341 4.52708932 3.93381565 5.0660415 ]\n",
      "pred [4.77411685 4.22550341 4.38038536 4.62018512 2.82071565 6.17940529]\n",
      "pred [4.17411526 4.82595379 4.3621696  4.63790874 4.1817775  4.81828581]\n",
      "pred [3.90583626 5.09425904 4.38464952 4.61540459 3.90782351 5.09224476]\n",
      "pred [3.92621441 5.07391008 4.27153107 4.72860924 4.09888574 4.90102995]\n",
      "pred [4.34275258 4.65735719 4.34651008 4.6535002  4.21379754 4.78632927]\n",
      "pred [5.06348161 3.93667167 4.57238237 4.42738427 4.2625279  4.7377004 ]\n",
      "pred [4.11986054 4.88018384 4.29597754 4.7041361  4.21230986 4.78776158]\n",
      "pred [4.1646564  4.83545269 4.36905324 4.63106065 4.19215341 4.80793907]\n",
      "pred [4.42972301 4.57035833 4.35549907 4.64453602 4.3086536  4.69150605]\n",
      "pred [3.21256476 5.78742718 4.58333079 4.41678777 4.01394127 4.98612709]\n",
      "pred [4.05018379 4.94947349 4.20397211 4.7960198  3.97506884 5.02538898]\n",
      "pred [3.93020915 5.06977836 4.51915545 4.48047281 3.38509013 5.61496625]\n",
      "pred [3.50363264 5.496477   4.08586357 4.91427321 3.85054713 5.14957559]\n",
      "pred [3.99973823 5.00039167 4.39452371 4.60556473 4.05321996 4.94677534]\n",
      "pred [4.89057038 4.10962388 4.3989065  4.60138637 4.35465606 4.64505552]\n",
      "pred [3.65812865 5.34175788 4.31451896 4.68496831 4.09720254 4.90313818]\n",
      "pred [3.12593118 5.87423247 4.63796257 4.3621801  3.83336131 5.16668864]\n",
      "pred [4.36147105 4.63857929 4.21969355 4.78040542 4.09265769 4.90717165]\n",
      "pred [4.14566656 4.8543766  4.38134645 4.61872126 4.18523019 4.81470108]\n",
      "pred [3.30468959 5.69544247 4.57192899 4.42803537 4.20669862 4.79316701]\n"
     ]
    }
   ],
   "source": [
    "ft_type=['HG-F', 'OG-F', 'ST-F']#['HG']#'OG', 'OGQ', 'OGSM', 'OGET']#,'DG','HG']\n",
    "\n",
    "ft_select=['all','PCA999','LR10','FS_S','RF', 'LR20', 'LR30', \n",
    "    'LR40','PCA99','PCA9999','FS_P','FS_K']\n",
    "\n",
    "dir_path = '../datasets/results/regression/ianuarie2025/'\n",
    "\n",
    "regression_types = ['rfr','gbr', 'svr']\n",
    "\n",
    "regression_tuning(dir_path, ft_type, ft_select, regression_types, \n",
    "                  feature_path='../datasets/results/features/ianuarie2025-v2/',\n",
    "                  ranks_path='../datasets/results/ranks/runTime_1min_sa_ts_agregated_filtered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian optimization for all representations, feature types and regression models\n",
    "ft_type=['HG-F', 'OG-F', 'ST-F']#['HG']#'OG', 'OGQ', 'OGSM', 'OGET']#,'DG','HG']\n",
    "\n",
    "ft_select=['all','PCA999','LR10','FS_S','RF', 'LR20', 'LR30', \n",
    "    'LR40','PCA99','PCA9999','FS_P','FS_K']\n",
    "\n",
    "dir_path = '../datasets/results/regression/ianuarie2025/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regression_type rfr\n",
      "******* Feature select: all  Feature type: HG-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8763847041516848\n",
      "R2 Best score (validation) val. score :  0.591721535445921\n",
      "R2 of the best estimator (testing dataset):  0.43311344405741536\n",
      "Selected metaheuristics: ['SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'TSL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: all  Feature type: OG-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.853359360414084\n",
      "R2 Best score (validation) val. score :  0.5720293506648341\n",
      "R2 of the best estimator (testing dataset):  0.43349002181060126\n",
      "Selected metaheuristics: ['TSL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Si-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: all  Feature type: ST-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8465170387821748\n",
      "R2 Best score (validation) val. score :  0.571293168032053\n",
      "R2 of the best estimator (testing dataset):  0.39877231585640416\n",
      "Selected metaheuristics: ['TSL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SA-Ei-LM', 'SA-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: PCA999  Feature type: HG-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8286406068590444\n",
      "R2 Best score (validation) val. score :  0.43056911981418616\n",
      "R2 of the best estimator (testing dataset):  0.14489681093846526\n",
      "Selected metaheuristics: ['SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: PCA999  Feature type: OG-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.829491984816332\n",
      "R2 Best score (validation) val. score :  0.44557812737429253\n",
      "R2 of the best estimator (testing dataset):  0.09958681777945366\n",
      "Selected metaheuristics: ['SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: PCA999  Feature type: ST-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8061132540332039\n",
      "R2 Best score (validation) val. score :  0.38235901444561604\n",
      "R2 of the best estimator (testing dataset):  0.1722914605317794\n",
      "Selected metaheuristics: ['SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: LR10  Feature type: HG-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.754865148229763\n",
      "R2 Best score (validation) val. score :  0.4626882323484721\n",
      "R2 of the best estimator (testing dataset):  0.40827474579202794\n",
      "Selected metaheuristics: ['SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TSL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: LR10  Feature type: OG-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.7872637618561995\n",
      "R2 Best score (validation) val. score :  0.5094466609869396\n",
      "R2 of the best estimator (testing dataset):  0.18919175690640605\n",
      "Selected metaheuristics: ['TSL-Ei-LM', 'TS-Si-LM', 'TSL-Ei-LM', 'SAL-Si-LM', 'TSL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'TSL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: LR10  Feature type: ST-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.7774989729991315\n",
      "R2 Best score (validation) val. score :  0.49713015052282017\n",
      "R2 of the best estimator (testing dataset):  0.4224233957715195\n",
      "Selected metaheuristics: ['TSL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'TSL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'TSL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'TS-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: FS_S  Feature type: HG-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8668773720255712\n",
      "R2 Best score (validation) val. score :  0.584157250093002\n",
      "R2 of the best estimator (testing dataset):  0.4331377764060158\n",
      "Selected metaheuristics: ['SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'TSL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: FS_S  Feature type: OG-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8430246474961218\n",
      "R2 Best score (validation) val. score :  0.5607057438446592\n",
      "R2 of the best estimator (testing dataset):  0.40911075370710054\n",
      "Selected metaheuristics: ['SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: FS_S  Feature type: ST-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8347670486901604\n",
      "R2 Best score (validation) val. score :  0.5517788691592532\n",
      "R2 of the best estimator (testing dataset):  0.4152903787591995\n",
      "Selected metaheuristics: ['TSL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: RF  Feature type: HG-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.7822161734899786\n",
      "R2 Best score (validation) val. score :  0.5179805086914948\n",
      "R2 of the best estimator (testing dataset):  0.36474838478877425\n",
      "Selected metaheuristics: ['SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'TSL-Ei-LM', 'TSL-Si-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'TSL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: RF  Feature type: OG-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8085955568455028\n",
      "R2 Best score (validation) val. score :  0.5307084265576058\n",
      "R2 of the best estimator (testing dataset):  0.36125176569741985\n",
      "Selected metaheuristics: ['SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'TSL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: RF  Feature type: ST-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.7946683933455952\n",
      "R2 Best score (validation) val. score :  0.5190428247316011\n",
      "R2 of the best estimator (testing dataset):  0.38617866410204305\n",
      "Selected metaheuristics: ['TSL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'TS-Si-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: LR20  Feature type: HG-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.7999414733724944\n",
      "R2 Best score (validation) val. score :  0.515075446715836\n",
      "R2 of the best estimator (testing dataset):  0.4234639203057123\n",
      "Selected metaheuristics: ['TSL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: LR20  Feature type: OG-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.7996290637863105\n",
      "R2 Best score (validation) val. score :  0.5245996120242955\n",
      "R2 of the best estimator (testing dataset):  0.37760649921249\n",
      "Selected metaheuristics: ['SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: LR20  Feature type: ST-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8032736395725217\n",
      "R2 Best score (validation) val. score :  0.5227878847981329\n",
      "R2 of the best estimator (testing dataset):  0.4078057028755556\n",
      "Selected metaheuristics: ['TSL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'TSL-Ei-LM', 'TSL-Si-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'TSL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: LR30  Feature type: HG-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8169644194726116\n",
      "R2 Best score (validation) val. score :  0.525929681071948\n",
      "R2 of the best estimator (testing dataset):  0.44329969332762703\n",
      "Selected metaheuristics: ['SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TSL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: LR30  Feature type: OG-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8086711528478242\n",
      "R2 Best score (validation) val. score :  0.5345375146970162\n",
      "R2 of the best estimator (testing dataset):  0.3541014991704048\n",
      "Selected metaheuristics: ['TSL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'TSL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'TSL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: LR30  Feature type: ST-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.812596298496272\n",
      "R2 Best score (validation) val. score :  0.5182658464291213\n",
      "R2 of the best estimator (testing dataset):  0.3911385394928396\n",
      "Selected metaheuristics: ['TS-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'TSL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'TSL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: LR40  Feature type: HG-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8337377744809713\n",
      "R2 Best score (validation) val. score :  0.549155956382765\n",
      "R2 of the best estimator (testing dataset):  0.46112951139708513\n",
      "Selected metaheuristics: ['TS-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: LR40  Feature type: OG-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8257960043665635\n",
      "R2 Best score (validation) val. score :  0.5521385244930498\n",
      "R2 of the best estimator (testing dataset):  0.385937469825102\n",
      "Selected metaheuristics: ['SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: LR40  Feature type: ST-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8116251831297588\n",
      "R2 Best score (validation) val. score :  0.5037194245768923\n",
      "R2 of the best estimator (testing dataset):  0.37133436835894573\n",
      "Selected metaheuristics: ['TS-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'TSL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'TSL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: PCA99  Feature type: HG-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8345730876705123\n",
      "R2 Best score (validation) val. score :  0.4914149224305813\n",
      "R2 of the best estimator (testing dataset):  0.14902819713224025\n",
      "Selected metaheuristics: ['SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'TSL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: PCA99  Feature type: OG-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8244320785942885\n",
      "R2 Best score (validation) val. score :  0.49426152763579767\n",
      "R2 of the best estimator (testing dataset):  0.11572872777624532\n",
      "Selected metaheuristics: ['SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: PCA99  Feature type: ST-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.808395309346872\n",
      "R2 Best score (validation) val. score :  0.424011498312643\n",
      "R2 of the best estimator (testing dataset):  0.1875270364137091\n",
      "Selected metaheuristics: ['SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: PCA9999  Feature type: HG-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8225058950864718\n",
      "R2 Best score (validation) val. score :  0.3731978252839994\n",
      "R2 of the best estimator (testing dataset):  0.12651369589021186\n",
      "Selected metaheuristics: ['SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: PCA9999  Feature type: OG-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.817999241703713\n",
      "R2 Best score (validation) val. score :  0.3946133144774266\n",
      "R2 of the best estimator (testing dataset):  0.07677102764937982\n",
      "Selected metaheuristics: ['SA-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: PCA9999  Feature type: ST-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8054988698335076\n",
      "R2 Best score (validation) val. score :  0.34161541111314725\n",
      "R2 of the best estimator (testing dataset):  0.14927641982284934\n",
      "Selected metaheuristics: ['SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM']\n",
      "******* Feature select: FS_P  Feature type: HG-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8673566539732263\n",
      "R2 Best score (validation) val. score :  0.5868679044693625\n",
      "R2 of the best estimator (testing dataset):  0.4382566052468769\n",
      "Selected metaheuristics: ['SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'TSL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: FS_P  Feature type: OG-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8438686179599985\n",
      "R2 Best score (validation) val. score :  0.5703138121727586\n",
      "R2 of the best estimator (testing dataset):  0.4213472450287337\n",
      "Selected metaheuristics: ['TSL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'TS-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: FS_P  Feature type: ST-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8336491523921157\n",
      "R2 Best score (validation) val. score :  0.5528088631236214\n",
      "R2 of the best estimator (testing dataset):  0.37703601220021693\n",
      "Selected metaheuristics: ['TSL-Si-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'TSL-Si-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: FS_K  Feature type: HG-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8701374718903333\n",
      "R2 Best score (validation) val. score :  0.5879251923471798\n",
      "R2 of the best estimator (testing dataset):  0.4255196300787883\n",
      "Selected metaheuristics: ['SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'TSL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: FS_K  Feature type: OG-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8537980390598162\n",
      "R2 Best score (validation) val. score :  0.5725675504731212\n",
      "R2 of the best estimator (testing dataset):  0.4248284185924921\n",
      "Selected metaheuristics: ['TSL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: FS_K  Feature type: ST-F Regression model: rfr ******\n",
      "R2 of the best estimator (training dataset):  0.8431072488086632\n",
      "R2 Best score (validation) val. score :  0.5551799826199709\n",
      "R2 of the best estimator (testing dataset):  0.38639773295161356\n",
      "Selected metaheuristics: ['TS-Si-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "regression_type gbr\n",
      "******* Feature select: all  Feature type: HG-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.9114751577885423\n",
      "R2 Best score (validation) val. score :  0.562310377770207\n",
      "R2 of the best estimator (testing dataset):  0.405740665761924\n",
      "Selected metaheuristics: ['SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'TSL-Ei-LM', 'TSL-Si-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'TSL-Ei-LM', 'TSL-Ei-LM', 'SA-Ei-LM', 'SA-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'TSL-Si-LM', 'SAL-Si-LM', 'SA-Ei-LM', 'TS-Si-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: all  Feature type: OG-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.948539050788928\n",
      "R2 Best score (validation) val. score :  0.5494979227204311\n",
      "R2 of the best estimator (testing dataset):  0.32528719114414706\n",
      "Selected metaheuristics: ['TSL-Si-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'TSL-Ei-LM', 'TSL-Si-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'TSL-Si-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'TSL-Si-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: all  Feature type: ST-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.8679404854796005\n",
      "R2 Best score (validation) val. score :  0.5462505938759572\n",
      "R2 of the best estimator (testing dataset):  0.3602443163791982\n",
      "Selected metaheuristics: ['TS-Si-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'TSL-Si-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM']\n",
      "******* Feature select: PCA999  Feature type: HG-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.9916349943818529\n",
      "R2 Best score (validation) val. score :  0.5452901746223867\n",
      "R2 of the best estimator (testing dataset):  0.10203234795750674\n",
      "Selected metaheuristics: ['SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'TS-Si-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: PCA999  Feature type: OG-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.9608000550839908\n",
      "R2 Best score (validation) val. score :  0.4892782657251235\n",
      "R2 of the best estimator (testing dataset):  0.059915634332337625\n",
      "Selected metaheuristics: ['TS-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'TSL-Ei-LM', 'TS-Si-LM', 'TS-Ei-LM', 'SA-Si-LM', 'TS-Si-LM', 'TSL-Si-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Si-LM', 'SA-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SA-Ei-LM', 'TS-Si-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TS-Si-LM', 'TS-Si-LM', 'TS-Si-LM', 'TS-Si-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: PCA999  Feature type: ST-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.931229998160998\n",
      "R2 Best score (validation) val. score :  0.42477334212540924\n",
      "R2 of the best estimator (testing dataset):  0.1173623643892395\n",
      "Selected metaheuristics: ['TS-Si-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'TS-Si-LM', 'TS-Si-LM', 'SAL-Si-LM', 'SA-Ei-LM', 'TS-Si-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SA-Ei-LM', 'TS-Si-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'TS-Si-LM', 'SA-Si-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'TS-Si-LM', 'TS-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SA-Ei-LM', 'TS-Si-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SA-Ei-LM']\n",
      "******* Feature select: LR10  Feature type: HG-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.8590457415783062\n",
      "R2 Best score (validation) val. score :  0.4437673715289896\n",
      "R2 of the best estimator (testing dataset):  0.33664572312303614\n",
      "Selected metaheuristics: ['SAL-Ei-LM', 'TS-Si-LM', 'TSL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SA-Ei-LM', 'TSL-Si-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM']\n",
      "******* Feature select: LR10  Feature type: OG-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.9015751787328621\n",
      "R2 Best score (validation) val. score :  0.514376530309608\n",
      "R2 of the best estimator (testing dataset):  -0.14505469979966987\n",
      "Selected metaheuristics: ['TSL-Ei-LM', 'TSL-Si-LM', 'TSL-Ei-LM', 'SA-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'TSL-Ei-LM', 'TSL-Si-LM', 'SA-Si-LM', 'TSL-Si-LM', 'TSL-Si-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'TSL-Si-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'TSL-Ei-LM', 'TSL-Ei-LM', 'TSL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TSL-Si-LM', 'TSL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Si-LM', 'TSL-Si-LM', 'TSL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: LR10  Feature type: ST-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.8565035492475312\n",
      "R2 Best score (validation) val. score :  0.45775542398614294\n",
      "R2 of the best estimator (testing dataset):  0.3220823535732622\n",
      "Selected metaheuristics: ['TSL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'TSL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'TSL-Si-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'TS-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: FS_S  Feature type: HG-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.896970329914459\n",
      "R2 Best score (validation) val. score :  0.5610988164619662\n",
      "R2 of the best estimator (testing dataset):  0.3883304405792479\n",
      "Selected metaheuristics: ['TSL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'TSL-Ei-LM', 'TSL-Si-LM', 'TS-Ei-LM', 'SAL-Si-LM', 'TS-Si-LM', 'TSL-Ei-LM', 'TSL-Ei-LM', 'TS-Si-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TS-Si-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SA-Ei-LM']\n",
      "******* Feature select: FS_S  Feature type: OG-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.942305712703437\n",
      "R2 Best score (validation) val. score :  0.557212366509816\n",
      "R2 of the best estimator (testing dataset):  0.33695963445165666\n",
      "Selected metaheuristics: ['TSL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'TSL-Ei-LM', 'TSL-Si-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'TSL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: FS_S  Feature type: ST-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.8529186350183244\n",
      "R2 Best score (validation) val. score :  0.532977914820384\n",
      "R2 of the best estimator (testing dataset):  0.37239023235116986\n",
      "Selected metaheuristics: ['TSL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'TS-Si-LM', 'SAL-Si-LM', 'TS-Ei-LM', 'TSL-Ei-LM', 'TSL-Ei-LM', 'TS-Si-LM', 'SA-Si-LM', 'SA-Ei-LM', 'SA-Si-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Si-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Si-LM', 'TS-Si-LM', 'TSL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'TS-Si-LM', 'SA-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'TS-Si-LM', 'SAL-Si-LM', 'SA-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM']\n",
      "******* Feature select: RF  Feature type: HG-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.8916930825809615\n",
      "R2 Best score (validation) val. score :  0.5497917584209814\n",
      "R2 of the best estimator (testing dataset):  0.30518809490199844\n",
      "Selected metaheuristics: ['TSL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'TSL-Ei-LM', 'TSL-Si-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'TSL-Ei-LM', 'TSL-Ei-LM', 'TSL-Si-LM', 'SA-Si-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TSL-Si-LM', 'SA-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SA-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'TSL-Si-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SA-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: RF  Feature type: OG-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.8614998573575953\n",
      "R2 Best score (validation) val. score :  0.5347947528326157\n",
      "R2 of the best estimator (testing dataset):  0.30030072782102935\n",
      "Selected metaheuristics: ['TS-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Si-LM', 'TS-Si-LM', 'SA-Si-LM', 'TS-Ei-LM', 'TSL-Ei-LM', 'TSL-Si-LM', 'SA-Si-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'TS-Si-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'TS-Si-LM', 'SAL-Si-LM', 'SA-Si-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: RF  Feature type: ST-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.8562591232382052\n",
      "R2 Best score (validation) val. score :  0.49930776329510423\n",
      "R2 of the best estimator (testing dataset):  0.25566818164316335\n",
      "Selected metaheuristics: ['TS-Si-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'TS-Si-LM', 'SA-Ei-LM', 'SAL-Si-LM', 'SAL-Si-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SA-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: LR20  Feature type: HG-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.8582873972814262\n",
      "R2 Best score (validation) val. score :  0.5066643388895795\n",
      "R2 of the best estimator (testing dataset):  0.40252827412915804\n",
      "Selected metaheuristics: ['SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: LR20  Feature type: OG-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.8687096262962503\n",
      "R2 Best score (validation) val. score :  0.4985874834487859\n",
      "R2 of the best estimator (testing dataset):  0.2958894064558896\n",
      "Selected metaheuristics: ['SA-Ei-LM', 'TSL-Si-LM', 'TSL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: LR20  Feature type: ST-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.865593906893465\n",
      "R2 Best score (validation) val. score :  0.505619970339364\n",
      "R2 of the best estimator (testing dataset):  0.33648744237586886\n",
      "Selected metaheuristics: ['TSL-Ei-LM', 'TS-Si-LM', 'TSL-Ei-LM', 'SA-Si-LM', 'TSL-Ei-LM', 'TSL-Si-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'TSL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: LR30  Feature type: HG-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.8259276291450385\n",
      "R2 Best score (validation) val. score :  0.4904183684585677\n",
      "R2 of the best estimator (testing dataset):  0.40464170769706315\n",
      "Selected metaheuristics: ['SAL-Ei-LM', 'TS-Si-LM', 'TSL-Ei-LM', 'SA-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TSL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'TS-Si-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: LR30  Feature type: OG-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.8723866683440967\n",
      "R2 Best score (validation) val. score :  0.5122869340300673\n",
      "R2 of the best estimator (testing dataset):  0.34801133376742716\n",
      "Selected metaheuristics: ['TSL-Si-LM', 'TSL-Si-LM', 'TSL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Si-LM', 'SAL-Si-LM', 'SAL-Si-LM', 'TSL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: LR30  Feature type: ST-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.80926027016214\n",
      "R2 Best score (validation) val. score :  0.5012867012718517\n",
      "R2 of the best estimator (testing dataset):  0.31325111276614465\n",
      "Selected metaheuristics: ['TSL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'TSL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'TSL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'TSL-Si-LM', 'SAL-Si-LM', 'SA-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: LR40  Feature type: HG-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.895428173842357\n",
      "R2 Best score (validation) val. score :  0.539571902295398\n",
      "R2 of the best estimator (testing dataset):  0.4415447965811922\n",
      "Selected metaheuristics: ['TS-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'TSL-Ei-LM', 'TSL-Si-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'TSL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'TS-Ei-LM', 'TSL-Si-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: LR40  Feature type: OG-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.908867316073495\n",
      "R2 Best score (validation) val. score :  0.5268793746488736\n",
      "R2 of the best estimator (testing dataset):  0.31790105654484624\n",
      "Selected metaheuristics: ['TS-Si-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'TSL-Ei-LM', 'TSL-Ei-LM', 'TS-Ei-LM', 'SA-Si-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'TS-Si-LM', 'TSL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'TS-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: LR40  Feature type: ST-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.8819752056537259\n",
      "R2 Best score (validation) val. score :  0.49539960618967627\n",
      "R2 of the best estimator (testing dataset):  0.32733429966947003\n",
      "Selected metaheuristics: ['TSL-Ei-LM', 'TS-Si-LM', 'TSL-Ei-LM', 'SAL-Si-LM', 'TSL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'TSL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'TS-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'TS-Si-LM', 'SAL-Si-LM', 'SA-Si-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: PCA99  Feature type: HG-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.967409317269708\n",
      "R2 Best score (validation) val. score :  0.5341099981109951\n",
      "R2 of the best estimator (testing dataset):  -0.02444654905678295\n",
      "Selected metaheuristics: ['TS-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'TSL-Ei-LM', 'TS-Si-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'TS-Si-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: PCA99  Feature type: OG-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.9339819976367908\n",
      "R2 Best score (validation) val. score :  0.48978566176512917\n",
      "R2 of the best estimator (testing dataset):  -0.07861828079007976\n",
      "Selected metaheuristics: ['TS-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'TSL-Si-LM', 'TS-Si-LM', 'SA-Si-LM', 'TS-Si-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SA-Ei-LM', 'TS-Si-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'TS-Si-LM', 'SA-Si-LM', 'SA-Si-LM', 'TS-Si-LM', 'TS-Si-LM', 'TS-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TS-Si-LM', 'SA-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Si-LM', 'TS-Si-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Si-LM', 'SA-Ei-LM', 'SA-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Si-LM', 'TS-Si-LM', 'TSL-Si-LM', 'TS-Si-LM', 'SA-Si-LM', 'SA-Si-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'SA-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM']\n",
      "******* Feature select: PCA99  Feature type: ST-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.8807753001854058\n",
      "R2 Best score (validation) val. score :  0.44534567262063174\n",
      "R2 of the best estimator (testing dataset):  0.07704335226350342\n",
      "Selected metaheuristics: ['TS-Si-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'TS-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Si-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'TS-Si-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Si-LM', 'SA-Ei-LM', 'TS-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Si-LM', 'SAL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TS-Si-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Si-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Si-LM', 'SA-Ei-LM', 'TS-Si-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SA-Ei-LM']\n",
      "******* Feature select: PCA9999  Feature type: HG-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.9908795784290013\n",
      "R2 Best score (validation) val. score :  0.5308337123449027\n",
      "R2 of the best estimator (testing dataset):  0.18759294544142058\n",
      "Selected metaheuristics: ['SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'TS-Si-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM']\n",
      "******* Feature select: PCA9999  Feature type: OG-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.9852062208503393\n",
      "R2 Best score (validation) val. score :  0.4814164995787137\n",
      "R2 of the best estimator (testing dataset):  0.010323794852782037\n",
      "Selected metaheuristics: ['TSL-Si-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'TS-Si-LM', 'TS-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Si-LM', 'SA-Si-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'TS-Si-LM', 'TS-Si-LM', 'TS-Si-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: PCA9999  Feature type: ST-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.9779987778142476\n",
      "R2 Best score (validation) val. score :  0.41431444491922625\n",
      "R2 of the best estimator (testing dataset):  0.06652316518323317\n",
      "Selected metaheuristics: ['TS-Si-LM', 'TS-Si-LM', 'SA-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'TS-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'TS-Si-LM', 'SA-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SA-Si-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'TS-Si-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'TS-Si-LM', 'TS-Ei-LM', 'TSL-Si-LM', 'SAL-Si-LM', 'SA-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SA-Ei-LM']\n",
      "******* Feature select: FS_P  Feature type: HG-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.9388321341656468\n",
      "R2 Best score (validation) val. score :  0.568398654356907\n",
      "R2 of the best estimator (testing dataset):  0.3932030563756285\n",
      "Selected metaheuristics: ['SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'TSL-Ei-LM', 'TSL-Si-LM', 'SAL-Si-LM', 'SAL-Si-LM', 'SA-Si-LM', 'TSL-Ei-LM', 'TSL-Ei-LM', 'SAL-Si-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'TSL-Si-LM', 'SA-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Si-LM', 'TS-Ei-LM', 'TSL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'TS-Si-LM', 'TSL-Si-LM', 'SAL-Si-LM', 'SA-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SA-Si-LM', 'SA-Ei-LM']\n",
      "******* Feature select: FS_P  Feature type: OG-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.8726025855050501\n",
      "R2 Best score (validation) val. score :  0.5458249397193725\n",
      "R2 of the best estimator (testing dataset):  0.33835030366119145\n",
      "Selected metaheuristics: ['TSL-Si-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'TSL-Ei-LM', 'TSL-Si-LM', 'SAL-Si-LM', 'SAL-Si-LM', 'SAL-Si-LM', 'TS-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: FS_P  Feature type: ST-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.8578641032806511\n",
      "R2 Best score (validation) val. score :  0.5479892177353092\n",
      "R2 of the best estimator (testing dataset):  0.3824065822231587\n",
      "Selected metaheuristics: ['TS-Si-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'TSL-Ei-LM', 'SAL-Si-LM', 'SAL-Si-LM', 'TSL-Ei-LM', 'TSL-Ei-LM', 'SA-Ei-LM', 'SA-Si-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Si-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Si-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'TS-Si-LM', 'SAL-Si-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'SA-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SA-Ei-LM']\n",
      "******* Feature select: FS_K  Feature type: HG-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.9416411931162935\n",
      "R2 Best score (validation) val. score :  0.5636345938257203\n",
      "R2 of the best estimator (testing dataset):  0.40195405782028415\n",
      "Selected metaheuristics: ['SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'TSL-Ei-LM', 'TSL-Si-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'TSL-Ei-LM', 'TSL-Si-LM', 'TS-Si-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SA-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'TSL-Si-LM', 'SAL-Si-LM', 'TS-Ei-LM', 'TS-Si-LM', 'SA-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: FS_K  Feature type: OG-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.9717851463135481\n",
      "R2 Best score (validation) val. score :  0.5432170351408969\n",
      "R2 of the best estimator (testing dataset):  0.3205015137020938\n",
      "Selected metaheuristics: ['TSL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'TSL-Ei-LM', 'TSL-Si-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'TSL-Si-LM', 'TSL-Si-LM', 'TSL-Si-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'TS-Si-LM', 'TSL-Si-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: FS_K  Feature type: ST-F Regression model: gbr ******\n",
      "R2 of the best estimator (training dataset):  0.9092461345542435\n",
      "R2 Best score (validation) val. score :  0.536594249140616\n",
      "R2 of the best estimator (testing dataset):  0.36906985397299086\n",
      "Selected metaheuristics: ['TS-Si-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SA-Ei-LM', 'TSL-Si-LM', 'TSL-Si-LM', 'SAL-Si-LM', 'TS-Ei-LM', 'TSL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'TSL-Si-LM', 'SA-Si-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Si-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TS-Si-LM', 'SAL-Si-LM', 'SA-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM']\n",
      "regression_type svr\n",
      "******* Feature select: all  Feature type: HG-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.9919774767301264\n",
      "R2 Best score (validation) val. score :  0.43855897191583504\n",
      "R2 of the best estimator (testing dataset):  0.11562190003102175\n",
      "Selected metaheuristics: ['SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: all  Feature type: OG-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.9943000548612215\n",
      "R2 Best score (validation) val. score :  0.3857380819987936\n",
      "R2 of the best estimator (testing dataset):  0.03346708155593141\n",
      "Selected metaheuristics: ['SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: all  Feature type: ST-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.9895372257566823\n",
      "R2 Best score (validation) val. score :  0.4424512413199199\n",
      "R2 of the best estimator (testing dataset):  0.3367295653022914\n",
      "Selected metaheuristics: ['TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SA-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SA-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM']\n",
      "******* Feature select: PCA999  Feature type: HG-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.991844361048146\n",
      "R2 Best score (validation) val. score :  0.482193110537926\n",
      "R2 of the best estimator (testing dataset):  0.1614636306428604\n",
      "Selected metaheuristics: ['SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM']\n",
      "******* Feature select: PCA999  Feature type: OG-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.9939171093156167\n",
      "R2 Best score (validation) val. score :  0.4966329190012334\n",
      "R2 of the best estimator (testing dataset):  -0.039510962842935135\n",
      "Selected metaheuristics: ['SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: PCA999  Feature type: ST-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.9955230651106404\n",
      "R2 Best score (validation) val. score :  0.43223988693301135\n",
      "R2 of the best estimator (testing dataset):  0.11169349854530813\n",
      "Selected metaheuristics: ['SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: LR10  Feature type: HG-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.8881490746442071\n",
      "R2 Best score (validation) val. score :  0.2864349042953282\n",
      "R2 of the best estimator (testing dataset):  0.2228478567289466\n",
      "Selected metaheuristics: ['TSL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'TSL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'TSL-Si-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Si-LM', 'SA-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'TSL-Si-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Si-LM', 'SA-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: LR10  Feature type: OG-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.7175959461073134\n",
      "R2 Best score (validation) val. score :  0.3600559673483968\n",
      "R2 of the best estimator (testing dataset):  0.2943408319942997\n",
      "Selected metaheuristics: ['TSL-Ei-LM', 'TS-Si-LM', 'TSL-Ei-LM', 'SAL-Si-LM', 'TSL-Ei-LM', 'TSL-Si-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SA-Ei-LM', 'TS-Si-LM', 'TS-Ei-LM', 'TSL-Si-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Si-LM', 'TSL-Si-LM', 'SA-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'TS-Si-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Si-LM', 'TS-Ei-LM', 'TS-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: LR10  Feature type: ST-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.8723276781357793\n",
      "R2 Best score (validation) val. score :  0.3828624047083717\n",
      "R2 of the best estimator (testing dataset):  0.24749472927114652\n",
      "Selected metaheuristics: ['TS-Ei-LM', 'TS-Si-LM', 'TSL-Ei-LM', 'SA-Si-LM', 'SA-Ei-LM', 'TSL-Si-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Si-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'TS-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'TSL-Si-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: FS_S  Feature type: HG-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.9894122165049304\n",
      "R2 Best score (validation) val. score :  0.5623917932164433\n",
      "R2 of the best estimator (testing dataset):  0.36938096964613815\n",
      "Selected metaheuristics: ['SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'TSL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: FS_S  Feature type: OG-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.9799486217790823\n",
      "R2 Best score (validation) val. score :  0.5260943198423104\n",
      "R2 of the best estimator (testing dataset):  0.342875237497288\n",
      "Selected metaheuristics: ['SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: FS_S  Feature type: ST-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.9925379803541845\n",
      "R2 Best score (validation) val. score :  0.4652721288439044\n",
      "R2 of the best estimator (testing dataset):  0.1862946975084619\n",
      "Selected metaheuristics: ['TSL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SA-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: RF  Feature type: HG-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.7312071981971978\n",
      "R2 Best score (validation) val. score :  0.34738144305273966\n",
      "R2 of the best estimator (testing dataset):  0.33549709386700366\n",
      "Selected metaheuristics: ['TSL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: RF  Feature type: OG-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.9696598224906201\n",
      "R2 Best score (validation) val. score :  0.41706925043183196\n",
      "R2 of the best estimator (testing dataset):  0.3778437300092117\n",
      "Selected metaheuristics: ['TSL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'TSL-Ei-LM', 'TSL-Si-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'TSL-Si-LM', 'SAL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: RF  Feature type: ST-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.9755393520137908\n",
      "R2 Best score (validation) val. score :  0.4251298466455613\n",
      "R2 of the best estimator (testing dataset):  0.22584627799758503\n",
      "Selected metaheuristics: ['TSL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'TSL-Si-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: LR20  Feature type: HG-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.9722336441960401\n",
      "R2 Best score (validation) val. score :  0.3760913960704557\n",
      "R2 of the best estimator (testing dataset):  0.16186616327939538\n",
      "Selected metaheuristics: ['TSL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'SA-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SA-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: LR20  Feature type: OG-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.8330050905473751\n",
      "R2 Best score (validation) val. score :  0.3757037032118001\n",
      "R2 of the best estimator (testing dataset):  0.2289047625016029\n",
      "Selected metaheuristics: ['SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: LR20  Feature type: ST-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.9742290619202997\n",
      "R2 Best score (validation) val. score :  0.4676779379273288\n",
      "R2 of the best estimator (testing dataset):  0.34571314162911426\n",
      "Selected metaheuristics: ['TSL-Ei-LM', 'TS-Si-LM', 'TSL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SA-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: LR30  Feature type: HG-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.9843374131240881\n",
      "R2 Best score (validation) val. score :  0.39167803660526906\n",
      "R2 of the best estimator (testing dataset):  0.18894175776027694\n",
      "Selected metaheuristics: ['TSL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: LR30  Feature type: OG-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.9643297698128095\n",
      "R2 Best score (validation) val. score :  0.38600079308847357\n",
      "R2 of the best estimator (testing dataset):  0.10785802782558294\n",
      "Selected metaheuristics: ['TSL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'TSL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'TS-Si-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: LR30  Feature type: ST-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.9832381753346221\n",
      "R2 Best score (validation) val. score :  0.45406979105656864\n",
      "R2 of the best estimator (testing dataset):  0.29895389370729564\n",
      "Selected metaheuristics: ['TSL-Ei-LM', 'TS-Si-LM', 'TSL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SA-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: LR40  Feature type: HG-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.9829868494080207\n",
      "R2 Best score (validation) val. score :  0.41538292007735994\n",
      "R2 of the best estimator (testing dataset):  0.30660900248013706\n",
      "Selected metaheuristics: ['TSL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: LR40  Feature type: OG-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.9928597781964982\n",
      "R2 Best score (validation) val. score :  0.3843626115661407\n",
      "R2 of the best estimator (testing dataset):  0.24632888462600588\n",
      "Selected metaheuristics: ['SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: LR40  Feature type: ST-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.9904186455238123\n",
      "R2 Best score (validation) val. score :  0.45286575186168265\n",
      "R2 of the best estimator (testing dataset):  0.26853322454268197\n",
      "Selected metaheuristics: ['TSL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SA-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: PCA99  Feature type: HG-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.9892128663068572\n",
      "R2 Best score (validation) val. score :  0.5123625122932935\n",
      "R2 of the best estimator (testing dataset):  -0.008886123112149202\n",
      "Selected metaheuristics: ['SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: PCA99  Feature type: OG-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.9853076671574954\n",
      "R2 Best score (validation) val. score :  0.5151315996559559\n",
      "R2 of the best estimator (testing dataset):  -0.04201644944487638\n",
      "Selected metaheuristics: ['SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: PCA99  Feature type: ST-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.987008517381909\n",
      "R2 Best score (validation) val. score :  0.4306880419127218\n",
      "R2 of the best estimator (testing dataset):  0.07275880865360913\n",
      "Selected metaheuristics: ['SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: PCA9999  Feature type: HG-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.8523979837538007\n",
      "R2 Best score (validation) val. score :  0.20221215089415553\n",
      "R2 of the best estimator (testing dataset):  -0.17704201458599683\n",
      "Selected metaheuristics: ['SAL-Ei-LM', 'TS-Si-LM', 'TSL-Ei-LM', 'TS-Si-LM', 'TSL-Ei-LM', 'TS-Si-LM', 'TS-Si-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'TS-Ei-LM', 'TSL-Ei-LM', 'TS-Si-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SAL-Si-LM', 'TS-Si-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: PCA9999  Feature type: OG-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.9945402205724632\n",
      "R2 Best score (validation) val. score :  0.42576314948469196\n",
      "R2 of the best estimator (testing dataset):  0.06101812397922135\n",
      "Selected metaheuristics: ['SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: PCA9999  Feature type: ST-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.9944590795562682\n",
      "R2 Best score (validation) val. score :  0.39901727737515447\n",
      "R2 of the best estimator (testing dataset):  0.2727411724351685\n",
      "Selected metaheuristics: ['TSL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Si-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM']\n",
      "******* Feature select: FS_P  Feature type: HG-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.9933998398671051\n",
      "R2 Best score (validation) val. score :  0.46766445165599213\n",
      "R2 of the best estimator (testing dataset):  0.12238627819769947\n",
      "Selected metaheuristics: ['SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: FS_P  Feature type: OG-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.9860255375120863\n",
      "R2 Best score (validation) val. score :  0.5477390540251234\n",
      "R2 of the best estimator (testing dataset):  0.46713349637590323\n",
      "Selected metaheuristics: ['SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'TSL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'TS-Si-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: FS_P  Feature type: ST-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.989392288542402\n",
      "R2 Best score (validation) val. score :  0.4747410544438095\n",
      "R2 of the best estimator (testing dataset):  0.2784098423129443\n",
      "Selected metaheuristics: ['TSL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SA-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM']\n",
      "******* Feature select: FS_K  Feature type: HG-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.9936130432975934\n",
      "R2 Best score (validation) val. score :  0.4173641420590621\n",
      "R2 of the best estimator (testing dataset):  0.07354703815114656\n",
      "Selected metaheuristics: ['SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM']\n",
      "******* Feature select: FS_K  Feature type: OG-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.9811392499177448\n",
      "R2 Best score (validation) val. score :  0.5334800285181025\n",
      "R2 of the best estimator (testing dataset):  0.50431747950937\n",
      "Selected metaheuristics: ['TSL-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'TSL-Ei-LM', 'TSL-Si-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SA-Ei-LM', 'SAL-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TS-Si-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'TS-Si-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Si-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM']\n",
      "******* Feature select: FS_K  Feature type: ST-F Regression model: svr ******\n",
      "R2 of the best estimator (training dataset):  0.9925234866424868\n",
      "R2 Best score (validation) val. score :  0.4535529426649231\n",
      "R2 of the best estimator (testing dataset):  0.26696132667594036\n",
      "Selected metaheuristics: ['TSL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Si-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Si-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "regression_types = ['rfr','gbr', 'svr']\n",
    "\n",
    "regression_tuning(dir_path, ft_type, ft_select, regression_types, \n",
    "                  feature_path='../datasets/results/features/ianuarie2025-v2/',\n",
    "                  ranks_path='../datasets/results/ranks/runTime_1min_sa_ts_filtered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_select=['all','PCA999','LR10','FS_S','RF', 'LR20', 'LR30', \n",
    "    'LR40','PCA99','PCA9999','FS_P','FS_K']\n",
    "\n",
    "\n",
    "regression_types = ['gbr'] #['gbr','rfr','svr']\n",
    "regression_tuning(dir_path, ft_type, ft_select, regression_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_types = ['svr'] #['gbr','rfr','svr']\n",
    "regression_tuning(dir_path, ft_type, ft_select, regression_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian optimization + SVR\n",
    "ft_type=['OG','HG']\n",
    "ft_select=['_PCA999','_LR20','_FS','_RF'] #'_all',\n",
    "dir_path = '../datasets/results/run_1min/ranks'\n",
    "regression_type = 'svr'\n",
    "regression_tuning(dir_path, ft_type, ft_select, regression_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian optimization + GBR\n",
    "ft_type=['OG','HG']\n",
    "ft_select=['_all','_PCA999','_LR20','_FS','_RF'] #'PCA999'\n",
    "dir_path = '../datasets/results/run_1min/ranks'\n",
    "regression_type = 'gbr'\n",
    "regression_tuning(dir_path, ft_type, ft_select, regression_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rez_gbr={'gbr_all_op':['SAL_Si_ML', 'TS-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'EAL-Ei-LM-10', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'TS_Si_ML', 'SAL_Si_ML', 'TS-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL_Si_ML', 'SA_Si_ML', 'SAL-Ei-LM', 'SA_Si_ML', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA_Si_ML', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM'],\n",
    "         'gbr_all_dis':['SAL-Ei-LM', 'SAL_Si_ML', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA_Si_ML', 'SAL_Si_ML', 'SAL-Ei-LM', 'SAL_Si_ML', 'SAL-Ei-LM', 'SA_Si_ML', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA_Si_ML', 'TSL-Ei-LM', 'SAL_Si_ML', 'TS-Ei-LM', 'TSL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL_Si_ML', 'TSL-Ei-LM', 'SA_Si_ML', 'SA-Ei-LM', 'SAL_Si_ML', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA_Si_ML'],\n",
    "         'gbr_all_het':['SA-Ei-LM', 'SAL-Ei-LM', 'TS_Si_ML', 'SAL_Si_ML', 'SAL-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'TS-Ei-LM', 'SAL_Si_ML', 'SA-Ei-LM', 'SAL_Si_ML', 'TSL-Ei-LM', 'EAL-Ei-LM-10', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'TS_Si_ML', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL_Si_ML', 'TSL-Ei-LM', 'SA-Ei-LM', 'TS_Si_ML', 'SA_Si_ML', 'SA-Ei-LM', 'EAL-Ei-LM-10', 'TSL-Ei-LM'],\n",
    "         'gbr_LR20_op':['SAL-Ei-LM', 'TS_Si_ML', 'SAL_Si_ML', 'SA-Ei-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA_Si_ML', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA_Si_ML', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'EAL-Ei-LM-10', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL_Si_ML', 'TS-Ei-LM'],\n",
    "         'gbr_LR20_dis':['SAL-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'TSL-Ei-LM', 'SA_Si_ML', 'EAL-Ei-LM-50', 'TS_Si_ML', 'TSL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA_Si_ML', 'SAL_Si_ML', 'SA-Ei-LM', 'EAL-Ei-LM-10', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'EAL-Ei-LM-50', 'SAL-Ei-LM', 'TSL_Si_ML', 'SAL-Ei-LM', 'TS-Ei-LM', 'SAL_Si_ML', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL_Si_ML', 'SA-Ei-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM'],\n",
    "         'gbr_LR20_het':['SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TS_Si_ML', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA_Si_ML', 'SA_Si_ML', 'SAL_Si_ML', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA_Si_ML', 'SA-Ei-LM']\n",
    "        }\n",
    "df = pd.DataFrame(rez_gbr)\n",
    "df.to_csv('../datasets/results/run_1min/ranks/gbr_metaheuristics.csv')\n",
    "for ft in ft_type:\n",
    "    column = f'gbr_all_{ft}'\n",
    "    # print(\"column=\",column)\n",
    "    # new_df=df.sort_values[by=column,ascending=True, inplace=True]\n",
    "    # print(\"new_df=\",new_df)\n",
    "    plt.hist(df[column])\n",
    "    plt.xlabel(f'gbr_all_{ft}')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Histogram of {ft}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian optimization + rfr\n",
    "ft_type=['op','dis','het']\n",
    "ft_select=['_all','LR20'] #'PCA999'\n",
    "dir_path = '../datasets/results/run_1min/ranks'\n",
    "regression_type = 'rfr'\n",
    "regression_tuning(dir_path, ft_type, ft_select, regression_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rez_rfr={'rfr_all_op':['SAL-Ei-LM', 'SAL-Ei-LM', 'SA_Si_ML', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA_Si_ML', 'SA-Ei-LM', 'SA-Ei-LM', 'SA_Si_ML', 'SA-Ei-LM', 'SA_Si_ML', 'SAL_Si_ML', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL_Si_ML', 'SAL_Si_ML', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA_Si_ML', 'SA-Ei-LM', 'TSL-Ei-LM', 'TSL-Ei-LM', 'SA_Si_ML', 'SA-Ei-LM', 'SA-Ei-LM'],\n",
    "         'rfr_all_dis':['EAL-Ei-LM-50', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SA_Si_ML', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SA_Si_ML', 'SAL-Ei-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'EAL-Ei-LM-50', 'SA_Si_ML', 'TSL-Ei-LM', 'TS_Si_ML', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL_Si_ML', 'SAL_Si_ML', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM'],\n",
    "         'rfr_all_het':['TS-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'EAL-Ei-LM-10', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'EAL-Ei-LM-10', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS_Si_ML', 'SAL-Ei-LM', 'SA_Si_ML', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA_Si_ML', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM'],\n",
    "         'rfr_LR20_op':['SAL-Ei-LM', 'SAL-Ei-LM', 'TSL_Si_ML', 'SA_Si_ML', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA_Si_ML', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'EAL-Ei-LM-10', 'SAL-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SA_Si_ML', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA_Si_ML', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'TSL-Ei-LM', 'SAL_Si_ML', 'EAL-Ei-LM-10'],\n",
    "         'rfr_LR20_dis':['SAL-Ei-LM', 'SA_Si_ML', 'SA_Si_ML', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TS_Si_ML', 'SAL_Si_ML', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'SA-Ei-LM', 'TS_Si_ML', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TS_Si_ML', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'SA-Ei-LM', 'TSL-Ei-LM'],\n",
    "         'rfr_LR20_het':['TS-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL_Si_ML', 'SA-Ei-LM', 'SA_Si_ML', 'EAL-Ei-LM-10', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TSL-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM']\n",
    "        }\n",
    "df = pd.DataFrame(rez_rfr)\n",
    "df.to_csv('../datasets/results/run_1min/ranks/rfr_metaheuristics.csv')\n",
    "for ft in ft_type:\n",
    "    column = f'rfr_all_{ft}'\n",
    "    # print(\"column=\",column)\n",
    "    # new_df=df.sort_values[by=column,ascending=True, inplace=True]\n",
    "    # print(\"new_df=\",new_df)\n",
    "    plt.hist(df[column])\n",
    "    plt.xlabel(f'rfr_all_{ft}')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Histogram of {ft}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian optimization + MLP\n",
    "ft_type=['op','dis','het']\n",
    "ft_select=['_all','LR20'] #'PCA999'\n",
    "dir_path = '../datasets/results/run_1min/ranks'\n",
    "regression_type = 'mlp'\n",
    "regression_tuning(dir_path, ft_type, ft_select, regression_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(opt.cv_results_)\n",
    "df_results=pd.DataFrame.from_dict(opt.cv_results_)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiOutputRegressor(estimator=SVR(C=5.933861485115002, degree=1, gamma=10.0,\n",
      "                                   kernel='linear')) 0.40659439191091346\n"
     ]
    }
   ],
   "source": [
    "print(opt.best_estimator_, opt.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 17 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plot_objective(opt.optimizer_results_[0],\n",
    "                   dimensions=[\"C\", \"degree\", \"gamma\", \"kernel\"],\n",
    "                   n_minimum_search=int(1e8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/zzd1992/GBDTMO  - Gradient Boosting Decision Trees for multi-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/ECOLE-ITN/NguyenSSCI2021/blob/assets/Example/BO4ML_simpleexample.ipynb  - AutoML \n",
    "try:\n",
    "    import hyperopt\n",
    "except ModuleNotFoundError:\n",
    "    !pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/automl/SMAC3?tab=readme-ov-file  - SMAC3\n",
    "# https://github.com/automl/dehb   -  Differential Evolution + Hyperband"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

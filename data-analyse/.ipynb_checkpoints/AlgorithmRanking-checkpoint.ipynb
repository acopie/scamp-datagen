{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "baa07622-efa2-4c9e-a5c7-193bd8f9e09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b5591c-8a0a-4027-8803-8471557ca4d9",
   "metadata": {},
   "source": [
    "# Algorithm ranking\n",
    "\n",
    "Build ranking files:\n",
    "1. for each problem in the data_set finds the rank based on makespan average value for the repeated algorithms runs (alg_ranks_per_problem_mean)\n",
    "2. for each problem in the data_set finds the rank based on rank averange value for the repeted algorithms runs (alg_ranks_per_problem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6e20192b-cc03-47e9-af3b-a074e59e0d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _build_instances_name(input_path, filter):\n",
    "    \"\"\"\n",
    "    Constructs a list with the files name from the input path that matches the filter\n",
    "    :param: input_path - the path to the dataset files\n",
    "    :param: filter - file filter\n",
    "    \"\"\"\n",
    "    test_instances = sorted(glob.glob(f'{input_path}/{filter}'))\n",
    "    result = []\n",
    "    for instance in test_instances:\n",
    "        result.append(Path(instance).stem)\n",
    "    return result\n",
    "\n",
    "def get_instances_name(root_dir, dataset_name):\n",
    "    \"\"\"\n",
    "    Constructs a list with dataset instances file names\n",
    "    :param root_dir - the root directory to the data  sets\n",
    "    :param  dataset_name - one of the datasets (DEEP, WIDE, MIXED, 2ASP, DYUTHI, FJSSP)\n",
    "    \"\"\"\n",
    "    input_path = None\n",
    "    instances_name = []\n",
    "    if dataset_name == 'deep':\n",
    "        input_path = f'{root_dir}/ASP-DEEP/'\n",
    "        filter=\"bom_deep*.json\"\n",
    "        instances_name = _build_instances_name(input_path, filter)\n",
    "        \n",
    "    elif dataset_name == 'wide':\n",
    "        input_path = f'{root_dir}/ASP-WIDE/'\n",
    "        filter=\"bom_wide*.json\"\n",
    "        instances_name = _build_instances_name(input_path, filter)\n",
    "        \n",
    "    elif dataset_name == 'dyuthi':\n",
    "        input_path = f'{root_dir}/dyuthi/'\n",
    "        filter=\"P*.json\"\n",
    "        instances_name = _build_instances_name(input_path, filter)\n",
    "        \n",
    "    elif dataset_name == '2asp':\n",
    "        input_path = f'{root_dir}/2ASP/'\n",
    "        filter=\"*.json\"\n",
    "        instances_name = _build_instances_name(input_path, filter)\n",
    "        \n",
    "    elif dataset_name == 'fjssp':\n",
    "        input_path = f'{root_dir}/FJSSP-Hurink-vdata/'\n",
    "        filter=\"*.fjs.json\"\n",
    "        instances_name = _build_instances_name(input_path, filter)\n",
    "        \n",
    "        input_path = f'{root_dir}/FJSSP/set1'\n",
    "        filter=\"bom_fjssp_*.json\"\n",
    "        instances_name.extend(_build_instances_name(input_path, filter))\n",
    "\n",
    "        input_path = f'{root_dir}/FJSSP/set2'\n",
    "        filter=\"bom_fjssp_*.json\"\n",
    "        instances_name.extend(_build_instances_name(input_path, filter))\n",
    "\n",
    "        \n",
    "    elif dataset_name == 'mixed':\n",
    "        input_path = f'{root_dir}/mixed_boms/set1/'\n",
    "        filter=\"bom_mix_*.json\"\n",
    "        instances_name = _build_instances_name(input_path, filter)\n",
    "        \n",
    "        input_path = f'{root_dir}/mixed_boms/set2/'\n",
    "        filter=\"bom_mix_*.json\"\n",
    "        instances_name.extend(_build_instances_name(input_path, filter))\n",
    "\n",
    "        input_path = f'{root_dir}/mixed_boms/set3/'\n",
    "        filter=\"bom_mix_*.json\"\n",
    "        instances_name.extend(_build_instances_name(input_path, filter))\n",
    "\n",
    "        input_path = f'{root_dir}/mixed_boms/set4/'\n",
    "        filter=\"bom_mix_*.json\"\n",
    "        instances_name.extend(_build_instances_name(input_path, filter))\n",
    "\n",
    "        input_path = f'{root_dir}/mixed_boms/set5/'\n",
    "        filter=\"bom_mix_*.json\"\n",
    "        instances_name.extend(_build_instances_name(input_path, filter))\n",
    "\n",
    "        input_path = f'{root_dir}/mixed_boms/set6/'\n",
    "        filter=\"bom_mix_*.json\"\n",
    "        instances_name.extend(_build_instances_name(input_path, filter))\n",
    "\n",
    "        input_path = f'{root_dir}/mixed_boms/set7/'\n",
    "        filter=\"bom_mix_*.json\"\n",
    "        instances_name.extend(_build_instances_name(input_path, filter))\n",
    "        \n",
    "    elif dataset_name == 'dafjs':\n",
    "        input_path = f'{root_dir}/dafjs/'\n",
    "        filter=\"DAFJS*.json\"\n",
    "        instances_name = _build_instances_name(input_path, filter)\n",
    "\n",
    "    elif dataset_name == 'yfjs':\n",
    "        input_path = f'{root_dir}/yfjs/'\n",
    "        filter=\"YFJS*.json\"\n",
    "        instances_name = _build_instances_name(input_path, filter)\n",
    "\n",
    "    else:\n",
    "        printf('Wrong dataset name')\n",
    "    return instances_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "497b9fb7-d237-4c4e-83e8-618db5254715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['YFJS01', 'YFJS02', 'YFJS03', 'YFJS04', 'YFJS05', 'YFJS06', 'YFJS07', 'YFJS08', 'YFJS09', 'YFJS10', 'YFJS11', 'YFJS12', 'YFJS13', 'YFJS14', 'YFJS15', 'YFJS16', 'YFJS17', 'YFJS18', 'YFJS19', 'YFJS20']\n"
     ]
    }
   ],
   "source": [
    "root_dir = \"../datasets/\"\n",
    "print(get_instances_name(root_dir, \"yfjs\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "362491ae-7c3a-4eed-948a-dec19dc55507",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alg_ranks_per_problem_mean(data_set_name, data_set, names_alg, output_path, input_file_name=None,input_files_path=None):\n",
    "    \"\"\"\n",
    "    for each problem in the data_set finds the rank based on makespan average value for the repeated\n",
    "    algorithms runs\n",
    "    :param input_file_name: the file name with the raw data\n",
    "    :param data_set: the test instances names\n",
    "    :param names_alg: algorithms name\n",
    "    :param output_path: output file to save the  results\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if input_files_path:\n",
    "        input_files_name=[\n",
    "            f'{input_files_path}/makespan-1minTime/ei-lm/results_bom_{data_set_name}_1min.csv',\n",
    "            f'{input_files_path}/makespan-1minTime/ei-lm-ea-popSize/ea-time-1min-10el-{data_set_name}.csv',\n",
    "            f'{input_files_path}/makespan-1minTime/ei-lm-ea-popSize/ea-time-1min-50el-{data_set_name}.csv',\n",
    "            f'{input_files_path}/makespan-1minTime/si-lm/results_bom_si_lm_{data_set_name}_1min.csv',\n",
    "        ]\n",
    "\n",
    "    print(input_files_name)\n",
    "    if input_file_name:\n",
    "        input_data = pd.read_csv(input_file_name)\n",
    "    if input_files_name:\n",
    "        list = []\n",
    "        for file in input_files_name:\n",
    "            list.append(pd.read_csv(file))\n",
    "        input_data = pd.concat(list)\n",
    "    df = input_data[input_data[\"Bom\"].isin(data_set)]\n",
    "\n",
    "    header_line = ['Problem']\n",
    "    header_line.extend(names_alg)\n",
    "    with open(output_path, 'w', newline='') as csvfile:\n",
    "        out_file = csv.writer(csvfile, delimiter=',')\n",
    "        out_file.writerow(header_line)\n",
    "        for test_instance in data_set:\n",
    "            df1 = df[df[\"Bom\"].isin([test_instance])]\n",
    "            group = []\n",
    "            for alg in names_alg:\n",
    "                group.append(df1[df1[\"Algorithm\"] == alg][\"Makespan\"].mean())\n",
    "\n",
    "            s = pd.Series(group)\n",
    "            r = s.rank()\n",
    "            ranks = [r[alg] for alg in range(len(names_alg))]\n",
    "            line = [test_instance]\n",
    "            line.extend(ranks)\n",
    "            out_file.writerow(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "87bcb0d5-510a-4964-9706-6d4ec8727405",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alg_ranks_per_problem( data_set_name, data_set, names_alg, output_path, input_file_name=None,input_files_path=None, alg_repetions_no=10):\n",
    "    \"\"\"\n",
    "        for each problem in the data_set finds the rank based on rank averange value for the repeted\n",
    "        algorithms runs\n",
    "        :param input_file_name: the file name with the raw data\n",
    "        :param data_set: the test instances names\n",
    "        :param names_alg: algorithms name\n",
    "        :param output_path: output file to save the  results\n",
    "        :pparam alg_repetions_no: number of repetions of an algorithm for an instance\n",
    "        :return:\n",
    "        \"\"\"\n",
    "    if input_files_path:\n",
    "        input_files_name=[\n",
    "            f'{input_files_path}/makespan-1minTime/ei-lm/results_bom_{data_set_name}_1min.csv',\n",
    "            f'{input_files_path}/makespan-1minTime/ei-lm-ea-popSize/ea-time-1min-10el-{data_set_name}.csv',\n",
    "            f'{input_files_path}/makespan-1minTime/ei-lm-ea-popSize/ea-time-1min-50el-{data_set_name}.csv',\n",
    "            f'{input_files_path}/makespan-1minTime/si-lm/results_bom_si_lm_{data_set_name}_1min.csv',\n",
    "            ]\n",
    "\n",
    "    print(input_files_name)\n",
    "    if input_file_name:\n",
    "        input_data = pd.read_csv(input_file_name)\n",
    "    if input_files_name:\n",
    "        list =[]\n",
    "        for file in input_files_name:\n",
    "            list.append(pd.read_csv(file))\n",
    "        input_data = pd.concat(list)\n",
    "    df = input_data[input_data[\"Bom\"].isin(data_set)]\n",
    "\n",
    "    header_line = ['Problem']\n",
    "    header_line.extend(names_alg)\n",
    "    with open(output_path, 'w', newline='') as csvfile:\n",
    "        out_file = csv.writer(csvfile, delimiter=',')\n",
    "        out_file.writerow(header_line)\n",
    "\n",
    "        for test_instance in data_set:\n",
    "            df1 = df[df[\"Bom\"].isin([test_instance])]\n",
    "            group = []\n",
    "            for alg in names_alg:\n",
    "                group.append(df1[df1[\"Algorithm\"] == alg][\"Makespan\"].values)\n",
    "                #print('-',test_instance, alg,len(group))\n",
    "            alg_ranking = [[] for alg in range(len(names_alg))]\n",
    "            for index in range(alg_repetions_no):\n",
    "                l = []\n",
    "                #print(index, group[0])\n",
    "                for index_alg in range(len(names_alg)):\n",
    "                    # print(test_instance, index_alg, names_alg[index_alg], group[index_alg], end=', ')\n",
    "                    # print(group[index_alg][index])\n",
    "                    l.append(group[index_alg][index])\n",
    "                s = pd.Series(l)\n",
    "                r = s.rank()\n",
    "                for alg in range(len(names_alg)):\n",
    "                    alg_ranking[alg].append(r[alg])\n",
    "            line = [test_instance]\n",
    "            for alg in range(len(names_alg)):\n",
    "                aux = np.array(alg_ranking[alg])\n",
    "                #print(aux)\n",
    "                line.append(aux.mean())\n",
    "            out_file.writerow(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed40c46d-b65c-46e6-9c60-8cde76eab48b",
   "metadata": {},
   "source": [
    "# Construct ranking files for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2ae4b523-4222-4dcc-8867-c3a1f8de0d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = [\"EA-Ei-LM\", \"TS-Ei-LM\", \"SA-Ei-LM\", \"EA-Ei-LM-10\", \"EA-Ei-LM-50\",\n",
    "          \"EAL-Ei-LM\", \"TSL-Ei-LM\", \"SAL-Ei-LM\", \"EAL-Ei-LM-10\", \"EAL-Ei-LM-50\",\n",
    "          \"EA-Si-LM\", \"TS-Si-LM\", \"SA-Si-LM\",\n",
    "          \"EAL-Si-LM\", \"TSL-Si-LM\", \"SAL-Si-LM\",\n",
    "          ]\n",
    "algorithms = [\"TS-Ei-LM\", \"SA-Ei-LM\", \n",
    "           \"TSL-Ei-LM\", \"SAL-Ei-LM\", \n",
    "           \"TS-Si-LM\", \"SA-Si-LM\",\n",
    "           \"TSL-Si-LM\", \"SAL-Si-LM\",\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb16e15e-3529-4af4-99de-47330de66bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_PATH='../datasets/results/ranks/runTime_1min_sa_ts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c9fd2c5e-856d-4b14-af07-901ea05b32ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets  = ['2asp', \n",
    "             'deep', \n",
    "             'wide', \n",
    "             'mixed', \n",
    "             'fjssp', \n",
    "             'dyuthi', 'dafjs','yfjs'\n",
    "            ]\n",
    "#datasets  = ['yfjs']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d457e862-519b-4dd7-8095-1fab4dd65952",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    alg_ranks_per_problem(dataset, input_files_path=\"../datasets/results\",\n",
    "                          data_set=get_instances_name(root_dir, dataset), \n",
    "                          names_alg=algorithms,\n",
    "                          output_path=f'{RESULTS_PATH}/rank_mean_{dataset}_1min_8alg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "22c19b23-7ad4-4ba9-913e-cc3e5a8d792b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../datasets/results/makespan-1minTime/ei-lm/results_bom_deep_1min.csv', '../datasets/results/makespan-1minTime/ei-lm-ea-popSize/ea-time-1min-10el-deep.csv', '../datasets/results/makespan-1minTime/ei-lm-ea-popSize/ea-time-1min-50el-deep.csv', '../datasets/results/makespan-1minTime/si-lm/results_bom_si_lm_deep_1min.csv']\n",
      "['../datasets/results/makespan-1minTime/ei-lm/results_bom_wide_1min.csv', '../datasets/results/makespan-1minTime/ei-lm-ea-popSize/ea-time-1min-10el-wide.csv', '../datasets/results/makespan-1minTime/ei-lm-ea-popSize/ea-time-1min-50el-wide.csv', '../datasets/results/makespan-1minTime/si-lm/results_bom_si_lm_wide_1min.csv']\n",
      "['../datasets/results/makespan-1minTime/ei-lm/results_bom_fjssp_1min.csv', '../datasets/results/makespan-1minTime/ei-lm-ea-popSize/ea-time-1min-10el-fjssp.csv', '../datasets/results/makespan-1minTime/ei-lm-ea-popSize/ea-time-1min-50el-fjssp.csv', '../datasets/results/makespan-1minTime/si-lm/results_bom_si_lm_fjssp_1min.csv']\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    alg_ranks_per_problem(dataset, input_files_path=\"../datasets/results\",\n",
    "                          data_set=get_instances_name(root_dir, dataset), \n",
    "                          names_alg=algorithms,\n",
    "                          output_path=f'{RESULTS_PATH}/rank_{dataset}_1min_8alg.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8900892a-3b83-462f-961b-ccb37cc90aa8",
   "metadata": {},
   "source": [
    " # Information regarding ranking files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "75f1462e-e55c-4923-b2e7-2f7cb081b95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "def all_algs_equivalent(input_directory, filter=\"*\"):\n",
    "    \"\"\"\n",
    "    identifies problems where all allgorithms are equivalent\n",
    "    \"\"\"\n",
    "    ranks_files = sorted(glob.glob(f'{input_directory}/{filter}'))\n",
    "\n",
    "    for rank_file in ranks_files:\n",
    "        print(rank_file)\n",
    "        data = pd.read_csv(rank_file)\n",
    "        data['stdev'] = data.std(axis=1, numeric_only=True)\n",
    "        #data['min'] = data.min(axis=1, numeric_only=True)\n",
    "\n",
    "        print(\"All algorithms have the same performance\\n\",data.query('stdev==0')['Problem'])\n",
    "\n",
    "        data = data.assign(Min_val = data[algorithms].min(axis=1), Min_col=data[algorithms].idxmin(axis=1))\n",
    "\n",
    "        df1 = data['Min_col'].value_counts().reset_index(name='Frequency')\n",
    "\n",
    "        print(df1)\n",
    "        #print(data)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5b5009c7-3118-42a4-92e5-7e3c5dda4164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../datasets/results/ranks/runTime_1min/rank_2asp_1min_16alg.csv\n",
      "All algorithms have the same performance\n",
      " Series([], Name: Problem, dtype: object)\n",
      "     Min_col  Frequency\n",
      "0  SAL-Ei-LM         13\n",
      "1   TS-Si-LM          9\n",
      "2  TSL-Si-LM          8\n",
      "3   SA-Si-LM          7\n",
      "4   SA-Ei-LM          7\n",
      "5  SAL-Si-LM          5\n",
      "6   TS-Ei-LM          1\n",
      "../datasets/results/ranks/runTime_1min/rank_dafjs_1min_16alg.csv\n",
      "All algorithms have the same performance\n",
      " 2    DAFJS03\n",
      "Name: Problem, dtype: object\n",
      "     Min_col  Frequency\n",
      "0   SA-Ei-LM         11\n",
      "1  SAL-Ei-LM          9\n",
      "2   EA-Ei-LM          3\n",
      "3  EAL-Si-LM          3\n",
      "4  TSL-Si-LM          2\n",
      "5   TS-Si-LM          1\n",
      "6   TS-Ei-LM          1\n",
      "../datasets/results/ranks/runTime_1min/rank_deep_1min_16alg.csv\n",
      "All algorithms have the same performance\n",
      " Series([], Name: Problem, dtype: object)\n",
      "        Min_col  Frequency\n",
      "0     SAL-Ei-LM         15\n",
      "1      SA-Ei-LM          8\n",
      "2     TSL-Ei-LM          8\n",
      "3      SA-Si-LM          4\n",
      "4  EAL-Ei-LM-10          3\n",
      "5     TSL-Si-LM          3\n",
      "6      TS-Si-LM          3\n",
      "7     SAL-Si-LM          3\n",
      "8      TS-Ei-LM          2\n",
      "9  EAL-Ei-LM-50          1\n",
      "../datasets/results/ranks/runTime_1min/rank_dyuthi_1min_16alg.csv\n",
      "All algorithms have the same performance\n",
      " Series([], Name: Problem, dtype: object)\n",
      "     Min_col  Frequency\n",
      "0   TS-Ei-LM         17\n",
      "1   SA-Ei-LM          7\n",
      "2   EA-Ei-LM          2\n",
      "3  TSL-Ei-LM          1\n",
      "4  SAL-Ei-LM          1\n",
      "../datasets/results/ranks/runTime_1min/rank_fjssp_1min_16alg.csv\n",
      "All algorithms have the same performance\n",
      " 16    la17.fjs\n",
      "19    la20.fjs\n",
      "Name: Problem, dtype: object\n",
      "     Min_col  Frequency\n",
      "0   SA-Ei-LM         15\n",
      "1  TSL-Ei-LM          9\n",
      "2  SAL-Ei-LM          9\n",
      "3   TS-Ei-LM          6\n",
      "4   EA-Ei-LM          4\n",
      "5   TS-Si-LM          3\n",
      "6  TSL-Si-LM          2\n",
      "7  SAL-Si-LM          2\n",
      "../datasets/results/ranks/runTime_1min/rank_mixed_1min_16alg.csv\n",
      "All algorithms have the same performance\n",
      " Series([], Name: Problem, dtype: object)\n",
      "     Min_col  Frequency\n",
      "0   SA-Ei-LM         13\n",
      "1  SAL-Ei-LM         12\n",
      "2   TS-Ei-LM          8\n",
      "3  SAL-Si-LM          6\n",
      "4   TS-Si-LM          4\n",
      "5   SA-Si-LM          3\n",
      "6  TSL-Si-LM          2\n",
      "7  TSL-Ei-LM          2\n",
      "../datasets/results/ranks/runTime_1min/rank_wide_1min_16alg.csv\n",
      "All algorithms have the same performance\n",
      " 7    bom_wide_2_7_20_10_No2\n",
      "Name: Problem, dtype: object\n",
      "        Min_col  Frequency\n",
      "0      SA-Ei-LM         17\n",
      "1     SAL-Ei-LM         15\n",
      "2     TSL-Ei-LM          7\n",
      "3     SAL-Si-LM          3\n",
      "4      SA-Si-LM          2\n",
      "5      EA-Ei-LM          2\n",
      "6  EAL-Ei-LM-10          2\n",
      "7      TS-Ei-LM          1\n",
      "8     TSL-Si-LM          1\n",
      "../datasets/results/ranks/runTime_1min/rank_yfjs_1min_16alg.csv\n",
      "All algorithms have the same performance\n",
      " Series([], Name: Problem, dtype: object)\n",
      "     Min_col  Frequency\n",
      "0   TS-Ei-LM          8\n",
      "1   SA-Ei-LM          8\n",
      "2  SAL-Ei-LM          4\n"
     ]
    }
   ],
   "source": [
    "all_algs_equivalent(RESULTS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fe92d347-4687-4218-9700-8e75946752c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_lehmer(sigma):\n",
    "    n = len(sigma)\n",
    "    c = []\n",
    "    c.append(0)\n",
    "    for x in range(1, n):\n",
    "        sigma_x = sigma[x]\n",
    "        c_x = 0\n",
    "        for y in range(0, x):\n",
    "            sigma_y = sigma[y]\n",
    "            if sigma_y >= sigma_x:\n",
    "                c_x += 1\n",
    "        c.append(c_x)\n",
    "    return c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "695e6143-7008-4ec4-8dac-ade03227bd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats\n",
    "def replace(row):\n",
    "    # for i, item in enumerate(row):\n",
    " \n",
    "    #     # updating the value of the row\n",
    "    #     row[i] = generate_range(item)\n",
    "    #print(\"input\", row)\n",
    "    ranks= stats.rankdata(row[1:])\n",
    "    #print(\"ranks\", ranks)\n",
    "    encode = encode_lehmer(ranks)\n",
    "    #print(\"encode\", encode)\n",
    "    for i, item in enumerate(row):\n",
    "        if i ==0: continue\n",
    "        # updating the value of the row\n",
    "        row[i] = encode[i-1]+1\n",
    "    return  row\n",
    "    \n",
    "def transform_to_lehmer_codes(input_directory, out_directory, filter=\"*\"):\n",
    "    \"\"\"\n",
    "    identifies problems where all allgorithms are equivalent\n",
    "    \"\"\"\n",
    "    ranks_files = sorted(glob.glob(f'{input_directory}/{filter}'))\n",
    "\n",
    "    for rank_file in ranks_files:\n",
    "        print(rank_file)\n",
    "        data = pd.read_csv(rank_file)\n",
    "        data = data.apply(lambda row: replace(row), axis=1)\n",
    "        name = Path(rank_file).stem\n",
    "        data.to_csv(out_directory+\"/\"+name+\".csv\", index=False)\n",
    "\n",
    "        #print(data)\n",
    "        #print(data)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fa68be13-ae05-41d7-ae5a-e43e2588cdaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../datasets/results/ranks/runTime_1min_sa_ts\\rank_2asp_1min_8alg.csv\n",
      "../datasets/results/ranks/runTime_1min_sa_ts\\rank_dafjs_1min_8alg.csv\n",
      "../datasets/results/ranks/runTime_1min_sa_ts\\rank_deep_1min_8alg.csv\n",
      "../datasets/results/ranks/runTime_1min_sa_ts\\rank_dyuthi_1min_8alg.csv\n",
      "../datasets/results/ranks/runTime_1min_sa_ts\\rank_fjssp_1min_8alg.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flavia.micota\\AppData\\Local\\Temp\\ipykernel_18164\\889238380.py:16: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  row[i] = encode[i-1]+1\n",
      "C:\\Users\\flavia.micota\\AppData\\Local\\Temp\\ipykernel_18164\\889238380.py:16: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  row[i] = encode[i-1]+1\n",
      "C:\\Users\\flavia.micota\\AppData\\Local\\Temp\\ipykernel_18164\\889238380.py:16: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  row[i] = encode[i-1]+1\n",
      "C:\\Users\\flavia.micota\\AppData\\Local\\Temp\\ipykernel_18164\\889238380.py:16: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  row[i] = encode[i-1]+1\n",
      "C:\\Users\\flavia.micota\\AppData\\Local\\Temp\\ipykernel_18164\\889238380.py:16: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  row[i] = encode[i-1]+1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../datasets/results/ranks/runTime_1min_sa_ts\\rank_mixed_1min_8alg.csv\n",
      "../datasets/results/ranks/runTime_1min_sa_ts\\rank_wide_1min_8alg.csv\n",
      "../datasets/results/ranks/runTime_1min_sa_ts\\rank_yfjs_1min_8alg.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flavia.micota\\AppData\\Local\\Temp\\ipykernel_18164\\889238380.py:16: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  row[i] = encode[i-1]+1\n",
      "C:\\Users\\flavia.micota\\AppData\\Local\\Temp\\ipykernel_18164\\889238380.py:16: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  row[i] = encode[i-1]+1\n",
      "C:\\Users\\flavia.micota\\AppData\\Local\\Temp\\ipykernel_18164\\889238380.py:16: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  row[i] = encode[i-1]+1\n"
     ]
    }
   ],
   "source": [
    "IN_PATH='../datasets/results/ranks/runTime_1min_sa_ts'\n",
    "OUT_PATH='../datasets/results/ranks/runTime_1min_sa_ts_lehmer'\n",
    "transform_to_lehmer_codes(IN_PATH, OUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b27e5b2-532e-4a0c-92c2-8621097da673",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40963735-a2a0-43a9-89f6-cbf9958f9650",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

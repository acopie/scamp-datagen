{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1f97ff2-ea35-46bd-addf-52a882beded8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14d6cf28-3294-406b-b2ed-af4ea670e5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_names = ['asp-deep','asp-wide','fjssp','Dyuthi','2asp','mixed', 'dafjs', 'yfjs']\n",
    "data_classes=list(range(len(data_names)))\n",
    "\n",
    "class InstanceClass(Enum):\n",
    "    \"\"\"\n",
    "    Enumeration that stores instance class: instances labeled by dataset (PROBLEM) or by best performing alg (ALGORITHM)\n",
    "    \"\"\"\n",
    "    PROBLEM = 1\n",
    "    ALGORTHM = 2\n",
    "\n",
    "    \n",
    "def read_info_graph(graph_type, root_path, instance_class=InstanceClass.PROBLEM):\n",
    "    \"\"\"\n",
    "    :param: type: graph attributes type (statistics, operations, disjunctive, heterogeneous)\n",
    "    :param root_path: directory for the representations\n",
    "    :param label_type: problem or best_alg\n",
    "    \"\"\"\n",
    "    if type  == \"operations\":\n",
    "        graph_type = \"operations\"\n",
    "    elif type == \"operations-quantity\":\n",
    "        graph_type = \"operations-quantity\"\n",
    "    elif type == \"operations-shared-machines\":\n",
    "        graph_type = \"operations-shared-machines\"\n",
    "    elif type == \"operations-exec-time\":\n",
    "        graph_type = \"operations-exec-time\"\n",
    "    elif type == \"disjunctive\":\n",
    "        graph_type = \"disjunctive\"\n",
    "    elif type == \"heterogeneous\":\n",
    "        graph_type = \"heterogeneous\"\n",
    "    elif type == \"statistics\":\n",
    "        graph_type = \"statistics\"\n",
    "         \n",
    "    data_deep   = pd.read_csv(f'{root_path}/{graph_type}/bom_info_graph_deep.csv')\n",
    "    data_wide   = pd.read_csv(f'{root_path}/{graph_type}/bom_info_graph_wide.csv')\n",
    "    data_fjssp  = pd.read_csv(f'{root_path}/{graph_type}/bom_info_graph_fjssp.csv')\n",
    "    data_dyuthi = pd.read_csv(f'{root_path}/{graph_type}/bom_info_graph_dyuthi.csv')\n",
    "    data_2asp   = pd.read_csv(f'{root_path}/{graph_type}/bom_info_graph_2asp.csv')\n",
    "    data_mixed  = pd.read_csv(f'{root_path}/{graph_type}/bom_info_graph_mixed.csv')\n",
    "    data_dafjs  = pd.read_csv(f'{root_path}/{graph_type}/bom_info_graph_dafjs.csv')\n",
    "    data_yfjs   = pd.read_csv(f'{root_path}/{graph_type}/bom_info_graph_yfjs.csv')\n",
    "    \n",
    "   \n",
    "    if instance_class == InstanceClass.PROBLEM:\n",
    "        data_labels = np.array([])\n",
    "        data_sets_len = [data_deep.shape[0],   data_wide.shape[0], data_fjssp.shape[0], \n",
    "                         data_dyuthi.shape[0], data_2asp.shape[0], data_mixed.shape[0],\n",
    "                         data_dafjs.shape[0],  data_yfjs.shape[0]]\n",
    "        for c in data_classes:\n",
    "            for i in range(data_sets_len[c]):\n",
    "                data_labels = np.append(data_labels, data_names[c])\n",
    "        data_labels = pd.DataFrame(data_labels)[0]\n",
    "    elif instance_class == InstanceClass.ALGORITM:\n",
    "        path = \"../datasets/results/ranks/class_alg/\"\n",
    "        class_deep   = pd.read_csv(f'{path}/class_deep.csv')\n",
    "        class_wide   = pd.read_csv(f'{path}/class_wide.csv')\n",
    "        class_fjssp  = pd.read_csv(f'{path}/class_fjssp.csv')\n",
    "        class_dyuthi = pd.read_csv(f'{path}/class_dyuthi.csv')\n",
    "        class_2asp   = pd.read_csv(f'{path}/class_2asp.csv')\n",
    "        class_mixed  = pd.read_csv(f'{path}/class_mixed.csv')\n",
    "        class_dafjs  = pd.read_csv(f'{path}/class_dafjs.csv')\n",
    "        class_yfjs   = pd.read_csv(f'{path}/class_yfjs.csv')\n",
    "\n",
    "        data_labels = pd.concat([class_deep, class_wide, class_fjssp, class_dyuthi, \n",
    "                      class_2asp, class_mixed, class_dafjs, class_yfjs], ignore_index=True)\n",
    "        data_labels = data_labels['BestAlg']\n",
    "    else:\n",
    "        raise Exception('Unknow class type')\n",
    "    \n",
    "    data = pd.concat([data_deep, data_wide, data_fjssp, data_dyuthi, \n",
    "                      data_2asp, data_mixed, data_dafjs, data_yfjs], ignore_index=True)\n",
    "\n",
    "    # print(data.columns[data.isnull().any()].tolist())\n",
    "    # df1 = data[data.isna().any(axis=1)]\n",
    "    print (data_labels)\n",
    "    return data, data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79456151-f4d1-4989-9038-73d097b5bc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_info_from_statistics_to_graph(statistics, graph):  \n",
    "     graph[\"st_depth-max\"] = statistics[\"depth_max\"]\n",
    "     graph[\"st_depth-avg\"] = statistics[\"depth_mean\"]\n",
    "     graph[\"st_depth-std\"] = statistics[\"depth_stdev\"]\n",
    "     graph[\"st_depth-q25\"] = statistics[\"depth_q25\"]\n",
    "     graph[\"st_depth-q75\"] = statistics[\"depth_q75\"]\n",
    "     \n",
    "     graph[\"st_assembly-nodes-per-manufacturing-nodes\"] = statistics[\"assembly-nodes-per-manufacturing-nodes\"]\n",
    "     return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96eb290f-d86e-4a48-aaef-8fd2d64acdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def  read_output(prefix='rank', sufix='_1min_16alg', \n",
    "                 dir_path = '../datasets/results/ranks/run_1min'):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    labels  = [\"deep\", \"wide\", \"fjssp\", \"dyuthi\", \"2asp\", \"mixed\", \"dafjs\", \"yfjs\"]\n",
    "   \n",
    "    data_deep   = pd.read_csv(f'{dir_path}/{prefix}_deep{sufix}.csv')\n",
    "    data_wide   = pd.read_csv(f'{dir_path}/{prefix}_wide{sufix}.csv')\n",
    "    data_fjssp  = pd.read_csv(f'{dir_path}/{prefix}_fjssp{sufix}.csv')\n",
    "    data_dyuthi = pd.read_csv(f'{dir_path}/{prefix}_dyuthi{sufix}.csv')\n",
    "    data_2asp   = pd.read_csv(f'{dir_path}/{prefix}_2asp{sufix}.csv')\n",
    "    data_mixed  = pd.read_csv(f'{dir_path}/{prefix}_mixed{sufix}.csv')\n",
    "    data_dafjs  = pd.read_csv(f'{dir_path}/{prefix}_dafjs{sufix}.csv')\n",
    "    data_yfjs   = pd.read_csv(f'{dir_path}/{prefix}_yfjs{sufix}.csv')\n",
    "\n",
    "    # print('r-data_deep', data_deep.shape)\n",
    "    # print('r-data_wide', data_wide.shape)\n",
    "    # print('r-data_fjssp', data_fjssp.shape)\n",
    "    # print('r-data_dyuthi', data_dyuthi.shape)\n",
    "    # print('r-data_mixed', data_mixed.shape)\n",
    "    \n",
    "    data = pd.concat([data_deep, data_wide, data_fjssp, data_dyuthi, data_2asp, \n",
    "                      data_mixed, data_dafjs, data_yfjs], ignore_index=True)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d248b5a1-41ea-48d8-a849-806fd03ca043",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_column_name(row, value, first):\n",
    "    \"\"\"\n",
    "    param row: dataframe row\n",
    "    param value: filter value for cell\n",
    "    param first: stop after first match\n",
    "    \"\"\"\n",
    "    name = []\n",
    "    for col in row.index:\n",
    "        if row[col] == value:\n",
    "            name.append(col)\n",
    "            if first: break\n",
    "    str = name[0]\n",
    "    \n",
    "    for i in range(1, len(name)):\n",
    "        str += \" & \" + name[i]\n",
    "    return str\n",
    "    \n",
    "def build_algorithm_class_label(data):\n",
    "    \"\"\"\n",
    "    data: the results dataframe\n",
    "    \"\"\"\n",
    "    data['Label'] = data.apply(find_column_name, axis=1, value=1, first=False)\n",
    "    return data['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0213a278-42ee-4284-8204-57bb55a61cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_instances_synchronization(type):\n",
    "    \"\"\"\n",
    "    Validate order of the test instances is the same in graph reeprresentation files and ranking file\n",
    "    \"\"\"\n",
    "    graphs, labels = read_info_graph(type)\n",
    "    ranks = read_output()\n",
    "    graphs_names = graphs[graphs.columns[0]]\n",
    "    ranks_names = ranks[ranks.columns[0]]\n",
    "    # graphs_names.rename(\"my_name\")  \n",
    "    # ranks_names.rename(\"my_name\")  \n",
    "    # print(graphs_names, ranks_names)\n",
    "    print('graphs_names', graphs_names.shape)\n",
    "    print('ranks_names', ranks_names.shape)\n",
    "    c=0\n",
    "    for i in range(len(ranks[ranks.columns[0]])):\n",
    "        print(c, graphs_names.iloc[i])\n",
    "        c +=1\n",
    "        if  graphs_names.iloc[i] != ranks_names.iloc[i]:\n",
    "            print( f'-{graphs_names.iloc[i]}-', f'-{ranks_names.iloc[i]}-')\n",
    "    if graphs_names.equals(ranks_names):\n",
    "        print(f'Graph representation {type} matches with ranks')\n",
    "    else:\n",
    "        print(f'Graph representation {type} DOES NOT match with ranks', graphs_names.equals(ranks_names))\n",
    "        print(graphs_names.compare(ranks_names))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70bf0772-7b90-403f-aaed-318d9bbfaef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#validate_instances_synchronization(\"statistics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7795364b-bf1e-486c-a2c4-2d2a0f9538e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_with_selected_atribute(graph_rep, scale, \n",
    "                                     feature_path = '../datasets/results/features_files/ff_septembrie/'):\n",
    "    data_all = pd.read_csv(f'{feature_path}/{graph_rep}/features_all_{scale}.csv')\n",
    "    columns_all = data_all.columns\n",
    "    selection_type = ['FS_K', 'FS_P', 'FS_S', 'LR', 'LR10', 'LR20', 'LR30', 'LR40','RF']\n",
    "    selected_features_map = {}\n",
    "    for st in selection_type:\n",
    "        presence = [0]*len(columns_all)\n",
    "        data = pd.read_csv(f'{feature_path}/{graph_rep}/features_{st}_{scale}.csv')\n",
    "        columns = data.columns\n",
    "        print(st, len(columns))\n",
    "        for c in columns:\n",
    "            for index, c_all in enumerate(columns_all):\n",
    "                if c == c_all:\n",
    "                    presence[index] = 1\n",
    "                    break\n",
    "        selected_features_map[st] = presence.copy()\n",
    "\n",
    "    \n",
    "    print(\"; \", end=\"; \")\n",
    "    for st in selection_type:\n",
    "        print(st, end=\"; \")\n",
    "    print()\n",
    "    for index, c in enumerate(columns_all):\n",
    "        print(c, end='; ')\n",
    "        for st in selection_type:\n",
    "            print(selected_features_map[st][index], end='; ')\n",
    "        print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bf5105c-ab11-4845-bada-18513398833f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#get_table_with_selected_atribute(\"HG\", \"minMaxIn01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74eeacbe-78eb-4ddc-a7e1-47d2aaf28d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_X_train= [184, 171, 142,  12, 117, 217,   3, 139, 229,  31,  66, 248, 254, 228, 187, 151,  49,  14,\n",
    "                  47,  95, 244,   8,  78, 247,  42,  57, 246, 120,  39,  68, 167,  46, 190, 148, 216,  44,\n",
    "                 158, 192,  76, 153,  15, 157, 241, 196,  82, 127, 122,   9, 181,  40,  69, 258,  38, 249,\n",
    "                  71, 237, 163, 168, 116, 175,  36,  33, 129, 234,  97, 179,   4, 222, 104,  87, 195,  63,\n",
    "                   7, 256, 178, 215,  45, 199, 159,  19, 188, 137,  85, 100, 259, 134, 102, 252,  29,  13,\n",
    "                  52,   1, 180, 155, 113, 267, 223,  58, 160, 218, 150,  53, 119,  86,  26, 118, 110, 238,\n",
    "                 269, 200, 250, 169, 277, 174, 162, 227, 275, 260, 182,  84,  72, 232, 135, 211, 166, 197,\n",
    "                 138, 109, 202, 204,  65, 272,  62,  93,  70, 124, 145,  21, 276,  77, 101, 152, 154, 133,\n",
    "                 136, 209, 183, 266,  20, 268,  24, 203, 265, 251,  94, 236,  89, 233,  96, 132, 239,  54,\n",
    "                  90, 206, 235, 224,  67, 219, 107, 173, 103,   2,  51, 255,  30, 221,  74, 231, 126,  28,\n",
    "                 144,   5, 214, 115, 253, 176,  43, 170,  17,  60,  59,  18, 261, 146,  83,  23,  75, 114,\n",
    "                 274, 164,  81, 185,  48,  88,  79, 193,  25, 147,  56, 172,  37, 198,  35, 212,  10, 230,\n",
    "                 186,  41, 123,  50, 106, 271]\n",
    "idx_X_test= [ 22,  32, 143, 105, 270,  99, 207,  16, 201, 156, 125, 264, 263,   6, 213, 111, 257,  73,\n",
    "             141, 121, 177, 225, 226, 243, 210,  55,  98, 112, 131,  91,   0, 161, 205,  34, 189,  11,\n",
    "             140, 242, 245,  61, 240, 273,  80, 165,  92, 149, 194, 128, 220, 208, 191,  64, 108, 130,\n",
    "             262,  27]\n",
    "\n",
    "def build_labels_train_test(labels, index_test_instances):\n",
    "    for index in index_test_instances:\n",
    "        labels[index] = 6\n",
    "    return labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c07f6c-eaac-433f-9058-aa7c32438806",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c19f3f61-b4c8-4747-a7c8-d01be9493341",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from functools import reduce\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1aa72a5c-127c-44ce-ad39-8aa61f5731a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH='../datasets/results/ranks/'\n",
    "algorithms = [\"EA-Ei-LM\", \"TS-Ei-LM\", \"SA-Ei-LM\", \"EA-Ei-LM-10\", \"EA-Ei-LM-50\",\n",
    "          \"EAL-Ei-LM\", \"TSL-Ei-LM\", \"SAL-Ei-LM\", \"EAL-Ei-LM-10\", \"EAL-Ei-LM-50\",\n",
    "          \"EA-Si-LM\", \"TS-Si-LM\", \"SA-Si-LM\",\n",
    "          \"EAL-Si-LM\", \"TSL-Si-LM\", \"SAL-Si-LM\",\n",
    "          ]\n",
    "algorithms_ts_sa = [\"TS-Ei-LM\", \"SA-Ei-LM\", \n",
    "           \"TSL-Ei-LM\", \"SAL-Ei-LM\", \n",
    "           \"TS-Si-LM\", \"SA-Si-LM\",\n",
    "           \"TSL-Si-LM\", \"SAL-Si-LM\",\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36d989ed-8f27-4d7b-af81-e7b85b556036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equivalent_algorithms(input_directory, filter=\"*\"):\n",
    "    \"\"\"\n",
    "    identifies problems where all algorithms are equivalent\n",
    "    \"\"\"\n",
    "    ranks_files = sorted(glob.glob(f'{input_directory}/{filter}'))\n",
    "\n",
    "    info = {'dataset':[], 'dataset_size':[], 'all_algs_eqivalent':[], 'istances_name': []}\n",
    "    for rank_file in ranks_files:\n",
    "        #print(rank_file)\n",
    "        data = pd.read_csv(rank_file)\n",
    "        data['stdev'] = data.std(axis=1, numeric_only=True)\n",
    "        \n",
    "        df = data.query('stdev==0')\n",
    "        #print(f\"All algorithms have the same performance {df.shape[0]}\\n\",df['Problem'])\n",
    "\n",
    "        info['dataset'].append(Path(rank_file).stem.split(\"_\")[1])\n",
    "        info['dataset_size'].append(data.shape[0])\n",
    "        info['all_algs_eqivalent'].append(df.shape[0])\n",
    "        info['istances_name'].append(list(df['Problem']))\n",
    "\n",
    "    #print(pd.DataFrame(info))\n",
    "    return info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "730825aa-d363-4caf-b9a6-3023e2c72f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = equivalent_algorithms(f'{ROOT_PATH}/runTime_1min_sa_ts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2cff923-bcc3-4383-87b3-0ed2b6b10a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_instances(input_directory, output_directory, \n",
    "                     ranks_directory, filter=\"*\", instance_id_key='Problem'):\n",
    "    \"\"\"\n",
    "    input_directory: - directory with all instances ranking\n",
    "    output_directory: -ddirectory to store filteed instances\n",
    "    \"\"\"\n",
    "    Path(output_directory).mkdir(exist_ok=True)\n",
    "    \n",
    "    ranks_files = sorted(glob.glob(f'{input_directory}/{filter}'))\n",
    "    \n",
    "    equivalent_algs = pd.DataFrame(equivalent_algorithms(ranks_directory))\n",
    "    list_instances = list(equivalent_algs['istances_name'])\n",
    "    list_instances = reduce(operator.concat, list_instances)\n",
    "    print(list_instances)\n",
    "    \n",
    "    for rank_file in ranks_files:\n",
    "        print(rank_file)\n",
    "        data = pd.read_csv(rank_file)\n",
    "        print(data.shape)\n",
    "        data  = data.query(f'{instance_id_key} not in @list_instances')\n",
    "        fileName = Path(rank_file).name\n",
    "        data.to_csv(f'{output_directory}/{fileName}', index=False)\n",
    "        print(data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c7831630-06c7-480c-9a54-3182a82d0ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DAFJS03', 'DAFJS04', 'DAFJS08', 'P1', 'P11', 'P15', 'P17', 'P18', 'P2', 'P24', 'P25', 'P26', 'P27', 'P3', 'P4', 'P5', 'P6', 'P7', 'P9', 'la16.fjs', 'la17.fjs', 'la18.fjs', 'la20.fjs', 'bom_wide_2_10_10_5_No2', 'bom_wide_2_7_20_10_No2', 'bom_wide_2_7_20_5_No2', 'YFJS01', 'YFJS04', 'YFJS08', 'YFJS09', 'YFJS10', 'YFJS14']\n",
      "../datasets/results/ranks//runTime_1min_sa_ts/rank_2asp_1min_8alg.csv\n",
      "(50, 9)\n",
      "(50, 9)\n",
      "../datasets/results/ranks//runTime_1min_sa_ts/rank_dafjs_1min_8alg.csv\n",
      "(30, 9)\n",
      "(27, 9)\n",
      "../datasets/results/ranks//runTime_1min_sa_ts/rank_deep_1min_8alg.csv\n",
      "(50, 9)\n",
      "(50, 9)\n",
      "../datasets/results/ranks//runTime_1min_sa_ts/rank_dyuthi_1min_8alg.csv\n",
      "(28, 9)\n",
      "(12, 9)\n",
      "../datasets/results/ranks//runTime_1min_sa_ts/rank_fjssp_1min_8alg.csv\n",
      "(50, 9)\n",
      "(46, 9)\n",
      "../datasets/results/ranks//runTime_1min_sa_ts/rank_mixed_1min_8alg.csv\n",
      "(50, 9)\n",
      "(50, 9)\n",
      "../datasets/results/ranks//runTime_1min_sa_ts/rank_wide_1min_8alg.csv\n",
      "(50, 9)\n",
      "(47, 9)\n",
      "../datasets/results/ranks//runTime_1min_sa_ts/rank_yfjs_1min_8alg.csv\n",
      "(20, 9)\n",
      "(14, 9)\n"
     ]
    }
   ],
   "source": [
    "remove_instances(f'{ROOT_PATH}/runTime_1min_sa_ts', \n",
    "                 f'{ROOT_PATH}/runTime_1min_sa_ts_filtered',\n",
    "                 f'{ROOT_PATH}/runTime_1min_sa_ts')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "2f2cc0e8-6ab2-42ed-afb5-c6ffd6065398",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilabel_output(input_directory, filter=\"*\", remove_all_eq_alg=False, alg_no=8):\n",
    "    \"\"\"\n",
    "    transform rank in binary\n",
    "    \"\"\"\n",
    "    ranks_files = sorted(glob.glob(f'{input_directory}/{filter}'))\n",
    "\n",
    "    all_binary = pd.DataFrame()\n",
    "    all_data =  pd.DataFrame()\n",
    "\n",
    "    for rank_file in ranks_files:\n",
    "        print(rank_file)\n",
    "        data = pd.read_csv(rank_file)\n",
    "\n",
    "        #transform rank to binary for multilabel\n",
    "        df_binary = data.iloc[:,1:].apply(lambda row: row.apply(lambda x: 1 if x==min(row) else 0), axis=1)\n",
    "\n",
    "        #add instance name column\n",
    "        data = pd.concat([data['Problem'], df_binary], axis=1)\n",
    "\n",
    "        #number of algorithms that are equivalent / row\n",
    "        data['Sum'] = data.iloc[:,1:].sum(axis=1)\n",
    "        data['Dataset'] = Path(rank_file).stem.split(\"_\")[1]\n",
    "\n",
    "        if remove_all_eq_alg:\n",
    "            data = data.query(f'Sum<{alg_no}')\n",
    "       \n",
    "        print(data[data['Sum']>1][['Problem', 'Sum']])\n",
    "        all_binary = pd.concat([all_binary, df_binary])\n",
    "        all_data = pd.concat([all_data, data])\n",
    "        \n",
    "    #for each algorithm find how may times is the best strategy    \n",
    "    aa = all_binary.sum()\n",
    "    print((aa / all_binary.shape[0]) * 100)\n",
    "\n",
    "    \n",
    "    df = all_data.sort_values(['Dataset', 'Sum'], ascending=[True, True])\n",
    "\n",
    "    # get first k rows from a group\n",
    "    # first_rows = df.groupby('Dataset').apply(lambda x: x.iloc[:12]).reset_index(drop=True)\n",
    "    # print(list(first_rows['Problem']))\n",
    "    # print(first_rows.groupby(['Dataset'])['Dataset'].count())\n",
    "    \n",
    "    print(\"Dataset instances no\")\n",
    "    print(all_data.groupby(['Dataset'])['Dataset'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "8b3b3b71-10df-4ff5-ab33-4e8dd59a469b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../datasets/results/ranks//runTime_1min_sa_ts/rank_2asp_1min_8alg.csv\n",
      "Empty DataFrame\n",
      "Columns: [Problem, Sum]\n",
      "Index: []\n",
      "../datasets/results/ranks//runTime_1min_sa_ts/rank_dafjs_1min_8alg.csv\n",
      "    Problem  Sum\n",
      "4   DAFJS05    2\n",
      "10  DAFJS11    2\n",
      "14  DAFJS15    2\n",
      "18  DAFJS19    2\n",
      "21  DAFJS22    2\n",
      "22  DAFJS23    2\n",
      "../datasets/results/ranks//runTime_1min_sa_ts/rank_deep_1min_8alg.csv\n",
      "                    Problem  Sum\n",
      "1    bom_deep_10_3_10_5_No2    2\n",
      "9   bom_deep_10_5_30_15_No2    2\n",
      "17   bom_deep_6_5_20_10_No2    2\n",
      "38    bom_deep_8_5_10_5_No1    2\n",
      "49   bom_deep_9_5_30_15_No2    2\n",
      "../datasets/results/ranks//runTime_1min_sa_ts/rank_dyuthi_1min_8alg.csv\n",
      "   Problem  Sum\n",
      "1      P10    5\n",
      "3      P12    4\n",
      "4      P13    2\n",
      "5      P14    6\n",
      "7      P16    4\n",
      "10     P19    2\n",
      "13     P21    4\n",
      "15     P23    2\n",
      "20     P28    3\n",
      "26      P8    2\n",
      "../datasets/results/ranks//runTime_1min_sa_ts/rank_fjssp_1min_8alg.csv\n",
      "                        Problem  Sum\n",
      "11                     la12.fjs    3\n",
      "12                     la13.fjs    2\n",
      "18                     la19.fjs    4\n",
      "22                     la23.fjs    2\n",
      "35                     la36.fjs    5\n",
      "36                     la37.fjs    4\n",
      "37                     la38.fjs    6\n",
      "38                     la39.fjs    5\n",
      "39                     la40.fjs    6\n",
      "42  bom_fjssp_10_5_15_50_10_No1    2\n",
      "../datasets/results/ranks//runTime_1min_sa_ts/rank_mixed_1min_8alg.csv\n",
      "                    Problem  Sum\n",
      "28  bom_mix_2_8_6_60_10_No1    2\n",
      "40  bom_mix_2_3_7_50_10_No1    2\n",
      "../datasets/results/ranks//runTime_1min_sa_ts/rank_wide_1min_8alg.csv\n",
      "                    Problem  Sum\n",
      "8     bom_wide_2_7_20_5_No1    4\n",
      "14  bom_wide_3_10_30_15_No1    2\n",
      "20    bom_wide_3_8_15_5_No1    2\n",
      "37   bom_wide_5_10_10_5_No2    2\n",
      "../datasets/results/ranks//runTime_1min_sa_ts/rank_yfjs_1min_8alg.csv\n",
      "   Problem  Sum\n",
      "1   YFJS02    7\n",
      "2   YFJS03    5\n",
      "12  YFJS13    3\n",
      "14  YFJS15    2\n",
      "16  YFJS17    2\n",
      "17  YFJS18    2\n",
      "18  YFJS19    2\n",
      "TS-Ei-LM     16.158537\n",
      "SA-Ei-LM     36.280488\n",
      "TSL-Ei-LM    23.475610\n",
      "SAL-Ei-LM    44.207317\n",
      "TS-Si-LM     17.987805\n",
      "SA-Si-LM     18.597561\n",
      "TSL-Si-LM    19.207317\n",
      "SAL-Si-LM    19.207317\n",
      "dtype: float64\n",
      "Dataset instances no\n",
      "Dataset\n",
      "2asp      50\n",
      "dafjs     27\n",
      "deep      50\n",
      "dyuthi    12\n",
      "fjssp     46\n",
      "mixed     50\n",
      "wide      47\n",
      "yfjs      14\n",
      "Name: Dataset, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "multilabel_output(f'{ROOT_PATH}/runTime_1min_sa_ts', remove_all_eq_alg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c84bef1-a820-409c-829a-bc8cf3c1d32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_multilabel(input_directory, output_directory,  filter=\"*\"):\n",
    "    \"\"\"\n",
    "    Transform ranking files to multilabel\n",
    "    \n",
    "    input_directory: - directory with all instances ranking\n",
    "    output_directory: -ddirectory to store filteed instances\n",
    "    \"\"\"\n",
    "    Path(output_directory).mkdir(exist_ok=True)\n",
    "\n",
    "    ranks_files = sorted(glob.glob(f'{input_directory}/{filter}'))\n",
    "\n",
    "    for rank_file in ranks_files:\n",
    "        print(rank_file)\n",
    "        data = pd.read_csv(rank_file)\n",
    "\n",
    "        #transform rank to binary for multilabel\n",
    "        df_binary = data.iloc[:,1:].apply(lambda row: row.apply(lambda x: 1 if x==min(row) else 0), axis=1)\n",
    "\n",
    "        #add instance name column\n",
    "        data = pd.concat([data['Problem'], df_binary], axis=1)\n",
    "\n",
    "        #save file\n",
    "        fileName = Path(rank_file).name\n",
    "        data.to_csv(f'{output_directory}/{fileName}', index=False)\n",
    "\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "def wilcoxon_test(data1, data2, label):\n",
    "    stat, p = wilcoxon(data1, data2)\n",
    "    \n",
    "    # Display results\n",
    "    # print(f'Wilcoxon Statistic ({label}): {stat}')\n",
    "    # print(f'P-value ({label}): {p}')\n",
    "    \n",
    "    # Interpretation\n",
    "    alpha = 0.05\n",
    "    if p < alpha:\n",
    "        return p, \"yes\"\n",
    "        #print(\"Reject the null hypothesis: Significant difference between datasets\")\n",
    "    else:\n",
    "        return p, \"no\"\n",
    "        #print(\"Fail to reject the null hypothesis: No significant difference\")\n",
    "        \n",
    "import re\n",
    "def get_dataset_name(dataset_file_name):\n",
    "    pattern = r\"rank_([a-zA-Z0-9]+)_1min_8alg\"\n",
    "    match = re.match(pattern, dataset_file_name)\n",
    "    \n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return None\n",
    "\n",
    "def build_df_wilcoxon_row(data, dataset_name):\n",
    "    row_df_wilcoxon =[dataset_name]\n",
    "        \n",
    "    strategy_SA = [\"SA-Ei-LM\", \"SAL-Ei-LM\", \"SA-Si-LM\", \"SAL-Si-LM\"]\n",
    "    strategy_TS = [\"TS-Ei-LM\", \"TSL-Ei-LM\", \"TS-Si-LM\", \"TSL-Si-LM\"]\n",
    "    data['strategy-sa'] = data[strategy_SA].mean(axis=1)\n",
    "    data['strategy-ts'] = data[strategy_TS].mean(axis=1)\n",
    "    p, rez = wilcoxon_test(data['strategy-sa'], data['strategy-ts'], 'staregy SAvsTS')\n",
    "    row_df_wilcoxon.extend([p, rez])\n",
    "\n",
    "    initialization_letsa  = [\"TSL-Ei-LM\", \"SAL-Ei-LM\", \"TSL-Si-LM\", \"SAL-Si-LM\"]\n",
    "    initialization_random = [\"TS-Ei-LM\", \"SA-Ei-LM\", \"TS-Si-LM\", \"SA-Si-LM\"]\n",
    "    data['init-letsa']  = data[initialization_letsa].mean(axis=1)\n",
    "    data['init-random'] = data[initialization_random].mean(axis=1)\n",
    "    p, rez = wilcoxon_test(data['init-letsa'], data['init-random'], 'init LETSAvsRandom')\n",
    "    row_df_wilcoxon.extend([p, rez])\n",
    "    \n",
    "    perturbation_ei = [\"TS-Ei-LM\", \"SA-Ei-LM\", \"TSL-Ei-LM\", \"SAL-Ei-LM\"]\n",
    "    perturbation_si = [\"TS-Si-LM\", \"SA-Si-LM\", \"TSL-Si-LM\", \"SAL-Si-LM\"]\n",
    "    data['perturbation_ei']  = data[perturbation_ei].mean(axis=1)\n",
    "    data['perturbation_si'] = data[perturbation_si].mean(axis=1)\n",
    "    p, rez = wilcoxon_test(data['perturbation_ei'], data['perturbation_si'], 'perturbation EivsSi')\n",
    "    row_df_wilcoxon.extend([p, rez])\n",
    "    \n",
    "    return row_df_wilcoxon, data\n",
    "                        \n",
    "def generate_agregated_multilabel(input_directory, output_directory,  filter=\"*\"):\n",
    "    \"\"\"\n",
    "    Transform ranking files to multilabel using 3 agregation (heuristic method, initialization, perturbation)\n",
    "    \n",
    "    input_directory: - directory with all instances ranking\n",
    "    output_directory: -directory to store filtered instances\n",
    "    \"\"\"\n",
    "    Path(output_directory).mkdir(exist_ok=True)\n",
    "\n",
    "    ranks_files = sorted(glob.glob(f'{input_directory}/{filter}'))\n",
    "\n",
    "    df_wilcoxon = pd.DataFrame(columns=['DataSet', \n",
    "                                       'staregy SAvsTS -pval', 'staregy SAvsTS - Significant difference',\n",
    "                                       'init LETSAvsRandom - pval', 'init LETSAvsRandom - Significant difference',\n",
    "                                       'perturbation EivsSi - pval', 'perturbation EivsSi - Significant difference'])\n",
    "\n",
    "    df_all = pd.DataFrame()\n",
    "    for rank_file in ranks_files:\n",
    "        print(rank_file)\n",
    "        data = pd.read_csv(rank_file)\n",
    "        df_wilcoxon.loc[len(df_wilcoxon)],data = build_df_wilcoxon_row(data, get_dataset_name(Path(rank_file).name))\n",
    "        df_all = pd.concat([df_all, data], ignore_index=True)\n",
    "\n",
    "        #save file\n",
    "        fileName = Path(rank_file).name\n",
    "        data[['Problem', 'strategy-sa','strategy-ts', 'init-letsa','init-random','perturbation_ei','perturbation_si']].to_csv(f'{output_directory}/{fileName}', index=False)\n",
    "\n",
    "    df_wilcoxon.loc[len(df_wilcoxon)], df_all = build_df_wilcoxon_row(df_all, 'all')\n",
    "\n",
    "    print(df_wilcoxon)\n",
    "\n",
    "def find_value(row, name1, name2):\n",
    "    val1 = row[name1]\n",
    "    val2 = row[name2]\n",
    "    if val1 == val2: return 2 \n",
    "    elif val1 < val2: return 0\n",
    "    else: return 1\n",
    "    \n",
    "\n",
    "def generate_agregated_multilabel_binary(input_directory, output_directory,  filter=\"*\", multilabel=False):\n",
    "    \"\"\"\n",
    "    Transform ranking files to multilabel using 3 agregation (heuristic method, initialization, perturbation)\n",
    "    \n",
    "    input_directory: - directory with all instances ranking\n",
    "    output_directory: -ddirectory to store filtered instances\n",
    "    \"\"\"\n",
    "    Path(output_directory).mkdir(exist_ok=True)\n",
    "\n",
    "    ranks_files = sorted(glob.glob(f'{input_directory}/{filter}'))\n",
    "\n",
    "    df_all = pd.DataFrame()\n",
    "    for rank_file in ranks_files:\n",
    "        print(rank_file)\n",
    "        data = pd.read_csv(rank_file)\n",
    "\n",
    "        #transform rank to binary for multilabel\n",
    "        df_binary = data.iloc[:,1:].apply(lambda row: row.apply(lambda x: 1 if x==min(row) else 0), axis=1)\n",
    "\n",
    "        strategy_SA = [\"SA-Ei-LM\", \"SAL-Ei-LM\", \"SA-Si-LM\", \"SAL-Si-LM\"]\n",
    "        strategy_TS = [\"TS-Ei-LM\", \"TSL-Ei-LM\", \"TS-Si-LM\", \"TSL-Si-LM\"]\n",
    "        df_binary['strategy-sa'] = df_binary[strategy_SA].sum(axis=1)\n",
    "        df_binary['strategy-ts'] = df_binary[strategy_TS].sum(axis=1)\n",
    "        df_binary['stategy'] = df_binary.apply(find_value, axis=1, name1='strategy-sa', name2='strategy-ts')\n",
    "        # p, rez = wilcoxon_test(data['strategy-sa'], data['strategy-ts'], 'staregy SAvsTS')\n",
    "        # row_df_wilcoxon.extend([p, rez])\n",
    "    \n",
    "        initialization_letsa  = [\"TSL-Ei-LM\", \"SAL-Ei-LM\", \"TSL-Si-LM\", \"SAL-Si-LM\"]\n",
    "        initialization_random = [\"TS-Ei-LM\", \"SA-Ei-LM\", \"TS-Si-LM\", \"SA-Si-LM\"]\n",
    "        df_binary['init-letsa']  = df_binary[initialization_letsa].sum(axis=1)\n",
    "        df_binary['init-random'] = df_binary[initialization_random].sum(axis=1)\n",
    "        df_binary['init'] = df_binary.apply(find_value, axis=1, name1='init-letsa', name2='init-random')\n",
    "\n",
    "        # p, rez = wilcoxon_test(data['init-letsa'], data['init-random'], 'init LETSAvsRandom')\n",
    "        # row_df_wilcoxon.extend([p, rez])\n",
    "        \n",
    "        perturbation_ei = [\"TS-Ei-LM\", \"SA-Ei-LM\", \"TSL-Ei-LM\", \"SAL-Ei-LM\"]\n",
    "        perturbation_si = [\"TS-Si-LM\", \"SA-Si-LM\", \"TSL-Si-LM\", \"SAL-Si-LM\"]\n",
    "        df_binary['perturbation_ei']  = df_binary[perturbation_ei].sum(axis=1)\n",
    "        df_binary['perturbation_si'] = df_binary[perturbation_si].sum(axis=1)\n",
    "        df_binary['perturbation'] = df_binary.apply(find_value, axis=1, name1='perturbation_ei', name2='perturbation_si')\n",
    "\n",
    "    \n",
    "        #add instance name column\n",
    "        data = pd.concat([data['Problem'], df_binary], axis=1)\n",
    "        \n",
    "        df_all = pd.concat([df_all, data], ignore_index=True)\n",
    "\n",
    "        #save file\n",
    "        fileName = Path(rank_file).name\n",
    "        if multilabel:\n",
    "            data[['Problem', 'stategy', 'init', 'perturbation']].to_csv(f'{output_directory}/{fileName}', index=False)\n",
    "        else:\n",
    "            data.to_csv(f'{output_directory}/{fileName}', index=False)\n",
    "\n",
    "    # df_wilcoxon.loc[len(df_wilcoxon)] = build_df_wilcoxon_row(df_all, 'all')\n",
    "\n",
    "    # print(df_wilcoxon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fd85006-0e05-45c7-837e-8b2834564749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../datasets/results/ranks//runTime_1min_sa_ts\\rank_2asp_1min_8alg.csv\n",
      "../datasets/results/ranks//runTime_1min_sa_ts\\rank_dafjs_1min_8alg.csv\n",
      "../datasets/results/ranks//runTime_1min_sa_ts\\rank_deep_1min_8alg.csv\n",
      "../datasets/results/ranks//runTime_1min_sa_ts\\rank_dyuthi_1min_8alg.csv\n",
      "../datasets/results/ranks//runTime_1min_sa_ts\\rank_fjssp_1min_8alg.csv\n",
      "../datasets/results/ranks//runTime_1min_sa_ts\\rank_mixed_1min_8alg.csv\n",
      "../datasets/results/ranks//runTime_1min_sa_ts\\rank_wide_1min_8alg.csv\n",
      "../datasets/results/ranks//runTime_1min_sa_ts\\rank_yfjs_1min_8alg.csv\n",
      "  DataSet  staregy SAvsTS -pval staregy SAvsTS - Significant difference  \\\n",
      "0    2asp          5.335711e-01                                      no   \n",
      "1   dafjs          7.269918e-05                                     yes   \n",
      "2    deep          1.422338e-03                                     yes   \n",
      "3  dyuthi          2.661661e-01                                      no   \n",
      "4   fjssp          3.641284e-02                                     yes   \n",
      "5   mixed          3.716661e-02                                     yes   \n",
      "6    wide          3.684800e-06                                     yes   \n",
      "7    yfjs          2.329440e-03                                     yes   \n",
      "8     all          2.002602e-12                                     yes   \n",
      "\n",
      "   init LETSAvsRandom - pval init LETSAvsRandom - Significant difference  \\\n",
      "0               5.405748e-01                                          no   \n",
      "1               4.232408e-01                                          no   \n",
      "2               1.780525e-05                                         yes   \n",
      "3               6.460336e-01                                          no   \n",
      "4               3.215198e-05                                         yes   \n",
      "5               7.667327e-01                                          no   \n",
      "6               1.745130e-03                                         yes   \n",
      "7               1.860293e-02                                         yes   \n",
      "8               4.138225e-08                                         yes   \n",
      "\n",
      "   perturbation EivsSi - pval perturbation EivsSi - Significant difference  \n",
      "0                3.881775e-01                                           no  \n",
      "1                5.612596e-02                                           no  \n",
      "2                1.192392e-09                                          yes  \n",
      "3                3.665793e-02                                          yes  \n",
      "4                2.997144e-06                                          yes  \n",
      "5                1.135862e-03                                          yes  \n",
      "6                2.038969e-08                                          yes  \n",
      "7                2.092317e-03                                          yes  \n",
      "8                3.214468e-16                                          yes  \n",
      "['DAFJS03', 'DAFJS04', 'DAFJS08', 'P1', 'P11', 'P15', 'P17', 'P18', 'P2', 'P24', 'P25', 'P26', 'P27', 'P3', 'P4', 'P5', 'P6', 'P7', 'P9', 'la16.fjs', 'la17.fjs', 'la18.fjs', 'la20.fjs', 'bom_wide_2_10_10_5_No2', 'bom_wide_2_7_20_10_No2', 'bom_wide_2_7_20_5_No2', 'YFJS01', 'YFJS04', 'YFJS08', 'YFJS09', 'YFJS10', 'YFJS14']\n",
      "../datasets/results/ranks//runTime_1min_sa_ts_agregated_multilabel\\rank_2asp_1min_8alg.csv\n",
      "(50, 7)\n",
      "(50, 7)\n",
      "../datasets/results/ranks//runTime_1min_sa_ts_agregated_multilabel\\rank_dafjs_1min_8alg.csv\n",
      "(30, 7)\n",
      "(27, 7)\n",
      "../datasets/results/ranks//runTime_1min_sa_ts_agregated_multilabel\\rank_deep_1min_8alg.csv\n",
      "(50, 7)\n",
      "(50, 7)\n",
      "../datasets/results/ranks//runTime_1min_sa_ts_agregated_multilabel\\rank_dyuthi_1min_8alg.csv\n",
      "(28, 7)\n",
      "(12, 7)\n",
      "../datasets/results/ranks//runTime_1min_sa_ts_agregated_multilabel\\rank_fjssp_1min_8alg.csv\n",
      "(50, 7)\n",
      "(46, 7)\n",
      "../datasets/results/ranks//runTime_1min_sa_ts_agregated_multilabel\\rank_mixed_1min_8alg.csv\n",
      "(50, 7)\n",
      "(50, 7)\n",
      "../datasets/results/ranks//runTime_1min_sa_ts_agregated_multilabel\\rank_wide_1min_8alg.csv\n",
      "(50, 7)\n",
      "(47, 7)\n",
      "../datasets/results/ranks//runTime_1min_sa_ts_agregated_multilabel\\rank_yfjs_1min_8alg.csv\n",
      "(20, 7)\n",
      "(14, 7)\n"
     ]
    }
   ],
   "source": [
    "# generate_agregated_multilabel(f'{ROOT_PATH}/runTime_1min_sa_ts', \n",
    "#                     f'{ROOT_PATH}/runTime_1min_sa_ts_agredated'\n",
    "#                     )\n",
    "# generate_agregated_multilabel_binary(f'{ROOT_PATH}/runTime_1min_sa_ts', \n",
    "#                     f'{ROOT_PATH}/runTime_1min_sa_ts_agredated_binary'\n",
    "#                     )\n",
    "\n",
    "generate_agregated_multilabel(f'{ROOT_PATH}/runTime_1min_sa_ts', \n",
    "                    f'{ROOT_PATH}/runTime_1min_sa_ts_agregated_multilabel')#,\n",
    "                    #multilabel=True)\n",
    "\n",
    "remove_instances(f'{ROOT_PATH}/runTime_1min_sa_ts_agregated_multilabel', \n",
    "                 f'{ROOT_PATH}/runTime_1min_sa_ts_agregated_multilabel_filtered',\n",
    "                 f'{ROOT_PATH}/runTime_1min_sa_ts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c7d5ae1d-111b-4e38-98db-4cb2d5796f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DAFJS03', 'DAFJS04', 'DAFJS08', 'P1', 'P11', 'P15', 'P17', 'P18', 'P2', 'P24', 'P25', 'P26', 'P27', 'P3', 'P4', 'P5', 'P6', 'P7', 'P9', 'la16.fjs', 'la17.fjs', 'la18.fjs', 'la20.fjs', 'bom_wide_2_10_10_5_No2', 'bom_wide_2_7_20_10_No2', 'bom_wide_2_7_20_5_No2', 'YFJS01', 'YFJS04', 'YFJS08', 'YFJS09', 'YFJS10', 'YFJS14']\n",
      "../datasets/results/ranks//runTime_1min_sa_ts_lehmer\\rank_2asp_1min_8alg.csv\n",
      "(50, 9)\n",
      "(50, 9)\n",
      "../datasets/results/ranks//runTime_1min_sa_ts_lehmer\\rank_dafjs_1min_8alg.csv\n",
      "(30, 9)\n",
      "(27, 9)\n",
      "../datasets/results/ranks//runTime_1min_sa_ts_lehmer\\rank_deep_1min_8alg.csv\n",
      "(50, 9)\n",
      "(50, 9)\n",
      "../datasets/results/ranks//runTime_1min_sa_ts_lehmer\\rank_dyuthi_1min_8alg.csv\n",
      "(28, 9)\n",
      "(12, 9)\n",
      "../datasets/results/ranks//runTime_1min_sa_ts_lehmer\\rank_fjssp_1min_8alg.csv\n",
      "(50, 9)\n",
      "(46, 9)\n",
      "../datasets/results/ranks//runTime_1min_sa_ts_lehmer\\rank_mixed_1min_8alg.csv\n",
      "(50, 9)\n",
      "(50, 9)\n",
      "../datasets/results/ranks//runTime_1min_sa_ts_lehmer\\rank_wide_1min_8alg.csv\n",
      "(50, 9)\n",
      "(47, 9)\n",
      "../datasets/results/ranks//runTime_1min_sa_ts_lehmer\\rank_yfjs_1min_8alg.csv\n",
      "(20, 9)\n",
      "(14, 9)\n"
     ]
    }
   ],
   "source": [
    "remove_instances(f'{ROOT_PATH}/runTime_1min_sa_ts_lehmer', \n",
    "                 f'{ROOT_PATH}/runTime_1min_sa_ts_lehmer_filtered',\n",
    "                 f'{ROOT_PATH}/runTime_1min_sa_ts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "9c442e9e-e6ba-4716-8901-b616ebde494f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../datasets/results/ranks//runTime_1min_sa_ts/rank_2asp_1min_8alg.csv\n",
      "../datasets/results/ranks//runTime_1min_sa_ts/rank_dafjs_1min_8alg.csv\n",
      "../datasets/results/ranks//runTime_1min_sa_ts/rank_deep_1min_8alg.csv\n",
      "../datasets/results/ranks//runTime_1min_sa_ts/rank_dyuthi_1min_8alg.csv\n",
      "../datasets/results/ranks//runTime_1min_sa_ts/rank_fjssp_1min_8alg.csv\n",
      "../datasets/results/ranks//runTime_1min_sa_ts/rank_mixed_1min_8alg.csv\n",
      "../datasets/results/ranks//runTime_1min_sa_ts/rank_wide_1min_8alg.csv\n",
      "../datasets/results/ranks//runTime_1min_sa_ts/rank_yfjs_1min_8alg.csv\n",
      "['DAFJS03', 'DAFJS04', 'DAFJS08', 'P1', 'P11', 'P15', 'P17', 'P18', 'P2', 'P24', 'P25', 'P26', 'P27', 'P3', 'P4', 'P5', 'P6', 'P7', 'P9', 'la16.fjs', 'la17.fjs', 'la18.fjs', 'la20.fjs', 'bom_wide_2_10_10_5_No2', 'bom_wide_2_7_20_10_No2', 'bom_wide_2_7_20_5_No2', 'YFJS01', 'YFJS04', 'YFJS08', 'YFJS09', 'YFJS10', 'YFJS14']\n",
      "../datasets/results/ranks//runTime_1min_sa_ts_multilabel/rank_2asp_1min_8alg.csv\n",
      "(50, 9)\n",
      "(50, 9)\n",
      "../datasets/results/ranks//runTime_1min_sa_ts_multilabel/rank_dafjs_1min_8alg.csv\n",
      "(30, 9)\n",
      "(27, 9)\n",
      "../datasets/results/ranks//runTime_1min_sa_ts_multilabel/rank_deep_1min_8alg.csv\n",
      "(50, 9)\n",
      "(50, 9)\n",
      "../datasets/results/ranks//runTime_1min_sa_ts_multilabel/rank_dyuthi_1min_8alg.csv\n",
      "(28, 9)\n",
      "(12, 9)\n",
      "../datasets/results/ranks//runTime_1min_sa_ts_multilabel/rank_fjssp_1min_8alg.csv\n",
      "(50, 9)\n",
      "(46, 9)\n",
      "../datasets/results/ranks//runTime_1min_sa_ts_multilabel/rank_mixed_1min_8alg.csv\n",
      "(50, 9)\n",
      "(50, 9)\n",
      "../datasets/results/ranks//runTime_1min_sa_ts_multilabel/rank_wide_1min_8alg.csv\n",
      "(50, 9)\n",
      "(47, 9)\n",
      "../datasets/results/ranks//runTime_1min_sa_ts_multilabel/rank_yfjs_1min_8alg.csv\n",
      "(20, 9)\n",
      "(14, 9)\n"
     ]
    }
   ],
   "source": [
    "generate_multilabel(f'{ROOT_PATH}/runTime_1min_sa_ts', \n",
    "                    f'{ROOT_PATH}/runTime_1min_sa_ts_multilabel'\n",
    "                    )\n",
    "\n",
    "remove_instances(f'{ROOT_PATH}/runTime_1min_sa_ts_multilabel', \n",
    "                 f'{ROOT_PATH}/runTime_1min_sa_ts_multilabel_filtered',\n",
    "                 f'{ROOT_PATH}/runTime_1min_sa_ts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6ddb513f-5169-4733-af56-a056107fbbf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "60 antrenare\n",
    "20 testare\n",
    "20 validare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "105a3bc4-a8e1-4463-9043-20f721d562d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DAFJS03', 'DAFJS04', 'DAFJS08', 'P1', 'P11', 'P15', 'P17', 'P18', 'P2', 'P24', 'P25', 'P26', 'P27', 'P3', 'P4', 'P5', 'P6', 'P7', 'P9', 'la16.fjs', 'la17.fjs', 'la18.fjs', 'la20.fjs', 'bom_wide_2_10_10_5_No2', 'bom_wide_2_7_20_10_No2', 'bom_wide_2_7_20_5_No2', 'YFJS01', 'YFJS04', 'YFJS08', 'YFJS09', 'YFJS10', 'YFJS14']\n",
      "../datasets/results/ranks/class_alg_unfiltered\\class_2asp.csv\n",
      "(50, 2)\n",
      "(50, 2)\n",
      "../datasets/results/ranks/class_alg_unfiltered\\class_dafjs.csv\n",
      "(30, 2)\n",
      "(27, 2)\n",
      "../datasets/results/ranks/class_alg_unfiltered\\class_deep.csv\n",
      "(50, 2)\n",
      "(50, 2)\n",
      "../datasets/results/ranks/class_alg_unfiltered\\class_dyuthi.csv\n",
      "(28, 2)\n",
      "(12, 2)\n",
      "../datasets/results/ranks/class_alg_unfiltered\\class_fjssp.csv\n",
      "(50, 2)\n",
      "(46, 2)\n",
      "../datasets/results/ranks/class_alg_unfiltered\\class_mixed.csv\n",
      "(50, 2)\n",
      "(50, 2)\n",
      "../datasets/results/ranks/class_alg_unfiltered\\class_wide.csv\n",
      "(50, 2)\n",
      "(47, 2)\n",
      "../datasets/results/ranks/class_alg_unfiltered\\class_yfjs.csv\n",
      "(20, 2)\n",
      "(14, 2)\n"
     ]
    }
   ],
   "source": [
    "#remove from instances characteristics\n",
    "ROOT_PATH_FEATURES='../datasets/results/instances_characteristics/februarie2025-v3/'\n",
    "# remove_instances(f'{ROOT_PATH_FEATURES}/heterogeneous', \n",
    "#                  f'{ROOT_PATH_FEATURES}/heterogeneous_filtered',\n",
    "#                  f'{ROOT_PATH}/runTime_1min_sa_ts', instance_id_key='problem')\n",
    "# remove_instances(f'{ROOT_PATH_FEATURES}/operations', \n",
    "#                  f'{ROOT_PATH_FEATURES}/operations_filtered',\n",
    "#                 f'{ROOT_PATH}/runTime_1min_sa_ts', instance_id_key='problem')\n",
    "# remove_instances(f'{ROOT_PATH_FEATURES}/statistics', \n",
    "#                  f'{ROOT_PATH_FEATURES}/statistics_filtered',\n",
    "#                  f'{ROOT_PATH}/runTime_1min_sa_ts', instance_id_key='problem')\n",
    "\n",
    "# remove_instances(f'../datasets/results/ranks/class_alg_unfiltered', \n",
    "#                  f'../datasets/results/ranks/class_alg',\n",
    "#                  f'{ROOT_PATH}/runTime_1min_sa_ts', instance_id_key='Problem')\n",
    "remove_instances(f'../datasets/results/forLehmerCode/runTime_1min_sa_ts', \n",
    "                 f'../datasets/results/forLehmerCode/runTime_1min_sa_ts',\n",
    "                 f'{ROOT_PATH}/runTime_1min_sa_ts', instance_id_key='Problem')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23abd0a4-6708-45aa-8805-ec6c78c5f10d",
   "metadata": {},
   "source": [
    "# Train - Test - Validate split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "1f49d139-1808-4cf4-b92a-052fd9ab3904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test [99, 161, 95, 175, 45, 166, 224, 50, 249, 102, 107, 284, 177, 121, 136, 241, 34, 260, 119, 199, 40, 24, 264, 169, 280, 51, 152, 110, 290, 4, 6, 55, 77, 167, 217, 124, 278, 56, 144, 91, 170, 74, 159, 232, 27, 41, 245, 164, 214, 230, 246, 263, 101, 18, 292, 92, 147, 115, 277, 15, 254, 62]\n",
      "train [30, 194, 248, 17, 81, 16, 58, 188, 160, 287, 129, 240, 213, 130, 256, 79, 282, 84, 145, 36, 257, 220, 28, 134, 265, 286, 142, 195, 201, 66, 273, 157, 128, 279, 150, 125, 109, 96, 26, 29, 227, 259, 276, 61, 73, 209, 178, 215, 11, 80, 218, 163, 98, 253, 20, 225, 168, 205, 104, 200, 197, 94, 106, 105, 118, 22, 187, 112, 202, 60, 237, 153, 75, 7, 294, 219, 285, 151, 204, 222, 196, 156, 90, 193, 10, 72, 155, 1, 247, 57, 13, 131, 113, 35, 5, 266, 139, 182, 38, 47, 12, 141, 207, 233, 123, 43, 88, 180, 165, 46, 267, 203, 179, 242, 184, 3, 198, 25, 39, 281, 87, 234, 138, 132, 126, 149, 68, 173, 216, 33, 171, 100, 86, 44, 255, 231, 23, 174, 71, 235, 172, 283, 250, 89, 192, 143, 8, 14, 65, 78, 93, 146, 275, 272, 82, 293, 262, 261, 133, 228, 212, 236, 70, 148, 116, 189, 226, 190, 210, 49, 52, 67, 186, 103, 181, 221, 85, 42, 239, 140, 21, 223, 76, 63, 206, 291, 274, 48, 0, 32, 238, 295, 185, 37, 288, 117, 162, 83, 137, 252, 64, 54, 251, 53, 208, 108, 191, 229, 183, 154, 59, 270, 271, 244, 122, 31, 19, 69, 114, 135, 176, 111, 258, 158, 9, 120, 268, 2, 289, 97, 243, 211, 127, 269]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import  random\n",
    "\n",
    "def get_train_validate_split(rank_files, train_size = 0.8):\n",
    "    #datasets order in features files\n",
    "    datasets  = [\"deep\", \"wide\", \"fjssp\", \"dyuthi\", \"2asp\", \"mixed\", \"dafjs\", \"yfjs\"]\n",
    "\n",
    "    df = pd.DataFrame(equivalent_algorithms(rank_files))\n",
    "\n",
    "    df['actual_dataset_size'] = df['dataset_size'] -  df['all_algs_eqivalent']\n",
    "\n",
    "    index = 0\n",
    "    train = []\n",
    "    test =[]\n",
    "    for dataset  in datasets:\n",
    "        ds_dim = df.loc[df[\"dataset\"] == dataset, \"actual_dataset_size\"].iloc[0]\n",
    "        indexes = list(range(index, index + ds_dim))\n",
    "        random.shuffle(indexes)\n",
    "        cut_point = int(ds_dim * train_size)\n",
    "        \n",
    "        index +=  ds_dim\n",
    "        train.extend(indexes[:cut_point])\n",
    "        test.extend(indexes[cut_point:])\n",
    "\n",
    "    random.shuffle(test)\n",
    "    random.shuffle(train)\n",
    "    \n",
    "    print(\"test\", test)\n",
    "    print(\"train\", train)\n",
    "    \n",
    "    \n",
    "get_train_validate_split(f'{ROOT_PATH}/runTime_1min_sa_ts')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5003b466-8085-40b4-857b-b2a3b9d3199a",
   "metadata": {},
   "source": [
    "# Class assign\n",
    "C1 = instantele pt care e TS-Ei-LM algoritmul cu cea mai buna performanta\n",
    "\n",
    "C2 =  instantele pt care e SA-Ei-LM algoritmul cu cea mai buna performanta  \n",
    "\n",
    "...\n",
    "\n",
    "C8  =  instantele pt care e SA-Ei-LM algoritmul cu cea mai buna performanta  SAL-Si-LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a95cc80-fb54-4612-8014-6c581447af96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../datasets/results/ranks//runTime_1min_sa_ts_multilabel\n",
      "['../datasets/results/ranks//runTime_1min_sa_ts_multilabel\\\\rank_2asp_1min_8alg.csv', '../datasets/results/ranks//runTime_1min_sa_ts_multilabel\\\\rank_dafjs_1min_8alg.csv', '../datasets/results/ranks//runTime_1min_sa_ts_multilabel\\\\rank_deep_1min_8alg.csv', '../datasets/results/ranks//runTime_1min_sa_ts_multilabel\\\\rank_dyuthi_1min_8alg.csv', '../datasets/results/ranks//runTime_1min_sa_ts_multilabel\\\\rank_fjssp_1min_8alg.csv', '../datasets/results/ranks//runTime_1min_sa_ts_multilabel\\\\rank_mixed_1min_8alg.csv', '../datasets/results/ranks//runTime_1min_sa_ts_multilabel\\\\rank_wide_1min_8alg.csv', '../datasets/results/ranks//runTime_1min_sa_ts_multilabel\\\\rank_yfjs_1min_8alg.csv']\n",
      "../datasets/results/ranks//runTime_1min_sa_ts_multilabel\\rank_2asp_1min_8alg.csv\n",
      "../datasets/results/ranks//runTime_1min_sa_ts_multilabel\\rank_dafjs_1min_8alg.csv\n",
      "../datasets/results/ranks//runTime_1min_sa_ts_multilabel\\rank_deep_1min_8alg.csv\n",
      "../datasets/results/ranks//runTime_1min_sa_ts_multilabel\\rank_dyuthi_1min_8alg.csv\n",
      "../datasets/results/ranks//runTime_1min_sa_ts_multilabel\\rank_fjssp_1min_8alg.csv\n",
      "../datasets/results/ranks//runTime_1min_sa_ts_multilabel\\rank_mixed_1min_8alg.csv\n",
      "../datasets/results/ranks//runTime_1min_sa_ts_multilabel\\rank_wide_1min_8alg.csv\n",
      "../datasets/results/ranks//runTime_1min_sa_ts_multilabel\\rank_yfjs_1min_8alg.csv\n",
      "29 {'TS-Ei-LM & SA-Ei-LM & SAL-Ei-LM & TS-Si-LM & SA-Si-LM & TSL-Si-LM', 'TS-Ei-LM & TSL-Ei-LM', 'TS-Ei-LM & SA-Ei-LM & TSL-Ei-LM & SAL-Ei-LM & TS-Si-LM & SA-Si-LM & TSL-Si-LM & SAL-Si-LM', 'TS-Ei-LM & TSL-Ei-LM & TS-Si-LM & TSL-Si-LM & SAL-Si-LM', 'TS-Si-LM', 'SA-Ei-LM & SAL-Ei-LM & SA-Si-LM & SAL-Si-LM', 'TSL-Ei-LM & TS-Si-LM', 'TSL-Ei-LM & SAL-Ei-LM', 'SA-Si-LM', 'TS-Ei-LM & TSL-Ei-LM & SA-Si-LM & SAL-Si-LM', 'TSL-Ei-LM', 'SA-Ei-LM & TSL-Ei-LM & SAL-Ei-LM & SA-Si-LM & TSL-Si-LM & SAL-Si-LM', 'TS-Ei-LM & TSL-Ei-LM & TS-Si-LM', 'TS-Ei-LM & SAL-Ei-LM', 'SA-Ei-LM & SAL-Ei-LM & TS-Si-LM', 'SAL-Ei-LM & SA-Si-LM', 'SA-Ei-LM & TSL-Ei-LM & SAL-Ei-LM & TSL-Si-LM & SAL-Si-LM', 'SAL-Ei-LM', 'TSL-Ei-LM & TS-Si-LM & SA-Si-LM & TSL-Si-LM & SAL-Si-LM', 'TS-Si-LM & TSL-Si-LM', 'TSL-Ei-LM & TSL-Si-LM', 'TS-Ei-LM', 'SAL-Si-LM', 'SA-Ei-LM & SAL-Ei-LM', 'SA-Ei-LM & TSL-Ei-LM & SAL-Ei-LM & TSL-Si-LM', 'SA-Ei-LM & SAL-Ei-LM & SA-Si-LM', 'TS-Ei-LM & TSL-Ei-LM & SAL-Ei-LM & TS-Si-LM & SA-Si-LM & TSL-Si-LM & SAL-Si-LM', 'SA-Ei-LM', 'TSL-Si-LM'}\n"
     ]
    }
   ],
   "source": [
    "def find_column_name(row, value):\n",
    "    name = []\n",
    "    for col in row.index:\n",
    "        if row[col] == value:\n",
    "            name.append(col)\n",
    "    str = name[0]\n",
    "    for i in range(1, len(name)):\n",
    "        str += \" & \" + name[i]\n",
    "    return str\n",
    "    \n",
    "def class_by_alg(input_directory, filter='*'):\n",
    "\n",
    "    print(input_directory)\n",
    "    multiclass_files = sorted(glob.glob(f'{input_directory}/{filter}'))\n",
    "    print(multiclass_files)\n",
    "\n",
    "    labels_set = set()\n",
    "    for rank_file in multiclass_files:\n",
    "        print(rank_file)\n",
    "        data = pd.read_csv(rank_file)\n",
    "\n",
    "        #transform rank to binary for multilabel\n",
    "        #data['Labe'] = data.apply(lambda row: row.apply(lambda x: x.index[0] if x==1 else \"\" ), axis=1)\n",
    "        data['Label'] = data.apply(find_column_name, axis=1, value=1)\n",
    "\n",
    "        #print(data)\n",
    "        labels_set.update(data['Label'])\n",
    "    print(len(labels_set), labels_set)\n",
    "    \n",
    "class_by_alg(f'{ROOT_PATH}/runTime_1min_sa_ts_multilabel')                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "caac0a3d-db7a-4057-815f-042362c9c791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../datasets/results/ranks//runTime_1min_sa_ts_multilabel\n",
      "['../datasets/results/ranks//runTime_1min_sa_ts_multilabel\\\\rank_2asp_1min_8alg.csv', '../datasets/results/ranks//runTime_1min_sa_ts_multilabel\\\\rank_dafjs_1min_8alg.csv', '../datasets/results/ranks//runTime_1min_sa_ts_multilabel\\\\rank_deep_1min_8alg.csv', '../datasets/results/ranks//runTime_1min_sa_ts_multilabel\\\\rank_dyuthi_1min_8alg.csv', '../datasets/results/ranks//runTime_1min_sa_ts_multilabel\\\\rank_fjssp_1min_8alg.csv', '../datasets/results/ranks//runTime_1min_sa_ts_multilabel\\\\rank_mixed_1min_8alg.csv', '../datasets/results/ranks//runTime_1min_sa_ts_multilabel\\\\rank_wide_1min_8alg.csv', '../datasets/results/ranks//runTime_1min_sa_ts_multilabel\\\\rank_yfjs_1min_8alg.csv']\n",
      "../datasets/results/ranks//runTime_1min_sa_ts_multilabel\\rank_2asp_1min_8alg.csv\n",
      "['2asp']\n",
      "../datasets/results/ranks//runTime_1min_sa_ts_multilabel\\rank_dafjs_1min_8alg.csv\n",
      "['dafjs']\n",
      "../datasets/results/ranks//runTime_1min_sa_ts_multilabel\\rank_deep_1min_8alg.csv\n",
      "['deep']\n",
      "../datasets/results/ranks//runTime_1min_sa_ts_multilabel\\rank_dyuthi_1min_8alg.csv\n",
      "['dyuthi']\n",
      "../datasets/results/ranks//runTime_1min_sa_ts_multilabel\\rank_fjssp_1min_8alg.csv\n",
      "['fjssp']\n",
      "../datasets/results/ranks//runTime_1min_sa_ts_multilabel\\rank_mixed_1min_8alg.csv\n",
      "['mixed']\n",
      "../datasets/results/ranks//runTime_1min_sa_ts_multilabel\\rank_wide_1min_8alg.csv\n",
      "['wide']\n",
      "../datasets/results/ranks//runTime_1min_sa_ts_multilabel\\rank_yfjs_1min_8alg.csv\n",
      "['yfjs']\n",
      "   Problem  TS-Ei-LM  SA-Ei-LM  TSL-Ei-LM  SAL-Ei-LM  TS-Si-LM  SA-Si-LM  \\\n",
      "0   YFJS01         1         1          1          1         1         1   \n",
      "1   YFJS02         1         0          1          1         1         1   \n",
      "2   YFJS03         1         0          1          0         1         0   \n",
      "3   YFJS04         1         1          1          1         1         1   \n",
      "4   YFJS05         0         0          0          1         0         0   \n",
      "5   YFJS06         0         1          0          0         0         0   \n",
      "6   YFJS07         0         0          0          1         0         0   \n",
      "7   YFJS08         1         1          1          1         1         1   \n",
      "8   YFJS09         1         1          1          1         1         1   \n",
      "9   YFJS10         1         1          1          1         1         1   \n",
      "10  YFJS11         0         0          0          1         0         0   \n",
      "11  YFJS12         0         1          0          0         0         0   \n",
      "12  YFJS13         0         1          0          1         0         1   \n",
      "13  YFJS14         1         1          1          1         1         1   \n",
      "14  YFJS15         0         1          0          1         0         0   \n",
      "15  YFJS16         0         0          0          1         0         0   \n",
      "16  YFJS17         0         1          0          1         0         0   \n",
      "17  YFJS18         0         1          0          1         0         0   \n",
      "18  YFJS19         0         1          0          1         0         0   \n",
      "19  YFJS20         0         1          0          0         0         0   \n",
      "\n",
      "    TSL-Si-LM  SAL-Si-LM    BestAlg  \n",
      "0           1          1   TS-Ei-LM  \n",
      "1           1          1  TSL-Ei-LM  \n",
      "2           1          1  TSL-Ei-LM  \n",
      "3           1          1  TSL-Ei-LM  \n",
      "4           0          0  SAL-Ei-LM  \n",
      "5           0          0   SA-Ei-LM  \n",
      "6           0          0  SAL-Ei-LM  \n",
      "7           1          1   TS-Si-LM  \n",
      "8           1          1   SA-Ei-LM  \n",
      "9           1          1   TS-Ei-LM  \n",
      "10          0          0  SAL-Ei-LM  \n",
      "11          0          0   SA-Ei-LM  \n",
      "12          0          0   SA-Si-LM  \n",
      "13          1          1  SAL-Si-LM  \n",
      "14          0          0  SAL-Ei-LM  \n",
      "15          0          0  SAL-Ei-LM  \n",
      "16          0          0   SA-Ei-LM  \n",
      "17          0          0   SA-Ei-LM  \n",
      "18          0          0   SA-Ei-LM  \n",
      "19          0          0   SA-Ei-LM  \n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "def get_best_alg(row, value):\n",
    "    name = []\n",
    "    for col in row.index:\n",
    "        if row[col] == value:\n",
    "            name.append(col)\n",
    "    index = random.randint(0, len(name)-1)#if multiples alg choose one random\n",
    "    return name[index]\n",
    "    \n",
    "def class_by_algorithm(input_directory, output_directory, filter='*'):\n",
    "\n",
    "    print(input_directory)\n",
    "    multiclass_files = sorted(glob.glob(f'{input_directory}/{filter}'))\n",
    "    print(multiclass_files)\n",
    "\n",
    "    for rank_file in multiclass_files:\n",
    "        print(rank_file)\n",
    "        data = pd.read_csv(rank_file)\n",
    "\n",
    "        #transform rank to binary for multilabel\n",
    "        #data['Labe'] = data.apply(lambda row: row.apply(lambda x: x.index[0] if x==1 else \"\" ), axis=1)\n",
    "        data['BestAlg'] = data.apply(get_best_alg, axis=1, value=1)\n",
    "\n",
    "        \n",
    "        pattern = re.compile( r'^rank_(\\w+?)_')\n",
    "        # Find all matches\n",
    "        matches = pattern.findall(Path(rank_file).stem)\n",
    "        print(matches)\n",
    "    \n",
    "        dataset_name = matches[0]\n",
    "\n",
    "        \n",
    "        data[['Problem','BestAlg']].to_csv(f'{output_directory}/class_{dataset_name}.csv', index=False)\n",
    "\n",
    "    print(data)\n",
    "    \n",
    "class_by_algorithm(f'{ROOT_PATH}/runTime_1min_sa_ts_multilabel', f'{ROOT_PATH}/class_alg')                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0b457751-e414-4b65-bcd4-c9b4fee0b9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 2 0 0 0 1 1 0 2] [2 2 1 0 2 0 1 1 0 0] [0 1 0 2 1 2 0 1 2 0] [[2 2 0]\n",
      " [1 2 1]\n",
      " [2 1 0]\n",
      " [0 0 2]\n",
      " [0 2 1]\n",
      " [0 0 2]\n",
      " [1 1 0]\n",
      " [1 1 1]\n",
      " [0 0 2]\n",
      " [2 0 0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2, 2, 0],\n",
       "       [1, 2, 1],\n",
       "       [2, 1, 0],\n",
       "       [0, 0, 2],\n",
       "       [0, 2, 1],\n",
       "       [0, 0, 2],\n",
       "       [1, 1, 0],\n",
       "       [1, 1, 1],\n",
       "       [0, 0, 2],\n",
       "       [2, 0, 0]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "X, y1 = make_classification(n_samples=10, n_features=100,\n",
    "                            n_informative=30, n_classes=3,\n",
    "                            random_state=1)\n",
    "y2 = shuffle(y1, random_state=1)\n",
    "y3 = shuffle(y1, random_state=2)\n",
    "Y = np.vstack((y1, y2, y3)).T\n",
    "print(y1,y2,y3, Y)\n",
    "n_samples, n_features = X.shape # 10,100\n",
    "n_outputs = Y.shape[1] # 3\n",
    "n_classes = 3\n",
    "forest = RandomForestClassifier(random_state=1)\n",
    "multi_target_forest = MultiOutputClassifier(forest, n_jobs=2)\n",
    "multi_target_forest.fit(X, Y).predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1480290f-7f05-4ff4-8495-7ebc7fd5a688",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

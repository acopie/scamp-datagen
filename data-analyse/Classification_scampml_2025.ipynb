{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, r2_score, hamming_loss, classification_report, f1_score, precision_score, recall_score\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt.plots import plot_objective, plot_histogram\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path \n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from skmultilearn.problem_transform import BinaryRelevance, LabelPowerset\n",
    "from skmultilearn.adapt import MLkNN\n",
    "\n",
    "\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Util.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  read_dataset(feat_select, # _all, _rf ...\n",
    "                  feat_type, #OG,HG,\n",
    "                  scale, #standar, minMax\n",
    "                  feature_path,\n",
    "                  ranks_path):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    data = read_output(sufix='_1min_8alg', dir_path = ranks_path)\n",
    "    data = data.drop(columns=[\"Problem\"])\n",
    "    \n",
    "    df_input = pd.read_csv(f'{feature_path}/{feat_type}/features_{feat_select}_{scale}.csv')\n",
    "    df_input = df_input.drop(columns=[\"problem\"])\n",
    "    return df_input, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input, data = read_dataset(feat_select='all',feat_type='HG-F', scale=\"standard\",\n",
    "                             feature_path='../datasets/results/features/ianuarie2025-v2/',\n",
    "                             ranks_path='../datasets/results/ranks/runTime_1min_sa_ts_multilabel_filtered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TS-Ei-LM</th>\n",
       "      <th>SA-Ei-LM</th>\n",
       "      <th>TSL-Ei-LM</th>\n",
       "      <th>SAL-Ei-LM</th>\n",
       "      <th>TS-Si-LM</th>\n",
       "      <th>SA-Si-LM</th>\n",
       "      <th>TSL-Si-LM</th>\n",
       "      <th>SAL-Si-LM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>296 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     TS-Ei-LM  SA-Ei-LM  TSL-Ei-LM  SAL-Ei-LM  TS-Si-LM  SA-Si-LM  TSL-Si-LM  \\\n",
       "0           0         0          0          1         0         0          0   \n",
       "1           1         0          0          1         0         0          0   \n",
       "2           0         1          0          0         0         0          0   \n",
       "3           0         0          0          1         0         0          0   \n",
       "4           0         0          0          1         0         0          0   \n",
       "..        ...       ...        ...        ...       ...       ...        ...   \n",
       "291         0         0          0          1         0         0          0   \n",
       "292         0         1          0          1         0         0          0   \n",
       "293         0         1          0          1         0         0          0   \n",
       "294         0         1          0          1         0         0          0   \n",
       "295         0         1          0          0         0         0          0   \n",
       "\n",
       "     SAL-Si-LM  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  \n",
       "..         ...  \n",
       "291          0  \n",
       "292          0  \n",
       "293          0  \n",
       "294          0  \n",
       "295          0  \n",
       "\n",
       "[296 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not used\n",
    "def get_fold(index, number_folds, test_fold_index):\n",
    "    data_size = len(index)\n",
    "    fold_size = data_size//number_folds\n",
    "    start_index_test = test_fold_index*fold_size\n",
    "    if test_fold_index != number_folds-1:\n",
    "        end_index_test = test_fold_index*fold_size + fold_size\n",
    "    else:\n",
    "        end_index_test = data_size\n",
    "    test_index = index[start_index_test:end_index_test]\n",
    "    if start_index_test == 0:\n",
    "        train_index = index[end_index_test:]\n",
    "    elif end_index_test == data_size:\n",
    "        train_index = index[:start_index_test]\n",
    "    else:\n",
    "        train_index = np.concatenate((index[:start_index_test], index[end_index_test:]))\n",
    "    return train_index, test_index    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not used\n",
    "def cross_validation(number_folds, feat_select='_all', feat_type='op', reg_type='rfr'):    \n",
    "    df_all_input, df_all_output = read_dataset(feat_select=feat_select, feat_type=feat_type)\n",
    "    index = np.random.permutation(len(df_all_input))\n",
    "    scores_train = []\n",
    "    scores_test = []\n",
    "    for f in range(number_folds):\n",
    "        train_index, test_index = get_fold(index, number_folds, f)\n",
    "        train_scaler = MinMaxScaler()\n",
    "        x_train_scaled = train_scaler.fit_transform(df_all_input.iloc[train_index])\n",
    "        y_train = df_all_output.iloc[train_index]\n",
    "        #y_train = train_scaler.fit_transform(df_all_output.iloc[train_index])\n",
    "        # unscaled output\n",
    "        test_scaler = MinMaxScaler()\n",
    "        x_test_scaled = test_scaler.fit_transform(df_all_input.iloc[test_index])\n",
    "        y_test = df_all_output.iloc[test_index]\n",
    "        #print(\"x_train_scaled=\",x_train_scaled)\n",
    "        #print(\"x_test_scaled=\",x_test_scaled)\n",
    "        if reg_type == 'gbr':\n",
    "            reg = MultiOutputRegressor(GradientBoostingRegressor(n_estimators=50,random_state=0)).fit(x_train_scaled, y_train)\n",
    "        if reg_type == 'hgbr':\n",
    "            reg = MultiOutputRegressor(HistGradientBoostingRegressor(max_iter=50,random_state=0)).fit(x_train_scaled, y_train)    \n",
    "        if reg_type == 'rfr':\n",
    "            reg = MultiOutputRegressor(RandomForestRegressor(n_estimators=20, random_state=0)).fit(x_train_scaled, y_train)\n",
    "        if reg_type == 'svr':    \n",
    "            reg = MultiOutputRegressor(SVR(C=5.0, epsilon=0.3, kernel='rbf')).fit(x_train_scaled, y_train) #  epsilon=0.3,\n",
    "        if reg_type == 'mlp':    \n",
    "            reg = MultiOutputRegressor(MLPRegressor(hidden_layer_sizes=(20,),max_iter=5000)).fit(x_train_scaled, y_train)\n",
    "        score = reg.score(x_test_scaled, y_test)\n",
    "        scores_test.append(score)\n",
    "        score = reg.score(x_train_scaled, y_train)\n",
    "        scores_train.append(score)\n",
    "    return reg, scores_train, scores_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression model tuning using Grid Search and Randomized Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification models tuning using Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scikit-optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt.plots import plot_objective, plot_histogram\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning based on Bayesian Optimization\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "target_names = ['TS-Ei', 'SA-Ei', 'TSL-Ei', 'SAL-Ei', 'TS-Si', 'SA-Si', 'TSL-Si', 'SAL-Si', ]\n",
    "\n",
    "def classification_tuning(out_dir_path, ft_type, ft_select, classification_types, feature_path, ranks_path):\n",
    "    #varianta veche de generarare, data_size  veenea ca parametru\n",
    "    #index = np.random.permutation(data_size)\n",
    "    # idx_X_train, idx_X_test, idx_y_train, idx_y_test = train_test_split(index, index, train_size = 0.8, test_size = 0.2, random_state=0)\n",
    "    # print(data_size)\n",
    "    # print('idx_X_train=',idx_X_train)\n",
    "    # print('idx_X_test=',idx_X_test)\n",
    "    Path(out_dir_path).mkdir(exist_ok=True)\n",
    "\n",
    "    #generate in  fisierul DatasetsRanking\n",
    "    idx_X_test = [99, 161, 95, 175, 45, 166, 224, 50, 249, 102, 107, 284, 177, 121, 136, \n",
    "                  241, 34, 260, 119, 199, 40, 24, 264, 169, 280, 51, 152, 110, 290, 4, \n",
    "                  6, 55, 77, 167, 217, 124, 278, 56, 144, 91, 170, 74, 159, 232, 27, 41, \n",
    "                  245, 164, 214, 230, 246, 263, 101, 18, 292, 92, 147, 115, 277, 15, 254, 62]\n",
    "\n",
    "    idx_X_train = [30, 194, 248, 17, 81, 16, 58, 188, 160, 287, 129, 240, 213, 130, 256, \n",
    "                   79, 282, 84, 145, 36, 257, 220, 28, 134, 265, 286, 142, 195, 201, 66, \n",
    "                   273, 157, 128, 279, 150, 125, 109, 96, 26, 29, 227, 259, 276, 61, 73, \n",
    "                   209, 178, 215, 11, 80, 218, 163, 98, 253, 20, 225, 168, 205, 104, 200, \n",
    "                   197, 94, 106, 105, 118, 22, 187, 112, 202, 60, 237, 153, 75, 7, 294, 219, \n",
    "                   285, 151, 204, 222, 196, 156, 90, 193, 10, 72, 155, 1, 247, 57, 13, 131, \n",
    "                   113, 35, 5, 266, 139, 182, 38, 47, 12, 141, 207, 233, 123, 43, 88, 180, \n",
    "                   165, 46, 267, 203, 179, 242, 184, 3, 198, 25, 39, 281, 87, 234, 138, 132, \n",
    "                   126, 149, 68, 173, 216, 33, 171, 100, 86, 44, 255, 231, 23, 174, 71, 235, \n",
    "                   172, 283, 250, 89, 192, 143, 8, 14, 65, 78, 93, 146, 275, 272, 82, 293, \n",
    "                   262, 261, 133, 228, 212, 236, 70, 148, 116, 189, 226, 190, 210, 49, 52, \n",
    "                   67, 186, 103, 181, 221, 85, 42, 239, 140, 21, 223, 76, 63, 206, 291, 274, \n",
    "                   48, 0, 32, 238, 295, 185, 37, 288, 117, 162, 83, 137, 252, 64, 54, 251, \n",
    "                   53, 208, 108, 191, 229, 183, 154, 59, 270, 271, 244, 122, 31, 19, 69, 114,\n",
    "                   135, 176, 111, 258, 158, 9, 120, 268, 2, 289, 97, 243, 211, 127, 269] \n",
    "      \n",
    "    idx_y_train = idx_X_train\n",
    "    idx_y_test = idx_X_test\n",
    "    if not sys.warnoptions:\n",
    "        import os, warnings\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        os.environ[\"PYTHONWARNINGS\"] = \"ignore\" # Also affect subprocesses\n",
    "\n",
    "    classificators_format = ['mlknn', 'lp_rfc', 'br_rfc']\n",
    "    for classification_type in classification_types:\n",
    "        #print(\"classification_type\", classification_type)\n",
    "        test_results_score={}\n",
    "        test_results_metaheuristic={}\n",
    "        test_results={}\n",
    "        for fs in ft_select:\n",
    "            for ft in ft_type:  \n",
    "                df_all_input, df_all_output = read_dataset(feat_select=fs, feat_type=ft, scale=\"standard\",\n",
    "                                                           feature_path=feature_path, ranks_path=ranks_path)\n",
    "                #df_all_input=df_all_input.filter(regex='^(?!.*gini)(?!.*q25)(?!.*q50)(?!.*q75)(?!.*min)(?!.*max)')\n",
    "\n",
    "                print(df_all_input.shape, df_all_output.shape)\n",
    "                index = np.random.permutation(len(df_all_input))\n",
    "                X_train = df_all_input.iloc[idx_X_train]\n",
    "                X_test = df_all_input.iloc[idx_X_test]\n",
    "                \n",
    "                y_train = df_all_output.iloc[idx_y_train]\n",
    "                y_test = df_all_output.iloc[idx_y_test]\n",
    "                #print(\"y_test\", y_test)\n",
    "                \n",
    "                train_scaler = MinMaxScaler()\n",
    "                X_train = train_scaler.fit_transform(X_train)\n",
    "                X_test = train_scaler.fit_transform(X_test)\n",
    "                \n",
    "                #y = df_all_output.iloc[index]\n",
    "                #X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, test_size = 0.2, random_state=0)\n",
    "                \n",
    "                \n",
    "                if classification_type == 'svc':\n",
    "                    classification_model = MultiOutputClassifier(SVC())\n",
    "                    param = {\n",
    "                            'estimator__C': (1e-2, 1e+2, 'uniform'), # (1e-6, 1e+6, 'log-uniform'),\n",
    "                            'estimator__gamma': (1e-2, 1e+1, 'uniform'),\n",
    "                            'estimator__degree': (2, 4),  # integer valued parameter\n",
    "                            'estimator__kernel': ['linear', 'poly', 'rbf'],  # categorical parameter\n",
    "                            }\n",
    "                if classification_type == 'gbc':\n",
    "                    classification_model = MultiOutputClassifier(GradientBoostingClassifier())\n",
    "                    param = {'estimator__n_estimators':[10,25,50,75,100,125,150],\n",
    "                             'estimator__loss':[ 'log_loss'],#'exponential',\n",
    "                             'estimator__min_samples_split':(0.1, 0.99, 'uniform'),\n",
    "                             'estimator__min_samples_leaf':(0.01, 0.99, 'uniform')\n",
    "                             }\n",
    "                if classification_type == 'rfc':\n",
    "                    classification_model = MultiOutputClassifier(RandomForestClassifier())\n",
    "                    param = {'estimator__n_estimators':[10,25,50,75,100,125,150],\n",
    "                             'estimator__criterion':['entropy', 'gini', 'log_loss'],\n",
    "                             'estimator__min_samples_split':(0.05, 0.2, 'uniform'),\n",
    "                             'estimator__max_features':['sqrt', 'log2', 1]\n",
    "                             }\n",
    "                if classification_type == 'mlp':\n",
    "                    classification_model = MultiOutputClassifier(MLPClassifier())\n",
    "                    param = {\n",
    "                             'estimator__hidden_layer_sizes':[(64,),(32,),(40,)],#[(40,20), (64,32), (64,64)]), # (20,),(30,),(40,), (64,),\n",
    "                             'estimator__activation':['logistic', 'tanh', 'relu'],\n",
    "                             'estimator__max_iter':[500, 1000, 2000, 5000]\n",
    "                             }\n",
    "                if classification_type == 'mcc':\n",
    "                    classification_model = ClassifierChain(LogisticRegression())\n",
    "\n",
    "                    param = {\n",
    "                        'base_estimator__C': (1e-6, 1e+6, 'log-uniform'),\n",
    "                        'base_estimator__penalty': [None, 'l2']\n",
    "                    }\n",
    "                if classification_type == 'br_rfc':\n",
    "                    classification_model = BinaryRelevance(RandomForestClassifier())\n",
    "                    param = {'classifier__n_estimators':[10,25,50,75,100,125,150],\n",
    "                             'classifier__criterion':['entropy', 'gini', 'log_loss'],\n",
    "                             'classifier__min_samples_split':(0.05, 0.2, 'uniform'),\n",
    "                             'classifier__max_features':['sqrt', 'log2', 1]\n",
    "                             }\n",
    "                if classification_type == 'lp_rfc':\n",
    "                    classification_model = LabelPowerset(RandomForestClassifier())\n",
    "                    param = {'classifier__n_estimators':[10,25,50,75,100,125,150],\n",
    "                             'classifier__criterion':['entropy', 'gini', 'log_loss'],\n",
    "                             'classifier__min_samples_split':(0.05, 0.2, 'uniform'),\n",
    "                             'classifier__max_features':['sqrt', 'log2', 1]\n",
    "                             }\n",
    "                if classification_type == 'mcc_rfc':\n",
    "                    classification_model = ClassifierChain(RandomForestClassifier())\n",
    "                    param = {'base_estimator__n_estimators':[10,25,50,75,100,125,150],\n",
    "                             'base_estimator__criterion':['entropy', 'gini', 'log_loss'],\n",
    "                             'base_estimator__min_samples_split':(0.05, 0.2, 'uniform'),\n",
    "                             'base_estimator__max_features':['sqrt', 'log2', 1]\n",
    "                            }\n",
    "                if classification_type == 'mlknn':\n",
    "                    classification_model = MLkNN()\n",
    "                    param = {\n",
    "                             'k': [2, 3, 4, 5, 8, 10, 15,23],\n",
    "                             's': [0.5, 0.7, 1.0]\n",
    "                             }\n",
    "                   \n",
    "                opt = BayesSearchCV(classification_model,param, n_iter=32, # default value: 32, 50\n",
    "                               cv=KFold(n_splits=5, random_state=100, shuffle=True),#5, # default value: 3\n",
    "                               return_train_score = True, verbose = 0)\n",
    "\n",
    "                \n",
    "                opt.fit(np.array(X_train), np.array(y_train))\n",
    "                #opt.fit(X_train, y_train)\n",
    "                \n",
    "                df_results=pd.DataFrame.from_dict(opt.cv_results_)\n",
    "                df_results.to_csv(f'{out_dir_path}/feat_{fs}_{ft}_regr_{classification_type}.csv', sep=',')\n",
    "        \n",
    "                print(\"******* Feature select:\",fs,\" Feature type:\",ft, \"Classification model:\", classification_type, \"******\")\n",
    "                        \n",
    "                print('Test score: ', opt.score(X_test, y_test))\n",
    "                best = opt.best_estimator_\n",
    "                results_test  = best.predict(X_test)\n",
    "                results_train = best.predict(X_train)\n",
    "                print('Best estimator:', best)\n",
    "                \n",
    "                #print('Accurecy of the best estimator (training dataset): ', accuracy_score(y_pred = results_train, y_true = y_train))\n",
    "                print('Accuracy Best score (validation) val. score : ', opt.best_score_)\n",
    "                #print('R2 Best score (validation) test score: ', opt.score(X_test, y_test))\n",
    "                test_score = None#accuracy_score(y_pred = results_test, y_true = y_test)\n",
    "                #print('Hamming loss: {0}'.format(hamming_loss(y_pred = results_test, y_true = y_test)))\n",
    "                #print('Accuracy of the best estimator (testing dataset): ',test_score)\n",
    "\n",
    "                #br_f1=f1_score(y_pred = results_test, y_true = y_test, average='micro')\n",
    "                #print('F1-score:',round(br_f1,3))\n",
    "                y_true = np.array(y_test)\n",
    "                y_pred = results_test\n",
    "\n",
    "\n",
    "                # print('y_true.size', y_true.size)\n",
    "                # for i in range(y_pred.shape[0]):\n",
    "                #     print('true', y_true[i], 'pred', y_pred[i], np.not_equal(y_true[i], y_pred[i]), np.sum(np.not_equal(y_true[i], y_pred[i])))\n",
    "                #print('Hamming loss :',  np.sum(np.not_equal(y_true, y_pred)),float(y_true.size))\n",
    "                print(\"Hamming loss test:\",   np.sum(np.not_equal(y_true, y_pred))/float(y_true.size))\n",
    "                print('Hamming loss train:',  np.sum(np.not_equal(y_train, results_train))/float(y_train.size))\n",
    "                #print(\"Hamming loss train:\", np.sum(np.not_equal(y_train, results_train))/float(y_train.size))\n",
    "\n",
    "                # print(\"Precision score:\", precision_score(y_true, y_pred))\n",
    "                # print(\"Recall score:\", recall_score(y_true, y_pred))\n",
    "\n",
    "                      \n",
    "                # print(classification_report(y_pred = results_test, y_true = y_test, target_names=target_names))\n",
    "\n",
    "                classes_identified_train =[]\n",
    "                for i in range(results_train.shape[0]):\n",
    "                     if classification_type in classificators_format:\n",
    "                         classes_identified_train.append(np.count_nonzero(results_train[i].toarray()[0] == 1))\n",
    "                     else:\n",
    "                         classes_identified_train.append(np.count_nonzero(results_train[i] == 1))\n",
    "                #print(classes_identified_train)\n",
    "                print (\"data size\", results_train.shape[0], \"found 0 alg\", np.count_nonzero(np.array(classes_identified_train) == 0))\n",
    "                \n",
    "                metaheuristic=[]\n",
    "                classes_identified_test = []\n",
    "                test_results[f'res_{classification_type}_{fs}_{ft}'] = {}\n",
    "                \n",
    "                for i in range(results_test.shape[0]):\n",
    "                    test_results[f'res_{classification_type}_{fs}_{ft}'][i] = results_test[i]\n",
    "                    idx_best=np.argmin(results_test[i])\n",
    "                    #print(idx_best, results_test[i].shape)\n",
    "                    if classification_type in classificators_format:\n",
    "                        metaheuristic.append(results_test[i].toarray()[0])\n",
    "                        classes_identified_test.append(np.count_nonzero(results_test[i].toarray()[0] == 1))\n",
    "                    else:\n",
    "                        metaheuristic.append(results_test[i])\n",
    "                        classes_identified_test.append(np.count_nonzero(results_test[i] == 1))\n",
    "                #print(\"Results test:\",metaheuristic)\n",
    "                print(\"classes_identified_test test:\",classes_identified_test,  np.count_nonzero(np.array(classes_identified_test) == 0))\n",
    "                \n",
    "\n",
    "                \n",
    "                test_results_score[f'Acc_{classification_type}_{fs}_{ft}']=[test_score]\n",
    "                test_results_metaheuristic[f'meta_{classification_type}_{fs}_{ft}']=metaheuristic\n",
    "    # save results on test instances \n",
    "        df_results = pd.DataFrame(test_results)\n",
    "        df_results.to_csv(f'{out_dir_path}/results_{classification_type}_test.csv')\n",
    "        df_results_score = pd.DataFrame(test_results_score)\n",
    "        df_results_score.to_csv(f'{out_dir_path}/results_{classification_type}_test_scores.csv')\n",
    "        df_results_metaheuristic = pd.DataFrame(test_results_metaheuristic)\n",
    "        df_results_metaheuristic.to_csv(f'{out_dir_path}/results_{classification_type}_test_metaheuristic.csv')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(296, 90) (296, 8)\n",
      "******* Feature select: all  Feature type: ST-F Classification model: rfc ******\n",
      "Test score:  0.08064516129032258\n",
      "Best estimator: MultiOutputClassifier(estimator=RandomForestClassifier(criterion='entropy',\n",
      "                                                       min_samples_split=0.05,\n",
      "                                                       n_estimators=10))\n",
      "Accuracy Best score (validation) val. score :  0.2053654024051804\n",
      "Hamming loss test: 0.14919354838709678\n",
      "Hamming loss train: TS-Ei-LM     0.007479\n",
      "SA-Ei-LM     0.010150\n",
      "TSL-Ei-LM    0.006410\n",
      "SAL-Ei-LM    0.012821\n",
      "TS-Si-LM     0.009081\n",
      "SA-Si-LM     0.008547\n",
      "TSL-Si-LM    0.006410\n",
      "SAL-Si-LM    0.006410\n",
      "dtype: float64\n",
      "data size 234 found 0 alg 72\n",
      "classes_identified_test test: [0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 2, 0, 1, 0, 1, 3, 2, 1, 0, 0, 0, 2, 2, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 2, 0, 0, 2, 0, 1, 1, 2, 0, 0, 0] 36\n",
      "(296, 10) (296, 8)\n",
      "******* Feature select: LR10  Feature type: ST-F Classification model: rfc ******\n",
      "Test score:  0.12903225806451613\n",
      "Best estimator: MultiOutputClassifier(estimator=RandomForestClassifier(criterion='log_loss',\n",
      "                                                       max_features='log2',\n",
      "                                                       min_samples_split=0.05,\n",
      "                                                       n_estimators=50))\n",
      "Accuracy Best score (validation) val. score :  0.18825161887141534\n",
      "Hamming loss test: 0.15725806451612903\n",
      "Hamming loss train: TS-Ei-LM     0.006410\n",
      "SA-Ei-LM     0.011218\n",
      "TSL-Ei-LM    0.006410\n",
      "SAL-Ei-LM    0.010684\n",
      "TS-Si-LM     0.005876\n",
      "SA-Si-LM     0.008013\n",
      "TSL-Si-LM    0.004274\n",
      "SAL-Si-LM    0.008547\n",
      "dtype: float64\n",
      "data size 234 found 0 alg 67\n",
      "classes_identified_test test: [0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 2, 0, 1, 2, 1, 1, 1, 1, 0, 1, 2, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 2, 0, 1, 2, 1, 3, 1, 2, 0, 0, 0] 30\n",
      "(296, 20) (296, 8)\n",
      "******* Feature select: LR20  Feature type: ST-F Classification model: rfc ******\n",
      "Test score:  0.08064516129032258\n",
      "Best estimator: MultiOutputClassifier(estimator=RandomForestClassifier(criterion='entropy',\n",
      "                                                       min_samples_split=0.05,\n",
      "                                                       n_estimators=10))\n",
      "Accuracy Best score (validation) val. score :  0.19241443108233117\n",
      "Hamming loss test: 0.15725806451612903\n",
      "Hamming loss train: TS-Ei-LM     0.004808\n",
      "SA-Ei-LM     0.010150\n",
      "TSL-Ei-LM    0.007479\n",
      "SAL-Ei-LM    0.013355\n",
      "TS-Si-LM     0.005342\n",
      "SA-Si-LM     0.007479\n",
      "TSL-Si-LM    0.007479\n",
      "SAL-Si-LM    0.008013\n",
      "dtype: float64\n",
      "data size 234 found 0 alg 62\n",
      "classes_identified_test test: [0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 2, 1, 1, 1, 0, 1, 0, 0, 2, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 2, 0, 1, 2, 0, 2, 0, 1, 0, 0, 0] 41\n",
      "(296, 30) (296, 8)\n",
      "******* Feature select: LR30  Feature type: ST-F Classification model: rfc ******\n",
      "Test score:  0.06451612903225806\n",
      "Best estimator: MultiOutputClassifier(estimator=RandomForestClassifier(criterion='log_loss',\n",
      "                                                       max_features='log2',\n",
      "                                                       min_samples_split=0.05,\n",
      "                                                       n_estimators=150))\n",
      "Accuracy Best score (validation) val. score :  0.1883441258094357\n",
      "Hamming loss test: 0.14717741935483872\n",
      "Hamming loss train: TS-Ei-LM     0.009081\n",
      "SA-Ei-LM     0.005342\n",
      "TSL-Ei-LM    0.005876\n",
      "SAL-Ei-LM    0.009081\n",
      "TS-Si-LM     0.005876\n",
      "SA-Si-LM     0.009081\n",
      "TSL-Si-LM    0.006410\n",
      "SAL-Si-LM    0.009081\n",
      "dtype: float64\n",
      "data size 234 found 0 alg 68\n",
      "classes_identified_test test: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 2, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 1, 1, 1, 0, 0, 0] 47\n",
      "(296, 40) (296, 8)\n",
      "******* Feature select: LR40  Feature type: ST-F Classification model: rfc ******\n",
      "Test score:  0.1774193548387097\n",
      "Best estimator: MultiOutputClassifier(estimator=RandomForestClassifier(min_samples_split=0.05,\n",
      "                                                       n_estimators=25))\n",
      "Accuracy Best score (validation) val. score :  0.20120259019426454\n",
      "Hamming loss test: 0.13306451612903225\n",
      "Hamming loss train: TS-Ei-LM     0.007479\n",
      "SA-Ei-LM     0.010150\n",
      "TSL-Ei-LM    0.006410\n",
      "SAL-Ei-LM    0.014423\n",
      "TS-Si-LM     0.005876\n",
      "SA-Si-LM     0.009081\n",
      "TSL-Si-LM    0.005342\n",
      "SAL-Si-LM    0.006944\n",
      "dtype: float64\n",
      "data size 234 found 0 alg 76\n",
      "classes_identified_test test: [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 1, 2, 1, 1, 0, 1, 1, 2, 0, 2, 0, 2, 2, 2, 1, 1, 2, 0, 2, 2, 0, 2, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 2, 0, 0, 2, 1, 4, 2, 2, 0, 0, 0] 30\n",
      "(296, 57) (296, 8)\n",
      "******* Feature select: RF  Feature type: ST-F Classification model: rfc ******\n",
      "Test score:  0.06451612903225806\n",
      "Best estimator: MultiOutputClassifier(estimator=RandomForestClassifier(criterion='entropy',\n",
      "                                                       max_features='log2',\n",
      "                                                       min_samples_split=0.05,\n",
      "                                                       n_estimators=50))\n",
      "Accuracy Best score (validation) val. score :  0.18843663274745603\n",
      "Hamming loss test: 0.15725806451612903\n",
      "Hamming loss train: TS-Ei-LM     0.008013\n",
      "SA-Ei-LM     0.005876\n",
      "TSL-Ei-LM    0.004274\n",
      "SAL-Ei-LM    0.008547\n",
      "TS-Si-LM     0.005342\n",
      "SA-Si-LM     0.008013\n",
      "TSL-Si-LM    0.005876\n",
      "SAL-Si-LM    0.008547\n",
      "dtype: float64\n",
      "data size 234 found 0 alg 56\n",
      "classes_identified_test test: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 2, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 2, 1, 1, 0, 1, 1] 40\n",
      "(296, 28) (296, 8)\n",
      "******* Feature select: PCA99  Feature type: ST-F Classification model: rfc ******\n",
      "Test score:  0.1774193548387097\n",
      "Best estimator: MultiOutputClassifier(estimator=RandomForestClassifier(max_features='log2',\n",
      "                                                       min_samples_split=0.05,\n",
      "                                                       n_estimators=25))\n",
      "Accuracy Best score (validation) val. score :  0.15439407955596668\n",
      "Hamming loss test: 0.14919354838709678\n",
      "Hamming loss train: TS-Ei-LM     0.008013\n",
      "SA-Ei-LM     0.004808\n",
      "TSL-Ei-LM    0.006410\n",
      "SAL-Ei-LM    0.005876\n",
      "TS-Si-LM     0.007479\n",
      "SA-Si-LM     0.005342\n",
      "TSL-Si-LM    0.005342\n",
      "SAL-Si-LM    0.010684\n",
      "dtype: float64\n",
      "data size 234 found 0 alg 60\n",
      "classes_identified_test test: [1, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 5, 1, 0, 2, 0, 2, 1, 3, 0, 1, 1, 1, 0, 1, 1, 2, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 2, 1, 2, 1, 1, 0, 0, 1] 32\n",
      "(296, 48) (296, 8)\n",
      "******* Feature select: PCA999  Feature type: ST-F Classification model: rfc ******\n",
      "Test score:  0.04838709677419355\n",
      "Best estimator: MultiOutputClassifier(estimator=RandomForestClassifier(criterion='entropy',\n",
      "                                                       max_features='log2',\n",
      "                                                       min_samples_split=0.050654108925106675,\n",
      "                                                       n_estimators=10))\n",
      "Accuracy Best score (validation) val. score :  0.16253469010175764\n",
      "Hamming loss test: 0.16330645161290322\n",
      "Hamming loss train: TS-Ei-LM     0.007479\n",
      "SA-Ei-LM     0.006944\n",
      "TSL-Ei-LM    0.005876\n",
      "SAL-Ei-LM    0.007479\n",
      "TS-Si-LM     0.005876\n",
      "SA-Si-LM     0.006410\n",
      "TSL-Si-LM    0.003205\n",
      "SAL-Si-LM    0.007479\n",
      "dtype: float64\n",
      "data size 234 found 0 alg 56\n",
      "classes_identified_test test: [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0] 51\n",
      "(296, 62) (296, 8)\n",
      "******* Feature select: PCA9999  Feature type: ST-F Classification model: rfc ******\n",
      "Test score:  0.06451612903225806\n",
      "Best estimator: MultiOutputClassifier(estimator=RandomForestClassifier(min_samples_split=0.05,\n",
      "                                                       n_estimators=50))\n",
      "Accuracy Best score (validation) val. score :  0.1285846438482886\n",
      "Hamming loss test: 0.1693548387096774\n",
      "Hamming loss train: TS-Ei-LM     0.006944\n",
      "SA-Ei-LM     0.003205\n",
      "TSL-Ei-LM    0.004808\n",
      "SAL-Ei-LM    0.000534\n",
      "TS-Si-LM     0.007479\n",
      "SA-Si-LM     0.006944\n",
      "TSL-Si-LM    0.004808\n",
      "SAL-Si-LM    0.008013\n",
      "dtype: float64\n",
      "data size 234 found 0 alg 48\n",
      "classes_identified_test test: [0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 2, 2, 0, 0, 1, 0, 0, 1, 0, 0, 0, 2, 0, 0, 1, 0, 1, 0, 0, 2, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0] 44\n",
      "(296, 25) (296, 8)\n",
      "******* Feature select: FS_S  Feature type: ST-F Classification model: rfc ******\n",
      "Test score:  0.11290322580645161\n",
      "Best estimator: MultiOutputClassifier(estimator=RandomForestClassifier(criterion='log_loss',\n",
      "                                                       min_samples_split=0.06392540800694095,\n",
      "                                                       n_estimators=25))\n",
      "Accuracy Best score (validation) val. score :  0.20952821461609622\n",
      "Hamming loss test: 0.15120967741935484\n",
      "Hamming loss train: TS-Ei-LM     0.009081\n",
      "SA-Ei-LM     0.008547\n",
      "TSL-Ei-LM    0.007479\n",
      "SAL-Ei-LM    0.013355\n",
      "TS-Si-LM     0.008013\n",
      "SA-Si-LM     0.008547\n",
      "TSL-Si-LM    0.006944\n",
      "SAL-Si-LM    0.010684\n",
      "dtype: float64\n",
      "data size 234 found 0 alg 82\n",
      "classes_identified_test test: [0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 1, 0, 1, 0, 2, 0, 2, 0, 2, 1, 2, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 3, 2, 1, 0, 0, 1] 40\n",
      "(296, 31) (296, 8)\n",
      "******* Feature select: FS_P  Feature type: ST-F Classification model: rfc ******\n",
      "Test score:  0.08064516129032258\n",
      "Best estimator: MultiOutputClassifier(estimator=RandomForestClassifier(criterion='entropy',\n",
      "                                                       min_samples_split=0.05))\n",
      "Accuracy Best score (validation) val. score :  0.19269195189639224\n",
      "Hamming loss test: 0.14717741935483872\n",
      "Hamming loss train: TS-Ei-LM     0.007479\n",
      "SA-Ei-LM     0.006410\n",
      "TSL-Ei-LM    0.005876\n",
      "SAL-Ei-LM    0.008013\n",
      "TS-Si-LM     0.006410\n",
      "SA-Si-LM     0.009081\n",
      "TSL-Si-LM    0.005342\n",
      "SAL-Si-LM    0.006944\n",
      "dtype: float64\n",
      "data size 234 found 0 alg 61\n",
      "classes_identified_test test: [0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 2, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 2, 1, 1, 0, 0, 0] 44\n",
      "(296, 40) (296, 8)\n",
      "******* Feature select: FS_K  Feature type: ST-F Classification model: rfc ******\n",
      "Test score:  0.0967741935483871\n",
      "Best estimator: MultiOutputClassifier(estimator=RandomForestClassifier(min_samples_split=0.0534511577236042,\n",
      "                                                       n_estimators=75))\n",
      "Accuracy Best score (validation) val. score :  0.19250693802035151\n",
      "Hamming loss test: 0.17540322580645162\n",
      "Hamming loss train: TS-Ei-LM     0.006944\n",
      "SA-Ei-LM     0.007479\n",
      "TSL-Ei-LM    0.005876\n",
      "SAL-Ei-LM    0.009615\n",
      "TS-Si-LM     0.006410\n",
      "SA-Si-LM     0.010150\n",
      "TSL-Si-LM    0.005876\n",
      "SAL-Si-LM    0.010684\n",
      "dtype: float64\n",
      "data size 234 found 0 alg 75\n",
      "classes_identified_test test: [0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 3, 1, 0, 0, 1, 4, 0, 1, 0, 1, 1, 1, 0, 2, 0, 2, 2, 1, 0, 0, 1, 1, 4, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 3, 1, 3, 3, 1, 0, 0, 2] 33\n",
      "(296, 14) (296, 8)\n",
      "******* Feature select: LASSO  Feature type: ST-F Classification model: rfc ******\n",
      "Test score:  0.11290322580645161\n",
      "Best estimator: MultiOutputClassifier(estimator=RandomForestClassifier(criterion='entropy',\n",
      "                                                       max_features='log2',\n",
      "                                                       min_samples_split=0.05,\n",
      "                                                       n_estimators=50))\n",
      "Accuracy Best score (validation) val. score :  0.17557816836262718\n",
      "Hamming loss test: 0.14919354838709678\n",
      "Hamming loss train: TS-Ei-LM     0.007479\n",
      "SA-Ei-LM     0.007479\n",
      "TSL-Ei-LM    0.008013\n",
      "SAL-Ei-LM    0.011218\n",
      "TS-Si-LM     0.007479\n",
      "SA-Si-LM     0.009615\n",
      "TSL-Si-LM    0.006410\n",
      "SAL-Si-LM    0.010150\n",
      "dtype: float64\n",
      "data size 234 found 0 alg 80\n",
      "classes_identified_test test: [0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 2, 0, 2, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 2, 1, 1, 1, 1, 0, 0, 0] 40\n",
      "(296, 28) (296, 8)\n",
      "******* Feature select: ELASTICNET  Feature type: ST-F Classification model: rfc ******\n",
      "Test score:  0.11290322580645161\n",
      "Best estimator: MultiOutputClassifier(estimator=RandomForestClassifier(min_samples_split=0.05))\n",
      "Accuracy Best score (validation) val. score :  0.18862164662349676\n",
      "Hamming loss test: 0.15524193548387097\n",
      "Hamming loss train: TS-Ei-LM     0.008547\n",
      "SA-Ei-LM     0.008547\n",
      "TSL-Ei-LM    0.005876\n",
      "SAL-Ei-LM    0.009615\n",
      "TS-Si-LM     0.007479\n",
      "SA-Si-LM     0.009615\n",
      "TSL-Si-LM    0.005876\n",
      "SAL-Si-LM    0.009081\n",
      "dtype: float64\n",
      "data size 234 found 0 alg 72\n",
      "classes_identified_test test: [0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 3, 0, 1, 1, 3, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 2, 1, 1, 1, 1, 0, 0, 0] 36\n"
     ]
    }
   ],
   "source": [
    "ft_type=['ST-F']#['HG']#'OG', 'OGQ', 'OGSM', 'OGET']#,'DG','HG']\n",
    "classification_types=['rfc']#['rfc','svc','gbc']\n",
    "ft_select=['all','LR10', 'LR20', 'LR30', 'LR40', 'RF', 'PCA99','PCA999','PCA9999','FS_S','FS_P','FS_K', 'LASSO', 'ELASTICNET']\n",
    "\n",
    "\n",
    "dir_path = '../datasets/results/classification/februarie2025-v4/'\n",
    "classification_tuning(dir_path, ft_type, ft_select, classification_types, \n",
    "                  feature_path='../datasets/results/features/februarie2025-v4/',\n",
    "                  ranks_path='../datasets/results/ranks/runTime_1min_sa_ts_multilabel_filtered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(296, 91) (296, 3)\n",
      "******* Feature select: all  Feature type: ST-F Classification model: rfc ******\n",
      "Test score:  0.2903225806451613\n",
      "Best estimator: MultiOutputClassifier(estimator=RandomForestClassifier(max_features='log2',\n",
      "                                                       min_samples_split=0.05))\n",
      "Accuracy Best score (validation) val. score :  0.30786308973172993\n",
      "Hamming loss test: 0.3172043010752688\n",
      "Hamming loss train: stategy         0.024217\n",
      "init            0.025641\n",
      "perturbation    0.021368\n",
      "dtype: float64\n",
      "data size 234 found 0 alg 11\n",
      "classes_identified_test test: [2, 3, 3, 1, 3, 0, 2, 2, 2, 2, 2, 3, 1, 3, 3, 3, 1, 3, 3, 2, 2, 3, 3, 2, 3, 1, 2, 2, 3, 3, 3, 3, 2, 1, 3, 3, 3, 2, 3, 3, 2, 2, 2, 2, 2, 2, 2, 3, 3, 2, 2, 3, 2, 3, 3, 3, 3, 3, 3, 2, 3, 2] 1\n",
      "(296, 10) (296, 3)\n",
      "******* Feature select: LR10  Feature type: ST-F Classification model: rfc ******\n",
      "Test score:  0.1935483870967742\n",
      "Best estimator: MultiOutputClassifier(estimator=RandomForestClassifier(max_features='log2',\n",
      "                                                       min_samples_split=0.056450713165929936,\n",
      "                                                       n_estimators=10))\n",
      "Accuracy Best score (validation) val. score :  0.2906567992599445\n",
      "Hamming loss test: 0.3870967741935484\n",
      "Hamming loss train: stategy         0.037037\n",
      "init            0.064103\n",
      "perturbation    0.044160\n",
      "dtype: float64\n",
      "data size 234 found 0 alg 4\n",
      "classes_identified_test test: [2, 1, 2, 2, 3, 1, 2, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 3, 1, 3, 3, 3, 1, 3, 2, 3, 2, 2, 3, 3, 2, 2, 1, 3, 3, 3, 1, 2, 3, 2, 3, 3, 2, 3, 3, 2, 2, 2, 2, 2, 3, 1, 3, 2, 2, 3, 3, 3, 3, 3, 3] 0\n",
      "(296, 20) (296, 3)\n",
      "******* Feature select: LR20  Feature type: ST-F Classification model: rfc ******\n",
      "Test score:  0.24193548387096775\n",
      "Best estimator: MultiOutputClassifier(estimator=RandomForestClassifier(criterion='log_loss',\n",
      "                                                       min_samples_split=0.05744234939309271))\n",
      "Accuracy Best score (validation) val. score :  0.29093432007400555\n",
      "Hamming loss test: 0.3172043010752688\n",
      "Hamming loss train: stategy         0.027066\n",
      "init            0.039886\n",
      "perturbation    0.034188\n",
      "dtype: float64\n",
      "data size 234 found 0 alg 9\n",
      "classes_identified_test test: [2, 2, 2, 2, 3, 0, 2, 2, 2, 1, 1, 3, 2, 3, 1, 3, 1, 2, 3, 2, 2, 3, 1, 0, 3, 3, 2, 2, 3, 3, 3, 2, 2, 1, 2, 3, 2, 2, 2, 3, 2, 3, 2, 2, 2, 2, 1, 3, 3, 2, 1, 3, 2, 3, 2, 3, 2, 3, 3, 3, 3, 3] 2\n",
      "(296, 30) (296, 3)\n",
      "******* Feature select: LR30  Feature type: ST-F Classification model: rfc ******\n",
      "Test score:  0.3064516129032258\n",
      "Best estimator: MultiOutputClassifier(estimator=RandomForestClassifier(criterion='log_loss',\n",
      "                                                       min_samples_split=0.12690347979994107,\n",
      "                                                       n_estimators=50))\n",
      "Accuracy Best score (validation) val. score :  0.3076780758556892\n",
      "Hamming loss test: 0.3225806451612903\n",
      "Hamming loss train: stategy         0.051282\n",
      "init            0.076923\n",
      "perturbation    0.054131\n",
      "dtype: float64\n",
      "data size 234 found 0 alg 5\n",
      "classes_identified_test test: [2, 3, 2, 2, 3, 1, 3, 3, 3, 2, 2, 3, 2, 3, 3, 3, 2, 3, 3, 2, 3, 3, 2, 1, 3, 3, 3, 2, 3, 3, 3, 3, 2, 1, 2, 3, 3, 2, 3, 3, 2, 3, 2, 2, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 3, 3, 3, 3] 0\n",
      "(296, 40) (296, 3)\n",
      "******* Feature select: LR40  Feature type: ST-F Classification model: rfc ******\n",
      "Test score:  0.3225806451612903\n",
      "Best estimator: MultiOutputClassifier(estimator=RandomForestClassifier(criterion='log_loss',\n",
      "                                                       min_samples_split=0.05,\n",
      "                                                       n_estimators=50))\n",
      "Accuracy Best score (validation) val. score :  0.30407030527289547\n",
      "Hamming loss test: 0.3172043010752688\n",
      "Hamming loss train: stategy         0.027066\n",
      "init            0.031339\n",
      "perturbation    0.027066\n",
      "dtype: float64\n",
      "data size 234 found 0 alg 9\n",
      "classes_identified_test test: [2, 2, 2, 1, 3, 1, 3, 2, 2, 2, 2, 3, 2, 3, 3, 3, 1, 2, 3, 1, 3, 3, 2, 0, 2, 3, 2, 2, 3, 3, 3, 3, 2, 1, 3, 3, 3, 2, 2, 3, 2, 3, 2, 3, 2, 3, 2, 2, 3, 2, 2, 3, 2, 3, 2, 3, 2, 3, 3, 3, 3, 3] 1\n",
      "(296, 47) (296, 3)\n",
      "******* Feature select: RF  Feature type: ST-F Classification model: rfc ******\n",
      "Test score:  0.20967741935483872\n",
      "Best estimator: MultiOutputClassifier(estimator=RandomForestClassifier(criterion='log_loss',\n",
      "                                                       max_features='log2',\n",
      "                                                       min_samples_split=0.0996169403456228,\n",
      "                                                       n_estimators=10))\n",
      "Accuracy Best score (validation) val. score :  0.3080481036077706\n",
      "Hamming loss test: 0.3978494623655914\n",
      "Hamming loss train: stategy         0.045584\n",
      "init            0.071225\n",
      "perturbation    0.055556\n",
      "dtype: float64\n",
      "data size 234 found 0 alg 6\n",
      "classes_identified_test test: [3, 2, 2, 2, 3, 2, 3, 3, 1, 3, 2, 3, 2, 3, 3, 1, 3, 2, 3, 3, 3, 3, 3, 2, 3, 2, 3, 2, 3, 3, 3, 2, 2, 2, 2, 3, 3, 2, 3, 3, 1, 3, 2, 2, 3, 3, 2, 2, 3, 2, 1, 2, 2, 2, 2, 3, 2, 3, 3, 3, 2, 2] 0\n",
      "(296, 28) (296, 3)\n",
      "******* Feature select: PCA99  Feature type: ST-F Classification model: rfc ******\n",
      "Test score:  0.22580645161290322\n",
      "Best estimator: MultiOutputClassifier(estimator=RandomForestClassifier(criterion='entropy',\n",
      "                                                       max_features='log2',\n",
      "                                                       min_samples_split=0.1668384391609617,\n",
      "                                                       n_estimators=150))\n",
      "Accuracy Best score (validation) val. score :  0.3035152636447734\n",
      "Hamming loss test: 0.3978494623655914\n",
      "Hamming loss train: stategy         0.054131\n",
      "init            0.091168\n",
      "perturbation    0.059829\n",
      "dtype: float64\n",
      "data size 234 found 0 alg 5\n",
      "classes_identified_test test: [3, 2, 2, 2, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 2, 2, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 3, 3, 2, 2, 2, 3, 3, 3, 3, 2, 3, 3, 3, 3, 2, 3, 3] 0\n",
      "(296, 49) (296, 3)\n",
      "******* Feature select: PCA999  Feature type: ST-F Classification model: rfc ******\n",
      "Test score:  0.22580645161290322\n",
      "Best estimator: MultiOutputClassifier(estimator=RandomForestClassifier(criterion='entropy',\n",
      "                                                       max_features=1,\n",
      "                                                       min_samples_split=0.05125751755762455,\n",
      "                                                       n_estimators=150))\n",
      "Accuracy Best score (validation) val. score :  0.31646623496762255\n",
      "Hamming loss test: 0.3924731182795699\n",
      "Hamming loss train: stategy         0.019943\n",
      "init            0.038462\n",
      "perturbation    0.027066\n",
      "dtype: float64\n",
      "data size 234 found 0 alg 11\n",
      "classes_identified_test test: [3, 2, 3, 3, 2, 3, 3, 2, 3, 3, 3, 2, 2, 3, 3, 3, 3, 2, 3, 3, 3, 3, 2, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 3, 3, 2, 2, 3, 2, 3, 3, 2, 3, 3, 3, 2, 3, 3, 2, 3, 3] 0\n",
      "(296, 66) (296, 3)\n",
      "******* Feature select: PCA9999  Feature type: ST-F Classification model: rfc ******\n",
      "Test score:  0.0967741935483871\n",
      "Best estimator: MultiOutputClassifier(estimator=RandomForestClassifier(min_samples_split=0.05))\n",
      "Accuracy Best score (validation) val. score :  0.32062904717853835\n",
      "Hamming loss test: 0.532258064516129\n",
      "Hamming loss train: stategy         0.014245\n",
      "init            0.014245\n",
      "perturbation    0.012821\n",
      "dtype: float64\n",
      "data size 234 found 0 alg 13\n",
      "classes_identified_test test: [1, 0, 2, 0, 3, 0, 2, 0, 0, 0, 0, 1, 1, 3, 1, 2, 0, 1, 1, 0, 3, 0, 2, 0, 2, 2, 2, 1, 2, 3, 1, 0, 2, 0, 1, 2, 1, 0, 2, 2, 0, 3, 1, 0, 1, 3, 2, 0, 0, 1, 0, 1, 0, 2, 0, 1, 2, 2, 0, 1, 3, 2] 22\n",
      "(296, 47) (296, 3)\n",
      "******* Feature select: FS_S  Feature type: ST-F Classification model: rfc ******\n",
      "Test score:  0.27419354838709675\n",
      "Best estimator: MultiOutputClassifier(estimator=RandomForestClassifier(criterion='log_loss',\n",
      "                                                       max_features=1,\n",
      "                                                       min_samples_split=0.05,\n",
      "                                                       n_estimators=75))\n",
      "Accuracy Best score (validation) val. score :  0.3078630897317299\n",
      "Hamming loss test: 0.34408602150537637\n",
      "Hamming loss train: stategy         0.029915\n",
      "init            0.047009\n",
      "perturbation    0.034188\n",
      "dtype: float64\n",
      "data size 234 found 0 alg 4\n",
      "classes_identified_test test: [3, 3, 3, 1, 3, 1, 2, 2, 2, 2, 2, 3, 1, 3, 3, 3, 2, 3, 3, 3, 2, 2, 3, 1, 3, 3, 3, 2, 3, 3, 2, 2, 3, 1, 3, 3, 3, 1, 3, 3, 2, 3, 2, 2, 2, 2, 2, 2, 3, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 3] 0\n",
      "(296, 47) (296, 3)\n",
      "******* Feature select: FS_P  Feature type: ST-F Classification model: rfc ******\n",
      "Test score:  0.24193548387096775\n",
      "Best estimator: MultiOutputClassifier(estimator=RandomForestClassifier(criterion='log_loss',\n",
      "                                                       max_features='log2',\n",
      "                                                       min_samples_split=0.07259820088268526,\n",
      "                                                       n_estimators=10))\n",
      "Accuracy Best score (validation) val. score :  0.33358001850138763\n",
      "Hamming loss test: 0.3709677419354839\n",
      "Hamming loss train: stategy         0.038462\n",
      "init            0.071225\n",
      "perturbation    0.038462\n",
      "dtype: float64\n",
      "data size 234 found 0 alg 5\n",
      "classes_identified_test test: [2, 1, 3, 2, 1, 1, 3, 3, 3, 3, 3, 3, 2, 3, 2, 3, 1, 2, 3, 2, 2, 3, 3, 1, 3, 3, 3, 3, 2, 3, 2, 3, 3, 1, 2, 3, 3, 2, 3, 3, 2, 3, 2, 2, 2, 2, 2, 1, 3, 2, 2, 3, 3, 2, 2, 2, 3, 2, 2, 3, 3, 3] 0\n",
      "(296, 70) (296, 3)\n",
      "******* Feature select: FS_K  Feature type: ST-F Classification model: rfc ******\n",
      "Test score:  0.2903225806451613\n",
      "Best estimator: MultiOutputClassifier(estimator=RandomForestClassifier(criterion='log_loss',\n",
      "                                                       min_samples_split=0.050394122388399035,\n",
      "                                                       n_estimators=150))\n",
      "Accuracy Best score (validation) val. score :  0.3122109158186864\n",
      "Hamming loss test: 0.3172043010752688\n",
      "Hamming loss train: stategy         0.017094\n",
      "init            0.024217\n",
      "perturbation    0.021368\n",
      "dtype: float64\n",
      "data size 234 found 0 alg 10\n",
      "classes_identified_test test: [3, 3, 3, 2, 3, 1, 3, 2, 3, 2, 2, 3, 2, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 1, 3, 2, 2, 2, 3, 3, 3, 3, 2, 1, 2, 3, 3, 2, 3, 2, 2, 3, 3, 2, 2, 3, 2, 2, 3, 2, 2, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3] 0\n"
     ]
    }
   ],
   "source": [
    "ft_type=['ST-F']#['HG']#'OG', 'OGQ', 'OGSM', 'OGET']#,'DG','HG']\n",
    "classification_types=['rfc']#['rfc','svc','gbc']\n",
    "ft_select=['all','LR10', 'LR20', 'LR30', 'LR40', 'RF', 'PCA99','PCA999','PCA9999','FS_S','FS_P','FS_K']\n",
    "\n",
    "\n",
    "dir_path = '../datasets/results/classification/februarie2025-v3/'\n",
    "classification_tuning(dir_path, ft_type, ft_select, classification_types, \n",
    "                  feature_path='../datasets/results/features/februarie2025-v3/',\n",
    "                  ranks_path='../datasets/results/ranks/runTime_1min_sa_ts_agregated_multilabel_filtered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******* Feature select: LR40  Feature type: OG-F Classification model: mlknn ******\n",
      "Test score:  0.14516129032258066\n",
      "Best estimator: MLkNN(k=5)\n",
      "Accurecy of the best estimator (training dataset):  0.32905982905982906\n",
      "Accuracy Best score (validation) val. score :  0.1666049953746531\n",
      "Hamming loss: 0.16532258064516128\n",
      "Accuracy of the best estimator (testing dataset):  0.14516129032258066\n",
      "F1-score: 0.369\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       TS-Ei       0.00      0.00      0.00         3\n",
      "       SA-Ei       0.71      0.45      0.56        22\n",
      "      TSL-Ei       0.00      0.00      0.00         7\n",
      "      SAL-Ei       0.46      0.57      0.51        21\n",
      "       TS-Si       0.00      0.00      0.00         6\n",
      "       SA-Si       0.00      0.00      0.00         8\n",
      "      TSL-Si       0.25      0.33      0.29         3\n",
      "      SAL-Si       0.17      0.17      0.17         6\n",
      "\n",
      "   micro avg       0.44      0.32      0.37        76\n",
      "   macro avg       0.20      0.19      0.19        76\n",
      "weighted avg       0.36      0.32      0.33        76\n",
      " samples avg       0.23      0.27      0.23        76\n",
      "\n",
      "data size 234 found 0 alg 96\n",
      "classes_identified_test test: [0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 5, 0, 0, 0, 1, 5, 1, 0, 0, 1, 0, 2, 1, 2, 0, 2, 1, 2, 0, 1, 0, 0, 4, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 2, 0, 2, 5, 2, 0, 0, 1] 31\n"
     ]
    }
   ],
   "source": [
    "ft_type=['OG-F']#['HG']#'OG', 'OGQ', 'OGSM', 'OGET']#,'DG','HG']\n",
    "classification_types=['mlknn']\n",
    "ft_select=['LR40']\n",
    "\n",
    "dir_path = '../datasets/results/classification/ianuarie2025/'\n",
    "classification_tuning(dir_path, ft_type, ft_select, classification_types, \n",
    "                  feature_path='../datasets/results/features/ianuarie2025-v2/',\n",
    "                  ranks_path='../datasets/results/ranks/runTime_1min_sa_ts_multilabel_filtered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_type=['OG-F']#['HG']#'OG', 'OGQ', 'OGSM', 'OGET']#,'DG','HG']\n",
    "classification_types=['mcc_rfc', 'mcc']\n",
    "ft_select=['LR40']\n",
    "\n",
    "dir_path = '../datasets/results/classification/ianuarie2025/'\n",
    "classification_tuning(dir_path, ft_type, ft_select, classification_types, \n",
    "                  feature_path='../datasets/results/features/ianuarie2025-v2/',\n",
    "                  ranks_path='../datasets/results/ranks/runTime_1min_sa_ts_multilabel_filtered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******* Feature select: LR40  Feature type: OG-F Classification model: rfc ******\n",
      "Test score:  0.0967741935483871\n",
      "Best estimator: MultiOutputClassifier(estimator=RandomForestClassifier(min_samples_split=0.05379679926080017,\n",
      "                                                       n_estimators=10))\n",
      "Accurecy of the best estimator (training dataset):  0.5170940170940171\n",
      "Accuracy Best score (validation) val. score :  0.17946345975948197\n",
      "Hamming loss: 0.2056451612903226\n",
      "Accuracy of the best estimator (testing dataset):  0.0967741935483871\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       TS-Ei       0.00      0.00      0.00         3\n",
      "       SA-Ei       0.69      0.50      0.58        22\n",
      "      TSL-Ei       0.23      0.43      0.30         7\n",
      "      SAL-Ei       0.50      0.38      0.43        21\n",
      "       TS-Si       0.33      0.17      0.22         6\n",
      "       SA-Si       0.00      0.00      0.00         8\n",
      "      TSL-Si       0.12      0.33      0.18         3\n",
      "      SAL-Si       0.05      0.17      0.08         6\n",
      "\n",
      "   micro avg       0.33      0.33      0.33        76\n",
      "   macro avg       0.24      0.25      0.22        76\n",
      "weighted avg       0.39      0.33      0.35        76\n",
      " samples avg       0.22      0.28      0.22        76\n",
      "\n",
      "data size 234 found 0 alg 71\n",
      "classes_identified_test test: [1, 0, 0, 0, 1, 0, 2, 0, 1, 1, 0, 5, 0, 5, 3, 1, 0, 1, 4, 1, 1, 0, 1, 1, 1, 0, 4, 0, 2, 1, 0, 1, 0, 2, 0, 5, 2, 1, 1, 0, 0, 1, 0, 2, 0, 1, 2, 0, 1, 1, 2, 2, 1, 1, 2, 1, 2, 4, 2, 0, 1, 1] 20\n",
      "******* Feature select: LR40  Feature type: OG-F Classification model: mcc_rfc ******\n",
      "Test score:  0.1774193548387097\n",
      "Best estimator: ClassifierChain(base_estimator=RandomForestClassifier(criterion='entropy',\n",
      "                                                      min_samples_split=0.05,\n",
      "                                                      n_estimators=50))\n",
      "Accurecy of the best estimator (training dataset):  0.6709401709401709\n",
      "Accuracy Best score (validation) val. score :  0.1667900092506938\n",
      "Hamming loss: 0.15120967741935484\n",
      "Accuracy of the best estimator (testing dataset):  0.1774193548387097\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       TS-Ei       0.00      0.00      0.00         3\n",
      "       SA-Ei       0.77      0.45      0.57        22\n",
      "      TSL-Ei       0.33      0.29      0.31         7\n",
      "      SAL-Ei       0.45      0.48      0.47        21\n",
      "       TS-Si       0.00      0.00      0.00         6\n",
      "       SA-Si       0.00      0.00      0.00         8\n",
      "      TSL-Si       0.50      0.33      0.40         3\n",
      "      SAL-Si       0.00      0.00      0.00         6\n",
      "\n",
      "   micro avg       0.51      0.30      0.38        76\n",
      "   macro avg       0.26      0.19      0.22        76\n",
      "weighted avg       0.40      0.30      0.34        76\n",
      " samples avg       0.24      0.27      0.24        76\n",
      "\n",
      "data size 234 found 0 alg 57\n",
      "classes_identified_test test: [1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 3, 1, 0, 0, 0, 3, 0, 1, 0, 1, 0, 1, 0, 2, 0, 2, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 2, 1, 1, 2, 0, 2, 2, 2, 0, 0, 2] 29\n"
     ]
    }
   ],
   "source": [
    "ft_type=['OG-F']#['HG']#'OG', 'OGQ', 'OGSM', 'OGET']#,'DG','HG']\n",
    "classification_types=['rfc', 'mcc_rfc']\n",
    "ft_select=['LR40']\n",
    "\n",
    "dir_path = '../datasets/results/classification/ianuarie2025/'\n",
    "classification_tuning(dir_path, ft_type, ft_select, classification_types, \n",
    "                  feature_path='../datasets/results/features/ianuarie2025-v2/',\n",
    "                  ranks_path='../datasets/results/ranks/runTime_1min_sa_ts_multilabel_filtered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******* Feature select: LR40  Feature type: OG-F Classification model: br_rfc ******\n",
      "Test score:  0.14516129032258066\n",
      "Best estimator: BinaryRelevance(classifier=RandomForestClassifier(min_samples_split=0.05409556809735245,\n",
      "                                                  n_estimators=75),\n",
      "                require_dense=[True, True])\n",
      "Accurecy of the best estimator (training dataset):  0.5512820512820513\n",
      "Accuracy Best score (validation) val. score :  0.18371877890841812\n",
      "Hamming loss: 0.18346774193548387\n",
      "Accuracy of the best estimator (testing dataset):  0.14516129032258066\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       TS-Ei       0.00      0.00      0.00         3\n",
      "       SA-Ei       0.71      0.45      0.56        22\n",
      "      TSL-Ei       0.25      0.29      0.27         7\n",
      "      SAL-Ei       0.50      0.38      0.43        21\n",
      "       TS-Si       1.00      0.17      0.29         6\n",
      "       SA-Si       0.00      0.00      0.00         8\n",
      "      TSL-Si       0.50      0.67      0.57         3\n",
      "      SAL-Si       0.10      0.33      0.15         6\n",
      "\n",
      "   micro avg       0.38      0.33      0.35        76\n",
      "   macro avg       0.38      0.29      0.28        76\n",
      "weighted avg       0.47      0.33      0.36        76\n",
      " samples avg       0.25      0.30      0.26        76\n",
      "\n",
      "data size 234 found 0 alg 74\n",
      "classes_identified_test test: [1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 2, 0, 3, 3, 1, 1, 0, 3, 0, 1, 1, 1, 1, 1, 0, 2, 0, 2, 1, 1, 0, 0, 2, 1, 2, 2, 0, 1, 1, 0, 1, 0, 2, 1, 1, 1, 0, 1, 2, 1, 2, 1, 0, 2, 1, 2, 3, 2, 0, 1, 2] 18\n",
      "******* Feature select: LR40  Feature type: OG-F Classification model: lp_rfc ******\n",
      "Test score:  0.2903225806451613\n",
      "Best estimator: LabelPowerset(classifier=RandomForestClassifier(criterion='log_loss',\n",
      "                                                min_samples_split=0.05202921395982867,\n",
      "                                                n_estimators=10),\n",
      "              require_dense=[True, True])\n",
      "Accurecy of the best estimator (training dataset):  0.6367521367521367\n",
      "Accuracy Best score (validation) val. score :  0.30740055504162817\n",
      "Hamming loss: 0.17338709677419356\n",
      "Accuracy of the best estimator (testing dataset):  0.2903225806451613\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       TS-Ei       0.00      0.00      0.00         3\n",
      "       SA-Ei       0.42      0.36      0.39        22\n",
      "      TSL-Ei       0.83      0.71      0.77         7\n",
      "      SAL-Ei       0.40      0.48      0.43        21\n",
      "       TS-Si       0.00      0.00      0.00         6\n",
      "       SA-Si       0.33      0.12      0.18         8\n",
      "      TSL-Si       0.50      0.67      0.57         3\n",
      "      SAL-Si       0.00      0.00      0.00         6\n",
      "\n",
      "   micro avg       0.42      0.34      0.38        76\n",
      "   macro avg       0.31      0.29      0.29        76\n",
      "weighted avg       0.36      0.34      0.35        76\n",
      " samples avg       0.42      0.34      0.36        76\n",
      "\n",
      "data size 234 found 0 alg 0\n",
      "classes_identified_test test: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] 0\n",
      "******* Feature select: LR40  Feature type: OG-F Classification model: mcc_rfc ******\n",
      "Test score:  0.0967741935483871\n",
      "Best estimator: ClassifierChain(base_estimator=RandomForestClassifier(criterion='log_loss',\n",
      "                                                      max_features='log2',\n",
      "                                                      min_samples_split=0.07932436680912591,\n",
      "                                                      n_estimators=10))\n",
      "Accurecy of the best estimator (training dataset):  0.405982905982906\n",
      "Accuracy Best score (validation) val. score :  0.19213691026827012\n",
      "Hamming loss: 0.1532258064516129\n",
      "Accuracy of the best estimator (testing dataset):  0.0967741935483871\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       TS-Ei       0.00      0.00      0.00         3\n",
      "       SA-Ei       0.73      0.36      0.48        22\n",
      "      TSL-Ei       0.38      0.43      0.40         7\n",
      "      SAL-Ei       0.60      0.29      0.39        21\n",
      "       TS-Si       0.00      0.00      0.00         6\n",
      "       SA-Si       0.00      0.00      0.00         8\n",
      "      TSL-Si       0.00      0.00      0.00         3\n",
      "      SAL-Si       0.00      0.00      0.00         6\n",
      "\n",
      "   micro avg       0.50      0.22      0.31        76\n",
      "   macro avg       0.21      0.13      0.16        76\n",
      "weighted avg       0.41      0.22      0.28        76\n",
      " samples avg       0.16      0.17      0.16        76\n",
      "\n",
      "data size 234 found 0 alg 98\n",
      "classes_identified_test test: [1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 3, 0, 2, 0, 0, 0, 2, 0, 1, 1, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, 0, 2, 0, 2, 3, 1, 0, 0, 1] 41\n"
     ]
    }
   ],
   "source": [
    "ft_type=['OG-F']#['HG']#'OG', 'OGQ', 'OGSM', 'OGET']#,'DG','HG']\n",
    "classification_types=['br_rfc', 'lp_rfc', 'mcc_rfc']\n",
    "ft_select=['LR40']\n",
    "\n",
    "dir_path = '../datasets/results/classification/ianuarie2025/'\n",
    "classification_tuning(dir_path, ft_type, ft_select, classification_types, \n",
    "                  feature_path='../datasets/results/features/ianuarie2025-v2/',\n",
    "                  ranks_path='../datasets/results/ranks/runTime_1min_sa_ts_multilabel_filtered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3760781482913213 0.0 0.8026315789473685\n",
      "0.3866226627924744 0.0 0.8289473684210527\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openne'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 273\u001b[0m\n\u001b[0;32m    270\u001b[0m ft_select\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLR40\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    272\u001b[0m dir_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../datasets/results/classification/ianuarie2025/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 273\u001b[0m \u001b[43mclassification_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdir_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mft_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mft_select\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassification_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mfeature_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../datasets/results/features/ianuarie2025-v2/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mranks_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../datasets/results/ranks/runTime_1min_sa_ts_multilabel_filtered\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[19], line 240\u001b[0m, in \u001b[0;36mclassification_graph\u001b[1;34m(out_dir_path, ft_type, ft_select, classification_types, feature_path, ranks_path)\u001b[0m\n\u001b[0;32m    201\u001b[0m graph_builder \u001b[38;5;241m=\u001b[39m LabelCooccurrenceGraphBuilder(weighted\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, include_self_edges\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    202\u001b[0m \u001b[38;5;66;03m# openne_line_params = dict(batch_size=1000, order=3)\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;66;03m# embedder = OpenNetworkEmbedder(\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;66;03m#     graph_builder,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    238\u001b[0m \n\u001b[0;32m    239\u001b[0m \u001b[38;5;66;03m# predictions = clf.predict(X_test)\u001b[39;00m\n\u001b[1;32m--> 240\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mskmultilearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membedding\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SKLearnEmbedder, EmbeddingClassifier\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmanifold\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SpectralEmbedding\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RandomForestRegressor\n",
      "File \u001b[1;32m~\\.conda\\envs\\scamp-ml-dataGenerator\\Lib\\site-packages\\skmultilearn\\embedding\\__init__.py:32\u001b[0m\n\u001b[0;32m     25\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCLEMS\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSKLearnEmbedder\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEmbeddingClassifier\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     29\u001b[0m ]\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (sys\u001b[38;5;241m.\u001b[39mversion_info[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m platform\u001b[38;5;241m.\u001b[39marchitecture()[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m32bit\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m---> 32\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenne\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenNetworkEmbedder\n\u001b[0;32m     34\u001b[0m     __all__\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOpenNetworkEmbedder\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\scamp-ml-dataGenerator\\Lib\\site-packages\\skmultilearn\\embedding\\openne.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcopy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m copy\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mopenne\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GraphFactorization\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mopenne\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Graph\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mopenne\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgrarep\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GraRep\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'openne'"
     ]
    }
   ],
   "source": [
    "from skmultilearn.cluster import LabelCooccurrenceGraphBuilder\n",
    "from skmultilearn.cluster.networkx import NetworkXLabelGraphClusterer\n",
    "\n",
    "\n",
    "# we define a helper function for visualization purposes\n",
    "def to_membership_vector(partition):\n",
    "    return {\n",
    "        member :  partition_id\n",
    "        for partition_id, members in enumerate(partition)\n",
    "        for member in members\n",
    "    }\n",
    "    \n",
    "def classification_graph(out_dir_path, ft_type, ft_select, classification_types, feature_path, ranks_path):\n",
    "    Path(out_dir_path).mkdir(exist_ok=True)\n",
    "\n",
    "    #generate in  fisierul DatasetsRanking\n",
    "    idx_X_test = [99, 161, 95, 175, 45, 166, 224, 50, 249, 102, 107, 284, 177, 121, 136, \n",
    "                  241, 34, 260, 119, 199, 40, 24, 264, 169, 280, 51, 152, 110, 290, 4, \n",
    "                  6, 55, 77, 167, 217, 124, 278, 56, 144, 91, 170, 74, 159, 232, 27, 41, \n",
    "                  245, 164, 214, 230, 246, 263, 101, 18, 292, 92, 147, 115, 277, 15, 254, 62]\n",
    "\n",
    "    idx_X_train = [30, 194, 248, 17, 81, 16, 58, 188, 160, 287, 129, 240, 213, 130, 256, \n",
    "                   79, 282, 84, 145, 36, 257, 220, 28, 134, 265, 286, 142, 195, 201, 66, \n",
    "                   273, 157, 128, 279, 150, 125, 109, 96, 26, 29, 227, 259, 276, 61, 73, \n",
    "                   209, 178, 215, 11, 80, 218, 163, 98, 253, 20, 225, 168, 205, 104, 200, \n",
    "                   197, 94, 106, 105, 118, 22, 187, 112, 202, 60, 237, 153, 75, 7, 294, 219, \n",
    "                   285, 151, 204, 222, 196, 156, 90, 193, 10, 72, 155, 1, 247, 57, 13, 131, \n",
    "                   113, 35, 5, 266, 139, 182, 38, 47, 12, 141, 207, 233, 123, 43, 88, 180, \n",
    "                   165, 46, 267, 203, 179, 242, 184, 3, 198, 25, 39, 281, 87, 234, 138, 132, \n",
    "                   126, 149, 68, 173, 216, 33, 171, 100, 86, 44, 255, 231, 23, 174, 71, 235, \n",
    "                   172, 283, 250, 89, 192, 143, 8, 14, 65, 78, 93, 146, 275, 272, 82, 293, \n",
    "                   262, 261, 133, 228, 212, 236, 70, 148, 116, 189, 226, 190, 210, 49, 52, \n",
    "                   67, 186, 103, 181, 221, 85, 42, 239, 140, 21, 223, 76, 63, 206, 291, 274, \n",
    "                   48, 0, 32, 238, 295, 185, 37, 288, 117, 162, 83, 137, 252, 64, 54, 251, \n",
    "                   53, 208, 108, 191, 229, 183, 154, 59, 270, 271, 244, 122, 31, 19, 69, 114,\n",
    "                   135, 176, 111, 258, 158, 9, 120, 268, 2, 289, 97, 243, 211, 127, 269] \n",
    "      \n",
    "    idx_y_train = idx_X_train\n",
    "    idx_y_test = idx_X_test\n",
    "    \n",
    "    classificators_format = ['mlknn', 'lp_rfc', 'br_rfc']\n",
    "    for classification_type in classification_types:\n",
    "        #print(\"classification_type\", classification_type)\n",
    "        test_results_score={}\n",
    "        test_results_metaheuristic={}\n",
    "        test_results={}\n",
    "        for fs in ft_select:\n",
    "            for ft in ft_type:  \n",
    "                df_all_input, df_all_output = read_dataset(feat_select=fs, feat_type=ft, scale=\"standard\",\n",
    "                                                           feature_path=feature_path, ranks_path=ranks_path)\n",
    "                #print(df_all_output.sum(axis=0))\n",
    "                index = np.random.permutation(len(df_all_input))\n",
    "                X_train = df_all_input.iloc[idx_X_train]\n",
    "                X_test = df_all_input.iloc[idx_X_test]\n",
    "                \n",
    "                y_train = df_all_output.iloc[idx_y_train]\n",
    "                y_test = df_all_output.iloc[idx_y_test]\n",
    "                \n",
    "                train_scaler = MinMaxScaler()\n",
    "                X_train = train_scaler.fit_transform(X_train)\n",
    "                X_test = train_scaler.fit_transform(X_test)\n",
    "\n",
    "                from skmultilearn.problem_transform import BinaryRelevance\n",
    "                from sklearn.naive_bayes import GaussianNB\n",
    "                \n",
    "                \n",
    "                # initialize Binary Relevance multi-label classifier\n",
    "                # with a gaussian naive bayes base classifier\n",
    "                classifier = BinaryRelevance(\n",
    "                    classifier = GaussianNB(),\n",
    "                    require_dense = [True, True]\n",
    "                )\n",
    "                # train\n",
    "                classifier.fit(X_train, y_train)\n",
    "                # predict\n",
    "                predictions = classifier.predict(X_test)\n",
    "                \n",
    "                from sklearn.metrics import accuracy_score, f1_score, recall_score\n",
    "                print(f1_score(y_test, predictions, average='weighted'), accuracy_score(y_test, predictions), recall_score(y_test, predictions, average='weighted'))\n",
    "\n",
    "                from skmultilearn.problem_transform import ClassifierChain\n",
    "\n",
    "\n",
    "                # initialize Classifier Chain multi-label classifier\n",
    "                # with a gaussian naive bayes base classifier\n",
    "                classifier = ClassifierChain(\n",
    "                    classifier = GaussianNB(),\n",
    "                    require_dense = [True, True]\n",
    "                )\n",
    "                # train\n",
    "                classifier.fit(X_train, y_train)\n",
    "                # predict\n",
    "                predictions = classifier.predict(X_test)\n",
    "                print(f1_score(y_test, predictions, average='weighted'), accuracy_score(y_test, predictions), recall_score(y_test, predictions, average='weighted'))\n",
    "\n",
    "                from scipy import sparse\n",
    "\n",
    "                ly_train=sparse.lil_matrix((y_train.shape[0],y_train.shape[1]))\n",
    "                for i in range(y_train.shape[0]):\n",
    "                    for j in range(len(y_train.iloc[i])):\n",
    "                        if y_train.iloc[i,j] == 1:\n",
    "                            ly_train[i,j]=1\n",
    "\n",
    "                ##########NetworkX - nu merge doar daca numarul de noduri din clustere este egal\n",
    "               \n",
    "                # graph_builder = LabelCooccurrenceGraphBuilder(weighted=True,\n",
    "                #                                               include_self_edges=False)\n",
    "                \n",
    "                # label_names=target_names#[i for i in range(nlabel)]\n",
    "                # edge_map = graph_builder.transform(ly_train)#np.array(y_train))\n",
    "                # print(\"{} labels, {} edges\".format(len(label_names), len(edge_map)))\n",
    "\n",
    "                # clusterer = NetworkXLabelGraphClusterer(graph_builder, method='louvain')\n",
    "\n",
    "                # print(np.array(X_train).shape, np.array(y_train).shape, ly_train.shape[1],type(ly_train))\n",
    "                # # for el in ly_train:\n",
    "                # #     print(\"!!!!!!!!! shape\", el.shape[1]) \n",
    "                # #partition = clusterer.fit_predict(_,ly_train[:4])\n",
    "\n",
    "                # y=ly_train\n",
    "                # edge_map = graph_builder.transform(y)\n",
    "\n",
    "                # if graph_builder.is_weighted:\n",
    "                #     weights_ = dict(weight=list(edge_map.values()))\n",
    "                # else:\n",
    "                #     weights_ = dict(weight=None)\n",
    "\n",
    "                # import community\n",
    "                # import networkx as nx\n",
    "                # from networkx.algorithms.community import asyn_lpa_communities\n",
    "\n",
    "                # graph_ = nx.Graph()\n",
    "                # for n in range(y.shape[1]):\n",
    "                #     graph_.add_node(n)\n",
    "        \n",
    "                # for e, w in edge_map.items():\n",
    "                #     graph_.add_edge(e[0], e[1], weight=w)\n",
    "\n",
    "                # ret_list_of_members=[]\n",
    "                # if True:#self.method == 'louvain':\n",
    "                #     partition_dict = community.best_partition(graph_)\n",
    "                #     memberships = [partition_dict[i] for i in range(y.shape[1])]\n",
    "                #     print('memberships',memberships)\n",
    "                #     list_of_members = [[] for _ in range(1 + max(memberships))]\n",
    "                #     for vertex_id, community_id in enumerate(memberships):\n",
    "                #         list_of_members[community_id].append(vertex_id)\n",
    "                #     print(list_of_members)\n",
    "                #     ret_list_of_members = list_of_members\n",
    "                \n",
    "                # else:\n",
    "                #     ret_list_of_members = [list(i) for i in asyn_lpa_communities(graph_, 'weight')]\n",
    "\n",
    "                # membership_vector = to_membership_vector(ret_list_of_members)\n",
    "                # print('There are', len(ret_list_of_members),'clusters')\n",
    "\n",
    "                # import networkx as nx\n",
    "                # names_dict = dict(enumerate(x for x in label_names))\n",
    "                # import matplotlib.pyplot as plt\n",
    "                # %matplotlib inline\n",
    "                # nx.draw(\n",
    "                #     graph_,\n",
    "                #     pos=nx.spring_layout(graph_,k=4),\n",
    "                #     labels=names_dict,\n",
    "                #     with_labels = True,\n",
    "                #     width = [10*x/y_train.shape[0] for x in edge_map.values()],\n",
    "                #     node_color = [membership_vector[i] for i in range(y_train.shape[1])],\n",
    "                #     cmap=plt.cm.viridis,\n",
    "                #     node_size=550,\n",
    "                #     font_size=6,\n",
    "                #     font_color='red',\n",
    "                #     alpha=0.8\n",
    "                # )\n",
    "\n",
    "                ###############iGraph\n",
    "                # from skmultilearn.cluster import IGraphLabelGraphClusterer\n",
    "                # import igraph as ig\n",
    "                # graph_builder = LabelCooccurrenceGraphBuilder(weighted=True,\n",
    "                #                                                include_self_edges=False)\n",
    "                \n",
    "                # label_names=target_names#[i for i in range(nlabel)]\n",
    "                # edge_map = graph_builder.transform(ly_train)#np.array(y_train))\n",
    "                # print(\"{} labels, {} edges\".format(len(label_names), len(edge_map)))\n",
    "\n",
    "                # clusterer_igraph = IGraphLabelGraphClusterer(graph_builder=graph_builder, method='walktrap')\n",
    "                # partition = clusterer_igraph.fit_predict(X_train, ly_train)\n",
    "                # partition\n",
    "\n",
    "                ################Stochastic Blockmodel from graph-tool\n",
    "                # import graph_tool - dificil de instalat pe windows\n",
    "                # from skmultilearn.cluster.graphtool import GraphToolLabelGraphClusterer, StochasticBlockModel\n",
    "                # model = StochasticBlockModel(nested=False, use_degree_correlation=True, allow_overlap=False, weight_model='real-normal')\n",
    "                # clusterer_graphtool = GraphToolLabelGraphClusterer(graph_builder=graph_builder, model=model)\n",
    "                # clusterer_graphtool.fit_predict(None, ly_train)\n",
    "                import sys\n",
    "                import joblib\n",
    "                #import openne\n",
    "                sys.modules['sklearn.externals.joblib'] = joblib\n",
    "                \n",
    "                #from skmultilearn.embedding import OpenNetworkEmbedder\n",
    "                from skmultilearn.cluster import LabelCooccurrenceGraphBuilder\n",
    "                graph_builder = LabelCooccurrenceGraphBuilder(weighted=True, include_self_edges=False)\n",
    "                # openne_line_params = dict(batch_size=1000, order=3)\n",
    "                # embedder = OpenNetworkEmbedder(\n",
    "                #     graph_builder,\n",
    "                #     'LINE',\n",
    "                #     dimension = 5*ly_train.shape[1],\n",
    "                #     aggregation_function = 'add',\n",
    "                #     normalize_weights=True,\n",
    "                #     param_dict = openne_line_params\n",
    "                # )\n",
    "                # from skmultilearn.embedding import EmbeddingClassifier\n",
    "                # from sklearn.ensemble import RandomForestRegressor\n",
    "                # from skmultilearn.adapt import MLkNN\n",
    "                # clf = EmbeddingClassifier(\n",
    "                #     embedder,\n",
    "                #     RandomForestRegressor(n_estimators=10),\n",
    "                #     MLkNN(k=5)\n",
    "                # )\n",
    "                \n",
    "                # clf.fit(X_train, y_train)\n",
    "                \n",
    "                # predictions = clf.predict(X_test)\n",
    "                # print(predictions)\n",
    "                # from skmultilearn.embedding import CLEMS, EmbeddingClassifier\n",
    "                # from sklearn.ensemble import RandomForestRegressor\n",
    "                # from skmultilearn.adapt import MLkNN\n",
    "                \n",
    "                # dimensional_scaler_params = {'n_jobs': -1}\n",
    "                \n",
    "                # clf = EmbeddingClassifier(\n",
    "                #     CLEMS(metrics.jaccard_similarity_score, is_score=True, params=dimensional_scaler_params),\n",
    "                #     RandomForestRegressor(n_estimators=10, n_jobs=-1),\n",
    "                #     MLkNN(k=1),\n",
    "                #     regressor_per_dimension= True\n",
    "                # )\n",
    "                \n",
    "                # clf.fit(X_train, y_train)\n",
    "                \n",
    "                # predictions = clf.predict(X_test)\n",
    "                from skmultilearn.embedding import SKLearnEmbedder, EmbeddingClassifier\n",
    "                from sklearn.manifold import SpectralEmbedding\n",
    "                from sklearn.ensemble import RandomForestRegressor\n",
    "                from skmultilearn.adapt import MLkNN\n",
    "\n",
    "                from skmultilearn.ensemble import MajorityVotingClassifier\n",
    "                from skmultilearn.cluster import FixedLabelSpaceClusterer\n",
    "                from skmultilearn.problem_transform import ClassifierChain\n",
    "                from sklearn.naive_bayes import GaussianNB\n",
    "                \n",
    "                classifier = MajorityVotingClassifier(\n",
    "                    clusterer = FixedLabelSpaceClusterer(clusters = [[1,3,4], [0, 2, 5]]),\n",
    "                    classifier = ClassifierChain(classifier=GaussianNB())\n",
    "                )\n",
    "                classifier.fit(X_train,y_train)\n",
    "                predictions = classifier.predict(X_test)\n",
    "                \n",
    "                clf = EmbeddingClassifier(\n",
    "                    SKLearnEmbedder(SpectralEmbedding(n_components = 10)),\n",
    "                    RandomForestRegressor(n_estimators=10),\n",
    "                    MLkNN(k=5)\n",
    "                )\n",
    "                \n",
    "                clf.fit(X_train, y_train)\n",
    "                \n",
    "                predictions = clf.predict(X_test)\n",
    "\n",
    "                  \n",
    "ft_type=['ST-F']#['HG']#'OG', 'OGQ', 'OGSM', 'OGET']#,'DG','HG']\n",
    "classification_types=['br_rfc']\n",
    "ft_select=['LR40']\n",
    "\n",
    "dir_path = '../datasets/results/classification/ianuarie2025/'\n",
    "classification_graph(dir_path, ft_type, ft_select, classification_types, \n",
    "                  feature_path='../datasets/results/features/ianuarie2025-v2/',\n",
    "                  ranks_path='../datasets/results/ranks/runTime_1min_sa_ts_multilabel_filtered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotions:train - exists, not redownloading\n",
      "emotions:test - exists, not redownloading\n",
      "(202, 72) (202, 6) [('amazed-suprised', ['0', '1']), ('happy-pleased', ['0', '1']), ('relaxing-calm', ['0', '1']), ('quiet-still', ['0', '1']), ('sad-lonely', ['0', '1']), ('angry-aggresive', ['0', '1'])]\n",
      "6 labels, 14 edges\n",
      "(1, 72) (202, 6) y_test   (0, 1)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 3)\t1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (4,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 28\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m     23\u001b[0m         member :  partition_id\n\u001b[0;32m     24\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m partition_id, members \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(partition)\n\u001b[0;32m     25\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m member \u001b[38;5;129;01min\u001b[39;00m members\n\u001b[0;32m     26\u001b[0m     }\n\u001b[0;32m     27\u001b[0m clusterer \u001b[38;5;241m=\u001b[39m NetworkXLabelGraphClusterer(graph_builder, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlouvain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 28\u001b[0m partition \u001b[38;5;241m=\u001b[39m \u001b[43mclusterer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m membership_vector \u001b[38;5;241m=\u001b[39m to_membership_vector(partition)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThere are\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mlen\u001b[39m(partition),\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclusters\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\scamp-ml-dataGenerator\\Lib\\site-packages\\skmultilearn\\cluster\\networkx.py:163\u001b[0m, in \u001b[0;36mNetworkXLabelGraphClusterer.fit_predict\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    160\u001b[0m     partition_dict \u001b[38;5;241m=\u001b[39m community\u001b[38;5;241m.\u001b[39mbest_partition(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph_)\n\u001b[0;32m    161\u001b[0m     memberships \u001b[38;5;241m=\u001b[39m [partition_dict[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])]\n\u001b[1;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(\n\u001b[0;32m    164\u001b[0m         _membership_to_list_of_communities(\n\u001b[0;32m    165\u001b[0m             memberships,\n\u001b[0;32m    166\u001b[0m             \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mmax\u001b[39m(memberships)\n\u001b[0;32m    167\u001b[0m         )\n\u001b[0;32m    168\u001b[0m     )\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28mlist\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m asyn_lpa_communities(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph_, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m'\u001b[39m)])\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (4,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "from skmultilearn.dataset import load_dataset\n",
    "from skmultilearn.cluster import LabelCooccurrenceGraphBuilder\n",
    "from skmultilearn.cluster import NetworkXLabelGraphClusterer\n",
    "\n",
    "\n",
    "X_train, y_train, feature_names, label_names = load_dataset('emotions', 'train')\n",
    "X_test, y_test, _, _ = load_dataset('emotions', 'test')\n",
    "print(X_test.shape, y_test.shape, label_names)\n",
    "graph_builder = LabelCooccurrenceGraphBuilder(weighted=True,\n",
    "                                              include_self_edges=False)\n",
    "\n",
    "edge_map = graph_builder.transform(y_train)\n",
    "print(\"{} labels, {} edges\".format(len(label_names), len(edge_map)))\n",
    "print(X_test[0].shape, y_test.shape, \"y_test\", y_test[10])\n",
    "\n",
    "# print(type(y_test))\n",
    "# for el in y_test:\n",
    "#     print(\"!!!!!!!!! shape\", el.shape, el) \n",
    "\n",
    "# we define a helper function for visualization purposes\n",
    "def to_membership_vector(partition):\n",
    "    return {\n",
    "        member :  partition_id\n",
    "        for partition_id, members in enumerate(partition)\n",
    "        for member in members\n",
    "    }\n",
    "clusterer = NetworkXLabelGraphClusterer(graph_builder, method='louvain')\n",
    "partition = clusterer.fit_predict(_,y_train[:6])\n",
    "membership_vector = to_membership_vector(partition)\n",
    "print('There are', len(partition),'clusters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian optimization for all representations, feature types and regression models\n",
    "ft_type=['OG-F']#['HG']#'OG', 'OGQ', 'OGSM', 'OGET']#,'DG','HG']\n",
    "\n",
    "ft_select=['all','LR10', 'LR20', 'LR30', \n",
    "    'LR40', 'RF', 'PCA99','PCA999','PCA9999','FS_S','FS_P','FS_K']\n",
    "\n",
    "dir_path = '../datasets/results/classification/ianuarie2025/'\n",
    "#https://towardsdatascience.com/journey-to-the-center-of-multi-label-classification-384c40229bff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'classification_model' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[70], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m classification_types \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrfr\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgbr\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      2\u001b[0m ft_type\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mST-F\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 4\u001b[0m \u001b[43mclassification_tuning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdir_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mft_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mft_select\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassification_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mfeature_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../datasets/results/features/ianuarie2025-v2/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mranks_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../datasets/results/ranks/runTime_1min_sa_ts_multilabel_filtered\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[31], line 135\u001b[0m, in \u001b[0;36mclassification_tuning\u001b[1;34m(out_dir_path, ft_type, ft_select, classification_types, feature_path, ranks_path)\u001b[0m\n\u001b[0;32m    129\u001b[0m     classification_model \u001b[38;5;241m=\u001b[39m MLkNN()\n\u001b[0;32m    130\u001b[0m     param \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    131\u001b[0m              \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m15\u001b[39m],\n\u001b[0;32m    132\u001b[0m              \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.7\u001b[39m, \u001b[38;5;241m1.0\u001b[39m]\n\u001b[0;32m    133\u001b[0m              }\n\u001b[1;32m--> 135\u001b[0m opt \u001b[38;5;241m=\u001b[39m BayesSearchCV(\u001b[43mclassification_model\u001b[49m,param, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, \u001b[38;5;66;03m# default value: 32, 50\u001b[39;00m\n\u001b[0;32m    136\u001b[0m                cv\u001b[38;5;241m=\u001b[39mKFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\u001b[38;5;66;03m#5, # default value: 3\u001b[39;00m\n\u001b[0;32m    137\u001b[0m                return_train_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    140\u001b[0m opt\u001b[38;5;241m.\u001b[39mfit(np\u001b[38;5;241m.\u001b[39marray(X_train), np\u001b[38;5;241m.\u001b[39marray(y_train))\n\u001b[0;32m    141\u001b[0m \u001b[38;5;66;03m#opt.fit(X_train, y_train)\u001b[39;00m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: cannot access local variable 'classification_model' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "classification_types = ['rfr','gbr']\n",
    "ft_type=['ST-F']\n",
    "\n",
    "classification_tuning(dir_path, ft_type, ft_select, classification_types, \n",
    "                  feature_path='../datasets/results/features/ianuarie2025-v2/',\n",
    "                  ranks_path='../datasets/results/ranks/runTime_1min_sa_ts_multilabel_filtered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******* Feature select: all  Feature type: OG-F Classification model: rfr ******\n",
      "Accurecy of the best estimator (training dataset):  0.6452991452991453\n",
      "Accuracy Best score (validation) val. score :  0.20536540240518036\n",
      "Hamming loss: 0.1431451612903226\n",
      "Accuracy of the best estimator (testing dataset):  0.11290322580645161\n",
      "******* Feature select: LR10  Feature type: OG-F Classification model: rfr ******\n",
      "Accurecy of the best estimator (training dataset):  0.5555555555555556\n",
      "Accuracy Best score (validation) val. score :  0.17530064754856614\n",
      "Hamming loss: 0.17943548387096775\n",
      "Accuracy of the best estimator (testing dataset):  0.06451612903225806\n",
      "******* Feature select: LR20  Feature type: OG-F Classification model: rfr ******\n",
      "Accurecy of the best estimator (training dataset):  0.5299145299145299\n",
      "Accuracy Best score (validation) val. score :  0.1752081406105458\n",
      "Hamming loss: 0.1774193548387097\n",
      "Accuracy of the best estimator (testing dataset):  0.1774193548387097\n",
      "******* Feature select: LR30  Feature type: OG-F Classification model: rfr ******\n",
      "Accurecy of the best estimator (training dataset):  0.49572649572649574\n",
      "Accuracy Best score (validation) val. score :  0.1924144310823312\n",
      "Hamming loss: 0.20766129032258066\n",
      "Accuracy of the best estimator (testing dataset):  0.14516129032258066\n",
      "******* Feature select: LR40  Feature type: OG-F Classification model: rfr ******\n",
      "Accurecy of the best estimator (training dataset):  0.5769230769230769\n",
      "Accuracy Best score (validation) val. score :  0.1753006475485661\n",
      "Hamming loss: 0.14516129032258066\n",
      "Accuracy of the best estimator (testing dataset):  0.14516129032258066\n",
      "******* Feature select: RF  Feature type: OG-F Classification model: rfr ******\n",
      "Accurecy of the best estimator (training dataset):  0.5384615384615384\n",
      "Accuracy Best score (validation) val. score :  0.16262719703977796\n",
      "Hamming loss: 0.16129032258064516\n",
      "Accuracy of the best estimator (testing dataset):  0.0967741935483871\n",
      "******* Feature select: PCA99  Feature type: OG-F Classification model: rfr ******\n",
      "Accurecy of the best estimator (training dataset):  0.6538461538461539\n",
      "Accuracy Best score (validation) val. score :  0.1709528214616096\n",
      "Hamming loss: 0.16330645161290322\n",
      "Accuracy of the best estimator (testing dataset):  0.08064516129032258\n",
      "******* Feature select: PCA999  Feature type: OG-F Classification model: rfr ******\n",
      "Accurecy of the best estimator (training dataset):  0.6623931623931624\n",
      "Accuracy Best score (validation) val. score :  0.14995374653098983\n",
      "Hamming loss: 0.15120967741935484\n",
      "Accuracy of the best estimator (testing dataset):  0.1774193548387097\n",
      "******* Feature select: PCA9999  Feature type: OG-F Classification model: rfr ******\n",
      "Accurecy of the best estimator (training dataset):  0.6923076923076923\n",
      "Accuracy Best score (validation) val. score :  0.13274745605920443\n",
      "Hamming loss: 0.1693548387096774\n",
      "Accuracy of the best estimator (testing dataset):  0.11290322580645161\n",
      "******* Feature select: FS_S  Feature type: OG-F Classification model: rfr ******\n",
      "Accurecy of the best estimator (training dataset):  0.6025641025641025\n",
      "Accuracy Best score (validation) val. score :  0.1752081406105458\n",
      "Hamming loss: 0.15524193548387097\n",
      "Accuracy of the best estimator (testing dataset):  0.0967741935483871\n",
      "******* Feature select: FS_P  Feature type: OG-F Classification model: rfr ******\n",
      "Accurecy of the best estimator (training dataset):  0.6239316239316239\n",
      "Accuracy Best score (validation) val. score :  0.188159111933395\n",
      "Hamming loss: 0.14717741935483872\n",
      "Accuracy of the best estimator (testing dataset):  0.0967741935483871\n",
      "******* Feature select: FS_K  Feature type: OG-F Classification model: rfr ******\n",
      "Accurecy of the best estimator (training dataset):  0.5811965811965812\n",
      "Accuracy Best score (validation) val. score :  0.20508788159111932\n",
      "Hamming loss: 0.19959677419354838\n",
      "Accuracy of the best estimator (testing dataset):  0.14516129032258066\n",
      "******* Feature select: all  Feature type: OG-F Classification model: svr ******\n",
      "Accurecy of the best estimator (training dataset):  0.9529914529914529\n",
      "Accuracy Best score (validation) val. score :  0.24366327474560592\n",
      "Hamming loss: 0.13911290322580644\n",
      "Accuracy of the best estimator (testing dataset):  0.1774193548387097\n",
      "******* Feature select: LR10  Feature type: OG-F Classification model: svr ******\n",
      "Accurecy of the best estimator (training dataset):  0.8846153846153846\n",
      "Accuracy Best score (validation) val. score :  0.2820536540240518\n",
      "Hamming loss: 0.20161290322580644\n",
      "Accuracy of the best estimator (testing dataset):  0.1774193548387097\n",
      "******* Feature select: LR20  Feature type: OG-F Classification model: svr ******\n",
      "Accurecy of the best estimator (training dataset):  0.9444444444444444\n",
      "Accuracy Best score (validation) val. score :  0.29472710453283996\n",
      "Hamming loss: 0.1935483870967742\n",
      "Accuracy of the best estimator (testing dataset):  0.0967741935483871\n",
      "******* Feature select: LR30  Feature type: OG-F Classification model: svr ******\n",
      "Accurecy of the best estimator (training dataset):  0.9358974358974359\n",
      "Accuracy Best score (validation) val. score :  0.2864939870490287\n",
      "Hamming loss: 0.21370967741935484\n",
      "Accuracy of the best estimator (testing dataset):  0.14516129032258066\n",
      "******* Feature select: LR40  Feature type: OG-F Classification model: svr ******\n",
      "Accurecy of the best estimator (training dataset):  0.8931623931623932\n",
      "Accuracy Best score (validation) val. score :  0.25235892691951894\n",
      "Hamming loss: 0.18548387096774194\n",
      "Accuracy of the best estimator (testing dataset):  0.1774193548387097\n",
      "******* Feature select: RF  Feature type: OG-F Classification model: svr ******\n",
      "Accurecy of the best estimator (training dataset):  0.9145299145299145\n",
      "Accuracy Best score (validation) val. score :  0.2650323774283071\n",
      "Hamming loss: 0.15524193548387097\n",
      "Accuracy of the best estimator (testing dataset):  0.22580645161290322\n",
      "******* Feature select: PCA99  Feature type: OG-F Classification model: svr ******\n",
      "Accurecy of the best estimator (training dataset):  0.9401709401709402\n",
      "Accuracy Best score (validation) val. score :  0.25670675300647544\n",
      "Hamming loss: 0.1532258064516129\n",
      "Accuracy of the best estimator (testing dataset):  0.0\n",
      "******* Feature select: PCA999  Feature type: OG-F Classification model: svr ******\n",
      "Accurecy of the best estimator (training dataset):  0.9786324786324786\n",
      "Accuracy Best score (validation) val. score :  0.24801110083256245\n",
      "Hamming loss: 0.14919354838709678\n",
      "Accuracy of the best estimator (testing dataset):  0.04838709677419355\n",
      "******* Feature select: PCA9999  Feature type: OG-F Classification model: svr ******\n",
      "Accurecy of the best estimator (training dataset):  0.8504273504273504\n",
      "Accuracy Best score (validation) val. score :  0.19685476410730804\n",
      "Hamming loss: 0.30443548387096775\n",
      "Accuracy of the best estimator (testing dataset):  0.03225806451612903\n",
      "******* Feature select: FS_S  Feature type: OG-F Classification model: svr ******\n",
      "Accurecy of the best estimator (training dataset):  0.9615384615384616\n",
      "Accuracy Best score (validation) val. score :  0.24819611470860314\n",
      "Hamming loss: 0.1532258064516129\n",
      "Accuracy of the best estimator (testing dataset):  0.1774193548387097\n",
      "******* Feature select: FS_P  Feature type: OG-F Classification model: svr ******\n",
      "Accurecy of the best estimator (training dataset):  0.9487179487179487\n",
      "Accuracy Best score (validation) val. score :  0.25670675300647544\n",
      "Hamming loss: 0.15120967741935484\n",
      "Accuracy of the best estimator (testing dataset):  0.16129032258064516\n",
      "******* Feature select: FS_K  Feature type: OG-F Classification model: svr ******\n",
      "Accurecy of the best estimator (training dataset):  0.9572649572649573\n",
      "Accuracy Best score (validation) val. score :  0.23524514338575392\n",
      "Hamming loss: 0.1431451612903226\n",
      "Accuracy of the best estimator (testing dataset):  0.1774193548387097\n",
      "******* Feature select: all  Feature type: OG-F Classification model: gbr ******\n",
      "Accurecy of the best estimator (training dataset):  0.9358974358974359\n",
      "Accuracy Best score (validation) val. score :  0.23968547641073085\n",
      "Hamming loss: 0.14717741935483872\n",
      "Accuracy of the best estimator (testing dataset):  0.12903225806451613\n",
      "******* Feature select: LR10  Feature type: OG-F Classification model: gbr ******\n",
      "Accurecy of the best estimator (training dataset):  0.9829059829059829\n",
      "Accuracy Best score (validation) val. score :  0.21785383903792782\n",
      "Hamming loss: 0.21774193548387097\n",
      "Accuracy of the best estimator (testing dataset):  0.11290322580645161\n",
      "******* Feature select: LR20  Feature type: OG-F Classification model: gbr ******\n",
      "Accurecy of the best estimator (training dataset):  0.9572649572649573\n",
      "Accuracy Best score (validation) val. score :  0.23940795559666977\n",
      "Hamming loss: 0.1875\n",
      "Accuracy of the best estimator (testing dataset):  0.12903225806451613\n",
      "******* Feature select: LR30  Feature type: OG-F Classification model: gbr ******\n",
      "Accurecy of the best estimator (training dataset):  0.9273504273504274\n",
      "Accuracy Best score (validation) val. score :  0.21387604070305272\n",
      "Hamming loss: 0.1875\n",
      "Accuracy of the best estimator (testing dataset):  0.12903225806451613\n",
      "******* Feature select: LR40  Feature type: OG-F Classification model: gbr ******\n",
      "Accurecy of the best estimator (training dataset):  0.9444444444444444\n",
      "Accuracy Best score (validation) val. score :  0.21803885291396857\n",
      "Hamming loss: 0.1875\n",
      "Accuracy of the best estimator (testing dataset):  0.12903225806451613\n",
      "******* Feature select: RF  Feature type: OG-F Classification model: gbr ******\n",
      "Accurecy of the best estimator (training dataset):  0.9871794871794872\n",
      "Accuracy Best score (validation) val. score :  0.22664199814986125\n",
      "Hamming loss: 0.18951612903225806\n",
      "Accuracy of the best estimator (testing dataset):  0.16129032258064516\n",
      "******* Feature select: PCA99  Feature type: OG-F Classification model: gbr ******\n",
      "Accurecy of the best estimator (training dataset):  1.0\n",
      "Accuracy Best score (validation) val. score :  0.24791859389454207\n",
      "Hamming loss: 0.17137096774193547\n",
      "Accuracy of the best estimator (testing dataset):  0.1935483870967742\n",
      "******* Feature select: PCA999  Feature type: OG-F Classification model: gbr ******\n",
      "Accurecy of the best estimator (training dataset):  1.0\n",
      "Accuracy Best score (validation) val. score :  0.21396854764107304\n",
      "Hamming loss: 0.22782258064516128\n",
      "Accuracy of the best estimator (testing dataset):  0.12903225806451613\n",
      "******* Feature select: PCA9999  Feature type: OG-F Classification model: gbr ******\n",
      "Accurecy of the best estimator (training dataset):  1.0\n",
      "Accuracy Best score (validation) val. score :  0.1795559666975023\n",
      "Hamming loss: 0.1814516129032258\n",
      "Accuracy of the best estimator (testing dataset):  0.1935483870967742\n",
      "******* Feature select: FS_S  Feature type: OG-F Classification model: gbr ******\n",
      "Accurecy of the best estimator (training dataset):  0.9700854700854701\n",
      "Accuracy Best score (validation) val. score :  0.23931544865864937\n",
      "Hamming loss: 0.13911290322580644\n",
      "Accuracy of the best estimator (testing dataset):  0.16129032258064516\n",
      "******* Feature select: FS_P  Feature type: OG-F Classification model: gbr ******\n",
      "Accurecy of the best estimator (training dataset):  1.0\n",
      "Accuracy Best score (validation) val. score :  0.22654949121184087\n",
      "Hamming loss: 0.19153225806451613\n",
      "Accuracy of the best estimator (testing dataset):  0.14516129032258066\n",
      "******* Feature select: FS_K  Feature type: OG-F Classification model: gbr ******\n",
      "Accurecy of the best estimator (training dataset):  1.0\n",
      "Accuracy Best score (validation) val. score :  0.22636447733580017\n",
      "Hamming loss: 0.19556451612903225\n",
      "Accuracy of the best estimator (testing dataset):  0.0967741935483871\n"
     ]
    }
   ],
   "source": [
    "classification_types = ['rfr','svr','gbr']\n",
    "#'ft_select=['LR10']\n",
    "\n",
    "classification_tuning(dir_path, ft_type, ft_select, classification_types, \n",
    "                  feature_path='../datasets/results/features/ianuarie2025-v2/',\n",
    "                  ranks_path='../datasets/results/ranks/runTime_1min_sa_ts_multilabel_filtered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******* Feature select: LR10  Feature type: OG-F Classification model: br_rfc ******\n",
      "Accurecy of the best estimator (training dataset):  0.5341880341880342\n",
      "Accuracy Best score (validation) val. score :  0.1624421831637373\n",
      "Hamming loss: 0.16532258064516128\n",
      "Accuracy of the best estimator (testing dataset):  0.06451612903225806\n"
     ]
    }
   ],
   "source": [
    "classification_types = ['br_rfc']\n",
    "ft_select=['LR10']\n",
    "target_names = ['TS-Ei', 'SA-Ei', 'TSL-Ei', 'SAL-Ei', 'TS-Si', 'SA-Si', 'TSL-Si', 'SAL-Si', ]\n",
    "\n",
    "classification_tuning(dir_path, ft_type, ft_select, classification_types, \n",
    "                  feature_path='../datasets/results/features/ianuarie2025-v2/',\n",
    "                  ranks_path='../datasets/results/ranks/runTime_1min_sa_ts_multilabel_filtered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_type lp_rfc\n",
      "TS-Ei-LM      21\n",
      "SA-Ei-LM      87\n",
      "TSL-Ei-LM     45\n",
      "SAL-Ei-LM    113\n",
      "TS-Si-LM      27\n",
      "SA-Si-LM      29\n",
      "TSL-Si-LM     31\n",
      "SAL-Si-LM     31\n",
      "dtype: int64\n",
      "******* Feature select: LR10  Feature type: HG-F Classification model: lp_rfc ******\n",
      "Accurecy of the best estimator (training dataset):  0.5384615384615384\n",
      "Accuracy Best score (validation) val. score :  0.2605920444033303\n",
      "Hamming loss: 0.18346774193548387\n",
      "Accuracy of the best estimator (testing dataset):  0.25806451612903225\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       TS-Ei       0.33      0.33      0.33         3\n",
      "       SA-Ei       0.75      0.27      0.40        22\n",
      "      TSL-Ei       0.25      0.14      0.18         7\n",
      "      SAL-Ei       0.37      0.76      0.50        21\n",
      "       TS-Si       0.00      0.00      0.00         6\n",
      "       SA-Si       0.00      0.00      0.00         8\n",
      "      TSL-Si       0.33      0.33      0.33         3\n",
      "      SAL-Si       0.00      0.00      0.00         6\n",
      "\n",
      "   micro avg       0.38      0.33      0.35        76\n",
      "   macro avg       0.25      0.23      0.22        76\n",
      "weighted avg       0.37      0.33      0.30        76\n",
      " samples avg       0.35      0.30      0.32        76\n",
      "\n",
      "Selected metaheuristics: ['TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM']\n"
     ]
    }
   ],
   "source": [
    "classification_types = ['lp_rfc']\n",
    "ft_select=['LR10']\n",
    "target_names = ['TS-Ei', 'SA-Ei', 'TSL-Ei', 'SAL-Ei', 'TS-Si', 'SA-Si', 'TSL-Si', 'SAL-Si', ]\n",
    "\n",
    "classification_tuning(dir_path, ft_type, ft_select, classification_types, \n",
    "                  feature_path='../datasets/results/features/ianuarie2025-v2/',\n",
    "                  ranks_path='../datasets/results/ranks/runTime_1min_sa_ts_multilabel_filtered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_type mcc\n",
      "TS-Ei-LM      21\n",
      "SA-Ei-LM      87\n",
      "TSL-Ei-LM     45\n",
      "SAL-Ei-LM    113\n",
      "TS-Si-LM      27\n",
      "SA-Si-LM      29\n",
      "TSL-Si-LM     31\n",
      "SAL-Si-LM     31\n",
      "dtype: int64\n",
      "******* Feature select: LR10  Feature type: HG-F Classification model: mcc ******\n",
      "Accurecy of the best estimator (training dataset):  0.1282051282051282\n",
      "Accuracy Best score (validation) val. score :  0.10666049953746529\n",
      "Hamming loss: 0.16532258064516128\n",
      "Accuracy of the best estimator (testing dataset):  0.11290322580645161\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       TS-Ei       0.00      0.00      0.00         3\n",
      "       SA-Ei       0.67      0.09      0.16        22\n",
      "      TSL-Ei       0.50      0.14      0.22         7\n",
      "      SAL-Ei       0.38      0.52      0.44        21\n",
      "       TS-Si       0.00      0.00      0.00         6\n",
      "       SA-Si       0.00      0.00      0.00         8\n",
      "      TSL-Si       0.00      0.00      0.00         3\n",
      "      SAL-Si       0.00      0.00      0.00         6\n",
      "\n",
      "   micro avg       0.41      0.18      0.25        76\n",
      "   macro avg       0.19      0.09      0.10        76\n",
      "weighted avg       0.34      0.18      0.19        76\n",
      " samples avg       0.19      0.15      0.16        76\n",
      "\n",
      "Selected metaheuristics: ['TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM']\n"
     ]
    }
   ],
   "source": [
    "classification_types = ['mcc']\n",
    "ft_select=['LR10']\n",
    "target_names = ['TS-Ei', 'SA-Ei', 'TSL-Ei', 'SAL-Ei', 'TS-Si', 'SA-Si', 'TSL-Si', 'SAL-Si', ]\n",
    "\n",
    "classification_tuning(dir_path, ft_type, ft_select, classification_types, \n",
    "                  feature_path='../datasets/results/features/ianuarie2025-v2/',\n",
    "                  ranks_path='../datasets/results/ranks/runTime_1min_sa_ts_multilabel_filtered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_type mcc_rfc\n",
      "TS-Ei-LM      21\n",
      "SA-Ei-LM      87\n",
      "TSL-Ei-LM     45\n",
      "SAL-Ei-LM    113\n",
      "TS-Si-LM      27\n",
      "SA-Si-LM      29\n",
      "TSL-Si-LM     31\n",
      "SAL-Si-LM     31\n",
      "dtype: int64\n",
      "******* Feature select: LR10  Feature type: HG-F Classification model: mcc_rfc ******\n",
      "Accurecy of the best estimator (training dataset):  0.5085470085470085\n",
      "Accuracy Best score (validation) val. score :  0.18362627197039777\n",
      "Hamming loss: 0.1532258064516129\n",
      "Accuracy of the best estimator (testing dataset):  0.11290322580645161\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       TS-Ei       0.00      0.00      0.00         3\n",
      "       SA-Ei       0.82      0.41      0.55        22\n",
      "      TSL-Ei       0.00      0.00      0.00         7\n",
      "      SAL-Ei       0.39      0.52      0.45        21\n",
      "       TS-Si       0.00      0.00      0.00         6\n",
      "       SA-Si       0.00      0.00      0.00         8\n",
      "      TSL-Si       0.00      0.00      0.00         3\n",
      "      SAL-Si       0.00      0.00      0.00         6\n",
      "\n",
      "   micro avg       0.50      0.26      0.34        76\n",
      "   macro avg       0.15      0.12      0.12        76\n",
      "weighted avg       0.35      0.26      0.28        76\n",
      " samples avg       0.20      0.22      0.20        76\n",
      "\n",
      "Selected metaheuristics: ['TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM']\n"
     ]
    }
   ],
   "source": [
    "classification_types = ['mcc_rfc']\n",
    "ft_select=['LR10']\n",
    "target_names = ['TS-Ei', 'SA-Ei', 'TSL-Ei', 'SAL-Ei', 'TS-Si', 'SA-Si', 'TSL-Si', 'SAL-Si', ]\n",
    "\n",
    "classification_tuning(dir_path, ft_type, ft_select, classification_types, \n",
    "                  feature_path='../datasets/results/features/ianuarie2025-v2/',\n",
    "                  ranks_path='../datasets/results/ranks/runTime_1min_sa_ts_multilabel_filtered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_type mlknn\n",
      "TS-Ei-LM      21\n",
      "SA-Ei-LM      87\n",
      "TSL-Ei-LM     45\n",
      "SAL-Ei-LM    113\n",
      "TS-Si-LM      27\n",
      "SA-Si-LM      29\n",
      "TSL-Si-LM     31\n",
      "SAL-Si-LM     31\n",
      "dtype: int64\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'getformat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_48368\\3374529916.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mclassification_types\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'mlknn'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mft_select\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'LR10'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtarget_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'TS-Ei'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'SA-Ei'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'TSL-Ei'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'SAL-Ei'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'TS-Si'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'SA-Si'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'TSL-Si'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'SAL-Si'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m classification_tuning(dir_path, ft_type, ft_select, classification_types, \n\u001b[0m\u001b[0;32m      6\u001b[0m                   \u001b[0mfeature_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'../datasets/results/features/ianuarie2025-v2/'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                   ranks_path='../datasets/results/ranks/runTime_1min_sa_ts_multilabel_filtered')\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_48368\\1933425822.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(out_dir_path, ft_type, ft_select, classification_types, feature_path, ranks_path)\u001b[0m\n\u001b[0;32m    132\u001b[0m                                \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;31m#5, # default value: 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m                                return_train_score = True, verbose = 0)\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m                 \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m                 \u001b[0mdf_results\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m                 \u001b[0mdf_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{out_dir_path}/feat_{fs}_{ft}_regr_{classification_type}.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\scamp-ml-dataGenerator\\Lib\\site-packages\\skopt\\searchcv.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y, groups, callback, **fit_params)\u001b[0m\n\u001b[0;32m    538\u001b[0m                 \u001b[1;34m\"as it doesn't define an implicit score to \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    539\u001b[0m                 \u001b[1;34m\"optimize\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m             )\n\u001b[0;32m    541\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgroups\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;31m# BaseSearchCV never ranked train scores,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m         \u001b[1;31m# but apparently we used to ship this (back-compat)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\scamp-ml-dataGenerator\\Lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1385\u001b[0m                 skip_parameter_validation=(\n\u001b[0;32m   1386\u001b[0m                     \u001b[0mprefer_skip_nested_validation\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1387\u001b[0m                 )\n\u001b[0;32m   1388\u001b[0m             ):\n\u001b[1;32m-> 1389\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\scamp-ml-dataGenerator\\Lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1020\u001b[0m                 )\n\u001b[0;32m   1021\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1022\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1024\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1026\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1027\u001b[0m             \u001b[1;31m# self.scoring the return type is only known after calling\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\scamp-ml-dataGenerator\\Lib\\site-packages\\skopt\\searchcv.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m    595\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mn_iter\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m                 \u001b[1;31m# when n_iter < n_points points left for evaluation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m                 \u001b[0mn_points_adjusted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_points\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m                 optim_result, score_name = self._step(\n\u001b[0m\u001b[0;32m    600\u001b[0m                     \u001b[0msearch_space\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m                     \u001b[0mscore_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\scamp-ml-dataGenerator\\Lib\\site-packages\\skopt\\searchcv.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, search_space, optimizer, score_name, evaluate_candidates, n_points)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m         \u001b[1;31m# make lists into dictionaries\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m         \u001b[0mparams_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpoint_asdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msearch_space\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 453\u001b[1;33m         \u001b[0mall_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    454\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m         \u001b[1;31m# if self.scoring is a callable, we have to wait until here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m         \u001b[1;31m# to get the score name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\scamp-ml-dataGenerator\\Lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    966\u001b[0m                             \u001b[0mn_splits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_candidates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_candidates\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mn_splits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m                         )\n\u001b[0;32m    968\u001b[0m                     )\n\u001b[0;32m    969\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 970\u001b[1;33m                 out = parallel(\n\u001b[0m\u001b[0;32m    971\u001b[0m                     delayed(_fit_and_score)(\n\u001b[0;32m    972\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    973\u001b[0m                         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\scamp-ml-dataGenerator\\Lib\\site-packages\\sklearn\\utils\\parallel.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     73\u001b[0m         iterable_with_config = (\n\u001b[0;32m     74\u001b[0m             \u001b[1;33m(\u001b[0m\u001b[0m_with_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelayed_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         )\n\u001b[1;32m---> 77\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\scamp-ml-dataGenerator\\Lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1914\u001b[0m             \u001b[1;31m# If n_jobs==1, run the computation sequentially and return\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1915\u001b[0m             \u001b[1;31m# immediately to avoid overheads.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1917\u001b[0m             \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1920\u001b[0m         \u001b[1;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1921\u001b[0m         \u001b[1;31m# call is interrupted early and that the same instance is immediately\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\scamp-ml-dataGenerator\\Lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1857\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1858\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1859\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_running\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1860\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1861\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\scamp-ml-dataGenerator\\Lib\\site-packages\\sklearn\\utils\\parallel.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    135\u001b[0m                 \u001b[0mUserWarning\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m             )\n\u001b[0;32m    137\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\scamp-ml-dataGenerator\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    869\u001b[0m         \u001b[1;31m# Note fit time as time until error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    871\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    872\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0merror_score\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"raise\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 873\u001b[1;33m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    874\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    875\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscorer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_MultimetricScorer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m                 \u001b[0mtest_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0merror_score\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_scorers\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\scamp-ml-dataGenerator\\Lib\\site-packages\\skmultilearn\\adapt\\mlknn.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m             \u001b[0mfitted\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mof\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m         \"\"\"\n\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_label_cache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_matrix_in_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'lil'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_instances\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_label_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_label_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;31m# Computing the prior probabilities\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\scamp-ml-dataGenerator\\Lib\\site-packages\\skmultilearn\\utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(original_matrix, matrix_format)\u001b[0m\n\u001b[0;32m     31\u001b[0m     \"\"\"\n\u001b[0;32m     32\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mSPARSE_FORMAT_TO_CONSTRUCTOR\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmatrix_format\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0moriginal_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mmatrix_format\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moriginal_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0moriginal_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatrix_format\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\scamp-ml-dataGenerator\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6295\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6296\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6297\u001b[0m         ):\n\u001b[0;32m   6298\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6299\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'getformat'"
     ]
    }
   ],
   "source": [
    "classification_types = ['mlknn']\n",
    "ft_select=['LR10']\n",
    "target_names = ['TS-Ei', 'SA-Ei', 'TSL-Ei', 'SAL-Ei', 'TS-Si', 'SA-Si', 'TSL-Si', 'SAL-Si', ]\n",
    "\n",
    "classification_tuning(dir_path, ft_type, ft_select, classification_types, \n",
    "                  feature_path='../datasets/results/features/ianuarie2025-v2/',\n",
    "                  ranks_path='../datasets/results/ranks/runTime_1min_sa_ts_multilabel_filtered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_type rfr\n",
      "******* Feature select: LR10  Feature type: HG-F Classification model: rfr ******\n",
      "Accurecy of the best estimator (training dataset):  0.49572649572649574\n",
      "Accuracy Best score (validation) val. score :  0.17086031452358927\n",
      "Hamming loss: 0.14717741935483872\n",
      "Accuracy of the best estimator (testing dataset):  0.11290322580645161\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.89      0.36      0.52        22\n",
      "           2       0.00      0.00      0.00         7\n",
      "           3       0.48      0.52      0.50        21\n",
      "           4       0.00      0.00      0.00         6\n",
      "           5       0.00      0.00      0.00         8\n",
      "           6       0.00      0.00      0.00         3\n",
      "           7       0.00      0.00      0.00         6\n",
      "\n",
      "   micro avg       0.54      0.25      0.34        76\n",
      "   macro avg       0.17      0.11      0.13        76\n",
      "weighted avg       0.39      0.25      0.29        76\n",
      " samples avg       0.19      0.20      0.19        76\n",
      "\n",
      "Selected metaheuristics: ['TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM']\n"
     ]
    }
   ],
   "source": [
    "classification_types = ['rfr']\n",
    "ft_select=['LR10']\n",
    "target_names = ['TS-Ei', 'SA-Ei', 'TSL-Ei', 'SAL-Ei', 'TS-Si', 'SA-Si', 'TSL-Si', 'SAL-Si', ]\n",
    "\n",
    "classification_tuning(dir_path, ft_type, ft_select, classification_types, \n",
    "                  feature_path='../datasets/results/features/ianuarie2025-v2/',\n",
    "                  ranks_path='../datasets/results/ranks/runTime_1min_sa_ts_multilabel_filtered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_type gbr\n",
      "******* Feature select: all  Feature type: HG-F Classification model: gbr ******\n",
      "Accurecy of the best estimator (training dataset):  0.9401709401709402\n",
      "Accuracy Best score (validation) val. score :  0.2650323774283071\n",
      "Hamming loss: 0.15725806451612903\n",
      "Accuracy of the best estimator (testing dataset):  0.12903225806451613\n",
      "Selected metaheuristics: ['TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM']\n",
      "******* Feature select: LR10  Feature type: HG-F Classification model: gbr ******\n",
      "Accurecy of the best estimator (training dataset):  0.7564102564102564\n",
      "Accuracy Best score (validation) val. score :  0.22627197039777985\n",
      "Hamming loss: 0.16330645161290322\n",
      "Accuracy of the best estimator (testing dataset):  0.14516129032258066\n",
      "Selected metaheuristics: ['TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM']\n",
      "******* Feature select: LR20  Feature type: HG-F Classification model: gbr ******\n",
      "Accurecy of the best estimator (training dataset):  0.8589743589743589\n",
      "Accuracy Best score (validation) val. score :  0.20064754856614248\n",
      "Hamming loss: 0.15725806451612903\n",
      "Accuracy of the best estimator (testing dataset):  0.22580645161290322\n",
      "Selected metaheuristics: ['TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM']\n",
      "******* Feature select: LR30  Feature type: HG-F Classification model: gbr ******\n",
      "Accurecy of the best estimator (training dataset):  0.9401709401709402\n",
      "Accuracy Best score (validation) val. score :  0.21794634597594822\n",
      "Hamming loss: 0.1693548387096774\n",
      "Accuracy of the best estimator (testing dataset):  0.11290322580645161\n",
      "Selected metaheuristics: ['TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM']\n",
      "******* Feature select: LR40  Feature type: HG-F Classification model: gbr ******\n",
      "Accurecy of the best estimator (training dataset):  0.9658119658119658\n",
      "Accuracy Best score (validation) val. score :  0.22654949121184087\n",
      "Hamming loss: 0.16330645161290322\n",
      "Accuracy of the best estimator (testing dataset):  0.1774193548387097\n",
      "Selected metaheuristics: ['TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TSL-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM']\n",
      "******* Feature select: RF  Feature type: HG-F Classification model: gbr ******\n",
      "Accurecy of the best estimator (training dataset):  0.7863247863247863\n",
      "Accuracy Best score (validation) val. score :  0.21794634597594822\n",
      "Hamming loss: 0.16532258064516128\n",
      "Accuracy of the best estimator (testing dataset):  0.11290322580645161\n",
      "Selected metaheuristics: ['TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM']\n",
      "******* Feature select: PCA99  Feature type: HG-F Classification model: gbr ******\n",
      "Accurecy of the best estimator (training dataset):  1.0\n",
      "Accuracy Best score (validation) val. score :  0.261054579093432\n",
      "Hamming loss: 0.19556451612903225\n",
      "Accuracy of the best estimator (testing dataset):  0.0967741935483871\n",
      "Selected metaheuristics: ['TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TSL-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM']\n",
      "******* Feature select: PCA999  Feature type: HG-F Classification model: gbr ******\n",
      "Accurecy of the best estimator (training dataset):  0.9658119658119658\n",
      "Accuracy Best score (validation) val. score :  0.2310823311748381\n",
      "Hamming loss: 0.18951612903225806\n",
      "Accuracy of the best estimator (testing dataset):  0.0967741935483871\n",
      "Selected metaheuristics: ['TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM']\n",
      "******* Feature select: PCA9999  Feature type: HG-F Classification model: gbr ******\n",
      "Accurecy of the best estimator (training dataset):  1.0\n",
      "Accuracy Best score (validation) val. score :  0.20545790934320074\n",
      "Hamming loss: 0.21169354838709678\n",
      "Accuracy of the best estimator (testing dataset):  0.0967741935483871\n",
      "Selected metaheuristics: ['TSL-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM']\n",
      "******* Feature select: FS_S  Feature type: HG-F Classification model: gbr ******\n",
      "Accurecy of the best estimator (training dataset):  0.9914529914529915\n",
      "Accuracy Best score (validation) val. score :  0.2693802035152636\n",
      "Hamming loss: 0.15725806451612903\n",
      "Accuracy of the best estimator (testing dataset):  0.14516129032258066\n",
      "Selected metaheuristics: ['SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM']\n",
      "******* Feature select: FS_P  Feature type: HG-F Classification model: gbr ******\n",
      "Accurecy of the best estimator (training dataset):  0.9871794871794872\n",
      "Accuracy Best score (validation) val. score :  0.252358926919519\n",
      "Hamming loss: 0.16129032258064516\n",
      "Accuracy of the best estimator (testing dataset):  0.12903225806451613\n",
      "Selected metaheuristics: ['TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM']\n",
      "******* Feature select: FS_K  Feature type: HG-F Classification model: gbr ******\n",
      "Accurecy of the best estimator (training dataset):  0.9188034188034188\n",
      "Accuracy Best score (validation) val. score :  0.2607770582793709\n",
      "Hamming loss: 0.15524193548387097\n",
      "Accuracy of the best estimator (testing dataset):  0.16129032258064516\n",
      "Selected metaheuristics: ['TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM']\n",
      "classification_type rfr\n",
      "******* Feature select: all  Feature type: HG-F Classification model: rfr ******\n",
      "Accurecy of the best estimator (training dataset):  0.7478632478632479\n",
      "Accuracy Best score (validation) val. score :  0.18390379278445884\n",
      "Hamming loss: 0.1532258064516129\n",
      "Accuracy of the best estimator (testing dataset):  0.12903225806451613\n",
      "Selected metaheuristics: ['TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM']\n",
      "******* Feature select: LR10  Feature type: HG-F Classification model: rfr ******\n",
      "Accurecy of the best estimator (training dataset):  0.358974358974359\n",
      "Accuracy Best score (validation) val. score :  0.16651248843663274\n",
      "Hamming loss: 0.1532258064516129\n",
      "Accuracy of the best estimator (testing dataset):  0.11290322580645161\n",
      "Selected metaheuristics: ['TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM']\n",
      "******* Feature select: LR20  Feature type: HG-F Classification model: rfr ******\n",
      "Accurecy of the best estimator (training dataset):  0.5341880341880342\n",
      "Accuracy Best score (validation) val. score :  0.17511563367252544\n",
      "Hamming loss: 0.1350806451612903\n",
      "Accuracy of the best estimator (testing dataset):  0.12903225806451613\n",
      "Selected metaheuristics: ['TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM']\n",
      "******* Feature select: LR30  Feature type: HG-F Classification model: rfr ******\n",
      "Accurecy of the best estimator (training dataset):  0.6282051282051282\n",
      "Accuracy Best score (validation) val. score :  0.15411655874190563\n",
      "Hamming loss: 0.15524193548387097\n",
      "Accuracy of the best estimator (testing dataset):  0.06451612903225806\n",
      "Selected metaheuristics: ['TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM']\n",
      "******* Feature select: LR40  Feature type: HG-F Classification model: rfr ******\n",
      "Accurecy of the best estimator (training dataset):  0.5299145299145299\n",
      "Accuracy Best score (validation) val. score :  0.1750231267345051\n",
      "Hamming loss: 0.18548387096774194\n",
      "Accuracy of the best estimator (testing dataset):  0.0967741935483871\n",
      "Selected metaheuristics: ['TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM']\n",
      "******* Feature select: RF  Feature type: HG-F Classification model: rfr ******\n",
      "Accurecy of the best estimator (training dataset):  0.5427350427350427\n",
      "Accuracy Best score (validation) val. score :  0.19222941720629047\n",
      "Hamming loss: 0.14516129032258066\n",
      "Accuracy of the best estimator (testing dataset):  0.14516129032258066\n",
      "Selected metaheuristics: ['TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM']\n",
      "******* Feature select: PCA99  Feature type: HG-F Classification model: rfr ******\n",
      "Accurecy of the best estimator (training dataset):  0.6111111111111112\n",
      "Accuracy Best score (validation) val. score :  0.15818686401480114\n",
      "Hamming loss: 0.1774193548387097\n",
      "Accuracy of the best estimator (testing dataset):  0.12903225806451613\n",
      "Selected metaheuristics: ['TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM']\n",
      "******* Feature select: PCA999  Feature type: HG-F Classification model: rfr ******\n",
      "Accurecy of the best estimator (training dataset):  0.6752136752136753\n",
      "Accuracy Best score (validation) val. score :  0.15393154486586494\n",
      "Hamming loss: 0.17943548387096775\n",
      "Accuracy of the best estimator (testing dataset):  0.04838709677419355\n",
      "Selected metaheuristics: ['TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM']\n",
      "******* Feature select: PCA9999  Feature type: HG-F Classification model: rfr ******\n",
      "Accurecy of the best estimator (training dataset):  0.688034188034188\n",
      "Accuracy Best score (validation) val. score :  0.1368177613320999\n",
      "Hamming loss: 0.17338709677419356\n",
      "Accuracy of the best estimator (testing dataset):  0.06451612903225806\n",
      "Selected metaheuristics: ['TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM']\n",
      "******* Feature select: FS_S  Feature type: HG-F Classification model: rfr ******\n",
      "Accurecy of the best estimator (training dataset):  0.6452991452991453\n",
      "Accuracy Best score (validation) val. score :  0.1879740980573543\n",
      "Hamming loss: 0.1774193548387097\n",
      "Accuracy of the best estimator (testing dataset):  0.08064516129032258\n",
      "Selected metaheuristics: ['TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM']\n",
      "******* Feature select: FS_P  Feature type: HG-F Classification model: rfr ******\n",
      "Accurecy of the best estimator (training dataset):  0.7692307692307693\n",
      "Accuracy Best score (validation) val. score :  0.19685476410730804\n",
      "Hamming loss: 0.14717741935483872\n",
      "Accuracy of the best estimator (testing dataset):  0.0967741935483871\n",
      "Selected metaheuristics: ['TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM']\n",
      "******* Feature select: FS_K  Feature type: HG-F Classification model: rfr ******\n",
      "Accurecy of the best estimator (training dataset):  0.7094017094017094\n",
      "Accuracy Best score (validation) val. score :  0.19250693802035154\n",
      "Hamming loss: 0.13911290322580644\n",
      "Accuracy of the best estimator (testing dataset):  0.16129032258064516\n",
      "Selected metaheuristics: ['TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM']\n",
      "classification_type svr\n",
      "******* Feature select: all  Feature type: HG-F Classification model: svr ******\n",
      "Accurecy of the best estimator (training dataset):  0.9188034188034188\n",
      "Accuracy Best score (validation) val. score :  0.22701202590194267\n",
      "Hamming loss: 0.24596774193548387\n",
      "Accuracy of the best estimator (testing dataset):  0.08064516129032258\n",
      "Selected metaheuristics: ['TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TSL-Ei-LM', 'TS-Ei-LM', 'TSL-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TSL-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TSL-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TSL-Ei-LM', 'TS-Ei-LM']\n",
      "******* Feature select: LR10  Feature type: HG-F Classification model: svr ******\n",
      "Accurecy of the best estimator (training dataset):  0.8803418803418803\n",
      "Accuracy Best score (validation) val. score :  0.23506012950971322\n",
      "Hamming loss: 0.20161290322580644\n",
      "Accuracy of the best estimator (testing dataset):  0.22580645161290322\n",
      "Selected metaheuristics: ['TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TSL-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM']\n",
      "******* Feature select: LR20  Feature type: HG-F Classification model: svr ******\n",
      "Accurecy of the best estimator (training dataset):  0.9145299145299145\n",
      "Accuracy Best score (validation) val. score :  0.23506012950971322\n",
      "Hamming loss: 0.1814516129032258\n",
      "Accuracy of the best estimator (testing dataset):  0.14516129032258066\n",
      "Selected metaheuristics: ['TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TSL-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM']\n",
      "******* Feature select: LR30  Feature type: HG-F Classification model: svr ******\n",
      "Accurecy of the best estimator (training dataset):  0.9358974358974359\n",
      "Accuracy Best score (validation) val. score :  0.25652173913043474\n",
      "Hamming loss: 0.18346774193548387\n",
      "Accuracy of the best estimator (testing dataset):  0.20967741935483872\n",
      "Selected metaheuristics: ['TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TSL-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM']\n",
      "******* Feature select: LR40  Feature type: HG-F Classification model: svr ******\n",
      "Accurecy of the best estimator (training dataset):  0.9572649572649573\n",
      "Accuracy Best score (validation) val. score :  0.23931544865864937\n",
      "Hamming loss: 0.18346774193548387\n",
      "Accuracy of the best estimator (testing dataset):  0.20967741935483872\n",
      "Selected metaheuristics: ['TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TSL-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM']\n",
      "******* Feature select: RF  Feature type: HG-F Classification model: svr ******\n",
      "Accurecy of the best estimator (training dataset):  0.7948717948717948\n",
      "Accuracy Best score (validation) val. score :  0.235522664199815\n",
      "Hamming loss: 0.2056451612903226\n",
      "Accuracy of the best estimator (testing dataset):  0.1774193548387097\n",
      "Selected metaheuristics: ['TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'TSL-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TSL-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM']\n",
      "******* Feature select: PCA99  Feature type: HG-F Classification model: svr ******\n",
      "Accurecy of the best estimator (training dataset):  0.9444444444444444\n",
      "Accuracy Best score (validation) val. score :  0.28223866790009255\n",
      "Hamming loss: 0.16129032258064516\n",
      "Accuracy of the best estimator (testing dataset):  0.12903225806451613\n",
      "Selected metaheuristics: ['TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM']\n",
      "******* Feature select: PCA999  Feature type: HG-F Classification model: svr ******\n",
      "Accurecy of the best estimator (training dataset):  0.9957264957264957\n",
      "Accuracy Best score (validation) val. score :  0.261054579093432\n",
      "Hamming loss: 0.14919354838709678\n",
      "Accuracy of the best estimator (testing dataset):  0.04838709677419355\n",
      "Selected metaheuristics: ['TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM']\n",
      "******* Feature select: PCA9999  Feature type: HG-F Classification model: svr ******\n",
      "Accurecy of the best estimator (training dataset):  0.9102564102564102\n",
      "Accuracy Best score (validation) val. score :  0.2097132284921369\n",
      "Hamming loss: 0.3064516129032258\n",
      "Accuracy of the best estimator (testing dataset):  0.04838709677419355\n",
      "Selected metaheuristics: ['TS-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'TSL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TSL-Ei-LM', 'TSL-Ei-LM', 'TSL-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM']\n",
      "******* Feature select: FS_S  Feature type: HG-F Classification model: svr ******\n",
      "Accurecy of the best estimator (training dataset):  0.8076923076923077\n",
      "Accuracy Best score (validation) val. score :  0.26123959296947274\n",
      "Hamming loss: 0.2318548387096774\n",
      "Accuracy of the best estimator (testing dataset):  0.12903225806451613\n",
      "Selected metaheuristics: ['TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'SAL-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TSL-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TSL-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TSL-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TSL-Ei-LM', 'TS-Ei-LM']\n",
      "******* Feature select: FS_P  Feature type: HG-F Classification model: svr ******\n",
      "Accurecy of the best estimator (training dataset):  0.8846153846153846\n",
      "Accuracy Best score (validation) val. score :  0.2440333024976873\n",
      "Hamming loss: 0.24193548387096775\n",
      "Accuracy of the best estimator (testing dataset):  0.14516129032258066\n",
      "Selected metaheuristics: ['TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TSL-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TSL-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TSL-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TSL-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TSL-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TSL-Ei-LM', 'TS-Ei-LM']\n",
      "******* Feature select: FS_K  Feature type: HG-F Classification model: svr ******\n",
      "Accurecy of the best estimator (training dataset):  0.8846153846153846\n",
      "Accuracy Best score (validation) val. score :  0.2482886216466235\n",
      "Hamming loss: 0.23588709677419356\n",
      "Accuracy of the best estimator (testing dataset):  0.16129032258064516\n",
      "Selected metaheuristics: ['TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'SA-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TSL-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TSL-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM', 'TS-Ei-LM']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "classification_types = ['gbr','rfr','svr']\n",
    "#'ft_select=['LR10']\n",
    "\n",
    "classification_tuning(dir_path, ft_type, ft_select, classification_types, \n",
    "                  feature_path='../datasets/results/features/ianuarie2025-v2/',\n",
    "                  ranks_path='../datasets/results/ranks/runTime_1min_sa_ts_multilabel_filtered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
